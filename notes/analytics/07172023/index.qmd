---
title: Categorical Data Analysis
date: 07/17/2023
date-modified: 07/20/2023
---

Recall: categorical variables are data whose measurement scale is inherently categorical.

Two types: nominal and ordinal. Nominal has no logical ordering and ordianl has a logical ordering.

```{r}
library(AmesHousing)
library(tidyverse)
library(reticulate)

set.seed(123)
use_condaenv("blues_clues")
ames <- make_ordinal_ames()

ames <- ames %>%
    mutate(id = row_number())

train <- ames %>%
    sample_frac(0.7)
test <- anti_join(ames, train, by = "id")
```

```{r}
train <- train %>%
    mutate(Bonus = ifelse(Sale_Price > 175000, 1, 0))
```

# Examining Categorical Variables

By examining the distributions of categorical variables, you can

-   Determine the frequencies of data values
-   Recognize possible associations among variables

An association exists between two categorical variables if the dist. of one variable changes when the level of the other variable changes.

If no association exists, the distribution of the first variable is the same regardless of the level of the other variable.

## R Code

```{r}
table(train$Central_Air)

ggplot(train) +
    geom_bar(mapping = aes(x = Central_Air))

table(train$Bonus)

ggplot(train) +
    geom_bar(mapping = aes(x = Bonus))
```

## Python Code

```{python}
import numpy as np
import seaborn as sns
import pandas as pd

train = r.train

train["Bonus"] == np.where(train["Sale_Price"] > 175000, 1, 0)
train["Bonus"].value_counts()

ax = sns.countplot(x="Bonus", data=train, color="Blue")
ax.set(
    xlabel="Bonus Eligible", ylabel="Frequency", title="Bar Graph of Bonus Eligibility"
)
```

# Tests of Association

How much of a change in the distribution is required to believe there actually is a difference?

::: text-center
$H_0:$ There is no association

$H_a:$ There is an association
:::

## $\chi^2$ Distribution

Characteristics of the distribution:

-   Bounded below by 0
-   Right skewed
-   One set of degrees of freedom

$$
\chi_P^2 = \sum_{i=1}^{R}\sum_{j=1}^{C} \frac{(Obs_{i,j} - Exp_{i,j})^2}{Exp_{i,j}}
$$

-   Summing over all the rows and columns and checking the difference between the observed frequencies and expected frequencies
-   $d.f.$ equals (# Rows - 1)(# Columns - 1)

![](images/expected-cell-counts.png)

To calculate expected cell counts, we take the proportion of column values and multiply them by the row totals to get that entry's expected count.

## Pearson Chi-Square Test

Think of Pearson Chi-Square Test as the categorical counterpart to Pearson correlation test with continuous variables.

### R Code

```{r}
chisq.test(table(train$Central_Air, train$Bonus))
```

### Python Code

```{python}
from scipy.stats import chi2_contingency

chi2_contingency(pd.crosstab(train["Central_Air"], train["Bonus"]))
```

## Likelihood Ratio Test

$$
\chi_{LR}^2 = 2 \cdot \sum_{i=1}^{R}\sum_{j=1}^{C} Obs_{i,j} \cdot \log(\frac{Obs_{i,j}}{Exp_{i,j}})
$$

-   $d.f.$ equals (# Rows - 1)(# Columns - 1)

## Assumptions

Both of the tests have a sample size requirement. The sample size requirement is **80% or more of the cells** in the cross-tabulation table need **expected** count larger than 5.

## Fisher's Exact Test

When we do not meet the assumption we use the **Fisher's exact test** that calculates all possible permutations of data.

### R Code

```{r}
fisher.test(table(train$Central_Air, train$Bonus))
```

### Python Code

```{python}
from scipy.stats import fisher_exact

fisher_exact(pd.crosstab(train["Central_Air"], train["Bonus"]))
```

## Ordinal Compared to Nominal

Pearson and Likelihood Ratio tests can handle any type of categorical variable. However, ordinal variables provide extra information due to order mattering.

We can test for ordinal variables against other ordinal variables with **Mantel-Haenszel Chi-Square Test**. This test checks whether two ordinal variables have a linear relationship as compared to just a general one.

However, if you are comparing nominal to ordinal, you have to stick to a general test of association with Pearson's chi-square.

## Mantel-Haenszel Chi-Square Test

::: text-center
$H_0:$ There is no linear association

$H_a:$ There is a linear association
:::

$$
\chi_{MH}^2 = (n - 1)r^2
$$

-   $d.f.$ equals 1

Just because you fail to reject in Mantel-Haenszel it **does not** mean that there is no association. There is just no linear association

```{r}
library(vcdExtra)
CMHtest(table(train$Central_Air, train$Bonus))$table[1, ]
```

One thing to keep in mind about this function is that it orders the variables alphanumerically. For more than two categories in a variable you need to make sure that the values reflect the correct order (e.g. encoding strings as ordered numerics).

# Measures of Association

Chi-square tests can determine whether an association exists. They cannot measure the strength of the association.

Common measures of association:

-   Odds Ratios (Only for 2x2 tables)
-   Cramer's V (Any size table)
-   Spearman's Correlation (Ordinal vs. ordinal)

## Odds Ratios

<!-- TODO: Add example of odds ratio and explaining why interpretation reverse is also true -->

Odds ratios indicates how much more likely, with respect to odds, a certain event occurs in one group relative to its occurrence in another group.

**Odds** of an event occurring is not the same as probability.

$$
\text{Odds} = \frac{p}{1 - p}
$$

## Cramer's V

$$
V = \sqrt{\frac{(\frac{\chi_P^2}{n})}{\min(\text{Rows} - 1, \text{Columns} - 1)}}
$$

-   Bounded between 0 and 1 (-1 and 1 for 2x2) where closer to 0 the weaker the relationship

### R Code

```{r}
library(vcd)
assocstats(table(train$Central_Air, train$Bonus))
```

### Python Code

```{python}
from scipy.stats.contingency import association

association(pd.crosstab(train['Central_Air'], train['Bonus']), method = 'cramer')
```

## Spearman's Correlation

Measures the strength of association between two ordinal variables. Calculated with Pearson's correlation on the ranks of the observations instead of the values of the observations.

### R Code

```{r}
cor.test(
    x = as.numeric(ordered(train$Central_Air)),
    y = as.numeric(ordered(train$Bonus)),
    method = "spearman"
)
```

-   As you increase the number of `Central_Air` the number of `Bonus` increases

### Python Code

```{python}
from scipy.stats import spearmanr

spearmanr(train['Central_Air'], train['Bonus'])
```