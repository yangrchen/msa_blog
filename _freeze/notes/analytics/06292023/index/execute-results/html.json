{
  "hash": "0b6495d614a112041b346cd24939ac4d",
  "result": {
    "markdown": "---\ntitle: Introduction to ANOVA and Regression\ndate: 06/29/2023\n---\n\n\n# Linear Models\n\nThe population model for our linear model is written as:\n\n$$\ny = \\beta_0 + \\beta_1x_1 + \\cdots + \\beta_kx_k + \\varepsilon\n$$\n\n-   $\\varepsilon$ is the random error\n-   All the modeled signal is the rest of the equation which is called the **deterministic component**\n-   $x_1, \\cdots, x_k$ are the explanatory variables\n-   $y$ is the response variable\n\nTypically linear models are used in an explanatory model fashion--we are trying to answer how our explanatory variables are related to our response. We are not predicting the response.\n\n## Honest Model Assessment\n\nBefore you look for any relationships, you should split into **training**, **validation** and **test** samples.\n\nDifferent rules of thumb for splits:\n\n-   Lots of data? 50-40-10 split\n-   Not so much data? 70-20-10 split\n-   Not enough data? Use Cross-Validation\n\n### The Overfitting Problem\n\nModels will capture nuances of the data on which they're built (training data)\n\nWhen these \"patterns\" do not hold up in validation or test, the model performance suffers. We call this **overfitting**.\n\n![Overfitting Example](images/overfitting.png)\n\n## Train-Test Split in R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(AmesHousing)\n\names <- make_ordinal_ames()\nset.seed(123)\names <- ames |> mutate(id = row_number())\ntrain <- ames |> sample_frac(0.7)\ntest <- anti_join(ames, train, by = \"id\")\n\ndim(train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2051   82\n```\n:::\n\n```{.r .cell-code}\ndim(test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 879  82\n```\n:::\n:::\n\n\n# Bivariate Exploratory Data Analysis\n\nAn **association** is the expected value of one variable changes at different levels of the other variable.\n\nA **linear association** between two continuous can be inferred when the general shape of a scatter plot is similar to a straight line.\n\nOne way to see associations with a continuous variable across our categorical variable is by using side-by-side boxplots or overlaid histograms:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(train, aes(y = Sale_Price / 1000, x = Exter_Qual, fill = Exter_Qual)) +\n    geom_boxplot() +\n    labs(y = \"Sales Price (Thousands $)\", x = \"Exterior Quality Category\") +\n    stat_summary(fun = mean, geom = \"point\", shape = 20, size = 5, color = \"red\", fill = \"red\") +\n    scale_fill_brewer(palette = \"Blues\") +\n    coord_flip()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/boxplots-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(ames, aes(x = Sale_Price / 1000, fill = Exter_Qual)) +\n    geom_density(alpha = 0.2, position = \"identity\") +\n    labs(x = \"Sales Price (Thousands $)\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/overlaid-density-1.png){width=672}\n:::\n:::\n\n\n-   In the density plot, variance is different between groups and the Excellent quality seems to have a higher overall mean\n\n# One-Way ANOVA\n\nOne-Way ANOVA is a test of relationship between categorical input and quantitative response.\n\nOne-Way refers to only one factor (e.g. a group of quality ratings).\n\nWe are comparing $k$ levels of our predictor variable and seeing if there are any statistically significant difference in their mean response.\n\n::: {.text-center}\n$H_0: F_1 = F_2 = F_3 = F_4$\n\n$H_a:$ Atleast one mean is different\n:::\n\nIn the ANOVA model, instead of using *one-hot encoding* for our variables, we use reference coding where we drop one of the levels. The level dropped will be the **reference level**.\n\nLevel | $x_a$ | $x_b$\n--- | --- | ---\nA | 1 | 0\nB | 0 | 1\nC | 0 | 0\n\n$$\ny = \\beta_0 + \\beta_Ax_A + \\beta_Bx_B + \\varepsilon\n$$\n\n-   $\\beta_A$ is the difference between mean response in level A vs. level C\n-   There are three unique values possible for the predicted value--one for each level\n\n## Assumptions for ANOVA\n\n-   Observations are independent\n-   Each group is normally distributed\n    -   Or the *residuals* of the ANOVA model are normally distributed\n-   All groups have equal variances (homeskedasticity)\n    -   If true, use \"pooled\" variance\n    -   If false, use Welch's ANOVA\n\n### Assessing ANOVA Assumptions\n\n-   Good data collection designs help the independence assumption\n-   Informal plots (QQ-Plots) or formal tests can verify the normally distributed assumption\n-   Formal test of equal variances or viewing residual plot to assess homoskedasticity\n\n## ANOVA Hypothesis Test in R\n\n$H_0$ is the means of each level of `Exter-Qual` are equal. $H_a$ is at least one mean is different.\n\n\n::: {.cell}\n\n```{.r .cell-code}\names_lm <- lm(Sale_Price ~ Exter_Qual, data = train)\nanova(ames_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: Sale_Price\n             Df     Sum Sq    Mean Sq F value    Pr(>F)    \nExter_Qual    3 6.6913e+12 2.2304e+12  701.83 < 2.2e-16 ***\nResiduals  2047 6.5054e+12 3.1780e+09                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n-   There appears to be a significant difference in mean sales price between the different levels of exterior quality.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain$pred_anova <- predict(ames_lm, data = train)\ntrain$resid_anova <- resid(ames_lm, data = train)\n\nmodel_output = train |> select(Sale_Price, pred_anova, resid_anova)\n```\n:::\n\n\nAnd then to test assumptions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(2, 2))\nplot(ames_lm)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/testing-assumptions-1-1.png){width=672}\n:::\n:::\n\n\nTo formally test our variance, we have **Levene's Test** which **requires normality of underlying data** and **Fligner's Test** which does **not require normality**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: carData\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'car'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:dplyr':\n\n    recode\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    some\n```\n:::\n\n```{.r .cell-code}\nleveneTest(Sale_Price ~ Exter_Qual, data = train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLevene's Test for Homogeneity of Variance (center = median)\n        Df F value    Pr(>F)    \ngroup    3  76.879 < 2.2e-16 ***\n      2047                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nfligner.test(Sale_Price ~ Exter_Qual, data = train)$p.value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.873388e-44\n```\n:::\n:::\n\n\n# Welch's ANOVA\n\nWe use Welch's ANOVA when the equal variances assumption fails. Similar to the two-sample t-test with unequal variances.\n\n\n::: {.cell}\n\n```{.r .cell-code}\noneway.test(Sale_Price ~ Exter_Qual, data = train, var.equal = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne-way analysis of means (not assuming equal variances)\n\ndata:  Sale_Price and Exter_Qual\nF = 431.82, num df = 3.00, denom df = 102.11, p-value < 2.2e-16\n```\n:::\n:::\n\n\n# Kruskal-Wallis\n\nKruskal-Wallis is a nonparametric test for more than two groups:\n\nConditions | Interpretation of Significant Kruskal-Wallis Test\n:-- | :--\nGroup distributions are identical in shape, variance, and symmetric | Difference in means\nGroup distributions are identical in shape, variance, but not symmetric | Difference in medians\nElse | Difference in location (distributional dominance)\n\n## Kruskal-Wallis ANOVA in R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkruskal.test(Sale_Price ~ Exter_Qual, data = train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tKruskal-Wallis rank sum test\n\ndata:  Sale_Price by Exter_Qual\nKruskal-Wallis chi-squared = 975.98, df = 3, p-value < 2.2e-16\n```\n:::\n:::\n\n\n# ANOVA Analysis Plan Summmary\n\n$H_0:$ All means are equal.\n\n$H_a:$ At least one mean is different\n\n1.  Produce descriptive statistics\n2.  Verify assumptions\n    1.  Independence\n    2.  Normality\n    3.  Equal variance for all groups\n3.  Examine the p-value for overall F-test in the ANOVA table. If p-value $< \\alpha$, reject $H_0$\n\n# ANOVA Post-Hoc Tests\n\nWhile the ANOVA F-Test tells us if at least one group mean is different, we need to understand which groups are different. \n\nWe will compare the groups pairwise to determine if they are different.\n\n\n```{mermaid}\nflowchart LR\n    A[Control Experimentwise Error Rate] --> B[All Pairwise Comparisons]\n    A --> C[Comparisons to a Control]\n    B --> D[Tukey]\n    C --> E[Dunnett]\n```\n\n\n## Tukey's Honest Significant Difference\n\nAppropriate for making *all* pairwise comparisons between groups.\n\nExperimentwise error rate is equal to $\\alpha$ when *all* pairwise comparisons are made and less than $\\alpha$ otherwise.\n\n\n::: {.cell}\n\n```{.r .cell-code}\names_aov <- aov(Sale_Price ~ Exter_Qual, data = train)\ntukey.ames <- TukeyHSD(ames_aov)\nprint(tukey.ames)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Sale_Price ~ Exter_Qual, data = train)\n\n$Exter_Qual\n                       diff       lwr       upr p adj\nTypical-Fair       57887.91  30194.31  85581.52 5e-07\nGood-Fair         144690.25 116739.87 172640.63 0e+00\nExcellent-Fair    291684.79 259752.41 323617.16 0e+00\nGood-Typical       86802.34  79910.03  93694.64 0e+00\nExcellent-Typical 233796.87 216886.62 250707.12 0e+00\nExcellent-Good    146994.54 129666.98 164322.10 0e+00\n```\n:::\n:::\n\n\n-   Conclusion is that all pairs are significantly different\n\n## Dunnett's Test for Control Comparison\n\nIf you're not making all pairwise comparisons, Tukey's is overly conservative. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DescTools)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'DescTools'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:car':\n\n    Recode\n```\n:::\n\n```{.r .cell-code}\nDunnettTest(x = train$Sale_Price, g = train$Exter_Qual, control = \"Typical\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  Dunnett's test for comparing several treatments with a control :  \n    95% family-wise confidence level\n\n$Typical\n                       diff    lwr.ci    upr.ci    pval    \nFair-Typical      -57887.91 -83628.55 -32147.28 2.6e-07 ***\nGood-Typical       86802.34  80396.08  93208.59 < 2e-16 ***\nExcellent-Typical 233796.87 218079.15 249514.60 < 2e-16 ***\n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}