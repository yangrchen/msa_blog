{
  "hash": "bc76aed9ae5c96a4192efe90cfa139d9",
  "result": {
    "markdown": "---\ntitle: Stationarity\ndate: 09/05/2023\ncategories:\n    -   time series\n---\n\n\n# ARMA\n\nARMA stands for **AutoRegressive Moving Averages**. AR and MA terms are used to model the dependency structure in the data.\n\nARMA models are based on statistical methods (will assume a distribution). The best model will be found by an iterative process.\n\n## Signal\n\nModels can have singal due to a seasonal pattern or due to trend. They can also have signal due to \"correlation structure\" which can be in the form of Autoregressive and moving averages.\n\nIn order to model the dependency in the data, we need to take care of the **functional form** and any random walks first.\n\n![ARIMA Modeling Flowchart](images/arima-modeling.png)\n\n# No Season and No Trend (Starting Simple)\n\n## Stationarity\n\nTo model AR and MA terms, we need to have stationarity first. \n\n**Weak stationarity** is where there is no predictable pattern, we have constant variance and converges to a constant mean in the \"long run.\"\n\n## Random Walk\n\n$$\nY_t = Y_{t-1} + \\epsilon_t\n$$\n\nThe current observation only depends on the previous observation and some error. There is no correlation/dependency throughout the entire series.\n\nIf we have a random walk, we try to take differences:\n\n$$\nY_t - Y_{t-1} = \\epsilon_t\n$$\n\nHow do we know if we have a random walk or not?\n\n# Unit Root Testing\n\n## Augmented Dickey-Fuller Unit Root Test\n\nProvides a statistical test for detecting a random walk.\n\n::: {.text-center}\n$H_0:$ Differencing is required (non-stationary data; random walk)\n\n$H_a:$ Stationary mean about zero (if the series is centered about 0); Stationary mean otherwise\n:::\n\nCalled \"unit root test\" because it looks to see if the equation with differenced series has a unit root ($\\phi = 1$)\n\n$$\nY_t = \\phi Y_{t-1} + \\epsilon_t\n$$\n\nUnit roots can exist in models with more than one lag of Y.\n\n-   Lag 0 tests are equivalent to what we have prev. seen\n-   Lag 1 tests consider models with differenced series of Y and first lag of differenced series\n-   Lag 2 tests consider models with differenced series of Y and first and second lag of differenced series\n\nWhen testing for stationarity, you should go to at least a lag 2 while looking at **ALL** of the tests.\n\n::: {.panel-tabset}\n# R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(aTSA)\n\nfile_dir <- \"https://raw.githubusercontent.com/sjsimmo2/TimeSeries/master/\"\nquotes <- read.csv(paste(file_dir, \"fpp_insurance.csv\", sep = \"\"))\nquotes_ts <- ts(quotes$Quotes, start = 2002, frequency = 12)\n\nadf.test(quotes_ts)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAugmented Dickey-Fuller Test \nalternative: stationary \n \nType 1: no drift no trend \n     lag     ADF p.value\n[1,]   0 -0.3061   0.550\n[2,]   1 -0.5980   0.458\n[3,]   2 -0.0632   0.620\n[4,]   3 -0.0950   0.611\nType 2: with drift no trend \n     lag   ADF p.value\n[1,]   0 -2.66  0.0939\n[2,]   1 -3.42  0.0192\n[3,]   2 -2.45  0.1608\n[4,]   3 -2.36  0.1943\nType 3: with drift and trend \n     lag   ADF p.value\n[1,]   0 -2.62  0.3212\n[2,]   1 -3.36  0.0772\n[3,]   2 -2.41  0.4012\n[4,]   3 -2.29  0.4463\n---- \nNote: in fact, p.value = 0.01 means p.value <= 0.01 \n```\n:::\n:::\n\n\nWe look at the type 2 test since our series does not seem to be centered around 0. Based on our p-values we believe that \n\n# Python\n:::\n\n## ADF Test Process\n\n1.  First decide if you are doing zero mean or single mean test\n2.  Decide how many lags you would like to look at (common in industry to do 3 - 5 lags)\n3.  See if you reject **ANY** of these hypotheses\n4.  If you reject all hypotheses then you are ready to start modeling AR and MA terms\n5.  If you fail to reject at least one, you have a random walk and will take differences and start modeling AR and MA terms on the difference.\n\n## Over-differencing\n\nWhen you difference and you don't need to difference or take too many differences you create **over-differencing**.\n\nOver-differencing introduces more dependence on error terms in the model. There are more moving average terms that don't really exist.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}