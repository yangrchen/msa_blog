{
  "hash": "36f2ae8fe62ffaf9e2f6b831090d77df",
  "result": {
    "markdown": "---\ntitle: Dynamic Regression Models\ndate: 10/06/2023\ndate-modified: 10/10/2023\n---\n\n\n# Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tseries)\nlibrary(forecast)\nlibrary(aTSA)\nlibrary(tidyverse)\n```\n:::\n\n\n# Regression with ARIMA Errors\n\nExternal information can make better forecasts as well as potentially account for trend and seasonality.\n\nWe can incorporate predictor variables through a regression:\n\n$$\nY_t = \\beta_0 + \\beta_1X_{1,t} + \\cdots + \\beta_kX_{k,t} + Z_t\n$$\n\nWe model the $Z_t$ error term with an ARIMA model. A regression with ARIMA(1, 0, 1) errors would have:\n\n$$\nZ_t = \\omega + \\phi_1Z_{t-1} + e_t + \\theta_1e_{t-1}\n$$\n\n-   $e_t$ represents the white noise\n\n# Intervention Variables\n\nAn **intervention variable** is an indicator variable that contains discrete values that flag the occurrence of an event affecting the response series:\n\n-   Valentine's Day while selling chocolate\n-   A special sales promotion raises sales\n\n## Use Cases\n\n-   Model and forecast the response series\n-   Analyze the impact of the intervention\n\n## Types\n\n1.  Point / Pulse Interventions\n2.  Step Interventions\n3.  Ramp Interventions\n\n## Point Interventions\n\n![Point Interventions](images/pulse-intervention.png){#fig-point-intervention}\n\nIn @fig-point-intervention we see a special sales promotion that occurs suddenly. How do we account for this? All we have to do is create a binary variable that indicates the intervention.\n\nWe model the impact through a coefficient in the model:\n\n$$\nY_t = \\beta_0 + \\beta_1I_t + Z_t\n$$\n\n## Step Interventions\n\nThe idea of a step intervention is that we make a permanent step in our data and the change continues on from that time on. \n\n![Step Inteventions](images/step-intervention.png){#fig-step-intervention}\n\nAny time period after the step is indicated by a 1 in the intervention variable. If we had multiple step events then we would have a variable for each one.\n\nWith intervention events, you need to have data prior to the intervention and after the intervention. Otherwise, you have no notion of change between the periods.\n\n$$\nY_t = \\beta_0 + \\beta_1I_t + Z_t\n$$\n\n## Ramp Intervention\n\nIn a ramp intervention, we introduce a new trend line into the model. Some event changes the overall trend following the event. Another way to think of this is that the angle of the time series changes.\n\n![Ramp Intervention](images/ramp-intervention.png){#fig-ramp-intervention}\n\n$$\nY_t = \\beta_0 + \\beta_1I_t + Z_t\n$$\n\n-   $\\beta_1$ is the impact measured by model coefficient (new slope)\n\n# Implementing in Software\n\n\n::: {.cell}\n\n```{.r .cell-code}\nUSAirlines <- read.csv(\"https://raw.githubusercontent.com/sjsimmo2/TimeSeries/master/usairlines.csv\")\npassenger <- ts(USAirlines$Passengers, start = 1990, frequency = 12)\ntrain <- subset(passenger, end = length(passenger) - 12)\ntest <- subset(passenger, start = length(passenger) - 11)\nsep11 <- rep(0, 207)\nsep11[141] <- 1\n\nfull_arima <- auto.arima(train, seasonal = TRUE, xreg = sep11, method = \"ML\")\nsummary(full_arima)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSeries: train \nRegression with ARIMA(2,0,0)(0,1,1)[12] errors \n\nCoefficients:\n         ar1     ar2     sma1     drift        xreg\n      0.7119  0.1369  -0.6626  125.6161  -11539.935\ns.e.  0.0709  0.0713   0.0579   22.6471    1150.961\n\nsigma^2 = 2442761:  log likelihood = -1712.17\nAIC=3436.35   AICc=3436.8   BIC=3455.99\n\nTraining set error measures:\n                    ME    RMSE      MAE        MPE     MAPE      MASE\nTraining set -3.349235 1497.38 1030.214 -0.1299989 2.123044 0.3826493\n                    ACF1\nTraining set 0.008315115\n```\n:::\n:::\n\n\n# Predictor Variables\n\nWe can include explanatory variables beyond just the response variable. Models that include external variables have different names--ARIMAX, dynamic regression models, transfer functions, etc.\n\nOften there are **lagged impacts** as well as immediate impacts--past values of explanatory variables can be important.\n\n## Determining Lags\n\nMultiple ways to evaluate how many lags of a predictor variable:\n\n-   Cross-correlation functions and pre-whitening of series.\n    -   Time consuming\n    -   Requires modeling of the predictor variables\n    -   Best used for small number of predictors\n-   Evaluate many different lag combinations models with AIC/BIC on validation set.\n    -   Essentially trial and error\n    -   Handles many variables much easier\n    -   Similar in accuracy of the \"elegant\" first approach\n\n## Adding Lags to Model\n\nThe idea here is that we are manually creating lags by shifting over the effect of the point intervention by 1 each time we add a new lag. The actual number is based on data context--what do you want to include based on events going on in the data?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsep11 <- rep(0, 207)\nsep11[141] <- 1\n\nsep11_L1 <- rep(0, 207)\nsep11_L1[142] <- 1\n\nsep11_L2 <- rep(0, 207)\nsep11_L2[143] <- 1\n\nsep11_L3 <- rep(0, 207)\nsep11_L3[144] <- 1\n\nsep11_L4 <- rep(0, 207)\nsep11_L4[145] <- 1\n\nsep11_L5 <- rep(0, 207)\nsep11_L5[146] <- 1\n\nsep11_L6 <- rep(0, 207)\nsep11_L6[147] <- 1\n\nanniv <- rep(0, 207)\nanniv[153] <- 1\n\nfull_arima <- auto.arima(train, seasonal = TRUE, xreg = cbind(sep11, sep11_L1, sep11_L2, sep11_L3, sep11_L4, sep11_L5, sep11_L6, anniv), method = \"ML\")\nsummary(full_arima)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSeries: train \nRegression with ARIMA(2,0,0)(1,1,1)[12] errors \n\nCoefficients:\n         ar1     ar2    sar1    sma1     drift       sep11    sep11_L1\n      0.6298  0.2207  0.1926  -0.696  124.7648  -17400.506  -12116.992\ns.e.  0.0714  0.0726  0.1143   0.081   21.1663    1162.397    1271.319\n       sep11_L2   sep11_L3   sep11_L4   sep11_L5   sep11_L6       anniv\n      -8076.851  -7671.385  -4345.788  -2172.452  -751.2682  -2306.2188\ns.e.   1387.184   1427.370   1403.915   1271.268  1105.3293    998.2212\n\nsigma^2 = 1736410:  log likelihood = -1673.71\nAIC=3375.42   AICc=3377.75   BIC=3421.24\n\nTraining set error measures:\n                   ME     RMSE      MAE         MPE     MAPE      MASE\nTraining set 1.041491 1235.597 944.9504 -0.08208786 1.937629 0.3509802\n                    ACF1\nTraining set 0.007658679\n```\n:::\n:::\n\n\nWhen checking residuals, be mindful of how many observations are in your data. The bars are representing **95% confidence intervals**. These may not be as informative for large data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(full_arima)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/checking-residuals-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tLjung-Box test\n\ndata:  Residuals from Regression with ARIMA(2,0,0)(1,1,1)[12] errors\nQ* = 16.049, df = 20, p-value = 0.7136\n\nModel df: 4.   Total lags used: 24\n```\n:::\n:::\n\n\n# Forecasting\n\nForecasting in time series with external variables has unique issues. What are the future values of the external variables? You need to research future estimates to pull this off.\n\n-   Known future values (interventions)\n-   External estimates of future values\n-   Need to forecast future values ourselves\n\nIn our case, we will say that the influence of these variables is removed (0) in the future:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsep11 <- rep(0, 12)\nsep11_L1 <- rep(0, 12)\nsep11_L2 <- rep(0, 12)\nsep11_L3 <- rep(0, 12)\nsep11_L4 <- rep(0, 12)\nsep11_L5 <- rep(0, 12)\nsep11_L6 <- rep(0, 12)\nanniv <- rep(0, 12)\n\nfull_arima_error <- test - forecast::forecast(full_arima, xreg = cbind(sep11, sep11_L1, sep11_L2, sep11_L3, sep11_L4, sep11_L5, sep11_L6, anniv), h = 12)$mean\n\nfull_arima_MAE <- mean(abs(full_arima_error))\nfull_arima_MAPE <- mean(abs(full_arima_error) / abs(test)) * 100.0\nsprintf(\"MAPE: %.3f\", full_arima_MAPE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MAPE: 1.800\"\n```\n:::\n\n```{.r .cell-code}\nsprintf(\"MAE: %.3f\", full_arima_MAE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MAE: 1180.971\"\n```\n:::\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}