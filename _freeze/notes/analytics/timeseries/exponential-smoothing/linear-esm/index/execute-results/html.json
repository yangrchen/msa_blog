{
  "hash": "92e9b3337b1ea0210cb1e9330be07452",
  "result": {
    "markdown": "---\ntitle: Linear Trend for Exponential Smoothing\ndate: 08/31/2023\ndate-modified: 09/17/2023\n---\n\n\n# Setup {.unnumbered}\n\n:::{.panel-tabset group=\"language\"}\n# R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tseries)\nlibrary(forecast)\nlibrary(tidyverse)\nlibrary(aTSA)\nlibrary(reticulate)\n\nuse_condaenv(\"msa\")\n\nsteel <- read.csv(\"https://raw.githubusercontent.com/sjsimmo2/TimeSeries/master/steel.csv\")\nus_airlines <- read.csv(\"https://raw.githubusercontent.com/sjsimmo2/TimeSeries/master/usairlines.csv\")\n\nsteel_ts <- ts(steel$steelshp, start = 1984, frequency = 12)\nusair_ts <- ts(us_airlines$Passengers, start = 1990, frequency = 12)\n```\n:::\n\n\n# Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.api import Holt\n\nsteel = r.steel\ndf = pd.date_range(\"1/1/1984\", \"12/1/1991\", freq=\"MS\")\nsteel.set_index(pd.to_datetime(df), inplace=True)\n\nus_airlines = r.us_airlines\ndf = pd.date_range(start='1/1/1990', end='3/1/2008', freq='MS')\nus_airlines.set_index(pd.to_datetime(df), inplace=True)\n```\n:::\n\n\n:::\n\n# Linear Trend for Exponential Smoothing\n\nSingle Exponential Smoothing models can't adequately handle data that is trending up or down.\n\nMultiple ways to incorporate a trend in the ESM:\n\n-   Linear / Holt Exponential Smoothing\n-   Damped Trend Exponential Smoothing\n\n## Linear/Holt Exponential Smoothing\n\nA linear ESM can only handle linear trends. Any trend that is more complicated (e.g. quadratic) cannot be captured effectively.\n\n$$\n\\begin{align*}\n\\hat{Y}_{t + h} &= L_t + hT_t \\\\\nL_t &= \\theta Y_t + (1 - \\theta)(L_{t - 1} + T_{t - 1}) \\\\\nT_t &= \\gamma(L_t - L_{t - 1}) + (1 - \\gamma)T_{t - 1}\n\\end{align*}\n$$\n\n-   $h$ is how many time points ahead. Controls how far along the trend we are.\n-   $L_t$, our level component, contains the previous level information plus the previous trend information\n\nAdding a component means we add a new smoothing parameter, $\\gamma$. $\\gamma$ controls how much emphasis we put on either the most recent trend or the average historical trend. Essentially, each component (level and trend) is doing the exact same thing.\n\n## Damped Trend Exponential Smoothing\n\nWe might believe our trend tapers off eventually. We can *dampen* our trend using the **damped trend exponential smoothing model**.\n\nWe have a new dampening parameter incorporated into our model, $\\phi$.\n\n$$\n\\begin{align*}\n\\hat{Y}_{t+h} &= L_t + \\sum_{i=1}^{h} \\phi^i T_t \\\\\nL_t &= \\theta Y_t + (1 - \\theta)(L_{t-1} + \\phi T_{t-1}) \\\\\nT_t &= \\gamma(L_t - L_{t-1}) + (1 - \\gamma)\\phi T_{t-1}\n\\end{align*}\n$$\n\n-   $0 < \\phi < 1$\n\n::: {.panel-tabset group=\"language\"}\n# R\n\nFor regular Holt, we use `holt`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nles_steel <- holt(steel_ts, initial = \"optimal\", h = 24)\nsummary(les_steel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nForecast method: Holt's method\n\nModel Information:\nHolt's method \n\nCall:\n holt(y = steel_ts, h = 24, initial = \"optimal\") \n\n  Smoothing parameters:\n    alpha = 0.4329 \n    beta  = 1e-04 \n\n  Initial states:\n    l = 6678.9989 \n    b = -0.0651 \n\n  sigma:  471.4322\n\n     AIC     AICc      BIC \n1626.001 1626.667 1638.822 \n\nError measures:\n                    ME     RMSE      MAE        MPE     MAPE      MASE\nTraining set -4.167318 461.5062 369.9177 -0.4760441 5.818476 0.8423858\n                    ACF1\nTraining set -0.03556298\n\nForecasts:\n         Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95\nJan 1992       6495.463 5891.298 7099.627 5571.472 7419.453\nFeb 1992       6495.357 5836.979 7153.736 5488.455 7502.260\nMar 1992       6495.252 5786.775 7203.730 5411.729 7578.775\nApr 1992       6495.147 5739.865 7250.429 5340.043 7650.251\nMay 1992       6495.042 5695.672 7294.412 5272.511 7717.573\nJun 1992       6494.937 5653.768 7336.106 5208.479 7781.395\nJul 1992       6494.832 5613.826 7375.838 5147.450 7842.214\nAug 1992       6494.727 5575.592 7413.861 5089.032 7900.421\nSep 1992       6494.622 5538.862 7450.381 5032.914 7956.330\nOct 1992       6494.516 5503.468 7485.565 4978.839 8010.194\nNov 1992       6494.411 5469.273 7519.549 4926.598 8062.225\nDec 1992       6494.306 5436.161 7552.452 4876.013 8112.600\nJan 1993       6494.201 5404.033 7584.369 4826.933 8161.470\nFeb 1993       6494.096 5372.805 7615.387 4779.229 8208.963\nMar 1993       6493.991 5342.404 7645.578 4732.791 8255.191\nApr 1993       6493.886 5312.767 7675.005 4687.520 8300.252\nMay 1993       6493.781 5283.837 7703.725 4643.331 8344.230\nJun 1993       6493.675 5255.565 7731.786 4600.149 8387.202\nJul 1993       6493.570 5227.907 7759.234 4557.905 8429.235\nAug 1993       6493.465 5200.824 7786.106 4516.541 8470.389\nSep 1993       6493.360 5174.281 7812.439 4476.003 8510.718\nOct 1993       6493.255 5148.246 7838.264 4436.241 8550.269\nNov 1993       6493.150 5122.689 7863.611 4397.211 8589.089\nDec 1993       6493.045 5097.585 7888.504 4358.874 8627.216\n```\n:::\n:::\n\n\nWe can also do a damped trend by setting `damped = TRUE`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nldes_steel <- holt(steel_ts, initial = \"optimal\", h = 24, damped = TRUE)\nsummary(ldes_steel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nForecast method: Damped Holt's method\n\nModel Information:\nDamped Holt's method \n\nCall:\n holt(y = steel_ts, h = 24, damped = TRUE, initial = \"optimal\") \n\n  Smoothing parameters:\n    alpha = 0.4202 \n    beta  = 1e-04 \n    phi   = 0.9083 \n\n  Initial states:\n    l = 6692.5352 \n    b = -54.4181 \n\n  sigma:  472.702\n\n     AIC     AICc      BIC \n1627.468 1628.412 1642.854 \n\nError measures:\n                   ME     RMSE     MAE        MPE     MAPE     MASE        ACF1\nTraining set 8.669068 460.2275 367.178 -0.2689588 5.765085 0.836147 -0.02936686\n\nForecasts:\n         Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95\nJan 1992       6504.538 5898.746 7110.330 5578.059 7431.017\nFeb 1992       6504.482 5847.350 7161.614 5499.485 7509.479\nMar 1992       6504.432 5799.671 7209.192 5426.594 7582.269\nApr 1992       6504.386 5755.003 7253.768 5358.304 7650.467\nMay 1992       6504.344 5712.838 7295.850 5293.839 7714.849\nJun 1992       6504.306 5672.796 7335.817 5232.621 7775.992\nJul 1992       6504.272 5634.585 7373.958 5174.201 7834.342\nAug 1992       6504.241 5597.976 7410.505 5118.229 7890.252\nSep 1992       6504.212 5562.783 7445.642 5064.420 7944.005\nOct 1992       6504.187 5528.852 7479.521 5012.541 7995.832\nNov 1992       6504.163 5496.057 7512.269 4962.398 8045.928\nDec 1992       6504.142 5464.292 7543.992 4913.829 8094.455\nJan 1993       6504.123 5433.465 7574.780 4866.693 8141.552\nFeb 1993       6504.105 5403.498 7604.712 4820.871 8187.339\nMar 1993       6504.089 5374.322 7633.856 4776.260 8231.919\nApr 1993       6504.075 5345.879 7662.271 4732.767 8275.383\nMay 1993       6504.062 5318.115 7690.008 4690.313 8317.810\nJun 1993       6504.050 5290.985 7717.114 4648.827 8359.272\nJul 1993       6504.039 5264.447 7743.631 4608.247 8399.831\nAug 1993       6504.029 5238.464 7769.594 4568.514 8439.544\nSep 1993       6504.020 5213.002 7795.038 4529.578 8478.462\nOct 1993       6504.012 5188.032 7819.992 4491.394 8516.630\nNov 1993       6504.005 5163.526 7844.483 4453.919 8554.090\nDec 1993       6503.998 5139.459 7868.537 4417.116 8590.880\n```\n:::\n:::\n\n\nKeep in mind that in both of these outputs, the parameter weights are not telling us whether we have a trend. All they are telling us how much weight is being put on the most recent information vs. how much is put on the average model.\n\n# Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfit = Holt(steel[\"steelshp\"]).fit()\nfit.summary()\n```\n\n::: {.cell-output-display}\n```{=html}\n<table class=\"simpletable\">\n<caption>Holt Model Results</caption>\n<tr>\n  <th>Dep. Variable:</th>    <td>steelshp</td> <th>  No. Observations:  </th>        <td>96</td>       \n</tr>\n<tr>\n  <th>Model:</th>              <td>Holt</td>   <th>  SSE                </th>   <td>22317588.149</td>  \n</tr>\n<tr>\n  <th>Optimized:</th>          <td>True</td>   <th>  AIC                </th>     <td>1194.228</td>    \n</tr>\n<tr>\n  <th>Trend:</th>            <td>Additive</td> <th>  BIC                </th>     <td>1204.485</td>    \n</tr>\n<tr>\n  <th>Seasonal:</th>           <td>None</td>   <th>  AICC               </th>     <td>1195.171</td>    \n</tr>\n<tr>\n  <th>Seasonal Periods:</th>   <td>None</td>   <th>  Date:              </th> <td>Sun, 17 Sep 2023</td>\n</tr>\n<tr>\n  <th>Box-Cox:</th>            <td>False</td>  <th>  Time:              </th>     <td>22:40:36</td>    \n</tr>\n<tr>\n  <th>Box-Cox Coeff.:</th>     <td>None</td>   <th>                     </th>         <td> </td>       \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n         <td></td>                 <th>coeff</th>                <th>code</th>               <th>optimized</th>     \n</tr>\n<tr>\n  <th>smoothing_level</th> <td>           0.5454469</td> <td>               alpha</td> <td>                True</td>\n</tr>\n<tr>\n  <th>smoothing_trend</th> <td>           0.0545996</td> <td>                beta</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_level</th>   <td>           5980.0000</td> <td>                 l.0</td> <td>               False</td>\n</tr>\n<tr>\n  <th>initial_trend</th>   <td>           170.00000</td> <td>                 b.0</td> <td>               False</td>\n</tr>\n</table>\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nfit.forecast(24)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1992-01-01    6394.260299\n1992-02-01    6375.055005\n1992-03-01    6355.849712\n1992-04-01    6336.644418\n1992-05-01    6317.439124\n1992-06-01    6298.233830\n1992-07-01    6279.028536\n1992-08-01    6259.823242\n1992-09-01    6240.617948\n1992-10-01    6221.412654\n1992-11-01    6202.207360\n1992-12-01    6183.002066\n1993-01-01    6163.796772\n1993-02-01    6144.591478\n1993-03-01    6125.386184\n1993-04-01    6106.180890\n1993-05-01    6086.975596\n1993-06-01    6067.770302\n1993-07-01    6048.565008\n1993-08-01    6029.359714\n1993-09-01    6010.154420\n1993-10-01    5990.949127\n1993-11-01    5971.743833\n1993-12-01    5952.538539\nFreq: MS, dtype: float64\n```\n:::\n:::\n\n\nWe can run a damped trend using the `damped_trend` parameter:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfit = Holt(steel[\"steelshp\"], damped_trend=True).fit()\nfit.summary()\n```\n\n::: {.cell-output-display}\n```{=html}\n<table class=\"simpletable\">\n<caption>Holt Model Results</caption>\n<tr>\n  <th>Dep. Variable:</th>    <td>steelshp</td> <th>  No. Observations:  </th>        <td>96</td>       \n</tr>\n<tr>\n  <th>Model:</th>              <td>Holt</td>   <th>  SSE                </th>   <td>22092850.854</td>  \n</tr>\n<tr>\n  <th>Optimized:</th>          <td>True</td>   <th>  AIC                </th>     <td>1195.256</td>    \n</tr>\n<tr>\n  <th>Trend:</th>            <td>Additive</td> <th>  BIC                </th>     <td>1208.078</td>    \n</tr>\n<tr>\n  <th>Seasonal:</th>           <td>None</td>   <th>  AICC               </th>     <td>1196.529</td>    \n</tr>\n<tr>\n  <th>Seasonal Periods:</th>   <td>None</td>   <th>  Date:              </th> <td>Sun, 17 Sep 2023</td>\n</tr>\n<tr>\n  <th>Box-Cox:</th>            <td>False</td>  <th>  Time:              </th>     <td>22:40:36</td>    \n</tr>\n<tr>\n  <th>Box-Cox Coeff.:</th>     <td>None</td>   <th>                     </th>         <td> </td>       \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n         <td></td>                 <th>coeff</th>                <th>code</th>               <th>optimized</th>     \n</tr>\n<tr>\n  <th>smoothing_level</th> <td>           0.5235714</td> <td>               alpha</td> <td>                True</td>\n</tr>\n<tr>\n  <th>smoothing_trend</th> <td>           0.0506682</td> <td>                beta</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_level</th>   <td>           5980.0000</td> <td>                 l.0</td> <td>               False</td>\n</tr>\n<tr>\n  <th>initial_trend</th>   <td>           168.30000</td> <td>                 b.0</td> <td>               False</td>\n</tr>\n<tr>\n  <th>damping_trend</th>   <td>           0.9900000</td> <td>                 phi</td> <td>                True</td>\n</tr>\n</table>\n```\n:::\n:::\n\n\n:::\n\n# Seasonal Exponential Smoothing\n\nESMs can also be adapted to account for seasonal factors. Seasonal models can be additive or multiplicative in the seasonal effect.\n\n-   Holt-Winters Additive Exponential Smoothing\n-   Holt-Winters Multiplicative Exponential Smoothing\n\n## Holt-Winters Additive\n\n$$\n\\begin{align*}\n\\hat{Y}_{t+h} &= L_t + hT_t + S_{t-p+h} \\\\\nL_t &= \\theta(Y_t - S_{t-p}) + (1 - \\theta)(L_{t-1} + T_{t-1}) \\\\\nT_t &= \\gamma(L_t - L_{t-1}) + (1 - \\gamma)T_{t-1} \\\\\nS_t &= \\delta(Y_t - L_{t-1} - T_{t-1}) + (1 - \\delta)(S_{t-p})\n\\end{align*}\n$$\n\n-   $p$ is the length of the season\n\n$S_{t-p}$ represents the historical seasonal information. Even after adding a third component, all these components are doing the same thing: **we are adding the weighted naive model plus the weighted historical average for the component**.\n\nWhen we talk about the weights for the seasonal piece, the weights stay the same until we move to the next season.\n\n:::{.panel-tabset group=\"language\"}\n# R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhwes_usair <- hw(usair_ts, seasonal = \"additive\")\nsummary(hwes_usair)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nForecast method: Holt-Winters' additive method\n\nModel Information:\nHolt-Winters' additive method \n\nCall:\n hw(y = usair_ts, seasonal = \"additive\") \n\n  Smoothing parameters:\n    alpha = 0.5967 \n    beta  = 1e-04 \n    gamma = 1e-04 \n\n  Initial states:\n    l = 38384.1383 \n    b = 171.3139 \n    s = -1607.408 -2735.133 -266.9438 -4488.589 6259.346 6626.648\n           4166.006 1369.769 250.523 2806.828 -6741.171 -5639.874\n\n  sigma:  1949.79\n\n     AIC     AICc      BIC \n4515.651 4518.696 4573.265 \n\nError measures:\n                    ME     RMSE      MAE        MPE     MAPE      MASE\nTraining set -84.80235 1877.214 1168.093 -0.2917412 2.495749 0.4389788\n                   ACF1\nTraining set 0.06636172\n\nForecasts:\n         Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95\nApr 2008       65005.38 62506.62 67504.13 61183.86 68826.90\nMay 2008       66294.00 63384.09 69203.92 61843.67 70744.34\nJun 2008       69259.75 65989.86 72529.64 64258.88 74260.62\nJul 2008       71890.05 68295.96 75484.15 66393.36 77386.74\nAug 2008       71692.11 67800.64 75583.59 65740.62 77643.61\nSep 2008       61113.61 56945.83 65281.39 54739.54 67487.68\nOct 2008       65504.72 61077.76 69931.67 58734.27 72275.16\nNov 2008       63206.01 58534.16 67877.87 56061.02 70351.00\nDec 2008       64502.98 59598.36 69407.60 57002.01 72003.95\nJan 2009       60640.36 55513.46 65767.26 52799.44 68481.28\nFeb 2009       59708.43 54368.43 65048.44 51541.60 67875.27\nMar 2009       69425.67 63880.68 74970.66 60945.34 77906.01\nApr 2009       67038.85 61296.05 72781.64 58255.99 75821.70\nMay 2009       68327.47 62393.46 74261.49 59252.18 77402.76\nJun 2009       71293.22 65173.90 77412.54 61934.53 80651.91\nJul 2009       73923.52 67624.29 80222.75 64289.67 83557.37\nAug 2009       73725.58 67251.38 80199.79 63824.14 83627.03\nSep 2009       63147.08 56502.45 69791.72 52984.99 73309.17\nOct 2009       67538.18 60727.34 74349.03 57121.89 77954.48\nNov 2009       65239.48 58266.32 72212.64 54574.96 75904.01\nDec 2009       66536.45 59404.62 73668.27 55629.26 77443.63\nJan 2010       62673.83 55386.73 69960.92 51529.18 73818.47\nFeb 2010       61741.90 54302.73 69181.07 50364.67 73119.13\nMar 2010       71459.14 63870.89 79047.39 59853.92 83064.36\n```\n:::\n:::\n\n\n# Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom statsmodels.tsa.api import ExponentialSmoothing\n\nhw_add = ExponentialSmoothing(\n    us_airlines[\"Passengers\"], trend=\"add\", seasonal=\"add\", seasonal_periods=12\n).fit()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n/opt/homebrew/Caskroom/miniconda/base/envs/msa/lib/python3.11/site-packages/statsmodels/tsa/holtwinters/model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n  warnings.warn(\n```\n:::\n\n```{.python .cell-code}\nhw_add.summary()\n```\n\n::: {.cell-output-display}\n```{=html}\n<table class=\"simpletable\">\n<caption>ExponentialSmoothing Model Results</caption>\n<tr>\n  <th>Dep. Variable:</th>         <td>Passengers</td>      <th>  No. Observations:  </th>        <td>219</td>      \n</tr>\n<tr>\n  <th>Model:</th>            <td>ExponentialSmoothing</td> <th>  SSE                </th>   <td>818443222.270</td> \n</tr>\n<tr>\n  <th>Optimized:</th>                <td>True</td>         <th>  AIC                </th>     <td>3346.312</td>    \n</tr>\n<tr>\n  <th>Trend:</th>                  <td>Additive</td>       <th>  BIC                </th>     <td>3400.537</td>    \n</tr>\n<tr>\n  <th>Seasonal:</th>               <td>Additive</td>       <th>  AICC               </th>     <td>3349.732</td>    \n</tr>\n<tr>\n  <th>Seasonal Periods:</th>          <td>12</td>          <th>  Date:              </th> <td>Sun, 17 Sep 2023</td>\n</tr>\n<tr>\n  <th>Box-Cox:</th>                  <td>False</td>        <th>  Time:              </th>     <td>22:40:36</td>    \n</tr>\n<tr>\n  <th>Box-Cox Coeff.:</th>           <td>None</td>         <th>                     </th>         <td> </td>       \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n           <td></td>                  <th>coeff</th>                <th>code</th>               <th>optimized</th>     \n</tr>\n<tr>\n  <th>smoothing_level</th>    <td>           0.3939286</td> <td>               alpha</td> <td>                True</td>\n</tr>\n<tr>\n  <th>smoothing_trend</th>    <td>           0.0218849</td> <td>                beta</td> <td>                True</td>\n</tr>\n<tr>\n  <th>smoothing_seasonal</th> <td>           0.3305844</td> <td>               gamma</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_level</th>      <td>           38232.794</td> <td>                 l.0</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_trend</th>      <td>          -95.864899</td> <td>                 b.0</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.0</th>  <td>          -4632.4028</td> <td>                 s.0</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.1</th>  <td>          -6032.6319</td> <td>                 s.1</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.2</th>  <td>           494.52431</td> <td>                 s.2</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.3</th>  <td>          -873.71528</td> <td>                 s.3</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.4</th>  <td>           368.01389</td> <td>                 s.4</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.5</th>  <td>           3047.9618</td> <td>                 s.5</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.6</th>  <td>           5402.8993</td> <td>                 s.6</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.7</th>  <td>           7100.5243</td> <td>                 s.7</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.8</th>  <td>          -1505.9653</td> <td>                 s.8</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.9</th>  <td>           325.04514</td> <td>                 s.9</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.10</th> <td>          -2405.4861</td> <td>                s.10</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.11</th> <td>          -1288.7674</td> <td>                s.11</td> <td>                True</td>\n</tr>\n</table>\n```\n:::\n:::\n\n\n:::\n\n## Holt-Winters Multiplicative\n\n$$\n\\begin{align*}\n\\hat{Y}_{t+h} &= (L_t + hT_t)S_{t-p+h} \\\\\nL_t &= \\theta(Y_t/S_{t-p}) + (1 - \\theta)(L_{t-1} + T_{t-1}) \\\\\nT_t &= \\gamma(L_t - L_{t-1}) + (1 - \\gamma)T_{t-1} \\\\\nS_t &= \\delta(Y_t/(L_{t-1} + T_{t-1})) + (1 - \\delta)S_{t-p}\n\\end{align*}\n$$\n\n::: {.panel-tabset group=\"language\"}\n# R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhwes_usair <- hw(usair_ts, seasonal = \"multiplicative\")\nsummary(hwes_usair)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nForecast method: Holt-Winters' multiplicative method\n\nModel Information:\nHolt-Winters' multiplicative method \n\nCall:\n hw(y = usair_ts, seasonal = \"multiplicative\") \n\n  Smoothing parameters:\n    alpha = 0.4372 \n    beta  = 1e-04 \n    gamma = 0.2075 \n\n  Initial states:\n    l = 38293.1221 \n    b = 173.9926 \n    s = 0.9658 0.962 1.0064 0.9745 1.1393 1.0801\n           1.0368 0.9994 1.0012 1.0401 0.8799 0.9146\n\n  sigma:  0.0381\n\n     AIC     AICc      BIC \n4504.228 4507.272 4561.842 \n\nError measures:\n                    ME     RMSE      MAE       MPE     MAPE      MASE      ACF1\nTraining set -113.1889 1848.797 1090.105 -0.383246 2.303162 0.4096702 0.1713934\n\nForecasts:\n         Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95\nApr 2008       65528.49 62329.64 68727.34 60636.28 70420.70\nMay 2008       66821.29 63262.13 70380.46 61378.02 72264.57\nJun 2008       70075.52 66056.65 74094.40 63929.19 76221.86\nJul 2008       73144.30 68671.62 77616.98 66303.93 79984.68\nAug 2008       71313.29 66698.66 75927.92 64255.83 78370.76\nSep 2008       58655.19 54662.55 62647.83 52548.97 64761.40\nOct 2008       64544.10 59944.79 69143.41 57510.06 71578.13\nNov 2008       62554.65 57906.98 67202.32 55446.66 69662.65\nDec 2008       63629.25 58716.73 68541.77 56116.20 71142.30\nJan 2009       59379.95 54629.79 64130.10 52115.21 66644.68\nFeb 2009       57852.76 53069.42 62636.10 50537.28 65168.25\nMar 2009       70682.78 64655.56 76710.00 61464.94 79900.62\nApr 2009       67606.25 61473.18 73739.32 58226.52 76985.97\nMay 2009       68934.51 62519.04 75349.97 59122.89 78746.12\nJun 2009       72285.87 65393.58 79178.16 61745.02 82826.72\nJul 2009       75445.45 68084.46 82806.44 64187.79 86703.11\nAug 2009       73551.02 66215.90 80886.14 62332.92 84769.12\nSep 2009       60490.96 54330.83 66651.08 51069.86 69912.06\nOct 2009       66558.97 59644.04 73473.89 55983.50 77134.43\nNov 2009       64502.39 57671.58 71333.21 54055.56 74949.22\nDec 2009       65605.36 58528.93 72681.80 54782.90 76427.83\nJan 2010       61219.37 54498.44 67940.31 50940.59 71498.16\nFeb 2010       59640.30 52980.57 66300.04 49455.12 69825.49\nMar 2010       72861.19 64590.90 81131.47 60212.88 85509.49\n```\n:::\n:::\n\n\nAgain these are just weights so this does not tell us if we have seasonality or not. We only see how our model is weighting recent information and historical average information.\n\n# Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nhw_mult = ExponentialSmoothing(\n    us_airlines[\"Passengers\"], trend=\"add\", seasonal=\"mul\", seasonal_periods=12\n).fit()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n/opt/homebrew/Caskroom/miniconda/base/envs/msa/lib/python3.11/site-packages/statsmodels/tsa/holtwinters/model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n  warnings.warn(\n```\n:::\n\n```{.python .cell-code}\nhw_mult.summary()\n```\n\n::: {.cell-output-display}\n```{=html}\n<table class=\"simpletable\">\n<caption>ExponentialSmoothing Model Results</caption>\n<tr>\n  <th>Dep. Variable:</th>         <td>Passengers</td>      <th>  No. Observations:  </th>        <td>219</td>      \n</tr>\n<tr>\n  <th>Model:</th>            <td>ExponentialSmoothing</td> <th>  SSE                </th>   <td>810065387.907</td> \n</tr>\n<tr>\n  <th>Optimized:</th>                <td>True</td>         <th>  AIC                </th>     <td>3344.058</td>    \n</tr>\n<tr>\n  <th>Trend:</th>                  <td>Additive</td>       <th>  BIC                </th>     <td>3398.283</td>    \n</tr>\n<tr>\n  <th>Seasonal:</th>            <td>Multiplicative</td>    <th>  AICC               </th>     <td>3347.478</td>    \n</tr>\n<tr>\n  <th>Seasonal Periods:</th>          <td>12</td>          <th>  Date:              </th> <td>Sun, 17 Sep 2023</td>\n</tr>\n<tr>\n  <th>Box-Cox:</th>                  <td>False</td>        <th>  Time:              </th>     <td>22:40:37</td>    \n</tr>\n<tr>\n  <th>Box-Cox Coeff.:</th>           <td>None</td>         <th>                     </th>         <td> </td>       \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n           <td></td>                  <th>coeff</th>                <th>code</th>               <th>optimized</th>     \n</tr>\n<tr>\n  <th>smoothing_level</th>    <td>           0.3939286</td> <td>               alpha</td> <td>                True</td>\n</tr>\n<tr>\n  <th>smoothing_trend</th>    <td>           0.0218849</td> <td>                beta</td> <td>                True</td>\n</tr>\n<tr>\n  <th>smoothing_seasonal</th> <td>           0.3030357</td> <td>               gamma</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_level</th>      <td>           38232.794</td> <td>                 l.0</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_trend</th>      <td>          -95.864899</td> <td>                 b.0</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.0</th>  <td>           0.8828055</td> <td>                 s.0</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.1</th>  <td>           0.8473624</td> <td>                 s.1</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.2</th>  <td>           1.0108916</td> <td>                 s.2</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.3</th>  <td>           0.9777503</td> <td>                 s.3</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.4</th>  <td>           1.0088677</td> <td>                 s.4</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.5</th>  <td>           1.0761260</td> <td>                 s.5</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.6</th>  <td>           1.1385855</td> <td>                 s.6</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.7</th>  <td>           1.1824059</td> <td>                 s.7</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.8</th>  <td>           0.9607449</td> <td>                 s.8</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.9</th>  <td>           1.0081718</td> <td>                 s.9</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.10</th> <td>           0.9385590</td> <td>                s.10</td> <td>                True</td>\n</tr>\n<tr>\n  <th>initial_seasons.11</th> <td>           0.9677292</td> <td>                s.11</td> <td>                True</td>\n</tr>\n</table>\n```\n:::\n:::\n\n\n:::\n\n# Evaluating Forecasts\n\nAccuracy of forecasts depends on your definition of accuracy (different across different industries).\n\nGood forecasts should have these characteristics:\n\n-   Be highly correlated with actual series values\n-   Exhibit small forecast errors\n-   Capture the important features of the original time series\n\n## Judgment Forecasting\n\nForecasts are found using quantitative or modeling approaches. However, there are instances where models are not availabe and qualitative or judgment forecast is used. Occasionally, we merge the two together.\n\n## Accuracy vs. Goodness-of-Fit\n\nGoodness-of-fit is calculated on the same sample used to build the model.\n\nA diagnostic statistic calculated using a hold out sample that was not used in model building is an **accuracy** statistic.\n\n# Hold Out Sample\n\nHold out sample in time sereies should always come from the end of the time series and doesn't typically go beyond **25% of the data**.\n\nIf you have a seasonal time series you should ideally have an entire season captured in the hold-out sample.\n\n1.  Divide time series into two or three segments--training, validation, and/or test\n2.  Derive a set of candidate models\n3.  Calculate the chosen accuracy statistic by forecasting the validation data set\n4.  Pick the model with the best accuracy statistic\n5.  Provide the accuracy of the model on the *test* data set\n\n# Model Diagnostic Statistics\n\n## Mean Absolute Percent Error\n\n$$\n\\text{MAPE} = \\frac{1}{n}\\sum_{t=1}^n \\left| \\frac{Y_t - \\hat{Y}_t}{Y_t} \\right|\n$$\n\n-   Can overweight over-predictions\n-   Can't divide by 0\n\n## Mean Absolute Error\n\n$$\n\\text{MAE} = \\frac{1}{n}\\sum_{t=1}^n \\left| Y_t - \\hat{Y}_t \\right|\n$$\n\n-   Not scale invariant\n\n## Square Root of Mean Square Error\n\n$$\n\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{t=1}^n (Y_t - \\hat{Y}_t)^2}\n$$\n\n-   Overweight of larger errors\n-   Not scale invariant\n\n## Symmetric Mean Absolute Percent Error\n\n$$\n\\text{sMAPE} = \\frac{1}{n}\\sum_{t=1}^n \\frac{\\left| Y_t - \\hat{Y}_t \\right|}{(\\left| Y_t \\right| + \\left| \\hat{Y}_t \\right|)}\n$$\n\n-   Divide by 0\n-   Still asymmetric\n\n## Comparison Across Diagnostics\n\n![Comparison Across Diagnostics](images/diagnostic-comparisons.png)\n\n# Error, Trend, Season (ETS)\n\nETS is an automated search procedure that will try to identify the best ESM based on treating the data as a state space problem.\n\n-   Error has choices of Additive or Multiplicative\n-   Trend has choices of None, Additive, or Multiplicative (can also have a damped trend)\n-   Seasonal has choices of None, Additive, or Multiplicative\n\nYou can choose which one you want or let the computer choose (specify \"Z\" for each feature, but by default it is automated).\n\n:::{.panel-tabset group=\"language\"}\n# R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nets_usair <- ets(usair_ts)\nsummary(ets_usair)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nETS(M,A,M) \n\nCall:\n ets(y = usair_ts) \n\n  Smoothing parameters:\n    alpha = 0.475 \n    beta  = 1e-04 \n    gamma = 4e-04 \n\n  Initial states:\n    l = 38293.0747 \n    b = 139.4654 \n    s = 0.9673 0.9469 0.9968 0.921 1.1302 1.1314\n           1.0727 1.0189 1.0021 1.0556 0.8676 0.8897\n\n  sigma:  0.036\n\n     AIC     AICc      BIC \n4479.269 4482.314 4536.884 \n\nTraining set error measures:\n                    ME     RMSE      MAE        MPE     MAPE      MASE\nTraining set -43.69617 1738.229 1036.209 -0.2029043 2.161854 0.3894156\n                  ACF1\nTraining set 0.1747747\n```\n:::\n:::\n\n\nThe summary tells us that the model selected is ETS(M, A, M) which means:\n\n-   Error is Multiplicative\n-   Trend is Additive\n-   Seasonality is Multiplicative\n\n# Python\n\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}