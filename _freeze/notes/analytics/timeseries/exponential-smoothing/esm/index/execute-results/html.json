{
  "hash": "02f04989da106447dd1aadb888b153e8",
  "result": {
    "markdown": "---\ntitle: Exponential Smoothing Models\ndate: 08/30/2023\ndate-modified: 09/16/2023\n---\n\n\n# Setup {.unnumbered}\n\n::: {.panel-tabset group=\"language\"}\n# R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tseries)\nlibrary(forecast)\nlibrary(tidyverse)\nlibrary(aTSA)\nlibrary(reticulate)\n\nuse_condaenv(\"msa\")\n\nsteel <- read.csv(\"https://raw.githubusercontent.com/sjsimmo2/TimeSeries/master/steel.csv\")\n```\n:::\n\n\n# Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing\n\nsteel = r.steel\ndf = pd.date_range(\"1/1/1984\", \"12/1/1991\", freq=\"MS\")\nsteel.set_index(pd.to_datetime(df), inplace=True)\n```\n:::\n\n:::\n\nTime series data assumes that observations at a certain time point depend on previous observations in time.\n\n:::{.text-center}\nNaive Model: $\\hat{Y}_{t+h} = Y_t$\n\nAverage Model: $\\hat{Y}_{t+h} = \\frac{1}{T} \\sum_{t=1}^{T} Y_t$\n:::\n\nExponential smoothing models take a weighted average between these two models.\n\n# Exponential Smoothing\n\nExponential smoothing models (ESM) take an average of our data, but uses a *weighted* average instead. Models only require a few parameters. ESMs are great for one-step ahead forecasting, but not for long-term forecasting.\n\nWe cover common types of exponential smoothing:\n\n-   Single\n-   Linear / Holt (trend)\n-   Holt-Winters (trend and seasonality)\n\n# Single Exponential Smoothing\n\nSingle exponential equates the predictions at time $t$ equal to the weighted values of the previous time period along with the previous time period's prediction.\n\n$$\n\\hat{Y}_{t+1} = \\theta Y_t + (1 - \\theta)\\hat{Y}_t\n$$\n\n-   $Y_t$ is the previous observation in the dataset\n-   $\\hat{Y}_t$ is the estimate of $Y_t$ (weighted average of prev. observations)\n-   $0 \\leq \\theta \\leq 1$\n\nWith exponential smoothing models, we can imagine that a forecasted model was fit over our data. Our model forecasts $\\hat{Y}_t$ and we have the actual observation $Y_t$. We calculate the weighted average of these two values to calculate the next value $\\hat{Y}_{t+1}$.\n\n$$\n\\hat{Y}_{t+1} = \\theta Y_t + \\theta(1 - \\theta)Y_{t - 1} + \\theta(1 - \\theta)^2Y_{t - 2} + \\cdots\n$$\n\nWeights decrease exponentially as we go further back in time so more weight is put on recent observations. If $\\theta$ is close to 1, the most recent observation is emphasized. If $\\theta$ is small, then there is more emphasis on the past averages.\n\n![Single Exponential Smoothing Weights](images/single-exponential-smoothing-weights.png){#fig-esm-weights}\n\n## Component Form\n\nSingle ESM can be written in component form:\n\n$$\n\\hat{Y}_{t+1} = L_t\n$$\n\n$$\nL_t = \\theta Y_t + (1 - \\theta)L_{t - 1}\n$$\n\n## Parameter Estimation\n\nTo calculate the optimal value of $\\theta$ in ESM, we can run the model with multiple values of $\\theta$ between 0 and 1 and find the $\\theta$ that minimizes the errors in your forecast.\n\nThe value of $\\theta$ that minimizes the one-step ahead forecast errors is considered the optimal value:\n\n$$\n\\text{SSE} = \\sum_{t=1}^T (Y_t - \\hat{Y}_t)^2\n$$\n\nEstimates that are not statistically significant should not be disqualified. Estimates are fine even without normality however normality is needed is trying to construct a confidence interval.\n\n::: {.panel-tabset group=\"language\"}\n# R\n\nWe can create a simple ESM using `ses`. The `h` argument controls how far we want to forecast in the series:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsteel_ts <- ts(steel$steelshp, start = 1984, frequency = 12)\nses_steel <- ses(steel_ts, initial = \"simple\", h = 24)\nsummary(ses_steel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nForecast method: Simple exponential smoothing\n\nModel Information:\nSimple exponential smoothing \n\nCall:\n ses(y = steel_ts, h = 24, initial = \"simple\") \n\n  Smoothing parameters:\n    alpha = 0.4549 \n\n  Initial states:\n    l = 5980 \n\n  sigma:  460.4357\nError measures:\n                   ME     RMSE      MAE        MPE     MAPE      MASE\nTraining set 11.43866 460.4357 363.9341 -0.2204828 5.708307 0.8287599\n                    ACF1\nTraining set -0.04379112\n\nForecasts:\n         Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95\nJan 1992       6479.571 5889.499 7069.643 5577.133 7382.008\nFeb 1992       6479.571 5831.305 7127.836 5488.134 7471.007\nMar 1992       6479.571 5777.922 7181.219 5406.492 7552.649\nApr 1992       6479.571 5728.323 7230.819 5330.636 7628.505\nMay 1992       6479.571 5681.801 7277.340 5259.487 7699.654\nJun 1992       6479.571 5637.847 7321.295 5192.265 7766.876\nJul 1992       6479.571 5596.077 7363.065 5128.383 7830.758\nAug 1992       6479.571 5556.194 7402.947 5067.388 7891.754\nSep 1992       6479.571 5517.964 7441.177 5008.920 7950.221\nOct 1992       6479.571 5481.197 7477.944 4952.690 8006.452\nNov 1992       6479.571 5445.736 7513.405 4898.458 8060.684\nDec 1992       6479.571 5411.453 7547.689 4846.025 8113.116\nJan 1993       6479.571 5378.236 7580.906 4795.224 8163.917\nFeb 1993       6479.571 5345.992 7613.150 4745.911 8213.230\nMar 1993       6479.571 5314.640 7644.502 4697.962 8261.179\nApr 1993       6479.571 5284.110 7675.032 4651.271 8307.871\nMay 1993       6479.571 5254.340 7704.801 4605.742 8353.399\nJun 1993       6479.571 5225.277 7733.864 4561.294 8397.847\nJul 1993       6479.571 5196.872 7762.269 4517.853 8441.289\nAug 1993       6479.571 5169.083 7790.058 4475.353 8483.789\nSep 1993       6479.571 5141.871 7817.271 4433.735 8525.406\nOct 1993       6479.571 5115.201 7843.940 4392.948 8566.194\nNov 1993       6479.571 5089.043 7870.098 4352.942 8606.199\nDec 1993       6479.571 5063.368 7895.773 4313.676 8645.465\n```\n:::\n:::\n\n\nWe can also plot our forecast from our model. The black line shown is our series and the red line is our model. Notice that if we forecast past one-step, we are always forecasting the same value:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(ses_steel) +\n    autolayer(fitted(ses_steel), series = \"Fitted\") +\n    ylab(\"US Steel Shipments\") +\n    geom_vline(xintercept = 1992, color = \"orange\", linetype = \"dashed\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n# Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing\n\nsteel = pd.read_csv(\n    \"https://raw.githubusercontent.com/sjsimmo2/TimeSeries/master/steel.csv\"\n)\ndf = pd.date_range(\"1/1/1984\", \"12/1/1991\", freq=\"MS\")\nsteel.set_index(pd.to_datetime(df), inplace=True)\n\nfit = SimpleExpSmoothing(steel[\"steelshp\"]).fit()\nfit.params[\"smoothing_level\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.45493602336086547\n```\n:::\n:::\n\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}