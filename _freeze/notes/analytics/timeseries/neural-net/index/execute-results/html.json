{
  "hash": "f07b85c199f4e0a3dbea7bdf0a802bf2",
  "result": {
    "markdown": "---\ntitle: Neural Network AR Models\ndate: 10/12/2023\ndate-modified: 10/17/2023\n---\n\n\n# Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tseries)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n```\n:::\n\n```{.r .cell-code}\nlibrary(aTSA)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'aTSA'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:tseries':\n\n    adf.test, kpss.test, pp.test\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:graphics':\n\n    identify\n```\n:::\n\n```{.r .cell-code}\nlibrary(forecast)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'forecast'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:aTSA':\n\n    forecast\n```\n:::\n\n```{.r .cell-code}\nset.seed(12345)\n\nUSAirlines <- read.csv(\"https://raw.githubusercontent.com/sjsimmo2/TimeSeries/master/usairlines.csv\")\npassenger <- ts(USAirlines$Passengers, start = 1990, frequency = 12)\ntrain <- subset(passenger, end = length(passenger) - 12)\ntest <- subset(passenger, start = length(passenger) - 11)\n```\n:::\n\n\n# Neural Net Basics\n\nNeural network models are models based on mathematical models of how the brain functions. \n\nThey are organized in a network of **neurons** through **layers**. The input variables are considered the neurons on the **bottom layer**. The output variable is considered the neuron on the **top layer**.\n\nThe layers in between are called **hidden layers** transfrom the input variables through activation functions to try and model the output variable.\n\n@fig-basic-neural-net shows a basic neural net structure without a hidden layer.\n\n![Basic Neural Net Structure](images/basic-neural-net){#fig-basic-neural-net}\n\nOnce we add a hidden layer, we apply non-linear activation functions in new nodes that get combined into an output.\n\n:::{layout-ncol=\"2\"}\n![Hidden Layer Added](images/hidden-layer-1.png)\n\n![Combining the Hidden Layer Output](images/hidden-to-output.png)\n:::\n\n# Autoregressive Neural Networks\n\nNeural network models used for forecasting in time series, just have lags of Y in the bottom layer along with other X variables.\n\n![Autoregressive Terms](images/autoregressive-terms.png)\n\n## Number of AR Lags\n\n-   Explore with correlation plots or automatic selection techniques\n-   Focus primarily on AR components of the model\n-   For seasonal data we typically include **all** lags up throguh one season unless correlation plots say you only need specific ones\n-   **Still want to make data stationary first**\n\nIf you don't have stationary data, the forecasts will still revert to overall mean far enough into the future.\n\n# Implementing Neural Net AR\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(12345)\n\nnn_model <- nnetar(diff(train, 12), p = 2, P = 3) # <1>\nnn_forecast <- forecast::forecast(nn_model, h = 12) # <2>\nplot(nn_forecast)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/neural-net-ar-1.png){width=672}\n:::\n:::\n\n1.  `p` refers to number of AR lags and `P` refers to number of seasonal AR lags. By default, the non-linear transformation used is the sigmoid function.\n2.  The neural net only knows about our differenced data so we need to add back the last 12 observations to get the original scale.\n\nIn the background, R automatically adjusts the forecasts to be on the original scale in ARIMA models. However, with neural net models we need to manually adjust the forecasts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npass_forecast <- train[(length(train) - 11):length(train)] + forecast::forecast(nn_model, h = 12)$mean[1:12]\n\nplot(train, main = \"US Airline Passengers ARIMA Model Forecasts\", xlab = \"Date\", ylab = \"Passengers (Thousands)\", xlim = c(1990, 2009), ylim = c(30000, 80000))\nlines(pass_forecast, col = \"blue\")\nabline(v = 2007.25, col = \"red\", lty = \"dashed\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/neural-net-forecasts-1.png){width=672}\n:::\n\n```{.r .cell-code}\nnn_error <- test - pass_forecast\nnn_MAE <- mean(abs(nn_error))\nnn_MAPE <- mean(abs(nn_error) / abs(test)) * 100.0\nprint(nn_MAE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1091.243\n```\n:::\n\n```{.r .cell-code}\nprint(nn_MAPE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.6728\n```\n:::\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}