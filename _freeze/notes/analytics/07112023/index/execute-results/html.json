{
  "hash": "4eca744d206eef9542a939f7e1eaa888",
  "result": {
    "markdown": "---\ntitle: Correlated Error Terms\ndate: 07/11/2023\ndate-modified: 07/23/2023\n---\n\n\nWhen we're trying to understand correlated error terms, we \nneed to know the source of our data:\n\n-   Clustered/grouped data\n-   Observations connected in some way\n-   Complex surveys\n-   Repeated measures\n-   **Data gathered over time**\n\n# Autocorrelation\n\nWith time-series data, **autocorrelation** can occur\nand residuals follow a cyclic pattern. Plot residuals\nover time to see if any cyclic trends occur.\n\n![Cyclic Residuals](images/autocorrelation-plot.png)\n\n## Durbin-Watson Statistic (First-Order)\n\nWe can also assess autocorrelation using the \n**Durbin-Watson statistic** which compares a residual\nagainst the previous time residual over the sum of\nresiduals squared.\n\n$$\nd = \\frac{\\sum_{t=2}^{T} (e_t - e_{t-1})^2}{\\sum_{t=1}^{T} e_t^2}\n$$\n\n-   Bounded in $[0, 4]$\n-   When $d=2$, fail to reject $H_0$ and assume there is\n    not enough evidence supporting autocorrelation\n-   $d < 2$, possible positive autocorrelation\n-   $d > 2$, possible negative autocorrelation\n\n## Handling Correlated Errors\n\n-   If correlated due to time, perform time series\n-   If correlated due to clustered data, perform a hierarchical model\n-   Longitudinal analysis/panel data\n\n# Influential Points and Outliers\n\nTwo main types of anomalous observations:\n\n-   Outliers: points with large standardized residuals\n-   Leverage Points: point that falls outside the normal\nrange (far from the mean) in the possible values of the\npredictor (X-space) and have a large \"influence\" on the \nregression line\n\nDon't just focus on residuals of data as residual\nanalysis tends to discover outliers instead of\nleverage points.\n\n## Diagnostic Statistics\n\n::: {.text-center}\n\n```{mermaid}\nflowchart LR\n    A[Detecting Outliers] --> B[Standardized Residuals]\n    A --> C[Studentized Residuals]\n    X[Detecting Influential Obs.] --> D[Cook's D]\n    X --> E[DFFITS]\n    X --> F[DFBETAS]\n    X --> G[Hat Values]\n```\n\n:::\n\n### Studentized Residuals\n\nDivide the residuals by their standard errors after\ndeleting that one observation\n\n-   $\\left|SR\\right| > 2$ for datasets with a relatively\nsmall number of observations\n-   $\\left|SR\\right| > 3$ for datasets with relatively large\nnumber of observations\n\n### Cook's D\n\nMeasures the difference in the regression estimates\nwhen the $i^{th}$ observation is left out\n\nCutoff formula:\n\n$$\nD_i > \\frac{4}{n - p - 1}\n$$\n\n-   $p$ is the number of parameters including the\nintercept\n\n### DFFITS\n\nMeasures impact that the $i^{th}$ observation has on\npredicted value\n\n$$\n\\left| DFFITS_i \\right| > 2\\sqrt{\\frac{p}{n}}\n$$\n\n### Hat Values\n\nFrom the normal equation, the estimate of the parameters\nis:\n\n$$\nb = (X'X)^{-1}X'y\n$$\n\nEstimated line is:\n\n$$\n\\hat{y} = X(X'X)^{-1}X'y\n$$\n\nWith the hat values being:\n\n$$\nX(X'X)^{-1}X'\n$$\n\nSuggested cutoff is:\n\n$$\nh_{ii} > \\frac{2p}{n}\n$$\n\n### DFBETA\n\nMeasure of change in the $j^{th}$ parameter estimate with\ndeletion of $i^{th}$ observation.\n\nOne DFBETA per parameter per observation. Helps to explain\nwhich parameter coefficient the influence most lies.\n\n$$\n\\left| DFBETA_{ij} \\right| > 2 \\sqrt{\\frac{1}{n}}\n$$\n\n## Scottish Hill Races\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nurl <- \"http://www.statsci.org/data/general/hills.txt\"\nraces.table <- read.table(url, header = TRUE, sep = \"\\t\")\n\nraces.table <- races.table %>%\n    mutate(idx = row_number())\n\nlm.model <- lm(Time ~ Distance + Climb, data = races.table)\n\nggplot(lm.model, aes(x = races.table$idx, y = rstudent(lm.model))) +\n    geom_point(color = \"orange\") +\n    geom_line(y = -3) +\n    geom_line(y = 3) +\n    labs(title = \"External Studentized Residuals\", x = \"Observation\", y = \"Residuals\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n## How to Handle Influential Observations\n\n1.  Recheck data to ensure no transcription or data entry\n    errors occurred.\n2.  If data is valid, maybe model is inadequate\n    -   Higher-order terms may be necessary\n    -   Nonlinear model\n3.  Determine robustness of the inference by running\n    analysis with and without influential observations\n4.  Robust Regression\n5.  Weighted Least Squares\n\n# Collinearity\n\nIf variables are strongly correlated with each other\neven removing one point can change our model in a\ncompletely different way.\n\n## Collinearity Diagnostics\n\nWe can look at correlation matrix of predictors, but\nthere is also the **variance inflation factor** that\nwe can consider:\n\n$$\nVIF_i = \\frac{1}{1 - R_i^2}\n$$\n\n-   $R_i^2$ is the $R^2$ value with all the other\nvariables predicting $x_i$\n-   $VIF > 10$ indicate collinearity\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: carData\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'car'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:dplyr':\n\n    recode\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    some\n```\n:::\n\n```{.r .cell-code}\ncor(mtcars)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            mpg        cyl       disp         hp        drat         wt\nmpg   1.0000000 -0.8521620 -0.8475514 -0.7761684  0.68117191 -0.8676594\ncyl  -0.8521620  1.0000000  0.9020329  0.8324475 -0.69993811  0.7824958\ndisp -0.8475514  0.9020329  1.0000000  0.7909486 -0.71021393  0.8879799\nhp   -0.7761684  0.8324475  0.7909486  1.0000000 -0.44875912  0.6587479\ndrat  0.6811719 -0.6999381 -0.7102139 -0.4487591  1.00000000 -0.7124406\nwt   -0.8676594  0.7824958  0.8879799  0.6587479 -0.71244065  1.0000000\nqsec  0.4186840 -0.5912421 -0.4336979 -0.7082234  0.09120476 -0.1747159\nvs    0.6640389 -0.8108118 -0.7104159 -0.7230967  0.44027846 -0.5549157\nam    0.5998324 -0.5226070 -0.5912270 -0.2432043  0.71271113 -0.6924953\ngear  0.4802848 -0.4926866 -0.5555692 -0.1257043  0.69961013 -0.5832870\ncarb -0.5509251  0.5269883  0.3949769  0.7498125 -0.09078980  0.4276059\n            qsec         vs          am       gear        carb\nmpg   0.41868403  0.6640389  0.59983243  0.4802848 -0.55092507\ncyl  -0.59124207 -0.8108118 -0.52260705 -0.4926866  0.52698829\ndisp -0.43369788 -0.7104159 -0.59122704 -0.5555692  0.39497686\nhp   -0.70822339 -0.7230967 -0.24320426 -0.1257043  0.74981247\ndrat  0.09120476  0.4402785  0.71271113  0.6996101 -0.09078980\nwt   -0.17471588 -0.5549157 -0.69249526 -0.5832870  0.42760594\nqsec  1.00000000  0.7445354 -0.22986086 -0.2126822 -0.65624923\nvs    0.74453544  1.0000000  0.16834512  0.2060233 -0.56960714\nam   -0.22986086  0.1683451  1.00000000  0.7940588  0.05753435\ngear -0.21268223  0.2060233  0.79405876  1.0000000  0.27407284\ncarb -0.65624923 -0.5696071  0.05753435  0.2740728  1.00000000\n```\n:::\n\n```{.r .cell-code}\nlm.model <- lm(mpg ~ ., data = mtcars)\nv <- vif(lm.model)\nv[v > 10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     cyl     disp       wt \n15.37383 21.62024 15.16489 \n```\n:::\n:::\n\n\n## Dealing with Multicollinearity\n\n-   Exclude redundant independent variables\n-   Redefine variables\n-   Use biased regression techniques (e.g. LASSO)\n-   Center the independent variables in polynomial\n    regression models or models with interaction terms\n    -   Subtract each value of the predictor by the\n        mean of that column\n\nYou should be dealing with multicollinearity **before** you do any model selection.\n\nAny time you take or add variables in, you should be\nmodifying one at a time and recalculating VIF at each\nstep.\n\n# Effective Modeling Cycle\n\n\n```{mermaid}\nflowchart LR\n    1[Preliminary Analysis] --> 2[Collinearity Detection]\n    2 --> 3[Candidate Model Selection]\n    3 --> 4[Assumption Validation and Influential Observation Detection]\n    4 --> 5[Model Revision]\n    5 -->|Yes| 3\n    5 -->|No| 6[Prediction Testing]\n```\n\n\nFollowing the model selection and assumption validation \nsteps, we might consider what is more \nimportant--significant p-values in our variables or the \ntotal predictive power of the selected model? The answer \nis it depends. We can take both models, one where the \ninsignificant p-value variables are pruned and one that \nwas selected by the step selection methods, and run them \non a validation set. We see which one performs better and \ngo forward with that model.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}