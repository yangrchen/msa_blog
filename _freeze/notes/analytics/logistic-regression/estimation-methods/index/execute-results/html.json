{
  "hash": "4433c0f664508d2107ae47568d3eb725",
  "result": {
    "markdown": "---\ntitle: Estimation Methods for Logistic Regression\ndate: 08/25/2023\n---\n\n\nIn logistic regression, the assumptions of residual Normality and constant variance are violated. OLS is not the best method for parameter estimation.\n\n# Maximum Likelihood Estimation\n\nEstimates are obtained with **maximum likelihood estimation (MLE)**. Likelihood function measures how probable a specific grid of $\\beta$ values is to have produced you data.\n\nFor a binomial target variable:\n\n$$\nL(\\beta's|y, x_1, x_2, \\cdots) = \\prod_{i=1}^n p_i^{y_i}(1 - p_i)^{1 - y_i}\n$$\n\n-   $p_i = \\frac{1}{1 + e^{-z}}$\n\nWithin this combination of inputs and outputs, what is the best combination of $\\beta$ to get our data.\n\nWe can work with the log of the likelihood function:\n\n$$\n\\log(L) = \\sum_{i=1}^n \\left[y_i\\log(p_i) + (1- y_i)\\log(1 - p_i)\\right]\n$$\n\n## Likelihood Ratio Tests\n\nLikelihood estimation allows us to do hypothesis testing. If extra predictors don't add information, then a model that includes them shouldn't be substantially more likely than the moel that doesn't include them.\n\n**Likelihood Ratio Test (LRT)** compares the full and reduced models.\n\n![Likelihood Ratio Test](images/likelihood-ratio-test.png)\n\n$L_0$ is the reduced model and $L_1$ is the full model.\n\n::: {.panel-tabset group=\"language\"}\n# R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(AmesHousing)\nlibrary(tidyverse)\nlibrary(reticulate)\n\nset.seed(123)\n\nuse_condaenv(\"msa\")\n\names <- make_ordinal_ames()\names <- ames |>\n    mutate(Bonus = ifelse(Sale_Price > 175000, 1, 0))\ntrain <- sample_frac(ames, 0.7)\n\nlogit_model <- glm(Bonus ~ Gr_Liv_Area + factor(Central_Air), data = train, family = binomial(link = \"logit\"))\n\nlogit_model_r <- glm(Bonus ~ 1, data = train, family = binomial(link = \"logit\"))\nanova(logit_model, logit_model_r, test = \"LRT\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table\n\nModel 1: Bonus ~ Gr_Liv_Area + factor(Central_Air)\nModel 2: Bonus ~ 1\n  Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    \n1      2048     1808.8                          \n2      2050     2775.8 -2  -966.96 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n# Python\n\nPython provides the Global Likelihood Ratio Test ('LLR p-value') in the model output. \n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.genmod.generalized_linear_model import GLM\nimport statsmodels.formula.api as smf\nimport scipy as sp\n\names = r.ames\ntrain = r.train\n\nlogit_model = GLM.from_formula(\n    \"Bonus ~ Gr_Liv_Area + C(Central_Air)\", data=train, family=Binomial()\n).fit()\n\nlogit_model.summary()\n```\n\n::: {.cell-output-display}\n```{=html}\n<table class=\"simpletable\">\n<caption>Generalized Linear Model Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>         <td>Bonus</td>      <th>  No. Observations:  </th>  <td>  2051</td> \n</tr>\n<tr>\n  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>  2048</td> \n</tr>\n<tr>\n  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     2</td> \n</tr>\n<tr>\n  <th>Link Function:</th>         <td>Logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n</tr>\n<tr>\n  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -904.42</td>\n</tr>\n<tr>\n  <th>Date:</th>            <td>Fri, 15 Sep 2023</td> <th>  Deviance:          </th> <td>  1808.8</td>\n</tr>\n<tr>\n  <th>Time:</th>                <td>16:47:56</td>     <th>  Pearson chi2:      </th> <td>1.98e+07</td>\n</tr>\n<tr>\n  <th>No. Iterations:</th>          <td>7</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.3759</td> \n</tr>\n<tr>\n  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n           <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>Intercept</th>           <td>  -10.3546</td> <td>    0.642</td> <td>  -16.124</td> <td> 0.000</td> <td>  -11.613</td> <td>   -9.096</td>\n</tr>\n<tr>\n  <th>C(Central_Air)[T.Y]</th> <td>    3.9519</td> <td>    0.518</td> <td>    7.629</td> <td> 0.000</td> <td>    2.937</td> <td>    4.967</td>\n</tr>\n<tr>\n  <th>Gr_Liv_Area</th>         <td>    0.0041</td> <td>    0.000</td> <td>   20.959</td> <td> 0.000</td> <td>    0.004</td> <td>    0.004</td>\n</tr>\n</table>\n```\n:::\n:::\n\n\n:::\n\nIn this example, you can think of LRT as comparing these two equations:\n\n$$\n\\begin{align*}\nL_1 &= \\beta_0 + \\beta_1GLA + \\beta_2CA + \\beta_3F1 \\beta_4F_2 + \\cdots \\\\\nL_0 &= \\beta_0 + \\beta_1GLA + \\beta_2CA\n\\end{align*}\n$$\n\nAlways check the difference in degrees of freedom to double-check if you are comparing the right number of variables (how many levels are in the additional variable you are including?).\n\n## Categorical P-Values\n\nFor categorical variables with more than 2 levels we shouldn't evaluate the significance of the entire variable with the individual p-values. Use LRT to compare model with and without the categorical variable since LRT compares the model with ALL the levels included against the model with ALL the levels not included.\n\n:::{.panel-tabset group=\"language\"}\n# R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogit_model_f <- glm(Bonus ~ Gr_Liv_Area + factor(Central_Air) + factor(Fireplaces), data = train, family = binomial(link = \"logit\"))\ncar::Anova(logit_model_f, test = \"LR\", type = \"III\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III tests)\n\nResponse: Bonus\n                    LR Chisq Df Pr(>Chisq)    \nGr_Liv_Area           565.89  1  < 2.2e-16 ***\nfactor(Central_Air)    86.81  1  < 2.2e-16 ***\nfactor(Fireplaces)     62.61  4  8.181e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n# Python\n\nIn Python, we are comparing the likelihood values from the original model without fireplace and the model with the addition of the `Fireplaces` variable. We have to calculate the LRT by hand using hte following:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nreduced_ll = logit_model.llf\nfull_ll = (\n    smf.logit(\"Bonus ~ Gr_Liv_Area + C(Central_Air) + C(Fireplaces)\", data=train)\n    .fit()\n    .llf\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWarning: Maximum number of iterations has been exceeded.\n         Current function value: 0.425703\n         Iterations: 35\n\n/opt/homebrew/Caskroom/miniconda/base/envs/msa/lib/python3.11/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\n```\n:::\n\n```{.python .cell-code}\nLR_stat = -2 * (reduced_ll - full_ll)\np_val = sp.stats.chi2.sf(LR_stat, 4)\np_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n8.181135706933704e-13\n```\n:::\n:::\n\n:::\n\n# Assumptions\n\nUnlike categorical variables, we need to test for linearity of the continuous variables with the logit.\n\n## General Additive Model (GAM)\n\nThe idea: We want to fit the best curve for our target and then we run a statistical test to see if it our fitted curve is any better than just a straight line relationship. If it is better, then our assumption of linearity is not met.\n\nTraditional logistic regression model:\n\n$$\n\\log(odds) = \\beta_0 + \\beta_1x_{1,i} + \\cdots + \\beta_kx_{k,i}\n$$\n\nGAM logistic regression model:\n\n$$\n\\log(odds) = \\beta_0 + f_1(x_{1,i}) + \\cdots + f_k(x_{k,i})\n$$\n\n::: {.panel-tabset group=\"language\"}\n# R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mgcv)\nfit_gam <- gam(Bonus ~ s(Gr_Liv_Area) + factor(Central_Air), data = train, family = binomial(link = \"logit\"), method = \"REML\")\n\nsummary(fit_gam)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFamily: binomial \nLink function: logit \n\nFormula:\nBonus ~ s(Gr_Liv_Area) + factor(Central_Air)\n\nParametric coefficients:\n                     Estimate Std. Error z value Pr(>|z|)    \n(Intercept)           -4.4616     0.5033  -8.864  < 2e-16 ***\nfactor(Central_Air)Y   3.4882     0.4911   7.103 1.22e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                 edf Ref.df Chi.sq p-value    \ns(Gr_Liv_Area) 6.221  7.232  380.4  <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =   0.43   Deviance explained =   39%\n-REML = 859.46  Scale est. = 1         n = 2051\n```\n:::\n\n```{.r .cell-code}\nplot(fit_gam)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nThe spline p-value is not telling us whether our assumption is met or not. It tells us whether or not the splined variable is significant in the model.\n\n`edf` in the splined variable is the polynomial degree that the fit thinks we should have. In theory, if the relationship was close to a straight line then `edf` would be close to 1.\n\nHow do we actually test if our variable satisfies the linearity assumption?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(logit_model, fit_gam, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table\n\nModel 1: Bonus ~ Gr_Liv_Area + factor(Central_Air)\nModel 2: Bonus ~ s(Gr_Liv_Area) + factor(Central_Air)\n  Resid. Df Resid. Dev     Df Deviance  Pr(>Chi)    \n1    2048.0     1808.8                              \n2    2042.8     1692.3 5.2212   116.58 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nIf our p-value is significant, then it means our two models are significantly different. If our two models are significantly different, then our curve model is providing more information than a straight line. Assumption is not met.\n\nIn conclusion, high p-value means our assumption is met, else not met.\n\n# Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom statsmodels.gam.api import GLMGam, BSplines\n\nx_spline = train[\"Gr_Liv_Area\"]\n\nbs = BSplines(x_spline, df=5, degree=2)\ngam_model = GLMGam.from_formula(\n    \"Bonus ~ C(Central_Air)\", data=train, smoother=bs, family=Binomial()\n).fit()\n\ngam_model.summary()\n```\n\n::: {.cell-output-display}\n```{=html}\n<table class=\"simpletable\">\n<caption>Generalized Linear Model Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>         <td>Bonus</td>      <th>  No. Observations:  </th>  <td>  2051</td> \n</tr>\n<tr>\n  <th>Model:</th>                <td>GLMGam</td>      <th>  Df Residuals:      </th> <td> 2045.00</td>\n</tr>\n<tr>\n  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th> <td>    5.00</td>\n</tr>\n<tr>\n  <th>Link Function:</th>         <td>Logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n</tr>\n<tr>\n  <th>Method:</th>                <td>PIRLS</td>      <th>  Log-Likelihood:    </th> <td> -846.90</td>\n</tr>\n<tr>\n  <th>Date:</th>            <td>Fri, 15 Sep 2023</td> <th>  Deviance:          </th> <td>  1693.8</td>\n</tr>\n<tr>\n  <th>Time:</th>                <td>16:47:56</td>     <th>  Pearson chi2:      </th> <td>1.84e+03</td>\n</tr>\n<tr>\n  <th>No. Iterations:</th>         <td>11</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.4100</td> \n</tr>\n<tr>\n  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n           <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>Intercept</th>           <td>  -43.0155</td> <td>   13.367</td> <td>   -3.218</td> <td> 0.001</td> <td>  -69.215</td> <td>  -16.816</td>\n</tr>\n<tr>\n  <th>C(Central_Air)[T.Y]</th> <td>    3.5085</td> <td>    0.490</td> <td>    7.160</td> <td> 0.000</td> <td>    2.548</td> <td>    4.469</td>\n</tr>\n<tr>\n  <th>Gr_Liv_Area_s0</th>      <td>   35.2886</td> <td>   13.706</td> <td>    2.575</td> <td> 0.010</td> <td>    8.425</td> <td>   62.153</td>\n</tr>\n<tr>\n  <th>Gr_Liv_Area_s1</th>      <td>   39.4951</td> <td>   13.318</td> <td>    2.966</td> <td> 0.003</td> <td>   13.393</td> <td>   65.597</td>\n</tr>\n<tr>\n  <th>Gr_Liv_Area_s2</th>      <td>   45.8674</td> <td>   13.501</td> <td>    3.397</td> <td> 0.001</td> <td>   19.406</td> <td>   72.329</td>\n</tr>\n<tr>\n  <th>Gr_Liv_Area_s3</th>      <td>   38.8671</td> <td>   13.376</td> <td>    2.906</td> <td> 0.004</td> <td>   12.651</td> <td>   65.083</td>\n</tr>\n</table>\n```\n:::\n:::\n\n\nWe can compare our spline model with the linear representation of `Gr_Liv_Area` using a Chi-square test to see if any value is added from the spline:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nreduced_ll = logit_model.llf\nfull_ll = gam_model.llf\n\nLR_statistic = -2 * (reduced_ll - full_ll)\nLR_statistic\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n115.04641517091682\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\np_val = sp.stats.chi2.sf(LR_statistic, 3)\np_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n8.99687925869741e-25\n```\n:::\n:::\n\n\n:::\n\n### Linearity Assumption Failed?\n\n1.  Use GAM logistic model instead with more limited interpretation on variables that break assumption\n2.  Bin the continuous variables that break assumption (keeps interpretation)\n\n![Binning Continuous Variable](images/continuous-binning.png)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain <- train %>%\n    mutate(Gr_Liv_Area_BIN = cut(Gr_Liv_Area, breaks = c(-Inf, 1000, 1500, 3000, 4500, Inf)))\n\nlogit_model_bin <- glm(Bonus ~ factor(Gr_Liv_Area_BIN) + factor(Central_Air), data = train, family = binomial())\nsummary(logit_model_bin)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = Bonus ~ factor(Gr_Liv_Area_BIN) + factor(Central_Air), \n    family = binomial(), data = train)\n\nCoefficients:\n                                       Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                             -8.8210     1.1065  -7.972 1.56e-15 ***\nfactor(Gr_Liv_Area_BIN)(1e+03,1.5e+03]   4.5121     1.0052   4.489 7.16e-06 ***\nfactor(Gr_Liv_Area_BIN)(1.5e+03,3e+03]   6.6437     1.0049   6.611 3.81e-11 ***\nfactor(Gr_Liv_Area_BIN)(3e+03,4.5e+03]  21.1646   363.8508   0.058  0.95361    \nfactor(Gr_Liv_Area_BIN)(4.5e+03, Inf]    5.5986     1.7331   3.230  0.00124 ** \nfactor(Central_Air)Y                     3.2224     0.4734   6.807 9.95e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2775.8  on 2050  degrees of freedom\nResidual deviance: 1892.0  on 2045  degrees of freedom\nAIC: 1904\n\nNumber of Fisher Scoring iterations: 14\n```\n:::\n:::\n\n\nNote that binning a continuous variable results in an *ordinal* variable.\n\n# Predicted Values\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_ames <- data.frame(Gr_Liv_Area = c(1500, 2000, 2250, 2500, 3500), Central_Air = c(\"N\", \"Y\", \"Y\", \"N\", \"Y\"))\n\nnew_ames <- data.frame(new_ames, \"Pred\" = predict(logit_model, newdata = new_ames, type = \"response\"))\nprint(new_ames)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Gr_Liv_Area Central_Air       Pred\n1        1500           N 0.01498152\n2        2000           Y 0.86084436\n3        2250           Y 0.94534188\n4        2500           N 0.48167577\n5        3500           Y 0.99966165\n```\n:::\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}