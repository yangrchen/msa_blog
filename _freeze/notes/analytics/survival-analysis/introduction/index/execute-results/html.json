{
  "hash": "dd3bf0db52799780f203f122c03a226a",
  "result": {
    "markdown": "---\ntitle: Censoring, Survival, and Hazards\ndate: 10/30/2023\n---\n\n\n# Setup {.unnumbered}\n\n:::{.panel-tabset}\n# R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(survival)\nlibrary(foreign)\nlibrary(ggplot2)\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'dplyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n:::\n\n```{.r .cell-code}\nlibrary(reticulate)\nlibrary(readr)\nlibrary(survminer)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: ggpubr\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'survminer'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:survival':\n\n    myeloma\n```\n:::\n\n```{.r .cell-code}\nuse_condaenv(\"msa\")\n```\n:::\n\n\n# Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sksurv.nonparametric import kaplan_meier_estimator\nfrom lifelines import KaplanMeierFitter\nfrom lifelines import NelsonAalenFitter\n```\n:::\n\n\n:::\n\n# What is Survival Analysis?\n\nSurvival analysis is a branch of statistics that deals with the analysis of time-to-event data. The event can be anything that occurs at a specific point in time, such as death, injury, or failure.\n\n**Time** generally refers to **tenure** rather than actual calendar time. The **event** is some specific outcome of interest:\n\n-   Customer cancel service\n-   Customer makes another purchase\n-   Patient develops disease\n\nCompare this to logistic regression, where we are studying if the event happened or not. Survival analysis is studying how long it took for the event to happen.\n\n## Numeric Target\n\nWe can't use OLS for time-to-event data due to **censoring**. For some observations, the event may never occur or has not happened yet. Tenure is also always positive and the risk of failure can change over time--not a linear relationship.\n\n## Data Structure\n\nSurvival analysis splits the target variable into two pieces: a continuous and a categorical variable.\n\n-   **Time**: Tenure for an observation\n-   **Event**: At the end of that time, what happened?\n\nUsing the Maryland Recidivism Data, we want to model the association between various factors and length of time before re-arrest.\n\n-   **Week**: Week of arrest - week which equals 52 is not arrested\n-   **Arrest**: Indicator for arrest (1 = yes, 0 = no)\n\nPredictors:\n\n-   **fin**: Received financial aid upon release (1 = yes, 0 = no)\n-   **age**: Age at time of release (years)\n-   **race**: Indicator for African American (1 = yes, 0 = no)\n-   **wexp**: Indicator of prior work experience prior to incarceration (1 = yes, 0 = no)\n-   **mar**: Married at time of release (1 = yes, 0 = no)\n-   **paro**: Released on parole (1 = yes, 0 = no)\n-   **prio**: Number of prior convictions\n\n# Time and Censoring\n\nSurvival analysis depends on a few assumptions:\n\n-   Every observation starts at the same time since we are not interested in time, but tenure\n-   We are interested in time to event $T$, but we can not observe this for all observations--they are censored\n    -   We take the minimum between $T_i$ and the censoring time $C_i$\n\n:::{layout-ncol=\"2\"}\n![Time vs. Tenure](images/time-vs-tenure.png){#fig-time-vs-tenure}\n\n![Data Structure](images/data-structure.png){#fig-data-structure}\n:::\n\nCensored data is **NOT** missing data. We do not know the actual time to event $T_i$ for censored observations. We only know that for some amount of time the event has not occurred. Data is incomplete, but not missing.\n\n## Types of Censoring\n\n**Type I** censoring is where there is an end time $c$ and any subject that hasn't had the event by time **c** is censored.\n\n**Type II** censoring is where time goes until a certain number of events have occurred and any subjects who haven't had the event by that time are censored.\n\n### Right, Left, and Interval Censoring\n\nObservation is **right censored** when $T > c$. An example is when a clinical trial ends and patient is still alive. Censoring is noninformative--patients who are censored should have the same future risk for the event happening, conditional on exposure, as those who continue to be followed.\n\nObservation is **left censored** when $T < c$. An example is whne a customer enrolled more than 3 years ago. A new customer tracking system was implemented, but current customers were around before.\n\n**Interval censoring** is where $a < T < b$. An example is when a person tests negative during appointment at $a$, but positive during appointment at $b$. So time developing disease occurs between $a$ and $b$.\n\n# Survival Function\n\nSurvival analysis is described in two major quantities: **survival function** and **hazard function**.\n\nSurvival function: Probability of surviving **beyond** time $t$.\n\n$$\nS(t) = P(T > t)\n$$\n\n-   Always starts at 1\n-   Never increases\n-   Bounded below by 0\n\n## Kaplan-Meier Estimator\n\nThe Kaplan-Meier estimator is a non-parametric estimator of the survival function. It is a product of the survival probabilities at each time point. We want to estimate the proportion of individuals \"still alive\" at any given time $t$.\n\n$$\n\\hat{S}(t) = \\prod_{k \\leq t} \\left(1 - \\frac{d_k}{r_k}\\right)\n$$\n\n-   $d_k$ is the number of events occurring at time $t$\n-   $r_k$ is the number of observations available right before time $t$ (**risk set**)\n\nNote that censored individuals are initially included in the risk set up until the point of censoring.\n\n![Calculating K-M Estimate](images/km-estimate.png){#fig-km-estimate}\n\n## Summary Statistics\n\nDue to censoring, mean is difficult to estimate but the **median** is still valid as long as the event occurs for at least half of the sample.\n\nThe median is the **half-life** or the time $t$ that $\\hat{S}(t)$ drops below 0.5. The half-life interpretation is that 50% of observations survive beyond time $t$.\n\n:::{.panel-tabset}\n# R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecid <- read_csv(\"https://raw.githubusercontent.com/sjsimmo2/Survival/master/recid.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 432 Columns: 63\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (63): week, arrest, fin, age, race, wexp, mar, paro, prio, educ, emp1, e...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nsimple <- data.frame(matrix(c(7, 8, 10, 3, 2, 3, 1, 1, 0, 1, 1, 0), ncol = 2))\ncolnames(simple) <- c(\"tenure\", \"censored\")\n\nsimple_s <- Surv(time = simple$tenure, event = simple$censored)\n```\n:::\n\n\nTo perform Kaplan-Meier:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimple_km <- survfit(Surv(time = tenure, event = censored) ~ 1, data = simple)\nsummary(simple_km)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall: survfit(formula = Surv(time = tenure, event = censored) ~ 1, \n    data = simple)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    2      6       1    0.833   0.152       0.5827            1\n    3      5       1    0.667   0.192       0.3786            1\n    7      3       1    0.444   0.222       0.1668            1\n    8      2       1    0.222   0.192       0.0407            1\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(simple_km, main = \"Survival Function\", xlab = \"Tenure\", ylab = \"Survival Probability\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrecid_fit <- survfit(Surv(time = week, event = arrest) ~ 1, data = recid)\nsummary(recid_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall: survfit(formula = Surv(time = week, event = arrest) ~ 1, data = recid)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    1    432       1    0.998 0.00231        0.993        1.000\n    2    431       1    0.995 0.00327        0.989        1.000\n    3    430       1    0.993 0.00400        0.985        1.000\n    4    429       1    0.991 0.00461        0.982        1.000\n    5    428       1    0.988 0.00515        0.978        0.999\n    6    427       1    0.986 0.00563        0.975        0.997\n    7    426       1    0.984 0.00607        0.972        0.996\n    8    425       5    0.972 0.00791        0.957        0.988\n    9    420       2    0.968 0.00852        0.951        0.984\n   10    418       1    0.965 0.00881        0.948        0.983\n   11    417       2    0.961 0.00935        0.942        0.979\n   12    415       2    0.956 0.00987        0.937        0.976\n   13    413       1    0.954 0.01011        0.934        0.974\n   14    412       3    0.947 0.01080        0.926        0.968\n   15    409       2    0.942 0.01123        0.920        0.964\n   16    407       2    0.937 0.01165        0.915        0.961\n   17    405       3    0.931 0.01223        0.907        0.955\n   18    402       3    0.924 0.01278        0.899        0.949\n   19    399       2    0.919 0.01313        0.894        0.945\n   20    397       5    0.907 0.01395        0.880        0.935\n   21    392       2    0.903 0.01425        0.875        0.931\n   22    390       1    0.900 0.01440        0.873        0.929\n   23    389       1    0.898 0.01455        0.870        0.927\n   24    388       4    0.889 0.01512        0.860        0.919\n   25    384       3    0.882 0.01552        0.852        0.913\n   26    381       3    0.875 0.01591        0.844        0.907\n   27    378       2    0.870 0.01616        0.839        0.903\n   28    376       2    0.866 0.01640        0.834        0.898\n   30    374       2    0.861 0.01664        0.829        0.894\n   31    372       1    0.859 0.01675        0.827        0.892\n   32    371       2    0.854 0.01698        0.822        0.888\n   33    369       2    0.850 0.01720        0.816        0.884\n   34    367       2    0.845 0.01742        0.811        0.880\n   35    365       4    0.836 0.01783        0.801        0.871\n   36    361       3    0.829 0.01813        0.794        0.865\n   37    358       4    0.819 0.01851        0.784        0.857\n   38    354       1    0.817 0.01860        0.781        0.854\n   39    353       2    0.812 0.01878        0.777        0.850\n   40    351       4    0.803 0.01913        0.767        0.842\n   42    347       2    0.799 0.01929        0.762        0.837\n   43    345       4    0.789 0.01962        0.752        0.829\n   44    341       2    0.785 0.01977        0.747        0.824\n   45    339       2    0.780 0.01993        0.742        0.820\n   46    337       4    0.771 0.02022        0.732        0.812\n   47    333       1    0.769 0.02029        0.730        0.809\n   48    332       2    0.764 0.02043        0.725        0.805\n   49    330       5    0.752 0.02077        0.713        0.794\n   50    325       3    0.745 0.02096        0.705        0.788\n   52    322       4    0.736 0.02121        0.696        0.779\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggsurvplot(recid_fit, data = recid, conf.int = TRUE, palette = \"purple\", xlab = \"Week\", ylab = \"Survival Probability\", legend = \"none\", break.y.by = 0.1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n# Python\n\n\n::: {.cell}\n\n:::\n\n\n:::\n\n# Stratified Analysis\n\nWe can also create separate / stratified curves by group. Different curves result in different estimates for each group.\n\nR provides 2 tests that each have the same null hypothesis--all survival curves are **equal** and alternative is that at least one curve is different.\n\n1.  Log-rank Test\n2.  Wilcoxon Test\n\n## Log-rank test\n\nCombines all the information from the K-M estimate at times where events occur.\n\nFor each group, calculate expected events and compare to observed events. This is a $\\chi^2$ statistic with $k - 1$ degrees of freedom. \n\n![Log-rank Tests](images/log-rank.png){#fig-log-rank}\n\n## Wilcoxon Test\n\nSimilar to Log-rank test except that we now use weights. This test places larger emphasis on earlier event times.\n\n# Hazard Function\n\nThe **hazard function** is the instantaneous rate of failure at time $t$ given that the individual has survived up to time $t$.\n\nWe have two common types of hazard functions: harzard probabilities and hazard rates.\n\n## Hazard Probabilities\n\n$$\nh(t) = P(t < T < t + 1 | T > t)\n$$\n\nIn general, hazard probability can be interpreted as \"assuming the event has not occurred yet, this is the probability the events occurs by the next time point.\"\n\nAn example is that a customer has survived for a certain length of time, so the customer's tenure is $t$. What is the probability that the customer leaves before $t + 1$?\n\n:::{layout-ncol=\"2\"}\n![Hazard Probability Events](images/hazard-probability-events.png){#fig-hazard-probability-events}\n\n![Hazard Probability Calculations](images/hazard-probability-calculations.png){#fig-hazard-probability-calculations}\n:::\n\n## Hazard Rates\n$$\nh(t) = \\lim_{\\Delta t \\to 0} \\frac{P(t < T < t + \\Delta t | T > t)}{\\Delta t}\n$$\n\nHazard rates have a slightly different interpretation than hazard probabilities because they are limits. Hazard rates are the instantaneous event rate at time $t$ for the risk set at time $t$. \n\nThe inverse of the hazard function is the length of time before the next occurrence.\n\nThe **cumulative hazard probability** is just the total hazard rate up until time $t$--denoted by $\\Lambda(t)$.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}