{
  "hash": "4428c6a29b2468fac7baca95ac2b89ea",
  "result": {
    "markdown": "---\ntitle: Diagnostics and Subset Selection\ndate: 09/05/2023\n---\n\n\n# Setup\n\n::: {.panel-tabset}\n# R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(AmesHousing)\nlibrary(tidyverse)\nlibrary(reticulate)\n\nset.seed(123)\n\nuse_condaenv(\"msa\")\n\names <- make_ordinal_ames()\names <- ames |>\n    mutate(Bonus = ifelse(Sale_Price > 175000, 1, 0))\ntrain <- sample_frac(ames, 0.7)\n```\n:::\n\n\n# Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\names = r.ames\ntrain = r.train\n```\n:::\n\n:::\n\n# Subset Selection Methods\n\nJust like with linear regression, we can use normal stepwise selection techniques (forward, backward, stepwise) to get different models.\n\n::: {.panel-tabset}\n# R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_model <- glm(Bonus ~ Gr_Liv_Area + factor(House_Style) + Garage_Area + Fireplaces + factor(Full_Bath) + factor(Half_Bath) + Lot_Area + factor(Central_Air) + Second_Flr_SF + TotRms_AbvGrd + First_Flr_SF, data = train, family = binomial())\n\nempty_model <- glm(Bonus ~ 1, data = train, family = binomial())\n\nstep_model <- step(empty_model, scope = list(lower = formula(empty_model), upper = formula(full_model)), direction = \"both\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=2777.81\nBonus ~ 1\n\n                      Df Deviance    AIC\n+ factor(Full_Bath)    4   1911.5 1921.5\n+ Gr_Liv_Area          1   1926.4 1930.4\n+ Garage_Area          1   2135.4 2139.4\n+ First_Flr_SF         1   2294.1 2298.1\n+ Fireplaces           1   2423.7 2427.7\n+ TotRms_AbvGrd        1   2449.7 2453.7\n+ factor(House_Style)  7   2542.1 2558.1\n+ factor(Half_Bath)    2   2608.1 2614.1\n+ Lot_Area             1   2621.9 2625.9\n+ Second_Flr_SF        1   2631.8 2635.8\n+ factor(Central_Air)  1   2654.3 2658.3\n<none>                     2775.8 2777.8\n\nStep:  AIC=1921.48\nBonus ~ factor(Full_Bath)\n\n                      Df Deviance    AIC\n+ Garage_Area          1   1616.3 1628.3\n+ Fireplaces           1   1659.5 1671.5\n+ Gr_Liv_Area          1   1665.7 1677.7\n+ First_Flr_SF         1   1711.7 1723.7\n+ Lot_Area             1   1811.5 1823.5\n+ factor(Half_Bath)    2   1812.2 1826.2\n+ factor(Central_Air)  1   1827.6 1839.6\n+ factor(House_Style)  7   1822.3 1846.3\n+ TotRms_AbvGrd        1   1885.6 1897.6\n+ Second_Flr_SF        1   1908.2 1920.2\n<none>                     1911.5 1921.5\n- factor(Full_Bath)    4   2775.8 2777.8\n\nStep:  AIC=1628.26\nBonus ~ factor(Full_Bath) + Garage_Area\n\n                      Df Deviance    AIC\n+ Fireplaces           1   1440.9 1454.9\n+ Gr_Liv_Area          1   1481.3 1495.3\n+ First_Flr_SF         1   1540.6 1554.6\n+ factor(Half_Bath)    2   1546.5 1562.5\n+ factor(House_Style)  7   1571.5 1597.5\n+ factor(Central_Air)  1   1585.6 1599.6\n+ Lot_Area             1   1589.0 1603.0\n+ TotRms_AbvGrd        1   1606.6 1620.6\n+ Second_Flr_SF        1   1608.7 1622.7\n<none>                     1616.3 1628.3\n- Garage_Area          1   1911.5 1921.5\n- factor(Full_Bath)    4   2135.4 2139.4\n\nStep:  AIC=1454.86\nBonus ~ factor(Full_Bath) + Garage_Area + Fireplaces\n\n                      Df Deviance    AIC\n+ Gr_Liv_Area          1   1381.5 1397.5\n+ factor(Half_Bath)    2   1389.8 1407.8\n+ factor(House_Style)  7   1386.2 1414.2\n+ First_Flr_SF         1   1413.8 1429.8\n+ factor(Central_Air)  1   1426.2 1442.2\n+ Lot_Area             1   1435.1 1451.1\n+ Second_Flr_SF        1   1436.5 1452.5\n<none>                     1440.9 1454.9\n+ TotRms_AbvGrd        1   1440.3 1456.3\n- Fireplaces           1   1616.3 1628.3\n- Garage_Area          1   1659.5 1671.5\n- factor(Full_Bath)    4   1943.5 1949.5\n\nStep:  AIC=1397.55\nBonus ~ factor(Full_Bath) + Garage_Area + Fireplaces + Gr_Liv_Area\n\n                      Df Deviance    AIC\n+ factor(House_Style)  7   1310.0 1340.0\n+ TotRms_AbvGrd        1   1335.1 1353.1\n+ factor(Central_Air)  1   1354.3 1372.3\n+ factor(Half_Bath)    2   1356.4 1376.4\n+ First_Flr_SF         1   1368.2 1386.2\n+ Second_Flr_SF        1   1370.7 1388.7\n<none>                     1381.5 1397.5\n+ Lot_Area             1   1381.2 1399.2\n- Gr_Liv_Area          1   1440.9 1454.9\n- Fireplaces           1   1481.3 1495.3\n- Garage_Area          1   1546.1 1560.1\n- factor(Full_Bath)    4   1626.6 1634.6\n\nStep:  AIC=1339.99\nBonus ~ factor(Full_Bath) + Garage_Area + Fireplaces + Gr_Liv_Area + \n    factor(House_Style)\n\n                      Df Deviance    AIC\n+ factor(Half_Bath)    2   1261.2 1295.2\n+ TotRms_AbvGrd        1   1268.8 1300.8\n+ factor(Central_Air)  1   1288.2 1320.2\n<none>                     1310.0 1340.0\n+ Lot_Area             1   1309.7 1341.7\n+ Second_Flr_SF        1   1309.9 1341.9\n+ First_Flr_SF         1   1309.9 1341.9\n- factor(House_Style)  7   1381.5 1397.5\n- Gr_Liv_Area          1   1386.2 1414.2\n- Fireplaces           1   1394.8 1422.8\n- Garage_Area          1   1403.9 1431.9\n- factor(Full_Bath)    4   1511.2 1533.2\n\nStep:  AIC=1295.15\nBonus ~ factor(Full_Bath) + Garage_Area + Fireplaces + Gr_Liv_Area + \n    factor(House_Style) + factor(Half_Bath)\n\n                      Df Deviance    AIC\n+ TotRms_AbvGrd        1   1228.3 1264.3\n+ factor(Central_Air)  1   1248.4 1284.4\n+ First_Flr_SF         1   1259.0 1295.0\n<none>                     1261.2 1295.2\n+ Second_Flr_SF        1   1260.3 1296.3\n+ Lot_Area             1   1260.7 1296.7\n- factor(Half_Bath)    2   1310.0 1340.0\n- Gr_Liv_Area          1   1331.8 1363.8\n- Fireplaces           1   1335.7 1367.7\n- Garage_Area          1   1336.7 1368.7\n- factor(House_Style)  7   1356.4 1376.4\n- factor(Full_Bath)    4   1490.6 1516.6\n\nStep:  AIC=1264.3\nBonus ~ factor(Full_Bath) + Garage_Area + Fireplaces + Gr_Liv_Area + \n    factor(House_Style) + factor(Half_Bath) + TotRms_AbvGrd\n\n                      Df Deviance    AIC\n+ factor(Central_Air)  1   1218.9 1256.9\n<none>                     1228.3 1264.3\n+ First_Flr_SF         1   1226.7 1264.7\n+ Lot_Area             1   1227.3 1265.3\n+ Second_Flr_SF        1   1227.7 1265.7\n- TotRms_AbvGrd        1   1261.2 1295.2\n- factor(Half_Bath)    2   1268.8 1300.8\n- Fireplaces           1   1291.2 1325.2\n- Garage_Area          1   1294.7 1328.7\n- factor(House_Style)  7   1315.8 1337.8\n- Gr_Liv_Area          1   1330.3 1364.3\n- factor(Full_Bath)    4   1453.8 1481.8\n\nStep:  AIC=1256.88\nBonus ~ factor(Full_Bath) + Garage_Area + Fireplaces + Gr_Liv_Area + \n    factor(House_Style) + factor(Half_Bath) + TotRms_AbvGrd + \n    factor(Central_Air)\n\n                      Df Deviance    AIC\n<none>                     1218.9 1256.9\n+ First_Flr_SF         1   1217.7 1257.7\n+ Lot_Area             1   1218.0 1258.0\n+ Second_Flr_SF        1   1218.5 1258.5\n- factor(Central_Air)  1   1228.3 1264.3\n- TotRms_AbvGrd        1   1248.4 1284.4\n- factor(Half_Bath)    2   1253.1 1287.1\n- Fireplaces           1   1272.7 1308.7\n- Garage_Area          1   1272.9 1308.9\n- factor(House_Style)  7   1300.0 1324.0\n- Gr_Liv_Area          1   1324.1 1360.1\n- factor(Full_Bath)    4   1428.7 1458.7\n```\n:::\n:::\n\n:::\n\nWe don't use forward selection as much as it cannot remove variables from your model. Instead, we might favor backward selection or stepwise selection. When we decide on our main effects after data exploration, we can create interactions within our subset and use forward selection to see which interactions stay in our model.\n\n![Interactions with Forward Selection](images/forward-selection-interactions.png)\n\n# P-Value vs. AIC/BIC Metrics\n\nAIC is not necessarily better than p-values when determining variable significance:\n\n$$\nAIC = -2\\log(L) + 2p\n$$\n\nIf a model is better with a lower AIC:\n\n$$\n-2\\log(L_{p+1}) + 2(p + 1) < -2\\log(L_p) + 2p\n$$\n\nAIC does not adjust for sample size as the significance level, $\\alpha$, calculation is determined as:\n\n$$\n1 - P(\\chi_1^2 > 2) = 0.1573\n$$\n\nThis is a relatively high significance level and for large datasets does not seem like a good technique for selecting variables.\n\nBIC instead adjusts for sample size:\n\n$$\n1 - P(\\chi_1^2 > \\log(n)) =\\cdots\n$$\n\n![P-Value vs. BIC Selection](images/pvalue-bic.png)\n\n# Diagnostics\n\nLinear regression residuals have properties useful for model diagnostics. In a binary response model setting, we have residuals but they are not as intuitive.\n\n-   Deviance residuals\n-   Partial residuals\n-   Pearson residuals\n-   Etc.\n\n## Deviance\n\nThe model is a summary of a data set. A **saturated** model fits the data perfectly but is not a useful summary. **Deviance** is a measure of how far the fitted model is from the saturated model--the error. Logistic regression minimizes the sum of squared deviances.\n\nDeviance residuals tell us how much each observation reduces the deviance.\n\n## Influence Statistics\n\n-   Cook's D\n    -   Measures the overall impact to the coefficients in the model\n-   DFBETAS\n    -   Measures standardized change in each parameter estimate with deletion of observation\n-   DIFCHISQ\n    -   Measures change in Pearson Chi-square with deletion of observation\n-   DIFDEV\n    -   Measures change in deviance with deletion of the observation\n\n::: {.panel-tabset}\n# R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\n\nlogit_model <- glm(Bonus ~ Gr_Liv_Area + factor(House_Style) + Garage_Area + Fireplaces + factor(Full_Bath) + Lot_Area + factor(Central_Air) + TotRms_AbvGrd + Gr_Liv_Area:Fireplaces, data = train, family = binomial())\n\n# influence.measures(logit_model)\n```\n:::\n\n\nTo plot Cook's D:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(logit_model, 4)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nTo plot DFBETAS:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndfbetasPlots(logit_model, terms = \"Gr_Liv_Area\", id.n = 5, col = ifelse(logit_model$y == 1, \"red\", \"blue\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n# Python\n:::\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}