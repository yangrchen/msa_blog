[
  {
    "objectID": "notes/analytics/06302023/lab_4.html",
    "href": "notes/analytics/06302023/lab_4.html",
    "title": "1 1",
    "section": "",
    "text": "1 1\n\n\nCode\nlibrary(AppliedPredictiveModeling)\ndata(FuelEconomy)\n\n\n\n\nCode\ncor(cars2010[, c(\"EngDispl\", \"NumCyl\", \"ExhaustValvesPerCyl\", \"VarValveTiming\", \"FE\")])\n\n\n                       EngDispl       NumCyl ExhaustValvesPerCyl VarValveTiming\nEngDispl             1.00000000  0.906260027          -0.4784380   -0.068256030\nNumCyl               0.90626003  1.000000000          -0.3398518    0.005399291\nExhaustValvesPerCyl -0.47843804 -0.339851831           1.0000000    0.279339052\nVarValveTiming      -0.06825603  0.005399291           0.2793391    1.000000000\nFE                  -0.78739383 -0.740217981           0.3356529    0.124952779\n                            FE\nEngDispl            -0.7873938\nNumCyl              -0.7402180\nExhaustValvesPerCyl  0.3356529\nVarValveTiming       0.1249528\nFE                   1.0000000\n\n\nCode\npairs(cars2010[, c(\"EngDispl\", \"NumCyl\", \"ExhaustValvesPerCyl\", \"VarValveTiming\", \"FE\")])\n\n\n\n\n\nCode\nengdispl_lm &lt;- lm(FE ~ EngDispl, data = cars2010)\npar(nfrow = c(2, 2))\n\n\nWarning in par(nfrow = c(2, 2)): \"nfrow\" is not a graphical parameter\n\n\nCode\nplot(engdispl_lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsummary(engdispl_lm)\n\n\n\nCall:\nlm(formula = FE ~ EngDispl, data = cars2010)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-14.486  -3.192  -0.365   2.671  27.215 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  50.5632     0.3985  126.89   &lt;2e-16 ***\nEngDispl     -4.5209     0.1065  -42.46   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.624 on 1105 degrees of freedom\nMultiple R-squared:   0.62, Adjusted R-squared:  0.6196 \nF-statistic:  1803 on 1 and 1105 DF,  p-value: &lt; 2.2e-16\n\n\n\nHighest correlation with FE is EnglDispl\n\n\n\nCode\ncor.test(cars2010$FE, cars2010$EngDispl)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  cars2010$FE and cars2010$EngDispl\nt = -42.46, df = 1105, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.8087913 -0.7639144\nsample estimates:\n       cor \n-0.7873938 \n\n\n\nP-value is significant at a 0.05 level and we have evidence that the correlation coefficient is not equal to 0\n\n\n\nCode\ncor(cars2010[, c(\"EngDispl\", \"NumCyl\", \"ExhaustValvesPerCyl\", \"VarValveTiming\")])\n\n\n                       EngDispl       NumCyl ExhaustValvesPerCyl VarValveTiming\nEngDispl             1.00000000  0.906260027          -0.4784380   -0.068256030\nNumCyl               0.90626003  1.000000000          -0.3398518    0.005399291\nExhaustValvesPerCyl -0.47843804 -0.339851831           1.0000000    0.279339052\nVarValveTiming      -0.06825603  0.005399291           0.2793391    1.000000000\n\n\n\nEnglDispl and NumCyl have a large correlation between one another\n\n\n\nCode\nslr &lt;- lm(FE ~ EngDispl, cars2010)\nsummary(slr)$r.squared\n\n\n[1] 0.619989\n\n\n\nF-statistic is 1803 with a p-value of 2.2e-16. Overall model is significant\n\\(y = 50.5632 - 4.5209x_1\\)\n\\(R^2\\) is 0.620 which means that 62% of the variability in FE can be explained by EngDispl alone\n\n\n\n2 2\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(ggplot2)\nicecream &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/icecream.csv\", sep = \" \")\nglimpse(icecream)\n\n\nRows: 50\nColumns: 2\n$ Temperature &lt;int&gt; 65, 87, 78, 68, 98, 86, 62, 86, 71, 85, 78, 90, 63, 80, 80…\n$ Sales       &lt;dbl&gt; 180.25, 218.75, 202.44, 176.50, 212.18, 210.68, 165.30, 22…\n\n\n\n\nCode\nsales_slr &lt;- lm(Sales ~ Temperature, icecream)\npar(mfrow = c(2, 2))\nplot(sales_slr)\n\n\n\n\n\nCode\nggplot(icecream, aes(x = Temperature, y = Sales)) +\n    geom_point() +\n    stat_smooth(method = \"lm\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nCode\nsummary(sales_slr)\n\n\n\nCall:\nlm(formula = Sales ~ Temperature, data = icecream)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-21.603  -8.159   1.005   7.212  23.666 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 119.3895    10.1931  11.713 1.12e-15 ***\nTemperature   1.0889     0.1241   8.771 1.54e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.07 on 48 degrees of freedom\nMultiple R-squared:  0.6158,    Adjusted R-squared:  0.6078 \nF-statistic: 76.94 on 1 and 48 DF,  p-value: 1.543e-11\n\n\n\nResiduals seem to be Normally distributed from the QQ-Plot\nError variance is constant and does not show a pattern\nLinearity of the mean\nOverall F-test is significant so Temperature seems to be significant in explaining Sales\nParameter estimate for Temperature is 1.0889\n\n\n\n3 3\n\n\nCode\nminntemp &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/minntemp.csv\", sep = \" \")\nglimpse(minntemp)\n\n\nRows: 795\nColumns: 3\n$ Temp   &lt;dbl&gt; 73.04, 73.04, 73.04, 69.98, 69.08, 69.98, 69.98, 71.96, 75.02, …\n$ TimeSq &lt;int&gt; 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, …\n$ Time   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, …\n\n\n\n\nCode\ntemp_slr &lt;- lm(Temp ~ Time, minntemp)\npar(mfrow = c(2, 2))\nplot(temp_slr)\n\n\n\n\n\nCode\nggplot(minntemp, aes(x = Time, y = Temp)) +\n    geom_point() +\n    stat_smooth(method = \"lm\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nCode\nsummary(temp_slr)\n\n\n\nCall:\nlm(formula = Temp ~ Time, data = minntemp)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-20.8189  -5.4495  -0.5359   5.1432  21.1455 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 70.755366   0.588230 120.285   &lt;2e-16 ***\nTime         0.002301   0.001280   1.797   0.0727 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.285 on 793 degrees of freedom\nMultiple R-squared:  0.004056,  Adjusted R-squared:  0.0028 \nF-statistic: 3.229 on 1 and 793 DF,  p-value: 0.07271\n\n\n\nNo linearity of the mean, seems quadratic\nNo constant variance\nNormally distributed errors\nNo statistical evidence that time is related to temperature at a confidence level of 0.05"
  },
  {
    "objectID": "notes/analytics/06302023/index.html",
    "href": "notes/analytics/06302023/index.html",
    "title": "Ordinary Least Squares Regression",
    "section": "",
    "text": "Pearson’s correlation measures linear relationships.\n\n\n\nPearson’s Correlation Scenarios\n\n\n\n\nParameter representing population correlation is \\(\\rho\\) and is estimated by \\(r\\)\n\\(H_0: \\rho = 0\\)\nHowever, rejecting \\(H_0\\) only means that \\(\\rho\\) is not exactly 0 so we need to see if the relationship is practically significant.\nNote that outliers affect correlation and correlation does not imply causation.\n\n\n\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(AmesHousing)\n\names &lt;- make_ordinal_ames()\nset.seed(123)\names &lt;- ames |&gt; mutate(id = row_number())\ntrain &lt;- ames |&gt; sample_frac(0.7)\ntest &lt;- anti_join(ames, train, by = \"id\")\n\ndim(train)\n\n\n[1] 2051   82\n\n\nCode\ndim(test)\n\n\n[1] 879  82\n\n\n\n\nCode\ncor.test(train$Gr_Liv_Area, train$Sale_Price)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  train$Gr_Liv_Area and train$Sale_Price\nt = 44.185, df = 2049, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6756538 0.7200229\nsample estimates:\n     cor \n0.698509 \n\n\n\n\n\n\n\nCode\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\n\ndata = pd.read_csv(\"data/AmesHousing.csv\")\n\ntrain, test = train_test_split(data, test_size=0.3, random_state=123)\n\n\n\n\nCode\nnp.corrcoef(train['Gr Liv Area'], train['SalePrice'])\n\n\narray([[1.        , 0.69584201],\n       [0.69584201, 1.        ]])\n\n\nCode\nnp.corrcoef(train[['Year Built', 'Total Bsmt SF', '1st Flr SF', 'Gr Liv Area']], rowvar=False)\n\n\narray([[1.        , 0.42722628, 0.32717559, 0.23863599],\n       [0.42722628, 1.        , 0.80658329, 0.45383515],\n       [0.32717559, 0.80658329, 1.        , 0.57135986],\n       [0.23863599, 0.45383515, 0.57135986, 1.        ]])\n\n\n\n\n\nA strong correlation does not mean that a change in one variable causes a change in the other."
  },
  {
    "objectID": "notes/analytics/06302023/index.html#hypothesis-test-for-correlation",
    "href": "notes/analytics/06302023/index.html#hypothesis-test-for-correlation",
    "title": "Ordinary Least Squares Regression",
    "section": "",
    "text": "Parameter representing population correlation is \\(\\rho\\) and is estimated by \\(r\\)\n\\(H_0: \\rho = 0\\)\nHowever, rejecting \\(H_0\\) only means that \\(\\rho\\) is not exactly 0 so we need to see if the relationship is practically significant.\nNote that outliers affect correlation and correlation does not imply causation."
  },
  {
    "objectID": "notes/analytics/06302023/index.html#test-of-correlation-in-r",
    "href": "notes/analytics/06302023/index.html#test-of-correlation-in-r",
    "title": "Ordinary Least Squares Regression",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(AmesHousing)\n\names &lt;- make_ordinal_ames()\nset.seed(123)\names &lt;- ames |&gt; mutate(id = row_number())\ntrain &lt;- ames |&gt; sample_frac(0.7)\ntest &lt;- anti_join(ames, train, by = \"id\")\n\ndim(train)\n\n\n[1] 2051   82\n\n\nCode\ndim(test)\n\n\n[1] 879  82\n\n\n\n\nCode\ncor.test(train$Gr_Liv_Area, train$Sale_Price)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  train$Gr_Liv_Area and train$Sale_Price\nt = 44.185, df = 2049, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6756538 0.7200229\nsample estimates:\n     cor \n0.698509"
  },
  {
    "objectID": "notes/analytics/06302023/index.html#pearson-in-python",
    "href": "notes/analytics/06302023/index.html#pearson-in-python",
    "title": "Ordinary Least Squares Regression",
    "section": "",
    "text": "Code\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\n\ndata = pd.read_csv(\"data/AmesHousing.csv\")\n\ntrain, test = train_test_split(data, test_size=0.3, random_state=123)\n\n\n\n\nCode\nnp.corrcoef(train['Gr Liv Area'], train['SalePrice'])\n\n\narray([[1.        , 0.69584201],\n       [0.69584201, 1.        ]])\n\n\nCode\nnp.corrcoef(train[['Year Built', 'Total Bsmt SF', '1st Flr SF', 'Gr Liv Area']], rowvar=False)\n\n\narray([[1.        , 0.42722628, 0.32717559, 0.23863599],\n       [0.42722628, 1.        , 0.80658329, 0.45383515],\n       [0.32717559, 0.80658329, 1.        , 0.57135986],\n       [0.23863599, 0.45383515, 0.57135986, 1.        ]])"
  },
  {
    "objectID": "notes/analytics/06302023/index.html#correlation-does-not-imply-causation",
    "href": "notes/analytics/06302023/index.html#correlation-does-not-imply-causation",
    "title": "Ordinary Least Squares Regression",
    "section": "",
    "text": "A strong correlation does not mean that a change in one variable causes a change in the other."
  },
  {
    "objectID": "notes/analytics/06302023/index.html#explained-vs.-unexplained-variability",
    "href": "notes/analytics/06302023/index.html#explained-vs.-unexplained-variability",
    "title": "Ordinary Least Squares Regression",
    "section": "2.1 Explained vs. Unexplained Variability",
    "text": "2.1 Explained vs. Unexplained Variability\nWe are trying to explain variation in the response variable. We can’t explain all of it due to random, uncontrollable error but we can model it.\n\n\n\nVariability Explained in SLR\n\n\nWith linear regression, we are trying to minimize a loss function called sum of squared errors:\n\\[\nSSE = \\sum_{i=1}^{n} (y_i - \\hat{y}_i) ^2\n\\]\n\nThis makes up the amount of unexplained variability in our model"
  },
  {
    "objectID": "notes/analytics/06302023/index.html#the-baseline-model",
    "href": "notes/analytics/06302023/index.html#the-baseline-model",
    "title": "Ordinary Least Squares Regression",
    "section": "2.2 The Baseline Model",
    "text": "2.2 The Baseline Model\n\n\\(H_0: \\beta_1 = 0\\)\n\\(H_a: \\beta_1 \\neq 0\\)\n\nFor SLR, the global F-Test, parameter t-test and the test of Pearson’s correlation are all equivalent.\nWhen we can’t reject the null hypothesis we are essentially saying that the independent variable doesn’t explain any of the variability in the response."
  },
  {
    "objectID": "notes/analytics/06302023/index.html#assumptions-of-simple-linear-regression",
    "href": "notes/analytics/06302023/index.html#assumptions-of-simple-linear-regression",
    "title": "Ordinary Least Squares Regression",
    "section": "2.3 Assumptions of Simple Linear Regression",
    "text": "2.3 Assumptions of Simple Linear Regression\n\nLinearity of the mean\n\nAs I change values in the independent variable, the line should go through the mean of the response linearly\n\nErrors are normally distributed\nErrors have equal variance (homoskedasticity)\nErrors are independent\n\n\n2.3.1 Testing of Assumptions\n\nNormality can use a histogram, QQ-Plot or normality test\nEqual variances can use residuals versus predicted values\nIndependence can look at residual plots for potential autocorrelation\nLinearity in the mean can be tested through a residual plot and finding that there is no pattern in residual plot\n\n\n\nCode\nslr &lt;- lm(Sale_Price ~ Gr_Liv_Area, data = train)\npar(mfrow = c(2, 2))\n\nplot(slr)\n\n\n\n\n\nCode\nsummary(slr)\n\n\n\nCall:\nlm(formula = Sale_Price ~ Gr_Liv_Area, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-478762  -30030   -1405   22273  335855 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 14045.872   3942.503   3.563 0.000375 ***\nGr_Liv_Area   110.726      2.506  44.185  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 57430 on 2049 degrees of freedom\nMultiple R-squared:  0.4879,    Adjusted R-squared:  0.4877 \nF-statistic:  1952 on 1 and 2049 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nCode\nimport statsmodels.formula.api as smf\n\ntrain = train.rename(columns={\"Gr Liv Area\": \"Gr_Liv_Area\"})\nmodel_slr = smf.ols(\"SalePrice ~ Gr_Liv_Area\", data=train).fit()\n\nmodel_slr.pvalues\n\n\nIntercept       8.540663e-05\nGr_Liv_Area    6.980208e-297\ndtype: float64"
  },
  {
    "objectID": "notes/analytics/06272023/lab_1.html",
    "href": "notes/analytics/06272023/lab_1.html",
    "title": "Lab 1",
    "section": "",
    "text": "Code\nlibrary(UsingR)\n\n\nLoading required package: MASS\n\n\nLoading required package: HistData\n\n\nLoading required package: Hmisc\n\n\n\nAttaching package: 'Hmisc'\n\n\nThe following objects are masked from 'package:base':\n\n    format.pval, units\n\n\nCode\nlibrary(ggplot2)\ndata(normtemp)\nstr(normtemp)\n\n\n'data.frame':   130 obs. of  3 variables:\n $ temperature: num  96.3 96.7 96.9 97 97.1 97.1 97.1 97.2 97.3 97.4 ...\n $ gender     : int  1 1 1 1 1 1 1 1 1 1 ...\n $ hr         : int  70 71 74 80 73 75 82 64 69 70 ...\n\n\n\n\nUse the normtemp dataset to answer the following:\n\nDetermine the following statistics for the variable temperature\n\n\n\nCode\nsummary(normtemp$temperature)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  96.30   97.80   98.30   98.25   98.70  100.80 \n\n\n\nDoes temperature appear to be normally distributed?\n\n\n\nCode\nggplot(normtemp, aes(sample = temperature)) +\n    stat_qq(col = \"blue\") +\n    stat_qq_line() +\n    labs(x = \"theoretical\", y = \"observed\")\n\n\n\n\n\nBased on the QQ-Plot, temperature appears to be approximately Normal. However, we should be wary that the distribution is tending towards a platykurtic distribution\n\nCreate box plots for temperature. Are there any outliers? Display a reference line at 98.6.\nFor horizontal line: geom_hline(yintercept=98.6)\nFor vertical line: geom_vline(xintercept=98.6)\n\n\n\nCode\nggplot(normtemp, aes(x = temperature)) +\n    geom_boxplot(outlier.color = \"red\") +\n    labs(x = \"Temperature\", title = \"Box-Plot of Temperature\") +\n    geom_vline(xintercept = 98.6, col = \"blue\")\n\n\n\n\n\nThree observations appear to be outliers (colored in red) for temperature. After plotting the reference line at 98.6 degrees, we can visually see that the median is actually lower than 98.6.\n\n\nUsing the Ameshousing dataset from our in-class examples, run some distributional analysis on Sale_Price, Log(Sale_Price), and Gr_Liv_Area.\n\nCreate histograms of these three variables.\n\nOverlay a kernel density estimator of the variables.\n\n\n\n\nCode\nlibrary(AmesHousing)\n\names &lt;- make_ordinal_ames()\n\n\n\n\nCode\nggplot(ames, aes(x = Sale_Price)) +\n    geom_histogram(aes(y = after_stat(!!str2lang(\"density\"))), fill = \"pink\", alpha = 0.4) +\n    geom_density() +\n    labs(x = \"Sales Price (USD)\", title = \"Histogram of Housing Sales Price\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nCode\nggplot(ames, aes(x = log(Sale_Price))) +\n    geom_histogram(aes(y = after_stat(!!str2lang(\"density\"))), fill = \"blue\", alpha = 0.4) +\n    geom_density() +\n    labs(x = \"Sales Price (USD)\", title = \"Histogram of Log(Sales Price)\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nCode\nggplot(ames, aes(x = Gr_Liv_Area)) +\n    geom_histogram(aes(y = after_stat(!!str2lang(\"density\"))), fill = \"purple\", alpha = 0.4) +\n    geom_density() +\n    labs(x = \"Sales Price (USD)\", title = \"Histogram of Living Area\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nCreate a QQ Plot for both Sale_Price and Log(Sale_Price). Based on these exploratory procedures, which version of the price information would you say is closer to being normally distributed?\n\n\n\nCode\nggplot(ames, aes(sample = Sale_Price)) +\n    stat_qq(col = \"blue\", shape = 8, size = 1) +\n    stat_qq_line() +\n    labs(x = \"theoretical\", y = \"observed\", title = \"QQ-Plot of Sale Price\")\n\n\n\n\n\nCode\nggplot(ames, aes(sample = log(Sale_Price))) +\n    stat_qq(col = \"blue\", shape = 8, size = 1) +\n    stat_qq_line()\n\n\n\n\n\nCode\nlabs(x = \"theoretical\", y = \"observed\", title = \"QQ-Plot of Log(Sale Price)\")\n\n\n$x\n[1] \"theoretical\"\n\n$y\n[1] \"observed\"\n\n$title\n[1] \"QQ-Plot of Log(Sale Price)\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\nThe Log(Sale Price) QQ-Plot shows a much closer similarity to a Normal distribution than just Sale Price.\n\n\nUsing the Ameshousing dataset from our in-class examples, determine the following:\n\nWhat type of variables are each of these columns (Nominal, Ordinal, or Continuous/Quantitative)? Keep in mind that the way they are represented in the R dataset may not be appropriate, so you should make this determination using your own judgement based on the data you are looking at.\n\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ lubridate 1.9.2     ✔ tibble    3.2.1\n✔ purrr     1.0.1     ✔ tidyr     1.3.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()    masks stats::filter()\n✖ dplyr::lag()       masks stats::lag()\n✖ dplyr::select()    masks MASS::select()\n✖ dplyr::src()       masks Hmisc::src()\n✖ dplyr::summarize() masks Hmisc::summarize()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nglimpse(ames)\n\n\nRows: 2,930\nColumns: 81\n$ MS_SubClass        &lt;fct&gt; One_Story_1946_and_Newer_All_Styles, One_Story_1946…\n$ MS_Zoning          &lt;fct&gt; Residential_Low_Density, Residential_High_Density, …\n$ Lot_Frontage       &lt;dbl&gt; 141, 80, 81, 93, 74, 78, 41, 43, 39, 60, 75, 0, 63,…\n$ Lot_Area           &lt;int&gt; 31770, 11622, 14267, 11160, 13830, 9978, 4920, 5005…\n$ Street             &lt;fct&gt; Pave, Pave, Pave, Pave, Pave, Pave, Pave, Pave, Pav…\n$ Alley              &lt;fct&gt; No_Alley_Access, No_Alley_Access, No_Alley_Access, …\n$ Lot_Shape          &lt;ord&gt; Slightly_Irregular, Regular, Slightly_Irregular, Re…\n$ Land_Contour       &lt;ord&gt; Lvl, Lvl, Lvl, Lvl, Lvl, Lvl, Lvl, HLS, Lvl, Lvl, L…\n$ Utilities          &lt;ord&gt; AllPub, AllPub, AllPub, AllPub, AllPub, AllPub, All…\n$ Lot_Config         &lt;fct&gt; Corner, Inside, Corner, Corner, Inside, Inside, Ins…\n$ Land_Slope         &lt;ord&gt; Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, G…\n$ Neighborhood       &lt;fct&gt; North_Ames, North_Ames, North_Ames, North_Ames, Gil…\n$ Condition_1        &lt;fct&gt; Norm, Feedr, Norm, Norm, Norm, Norm, Norm, Norm, No…\n$ Condition_2        &lt;fct&gt; Norm, Norm, Norm, Norm, Norm, Norm, Norm, Norm, Nor…\n$ Bldg_Type          &lt;fct&gt; OneFam, OneFam, OneFam, OneFam, OneFam, OneFam, Twn…\n$ House_Style        &lt;fct&gt; One_Story, One_Story, One_Story, One_Story, Two_Sto…\n$ Overall_Qual       &lt;ord&gt; Above_Average, Average, Above_Average, Good, Averag…\n$ Overall_Cond       &lt;ord&gt; Average, Above_Average, Above_Average, Average, Ave…\n$ Year_Built         &lt;int&gt; 1960, 1961, 1958, 1968, 1997, 1998, 2001, 1992, 199…\n$ Year_Remod_Add     &lt;int&gt; 1960, 1961, 1958, 1968, 1998, 1998, 2001, 1992, 199…\n$ Roof_Style         &lt;fct&gt; Hip, Gable, Hip, Hip, Gable, Gable, Gable, Gable, G…\n$ Roof_Matl          &lt;fct&gt; CompShg, CompShg, CompShg, CompShg, CompShg, CompSh…\n$ Exterior_1st       &lt;fct&gt; BrkFace, VinylSd, Wd Sdng, BrkFace, VinylSd, VinylS…\n$ Exterior_2nd       &lt;fct&gt; Plywood, VinylSd, Wd Sdng, BrkFace, VinylSd, VinylS…\n$ Mas_Vnr_Type       &lt;fct&gt; Stone, None, BrkFace, None, None, BrkFace, None, No…\n$ Mas_Vnr_Area       &lt;dbl&gt; 112, 0, 108, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6…\n$ Exter_Qual         &lt;ord&gt; Typical, Typical, Typical, Good, Typical, Typical, …\n$ Exter_Cond         &lt;ord&gt; Typical, Typical, Typical, Typical, Typical, Typica…\n$ Foundation         &lt;fct&gt; CBlock, CBlock, CBlock, CBlock, PConc, PConc, PConc…\n$ Bsmt_Qual          &lt;ord&gt; Typical, Typical, Typical, Typical, Good, Typical, …\n$ Bsmt_Cond          &lt;ord&gt; Good, Typical, Typical, Typical, Typical, Typical, …\n$ Bsmt_Exposure      &lt;ord&gt; Gd, No, No, No, No, No, Mn, No, No, No, No, No, No,…\n$ BsmtFin_Type_1     &lt;ord&gt; BLQ, Rec, ALQ, ALQ, GLQ, GLQ, GLQ, ALQ, GLQ, Unf, U…\n$ BsmtFin_SF_1       &lt;dbl&gt; 2, 6, 1, 1, 3, 3, 3, 1, 3, 7, 7, 1, 7, 3, 3, 1, 3, …\n$ BsmtFin_Type_2     &lt;ord&gt; Unf, LwQ, Unf, Unf, Unf, Unf, Unf, Unf, Unf, Unf, U…\n$ BsmtFin_SF_2       &lt;dbl&gt; 0, 144, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1120, 0…\n$ Bsmt_Unf_SF        &lt;dbl&gt; 441, 270, 406, 1045, 137, 324, 722, 1017, 415, 994,…\n$ Total_Bsmt_SF      &lt;dbl&gt; 1080, 882, 1329, 2110, 928, 926, 1338, 1280, 1595, …\n$ Heating            &lt;fct&gt; GasA, GasA, GasA, GasA, GasA, GasA, GasA, GasA, Gas…\n$ Heating_QC         &lt;ord&gt; Fair, Typical, Typical, Excellent, Good, Excellent,…\n$ Central_Air        &lt;fct&gt; Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, …\n$ Electrical         &lt;ord&gt; SBrkr, SBrkr, SBrkr, SBrkr, SBrkr, SBrkr, SBrkr, SB…\n$ First_Flr_SF       &lt;int&gt; 1656, 896, 1329, 2110, 928, 926, 1338, 1280, 1616, …\n$ Second_Flr_SF      &lt;int&gt; 0, 0, 0, 0, 701, 678, 0, 0, 0, 776, 892, 0, 676, 0,…\n$ Low_Qual_Fin_SF    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Gr_Liv_Area        &lt;int&gt; 1656, 896, 1329, 2110, 1629, 1604, 1338, 1280, 1616…\n$ Bsmt_Full_Bath     &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, …\n$ Bsmt_Half_Bath     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Full_Bath          &lt;int&gt; 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 2, …\n$ Half_Bath          &lt;int&gt; 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, …\n$ Bedroom_AbvGr      &lt;int&gt; 3, 2, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 2, 1, 4, 4, …\n$ Kitchen_AbvGr      &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ Kitchen_Qual       &lt;ord&gt; Typical, Typical, Good, Excellent, Typical, Good, G…\n$ TotRms_AbvGrd      &lt;int&gt; 7, 5, 6, 8, 6, 7, 6, 5, 5, 7, 7, 6, 7, 5, 4, 12, 8,…\n$ Functional         &lt;ord&gt; Typ, Typ, Typ, Typ, Typ, Typ, Typ, Typ, Typ, Typ, T…\n$ Fireplaces         &lt;int&gt; 2, 0, 0, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, …\n$ Fireplace_Qu       &lt;ord&gt; Good, No_Fireplace, No_Fireplace, Typical, Typical,…\n$ Garage_Type        &lt;fct&gt; Attchd, Attchd, Attchd, Attchd, Attchd, Attchd, Att…\n$ Garage_Finish      &lt;ord&gt; Fin, Unf, Unf, Fin, Fin, Fin, Fin, RFn, RFn, Fin, F…\n$ Garage_Cars        &lt;dbl&gt; 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, …\n$ Garage_Area        &lt;dbl&gt; 528, 730, 312, 522, 482, 470, 582, 506, 608, 442, 4…\n$ Garage_Qual        &lt;ord&gt; Typical, Typical, Typical, Typical, Typical, Typica…\n$ Garage_Cond        &lt;ord&gt; Typical, Typical, Typical, Typical, Typical, Typica…\n$ Paved_Drive        &lt;ord&gt; Partial_Pavement, Paved, Paved, Paved, Paved, Paved…\n$ Wood_Deck_SF       &lt;int&gt; 210, 140, 393, 0, 212, 360, 0, 0, 237, 140, 157, 48…\n$ Open_Porch_SF      &lt;int&gt; 62, 0, 36, 0, 34, 36, 0, 82, 152, 60, 84, 21, 75, 0…\n$ Enclosed_Porch     &lt;int&gt; 0, 0, 0, 0, 0, 0, 170, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Three_season_porch &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Screen_Porch       &lt;int&gt; 0, 120, 0, 0, 0, 0, 0, 144, 0, 0, 0, 0, 0, 0, 140, …\n$ Pool_Area          &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Pool_QC            &lt;ord&gt; No_Pool, No_Pool, No_Pool, No_Pool, No_Pool, No_Poo…\n$ Fence              &lt;ord&gt; No_Fence, Minimum_Privacy, No_Fence, No_Fence, Mini…\n$ Misc_Feature       &lt;fct&gt; None, None, Gar2, None, None, None, None, None, Non…\n$ Misc_Val           &lt;int&gt; 0, 0, 12500, 0, 0, 0, 0, 0, 0, 0, 0, 500, 0, 0, 0, …\n$ Mo_Sold            &lt;int&gt; 5, 6, 6, 4, 3, 6, 4, 1, 3, 6, 4, 3, 5, 2, 6, 6, 6, …\n$ Year_Sold          &lt;int&gt; 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 201…\n$ Sale_Type          &lt;fct&gt; WD , WD , WD , WD , WD , WD , WD , WD , WD , WD , W…\n$ Sale_Condition     &lt;fct&gt; Normal, Normal, Normal, Normal, Normal, Normal, Nor…\n$ Sale_Price         &lt;int&gt; 215000, 105000, 172000, 244000, 189900, 195500, 213…\n$ Longitude          &lt;dbl&gt; -93.61975, -93.61976, -93.61939, -93.61732, -93.638…\n$ Latitude           &lt;dbl&gt; 42.05403, 42.05301, 42.05266, 42.05125, 42.06090, 4…\n\n\n\nOverall_Qual is an ordinal variable as it represents categories that could be ordered based on the rated quality of the house\nLot_Shape is an ordinal variable. It represents categories that could be ordered based on the rated lot shape. For example, Slightly_Irregular could be ordered after Irregular\nHeating_QC is an ordinal variable. It represents the categories of heating quality that could be ordered. For example, Excellent would represent a higher order than Good\nLot_Area is a quantitative variable as it represents a continuous quantity of the area of the lot"
  },
  {
    "objectID": "notes/analytics/07182023/lab_13.html",
    "href": "notes/analytics/07182023/lab_13.html",
    "title": "Lab 13",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nsafety &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/safety.csv\")\n\nsafety &lt;- safety %&gt;%\n    mutate(across(c(Region, Size), as.factor))\n\n\n\n\nCode\nmodel &lt;- glm(Unsafe ~ Region + Weight + Size, family = binomial(), data = safety)\nsummary(model)\n\n\n\nCall:\nglm(formula = Unsafe ~ Region + Weight + Size, family = binomial(), \n    data = safety)\n\nCoefficients:\n                Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)       2.7285     1.3949   1.956  0.05046 . \nRegionN America  -0.3775     0.5624  -0.671  0.50203   \nWeight           -0.6678     0.4589  -1.455  0.14559   \nSize2            -2.0200     0.6246  -3.234  0.00122 **\nSize3            -2.6785     0.8810  -3.040  0.00236 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 119.249  on 95  degrees of freedom\nResidual deviance:  84.004  on 91  degrees of freedom\nAIC: 94.004\n\nNumber of Fisher Scoring iterations: 5\n\n\nSignificant variables are Size\n\n\nCode\nlibrary(survival)\nconcordance(model)\n\n\nCall:\nconcordance.lm(object = model)\n\nn= 96 \nConcordance= 0.8482 se= 0.03897\nconcordant discordant     tied.x     tied.y    tied.xy \n      1622        243        115       2273        307 \n\n\nModel correctly ranks unsafe cars ahead of safe cars 84.8% of the time."
  },
  {
    "objectID": "notes/analytics/07182023/lab_13.html#a",
    "href": "notes/analytics/07182023/lab_13.html#a",
    "title": "Lab 13",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nsafety &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/safety.csv\")\n\nsafety &lt;- safety %&gt;%\n    mutate(across(c(Region, Size), as.factor))\n\n\n\n\nCode\nmodel &lt;- glm(Unsafe ~ Region + Weight + Size, family = binomial(), data = safety)\nsummary(model)\n\n\n\nCall:\nglm(formula = Unsafe ~ Region + Weight + Size, family = binomial(), \n    data = safety)\n\nCoefficients:\n                Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)       2.7285     1.3949   1.956  0.05046 . \nRegionN America  -0.3775     0.5624  -0.671  0.50203   \nWeight           -0.6678     0.4589  -1.455  0.14559   \nSize2            -2.0200     0.6246  -3.234  0.00122 **\nSize3            -2.6785     0.8810  -3.040  0.00236 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 119.249  on 95  degrees of freedom\nResidual deviance:  84.004  on 91  degrees of freedom\nAIC: 94.004\n\nNumber of Fisher Scoring iterations: 5\n\n\nSignificant variables are Size\n\n\nCode\nlibrary(survival)\nconcordance(model)\n\n\nCall:\nconcordance.lm(object = model)\n\nn= 96 \nConcordance= 0.8482 se= 0.03897\nconcordant discordant     tied.x     tied.y    tied.xy \n      1622        243        115       2273        307 \n\n\nModel correctly ranks unsafe cars ahead of safe cars 84.8% of the time."
  },
  {
    "objectID": "notes/analytics/07182023/lab_13.html#b",
    "href": "notes/analytics/07182023/lab_13.html#b",
    "title": "Lab 13",
    "section": "2 b",
    "text": "2 b\n\n\nCode\nmodel2 &lt;- glm(Unsafe ~ Weight + Size, data = safety, family = binomial())\nsummary(model2)\n\n\n\nCall:\nglm(formula = Unsafe ~ Weight + Size, family = binomial(), data = safety)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)   2.5272     1.3427   1.882  0.05981 . \nWeight       -0.6686     0.4553  -1.469  0.14195   \nSize2        -2.0142     0.6222  -3.237  0.00121 **\nSize3        -2.7911     0.8666  -3.221  0.00128 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 119.249  on 95  degrees of freedom\nResidual deviance:  84.455  on 92  degrees of freedom\nAIC: 92.455\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\nCode\nmodel3 &lt;- glm(Unsafe ~ Size, data = safety, family = binomial())\nsummary(model3)\n\n\n\nCall:\nglm(formula = Unsafe ~ Size, family = binomial(), data = safety)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.6506     0.3561   1.827 0.067708 .  \nSize2        -2.2192     0.6070  -3.656 0.000256 ***\nSize3        -3.3586     0.8125  -4.134 3.57e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 119.249  on 95  degrees of freedom\nResidual deviance:  86.629  on 93  degrees of freedom\nAIC: 92.629\n\nNumber of Fisher Scoring iterations: 5\n\n\nCode\nconcordance(model3)\n\n\nCall:\nconcordance.lm(object = model3)\n\nn= 96 \nConcordance= 0.8182 se= 0.043\nconcordant discordant     tied.x     tied.y    tied.xy \n      1392        132        456       1539       1041 \n\n\nCode\nexp(cbind(coef(model3), confint(model3)))\n\n\nWaiting for profiling to be done...\n\n\n                             2.5 %    97.5 %\n(Intercept) 1.91666667 0.971535104 3.9816962\nSize2       0.10869565 0.030145216 0.3357070\nSize3       0.03478261 0.005058893 0.1414522\n\n\nOnly Size remained in the model. 0.8182 C-statistic\nThe interpretation of the Size variable in the model is that Size2 is 0.108 times more likely to be unsafe than compared to Size1. Size3 is 0.03 times more likely to be unsafe than compared to Size1."
  },
  {
    "objectID": "notes/analytics/07132023/breakout_11.html",
    "href": "notes/analytics/07132023/breakout_11.html",
    "title": "Breakout 11",
    "section": "",
    "text": "1 1\n\n\nCode\nlibrary(glmnet)\n\n\nLoading required package: Matrix\n\n\nLoaded glmnet 4.1-7\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::expand() masks Matrix::expand()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ tidyr::pack()   masks Matrix::pack()\n✖ tidyr::unpack() masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nbike &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/bike.csv\")\nset.seed(123)\n\nbike &lt;- bike %&gt;%\n    mutate(id = row_number())\ntrain &lt;- bike %&gt;%\n    sample_frac(0.7)\ntest &lt;- anti_join(bike, train, by = \"id\")\n\n\n\n\nCode\nnrow(train)\n\n\n[1] 12165\n\n\nCode\nnrow(test)\n\n\n[1] 5214\n\n\n12165 rows in train, 5214 rows in test\n\n\nCode\ntrain_x &lt;- model.matrix(cnt ~ temp + atemp + hum + windspeed, data = train)[, -1]\ntrain_y &lt;- train$cnt\n\ntest_x &lt;- model.matrix(cnt ~ temp + atemp + hum + windspeed, data = test)[, -1]\ntest_y &lt;- test$cnt\n\n\n\n\nCode\ntrain_ridge &lt;- glmnet(x = train_x, y = train_y, alpha = 0)\ntrain_ridge_cv &lt;- cv.glmnet(x = train_x, y = train_y, alpha = 0)\ntrain_ridge_cv$lambda.min\n\n\n[1] 7.388165\n\n\nMin. \\(\\lambda\\) is 7.388165\n\n\nCode\ntest$pred_ridge &lt;- predict(train_ridge, s = train_ridge_cv$lambda.min, newx = test_x)\nhead(test$pred_ridge)\n\n\n         s1\n1  25.04585\n2  92.24244\n3  96.43314\n4 117.79311\n5  98.29221\n6  98.29221\n\n\nCode\nhead(test$cnt)\n\n\n[1]  3 56 34 39  6  3"
  },
  {
    "objectID": "notes/analytics/07132023/index.html",
    "href": "notes/analytics/07132023/index.html",
    "title": "Model Building and Scoring for Prediction",
    "section": "",
    "text": "Linear regression is a good initial approach to model building, but not the only form of regression.\nLinear regression is the best linear unbiased estimator.\n\n\n\\[\n\\hat{\\beta}_j ~ N(\\beta_j, s_{\\hat{\\beta}_j})\n\\]\nOn average, coefficients from all samples are centered from the true coefficient. What does it mean to be best? If assumptions hold, \\(s_{\\hat{\\beta}_j}\\) is the minimum variance of all the unbiased estimators.\nPut another way: The spread of our guesses is as narrow as it can be.\nWhat if biased estimators had smaller variance?"
  },
  {
    "objectID": "notes/analytics/07132023/index.html#best-linear-unbiased-estimator",
    "href": "notes/analytics/07132023/index.html#best-linear-unbiased-estimator",
    "title": "Model Building and Scoring for Prediction",
    "section": "",
    "text": "\\[\n\\hat{\\beta}_j ~ N(\\beta_j, s_{\\hat{\\beta}_j})\n\\]\nOn average, coefficients from all samples are centered from the true coefficient. What does it mean to be best? If assumptions hold, \\(s_{\\hat{\\beta}_j}\\) is the minimum variance of all the unbiased estimators.\nPut another way: The spread of our guesses is as narrow as it can be.\nWhat if biased estimators had smaller variance?"
  },
  {
    "objectID": "notes/analytics/07132023/index.html#penalties-in-models",
    "href": "notes/analytics/07132023/index.html#penalties-in-models",
    "title": "Model Building and Scoring for Prediction",
    "section": "2.1 Penalties in Models",
    "text": "2.1 Penalties in Models\nRecall OLS regression minimizes the sum of squared errors:\n\\[\n\\min(\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2) = \\min(SSE)\n\\]\nRegularized regression introduces a penalty term to the minimization:\n\\[\n\\min(\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\text{Penalty}) = \\min(SSE + \\text{Penalty})\n\\]"
  },
  {
    "objectID": "notes/analytics/07132023/index.html#r-code",
    "href": "notes/analytics/07132023/index.html#r-code",
    "title": "Model Building and Scoring for Prediction",
    "section": "3.1 R Code",
    "text": "3.1 R Code\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(AmesHousing)\nlibrary(car)\n\n\nLoading required package: carData\n\nAttaching package: 'car'\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\nThe following object is masked from 'package:purrr':\n\n    some\n\n\nCode\nset.seed(123)\n\names &lt;- make_ordinal_ames()\n\names &lt;- ames %&gt;%\n    mutate(id = row_number())\n\ntrain &lt;- ames %&gt;%\n    sample_frac(0.7)\n\ntest &lt;- anti_join(ames, train, by = \"id\")\ndim(train)\n\n\n[1] 2051   82\n\n\n\n\nCode\ntrain_reg &lt;- train %&gt;%\n    select(Sale_Price, Lot_Area, Street, Bldg_Type, House_Style, Overall_Qual, Roof_Style, Central_Air, First_Flr_SF, Second_Flr_SF, Full_Bath, Half_Bath, Fireplaces, Garage_Area, Gr_Liv_Area, TotRms_AbvGrd) %&gt;%\n    replace(is.na(.), 0)\n\n# Leave all continuous variables alone\n# Dummy encode all categorical variables\n# Still need to factor any numeric categoricals beforehand\n# We delete the first column from the model matrix since we don't need the intercept column that model.matrix provides\ntrain_x &lt;- model.matrix(Sale_Price ~ ., data = train_reg)[, -1]\ntrain_y &lt;- train_reg$Sale_Price\n\ntest_reg &lt;- test %&gt;%\n    select(Sale_Price, Lot_Area, Street, Bldg_Type, House_Style, Overall_Qual, Roof_Style, Central_Air, First_Flr_SF, Second_Flr_SF, Full_Bath, Half_Bath, Fireplaces, Garage_Area, Gr_Liv_Area, TotRms_AbvGrd) %&gt;%\n    replace(is.na(.), 0)\n\ntest_x &lt;- model.matrix(Sale_Price ~ ., data = test_reg)[, -1]\ntest_y &lt;- train_reg$Sale_Price\n\n\n\n\nCode\nlibrary(glmnet)\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-7\n\n\nCode\n# alpha controls the option as to which penalty to use\names_ridge &lt;- glmnet(x = train_x, y = train_y, alpha = 0)\nplot(ames_ridge, xvar = \"lambda\")"
  },
  {
    "objectID": "notes/analytics/07132023/index.html#python-code",
    "href": "notes/analytics/07132023/index.html#python-code",
    "title": "Model Building and Scoring for Prediction",
    "section": "3.2 Python Code",
    "text": "3.2 Python Code\n\n\nCode\ntrain = r.train\ntest = r.test"
  },
  {
    "objectID": "notes/analytics/07132023/index.html#differences-in-effects",
    "href": "notes/analytics/07132023/index.html#differences-in-effects",
    "title": "Model Building and Scoring for Prediction",
    "section": "4.1 Differences in Effects",
    "text": "4.1 Differences in Effects\nLASSO can delete variables whereas Ridge can only get close to 0. Differences in effects are due to differences in penalty. The deletion of variables can actually act as variable selection."
  },
  {
    "objectID": "notes/analytics/07132023/index.html#r-code-1",
    "href": "notes/analytics/07132023/index.html#r-code-1",
    "title": "Model Building and Scoring for Prediction",
    "section": "4.2 R Code",
    "text": "4.2 R Code\n\n\nCode\nlibrary(glmnet)\names_lasso &lt;- glmnet(x = train_x, y = train_y, alpha = 1)\nplot(ames_lasso, xvar = \"lambda\")"
  },
  {
    "objectID": "notes/analytics/07132023/index.html#cross-validation",
    "href": "notes/analytics/07132023/index.html#cross-validation",
    "title": "Model Building and Scoring for Prediction",
    "section": "6.1 Cross-Validation",
    "text": "6.1 Cross-Validation\nCross-validation is one approach to prevent overfitting when tuning a parameter.\n\nSplit training data into multiple pieces\nBuild model on majority of pieces\nEvaluate on remaining piece\nRepeat process with switching out pieces for building and evaluation\n\n\n\nCode\n# Gives us lambda.min and lambda.1se on the graph\n# By default, k-fold = 10\names_lasso_cv &lt;- cv.glmnet(x = train_x, y = train_y, alpha = 1)\nplot(ames_lasso_cv)"
  },
  {
    "objectID": "notes/analytics/07132023/index.html#important-variables",
    "href": "notes/analytics/07132023/index.html#important-variables",
    "title": "Model Building and Scoring for Prediction",
    "section": "6.2 Important Variables",
    "text": "6.2 Important Variables\n\n\nCode\ncoef(ames_lasso, s = c(ames_lasso_cv$lambda.min, ames_lasso_cv$lambda.1se))\n\n\n37 x 2 sparse Matrix of class \"dgCMatrix\"\n                                       s1            s2\n(Intercept)                  4.809883e+04  8.326132e+04\nLot_Area                     5.455632e-01  3.727557e-01\nStreetPave                   7.742774e+03  .           \nBldg_TypeTwoFmCon           -9.791571e+03  .           \nBldg_TypeDuplex             -2.380411e+04  .           \nBldg_TypeTwnhs              -1.755640e+04 -1.552627e+03\nBldg_TypeTwnhsE             -8.901776e+03  .           \nHouse_StyleOne_and_Half_Unf  1.006755e+04  .           \nHouse_StyleOne_Story         2.100854e+04  .           \nHouse_StyleSFoyer            3.314566e+04  .           \nHouse_StyleSLvl              9.806126e+03  .           \nHouse_StyleTwo_and_Half_Fin -2.786798e+04  .           \nHouse_StyleTwo_and_Half_Unf -8.735039e+03  .           \nHouse_StyleTwo_Story         .             .           \nOverall_Qual.L               2.270985e+05  1.963587e+05\nOverall_Qual.Q               1.004889e+05  1.061646e+05\nOverall_Qual.C               1.201336e+04  .           \nOverall_Qual^4              -9.446123e+02  .           \nOverall_Qual^5              -2.520393e+04 -5.544525e+03\nOverall_Qual^6              -8.477324e+03  .           \nOverall_Qual^7              -2.899510e+03  .           \nOverall_Qual^8               .             .           \nOverall_Qual^9              -7.317252e+01  .           \nRoof_StyleGable             -1.083345e+03  .           \nRoof_StyleGambrel            .             .           \nRoof_StyleHip                4.183190e+03  3.243469e+03\nRoof_StyleMansard           -4.033550e+04  .           \nRoof_StyleShed              -2.192610e+04  .           \nCentral_AirY                 1.360755e+04  1.155248e+04\nFirst_Flr_SF                 4.577067e-02  1.421832e+01\nSecond_Flr_SF                4.756848e+00  .           \nFull_Bath                    1.503856e+04  4.316036e+03\nHalf_Bath                    1.073726e+04  1.820427e+02\nFireplaces                   8.158764e+03  6.631559e+03\nGarage_Area                  3.623071e+01  4.285732e+01\nGr_Liv_Area                  4.233104e+01  3.285089e+01\nTotRms_AbvGrd               -7.343589e+02  .           \n\n\nRegularized regression"
  },
  {
    "objectID": "notes/analytics/07132023/index.html#model-metrics",
    "href": "notes/analytics/07132023/index.html#model-metrics",
    "title": "Model Building and Scoring for Prediction",
    "section": "7.1 Model Metrics",
    "text": "7.1 Model Metrics\nRoot MSE:\n\\[\nRMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n\\]\nMean Absolute Error:\n\\[\nMAE = \\frac{1}{n}\\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n\\]\nMean Absolute Percentage Error:\n\\[\nMAPE = 100 \\cdot \\frac{1}{n}\\sum_{i=1}^{n} |\\frac{y_i - \\hat{y}_i}{y_i}\n\\]"
  },
  {
    "objectID": "notes/analytics/07072023/breakout_7.html",
    "href": "notes/analytics/07072023/breakout_7.html",
    "title": "Breakout 7",
    "section": "",
    "text": "1 1\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nbike &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/bike.csv\")\nglimpse(bike)\n\n\nRows: 17,379\nColumns: 16\n$ dteday     &lt;int&gt; 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 149…\n$ season     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ yr         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ mnth       &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ hr         &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ holiday    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ weekday    &lt;int&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,…\n$ workingday &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ weathersit &lt;int&gt; 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3,…\n$ temp       &lt;dbl&gt; 0.24, 0.22, 0.22, 0.24, 0.24, 0.24, 0.22, 0.20, 0.24, 0.32,…\n$ atemp      &lt;dbl&gt; 0.2879, 0.2727, 0.2727, 0.2879, 0.2879, 0.2576, 0.2727, 0.2…\n$ hum        &lt;dbl&gt; 0.81, 0.80, 0.80, 0.75, 0.75, 0.75, 0.80, 0.86, 0.75, 0.76,…\n$ windspeed  &lt;dbl&gt; 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0896, 0.0000, 0.0…\n$ casual     &lt;int&gt; 3, 8, 5, 3, 0, 0, 2, 1, 1, 8, 12, 26, 29, 47, 35, 40, 41, 1…\n$ registered &lt;int&gt; 13, 32, 27, 10, 1, 1, 0, 2, 7, 6, 24, 30, 55, 47, 71, 70, 5…\n$ cnt        &lt;int&gt; 16, 40, 32, 13, 1, 1, 2, 3, 8, 14, 36, 56, 84, 94, 106, 110…\n\n\n\n\nCode\nset.seed(18954)\nbike &lt;- bike %&gt;%\n    mutate(id = row_number()) %&gt;%\n    select(-dteday)\n\ntrain &lt;- sample_frac(bike, 0.7)\ntest &lt;- anti_join(bike, train, by = \"id\")\n\n\n\n\nCode\ntrain &lt;- train %&gt;%\n    select(-id)\n\nfull.model &lt;- lm(cnt ~ ., data = train)\nempty.model &lt;- lm(cnt ~ 1, data = train)\n\ncor(train)\n\n\n                  season           yr          mnth            hr      holiday\nseason      1.0000000000 -0.017728740  0.8341892714  0.0007029716 -0.008004203\nyr         -0.0177287399  1.000000000 -0.0127230269  0.0015380450  0.009701818\nmnth        0.8341892714 -0.012723027  1.0000000000  0.0005688982  0.016990981\nhr          0.0007029716  0.001538045  0.0005688982  1.0000000000  0.005471284\nholiday    -0.0080042032  0.009701818  0.0169909807  0.0054712840  1.000000000\nweekday    -0.0005697724  0.001429914  0.0107269128 -0.0014009498 -0.103965916\nworkingday  0.0165320138 -0.008277955  0.0017000694 -0.0005299508 -0.251746297\nweathersit -0.0151361998 -0.017434710  0.0054373800 -0.0187000757 -0.022398585\ntemp        0.3127250206  0.044994421  0.2027039404  0.1373762513 -0.022839374\natemp       0.3206906241  0.043824690  0.2093992596  0.1329508772 -0.027588827\nhum         0.1566301682 -0.078213509  0.1672219767 -0.2791132639 -0.012661765\nwindspeed  -0.1583175184 -0.011899846 -0.1395026596  0.1423059728 -0.001187728\ncasual      0.1200666387  0.139655612  0.0678288263  0.3015976700  0.029554121\nregistered  0.1732086022  0.251636065  0.1214334433  0.3750279189 -0.044113763\ncnt         0.1771539640  0.247838770  0.1197199984  0.3949779016 -0.028641358\n                 weekday    workingday   weathersit          temp        atemp\nseason     -0.0005697724  0.0165320138 -0.015136200  0.3127250206  0.320690624\nyr          0.0014299143 -0.0082779549 -0.017434710  0.0449944213  0.043824690\nmnth        0.0107269128  0.0017000694  0.005437380  0.2027039404  0.209399260\nhr         -0.0014009498 -0.0005299508 -0.018700076  0.1373762513  0.132950877\nholiday    -0.1039659165 -0.2517462966 -0.022398585 -0.0228393738 -0.027588827\nweekday     1.0000000000  0.0440390626  0.002079925 -0.0002332587 -0.006308329\nworkingday  0.0440390626  1.0000000000  0.046345654  0.0503730352  0.050603957\nweathersit  0.0020799250  0.0463456539  1.000000000 -0.1107357489 -0.113473368\ntemp       -0.0002332587  0.0503730352 -0.110735749  1.0000000000  0.988793611\natemp      -0.0063083285  0.0506039568 -0.113473368  0.9887936108  1.000000000\nhum        -0.0423660688  0.0171985675  0.418553933 -0.0711446535 -0.053368085\nwindspeed   0.0085516606 -0.0086861227  0.026242630 -0.0238094722 -0.062370548\ncasual      0.0247987465 -0.3092849530 -0.157273847  0.4601798782  0.456775438\nregistered  0.0261143092  0.1312660111 -0.127020760  0.3366572816  0.335080666\ncnt         0.0285440726  0.0245754369 -0.148882272  0.4064747925  0.404228875\n                   hum    windspeed      casual  registered         cnt\nseason      0.15663017 -0.158317518  0.12006664  0.17320860  0.17715396\nyr         -0.07821351 -0.011899846  0.13965561  0.25163607  0.24783877\nmnth        0.16722198 -0.139502660  0.06782883  0.12143344  0.11972000\nhr         -0.27911326  0.142305973  0.30159767  0.37502792  0.39497790\nholiday    -0.01266176 -0.001187728  0.02955412 -0.04411376 -0.02864136\nweekday    -0.04236607  0.008551661  0.02479875  0.02611431  0.02854407\nworkingday  0.01719857 -0.008686123 -0.30928495  0.13126601  0.02457544\nweathersit  0.41855393  0.026242630 -0.15727385 -0.12702076 -0.14888227\ntemp       -0.07114465 -0.023809472  0.46017988  0.33665728  0.40647479\natemp      -0.05336809 -0.062370548  0.45677544  0.33508067  0.40422887\nhum         1.00000000 -0.295339230 -0.34747646 -0.27486663 -0.32413130\nwindspeed  -0.29533923  1.000000000  0.08710282  0.07999503  0.09048990\ncasual     -0.34747646  0.087102823  1.00000000  0.50678257  0.69607810\nregistered -0.27486663  0.079995030  0.50678257  1.00000000  0.97170007\ncnt        -0.32413130  0.090489897  0.69607810  0.97170007  1.00000000\n\n\nCode\nfor.model &lt;- step(empty.model,\n    scope = list(\n        lower = empty.model,\n        upper = full.model\n    ), direction = \"forward\", k = 2, trace = FALSE\n)\n\n\nWarning: attempting model selection on an essentially perfect fit is nonsense\n\nWarning: attempting model selection on an essentially perfect fit is nonsense\n\nWarning: attempting model selection on an essentially perfect fit is nonsense\n\nWarning: attempting model selection on an essentially perfect fit is nonsense\n\nWarning: attempting model selection on an essentially perfect fit is nonsense\n\nWarning: attempting model selection on an essentially perfect fit is nonsense\n\n\nCode\nfor.model\n\n\n\nCall:\nlm(formula = cnt ~ registered + casual + workingday + hum + season + \n    weathersit + weekday, data = train)\n\nCoefficients:\n(Intercept)   registered       casual   workingday          hum       season  \n  1.417e-12    1.000e+00    1.000e+00   -5.752e-14   -1.960e-13    2.421e-14  \n weathersit      weekday  \n  3.765e-14    9.453e-15  \n\n\n\n\n2 2\n\n\nCode\ntrain &lt;- train %&gt;%\n    select(-c(casual, registered))\n\nfull.model &lt;- lm(cnt ~ ., data = train)\nempty.model &lt;- lm(cnt ~ 1, data = train)\n\nfor.model &lt;- step(empty.model,\n    scope = list(\n        lower = empty.model,\n        upper = full.model\n    ), direction = \"forward\", k = 2, trace = FALSE\n)\nfor.model\n\n\n\nCall:\nlm(formula = cnt ~ temp + hr + yr + hum + season + atemp + holiday + \n    windspeed + weekday + weathersit, data = train)\n\nCoefficients:\n(Intercept)         temp           hr           yr          hum       season  \n    -22.084       13.217        7.669       80.195     -201.396       19.819  \n      atemp      holiday    windspeed      weekday   weathersit  \n    312.098      -26.051       39.301        1.701       -4.288"
  },
  {
    "objectID": "notes/analytics/index.html",
    "href": "notes/analytics/index.html",
    "title": "Analytics",
    "section": "",
    "text": "Introduction to Logistic Regression\n\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\n\n\nJul 18, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nModel Building and Scoring for Prediction\n\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\n\n\nJul 13, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nCorrelated Error Terms\n\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\n\n\nJul 11, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nDiagnostics\n\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nModel Selection\n\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\n\n\nJul 7, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nMultiple Linear Regression\n\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nMore Complex ANOVA & Regression\n\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nOrdinary Least Squares Regression\n\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\n\n\nJun 30, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nIntroduction to ANOVA and Regression\n\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\n\n\nJun 29, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nIntroduction to Statistical Inference\n\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\n\n\nJun 28, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nExploratory Data Analysis\n\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2023\n\n\nYang Chen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notes/analytics/07062023/breakout_6.html",
    "href": "notes/analytics/07062023/breakout_6.html",
    "title": "Breakout 6",
    "section": "",
    "text": "1 1\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nbike &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/bike.csv\")\n\nset.seed(123)\nbike &lt;- bike %&gt;% mutate(id = row_number())\ntrain &lt;- bike %&gt;% sample_frac(0.7)\ntest &lt;- anti_join(bike, train, by = \"id\")\ndim(train)\n\n\n[1] 12165    17\n\n\nCode\ndim(test)\n\n\n[1] 5214   17\n\n\n\n\n2 2\n\n\nCode\nbike_lm &lt;- lm(cnt ~ temp + hum + windspeed, train)\nsummary(bike_lm)\n\n\n\nCall:\nlm(formula = cnt ~ temp + hum + windspeed, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-327.84 -102.59  -32.51   65.79  707.92 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  172.430      7.443  23.166   &lt;2e-16 ***\ntemp         365.042      7.458  48.946   &lt;2e-16 ***\nhum         -268.340      7.776 -34.508   &lt;2e-16 ***\nwindspeed     22.749     12.208   1.863   0.0624 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 157.5 on 12161 degrees of freedom\nMultiple R-squared:  0.2489,    Adjusted R-squared:  0.2487 \nF-statistic:  1343 on 3 and 12161 DF,  p-value: &lt; 2.2e-16\n\n\n\n\\(R_a^2 is 0.2487\\)\nThe variables temp, hum are significant at the 0.01 level\n\n\n\n3 3\n\n\nCode\nbike_lm2 &lt;- lm(cnt ~ atemp + hum + windspeed, train)\nsummary(bike_lm2)\n\n\n\nCall:\nlm(formula = cnt ~ atemp + hum + windspeed, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-349.42 -102.16  -32.60   65.91  702.10 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  155.087      7.631  20.323  &lt; 2e-16 ***\natemp        411.554      8.365  49.198  &lt; 2e-16 ***\nhum         -270.493      7.766 -34.831  &lt; 2e-16 ***\nwindspeed     45.606     12.225   3.731 0.000192 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 157.4 on 12161 degrees of freedom\nMultiple R-squared:  0.2502,    Adjusted R-squared:   0.25 \nF-statistic:  1352 on 3 and 12161 DF,  p-value: &lt; 2.2e-16\n\n\n\n\\(R_a^2\\) is 0.25\natemp, hum, and windspeed are all significant at the 0.01 level\n\n\n\n4 4\nOur second model with atemp has a higher \\(R_a^2\\) value."
  },
  {
    "objectID": "notes/analytics/07102023/lab_8.html",
    "href": "notes/analytics/07102023/lab_8.html",
    "title": "Lab 8",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\ncafeteria &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/cafeteria.csv\")\n\n\n\n1 1\n\n\nCode\ncafeteria_lm &lt;- lm(Sales ~ Dispensers, data = cafeteria)\n\nggplot(cafeteria_lm, aes(x = .fitted, y = .resid)) +\n    geom_point() +\n    geom_hline(yintercept = 0)\n\n\n\n\n\n\nWe see a curved pattern in the residuals vs. fitted values plot\nMay want to introduce higher order terms to account for the pattern\n\n\n\n2 2\nForward selection by hand:\n\n\nCode\nempty.model &lt;- lm(Sales ~ 1, data = cafeteria)\nfull.model &lt;- lm(Sales ~ I(Dispensers^4) + I(Dispensers^3) + I(Dispensers^2) + Dispensers, data = cafeteria)\n\n\n\n\nCode\nc(AIC(empty.model), AIC(lm(Sales ~ Dispensers, data = cafeteria)), AIC(lm(Sales ~ Dispensers + I(Dispensers^2), data = cafeteria)), AIC(lm(Sales ~ Dispensers + I(Dispensers^2) + I(Dispensers^3), data = cafeteria)), AIC(full.model))\n\n\n[1] 176.0696 126.8844 101.9835 102.6002 104.5498\n\n\n\nBest degree for the model is the second-order: 2\n\n\n\nCode\nselected.model &lt;- lm(Sales ~ Dispensers + I(Dispensers^2), data = cafeteria)\n\nggplot(selected.model, aes(x = .fitted, y = .resid)) +\n    geom_point() +\n    geom_hline(yintercept = 0)\n\n\n\n\n\nCode\nggplot(selected.model, aes(sample = .resid)) +\n    stat_qq() +\n    stat_qq_line()\n\n\n\n\n\nCode\nhist(selected.model$resid)\n\n\n\n\n\n\nQQ-Plot shows evidence of normality\nHistogram shows a fairly Normal dist."
  },
  {
    "objectID": "notes/analytics/07112023/breakout_9.html",
    "href": "notes/analytics/07112023/breakout_9.html",
    "title": "Breakout 9",
    "section": "",
    "text": "Code\nlibrary(car)\n\n\nLoading required package: carData\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ dplyr::recode() masks car::recode()\n✖ purrr::some()   masks car::some()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nglimpse(mtcars)\n\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\n\n\n\nCode\nlm.model &lt;- lm(mpg ~ ., data = mtcars)\nv &lt;- vif(lm.model)\nv[v &gt; 10]\n\n\n     cyl     disp       wt \n15.37383 21.62024 15.16489 \n\n\nCode\nwhich.min(abs(cor(mtcars)[\"mpg\", c(\"cyl\", \"disp\", \"wt\")]))\n\n\ndisp \n   2 \n\n\n\n\nCode\nmtcars.subset &lt;- mtcars %&gt;%\n    select(-disp)\n\nlm.model &lt;- lm(mpg ~ ., data = mtcars.subset)\nv &lt;- vif(lm.model)\nv[v &gt; 10]\n\n\n     cyl \n14.28474 \n\n\n\n\nCode\nmtcars.subset &lt;- mtcars.subset %&gt;%\n    select(-cyl)\n\nlm.model &lt;- lm(mpg ~ ., data = mtcars.subset)\nv &lt;- vif(lm.model)\nv[v &gt; 10]\n\n\nnamed numeric(0)\n\n\n\n1 Model Selection\n\n\nCode\nempty.model &lt;- lm(mpg ~ 1, data = mtcars.subset)\nfull.model &lt;- lm(mpg ~ ., data = mtcars.subset)\n\nfor.model &lt;- step(empty.model,\n    scope = list(\n        lower = empty.model,\n        upper = full.model\n    ),\n    direction = \"forward\",\n    k = 2,\n    trace = FALSE\n)\nsummary(for.model)\n\n\n\nCall:\nlm(formula = mpg ~ wt + hp + am + qsec, data = mtcars.subset)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4975 -1.5902 -0.1122  1.1795  4.5404 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept) 17.44019    9.31887   1.871  0.07215 . \nwt          -3.23810    0.88990  -3.639  0.00114 **\nhp          -0.01765    0.01415  -1.247  0.22309   \nam           2.92550    1.39715   2.094  0.04579 * \nqsec         0.81060    0.43887   1.847  0.07573 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.435 on 27 degrees of freedom\nMultiple R-squared:  0.8579,    Adjusted R-squared:  0.8368 \nF-statistic: 40.74 on 4 and 27 DF,  p-value: 4.589e-11\n\n\n\n\nCode\nggplot(for.model, aes(sample = .resid)) +\n    stat_qq() +\n    stat_qq_line()\n\n\n\n\n\nCode\nhist(resid(for.model))\n\n\n\n\n\nCode\nggplot(for.model, aes(x = .fitted, y = .resid)) +\n    geom_point() +\n    geom_line(y = 0)"
  },
  {
    "objectID": "notes/analytics/07032023/lab_5.html",
    "href": "notes/analytics/07032023/lab_5.html",
    "title": "Lab 5",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndrugdose = pd.read_csv('https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/drug.csv')\n\ndrugdose.T.head()\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n\n\n\n\nPatientID\n69\n162\n181\n209\n308\n331\n340\n350\n360\n363\n...\n9679\n9682\n9693\n9714\n9735\n9865\n9878\n9941\n9947\n9990\n\n\nDrugDose\n2\n4\n1\n4\n2\n4\n4\n1\n2\n4\n...\n2\n2\n4\n2\n1\n3\n1\n2\n1\n2\n\n\nDisease\nB\nA\nB\nA\nA\nC\nC\nB\nB\nA\n...\nB\nB\nA\nC\nC\nB\nC\nB\nA\nC\n\n\nBloodP\n13\n-47\n12\n-4\n4\n37\n-19\n-9\n-17\n-41\n...\n15\n21\n6\n-32\n-7\n-24\n19\n23\n5\n-24\n\n\n\n\n4 rows × 170 columns"
  },
  {
    "objectID": "notes/analytics/07032023/lab_5.html#a",
    "href": "notes/analytics/07032023/lab_5.html#a",
    "title": "Lab 5",
    "section": "1.1 a",
    "text": "1.1 a\n\n\nCode\nax = sns.catplot(\n    drugdose, kind=\"bar\",\n    x=\"DrugDose\", y=\"BloodP\", hue=\"Disease\",\n    errorbar=None, palette=\"dark\", alpha=.6, height=6\n)\n\n\n\n\n\n\nThere seems to be a significant difference in blood pressure for the 100mg drug dose with disease B as well as the 200mg drug dose with disease B"
  },
  {
    "objectID": "notes/analytics/07032023/lab_5.html#b",
    "href": "notes/analytics/07032023/lab_5.html#b",
    "title": "Lab 5",
    "section": "1.2 b",
    "text": "1.2 b\n\n\nCode\ndrug_lm = smf.ols('BloodP ~ C(DrugDose) * C(Disease)', drugdose).fit()\n\nsm.stats.anova_lm(drug_lm, typ=2)\n\n\n\n\n\n\n\n\n\nsum_sq\ndf\nF\nPR(&gt;F)\n\n\n\n\nC(DrugDose)\n202.577573\n3.0\n0.156057\n9.256570e-01\n\n\nC(Disease)\n19276.486901\n2.0\n22.274702\n3.005823e-09\n\n\nC(DrugDose):C(Disease)\n17146.316981\n6.0\n6.604404\n3.021199e-06\n\n\nResidual\n68366.458868\n158.0\nNaN\nNaN\n\n\n\n\n\n\n\n\nInteraction between DrugDose and Disease seems to be significant in explaining BloodP"
  },
  {
    "objectID": "notes/analytics/07032023/lab_5.html#c",
    "href": "notes/analytics/07032023/lab_5.html#c",
    "title": "Lab 5",
    "section": "1.3 c",
    "text": "1.3 c\n\n\nCode\nunique_disease = np.sort(drugdose['Disease'].unique())\n\nfor disease in unique_disease:\n    sliced_data = smf.ols('BloodP ~ C(DrugDose)', drugdose[drugdose['Disease'] == disease]).fit()\n    print(f'\\nDisease: {disease}')\n    print(sm.stats.anova_lm(sliced_data)['PR(&gt;F)'])\n\n\n\nDisease: A\nC(DrugDose)    0.001123\nResidual            NaN\nName: PR(&gt;F), dtype: float64\n\nDisease: B\nC(DrugDose)    0.00027\nResidual           NaN\nName: PR(&gt;F), dtype: float64\n\nDisease: C\nC(DrugDose)    0.81447\nResidual           NaN\nName: PR(&gt;F), dtype: float64\n\n\n\nFor diseases A and B there seems to be significant differences in drug dose on blood pressure. Disease C does not seem to have a significant difference in drug dose on blood pressure."
  },
  {
    "objectID": "notes/analytics/07032023/lab_5.html#a-1",
    "href": "notes/analytics/07032023/lab_5.html#a-1",
    "title": "Lab 5",
    "section": "2.1 a",
    "text": "2.1 a\n\n\nCode\ndisks_lm = smf.ols('Time ~ C(Technician) * C(Brand)', disks).fit()\n\nprint(disks_lm.summary())\nsm.stats.anova_lm(disks_lm, typ=2)\n\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   Time   R-squared:                       0.619\nModel:                            OLS   Adj. R-squared:                  0.569\nMethod:                 Least Squares   F-statistic:                     12.38\nDate:                Tue, 04 Jul 2023   Prob (F-statistic):           1.66e-13\nTime:                        20:05:50   Log-Likelihood:                -376.10\nNo. Observations:                  96   AIC:                             776.2\nDf Residuals:                      84   BIC:                             807.0\nDf Model:                          11                                         \nCovariance Type:            nonrobust                                         \n=========================================================================================================\n                                            coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------------------------------\nIntercept                                37.5000      4.599      8.154      0.000      28.354      46.646\nC(Technician)[T.Bob]                     19.3750      6.504      2.979      0.004       6.441      32.309\nC(Technician)[T.Justin]                   5.0000      6.504      0.769      0.444      -7.934      17.934\nC(Technician)[T.Karen]                   35.5000      6.504      5.458      0.000      22.566      48.434\nC(Brand)[T.2]                            -6.2500      6.504     -0.961      0.339     -19.184       6.684\nC(Brand)[T.3]                            12.1250      6.504      1.864      0.066      -0.809      25.059\nC(Technician)[T.Bob]:C(Brand)[T.2]       21.5000      9.198      2.337      0.022       3.209      39.791\nC(Technician)[T.Justin]:C(Brand)[T.2]     8.7500      9.198      0.951      0.344      -9.541      27.041\nC(Technician)[T.Karen]:C(Brand)[T.2]    -11.0000      9.198     -1.196      0.235     -29.291       7.291\nC(Technician)[T.Bob]:C(Brand)[T.3]      -25.8750      9.198     -2.813      0.006     -44.166      -7.584\nC(Technician)[T.Justin]:C(Brand)[T.3]   -10.1250      9.198     -1.101      0.274     -28.416       8.166\nC(Technician)[T.Karen]:C(Brand)[T.3]     -0.1250      9.198     -0.014      0.989     -18.416      18.166\n==============================================================================\nOmnibus:                        2.790   Durbin-Watson:                   2.199\nProb(Omnibus):                  0.248   Jarque-Bera (JB):                2.505\nSkew:                           0.396   Prob(JB):                        0.286\nKurtosis:                       2.997   Cond. No.                         17.9\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\n\n\n\n\nsum_sq\ndf\nF\nPR(&gt;F)\n\n\n\n\nC(Technician)\n14797.875000\n3.0\n29.151194\n5.153348e-13\n\n\nC(Brand)\n343.145833\n2.0\n1.013974\n3.671708e-01\n\n\nC(Technician):C(Brand)\n7907.437500\n6.0\n7.788660\n1.122763e-06\n\n\nResidual\n14213.500000\n84.0\nNaN\nNaN\n\n\n\n\n\n\n\n\nAt a significant level of \\(\\alpha = 0.05\\), the overall F-test is significant in our model\nSimilarly, the interaction is also significant"
  },
  {
    "objectID": "notes/analytics/07032023/lab_5.html#b-1",
    "href": "notes/analytics/07032023/lab_5.html#b-1",
    "title": "Lab 5",
    "section": "2.2 b",
    "text": "2.2 b\nSince our interaction is significant, we no longer care about the significance of our main effects. With model hierarchy, we keep the main effects in our model as well"
  },
  {
    "objectID": "notes/analytics/07032023/lab_5.html#c-1",
    "href": "notes/analytics/07032023/lab_5.html#c-1",
    "title": "Lab 5",
    "section": "2.3 c",
    "text": "2.3 c\n\n\nCode\nimport statsmodels.stats.multicomp as mc\n\nunique_brands = np.sort(disks['Brand'].unique())\n\nfor b in unique_brands:\n    sliced_data = disks[disks['Brand'] == b]\n    sliced_ols = smf.ols('Time ~ C(Technician)', sliced_data).fit()\n    print(f'\\nBrand: {b}')\n    print(mc.MultiComparison(sliced_data['Time'], sliced_data['Technician']).tukeyhsd(alpha=0.01))\n    print(sm.stats.anova_lm(sliced_ols))\n\n\n\nBrand: 1\n Multiple Comparison of Means - Tukey HSD, FWER=0.01 \n=====================================================\ngroup1 group2 meandiff p-adj   lower    upper  reject\n-----------------------------------------------------\nAngela    Bob   19.375 0.0118  -0.3933 39.1433  False\nAngela Justin      5.0 0.8233 -14.7683 24.7683  False\nAngela  Karen     35.5    0.0  15.7317 55.2683   True\n   Bob Justin  -14.375 0.0847 -34.1433  5.3933  False\n   Bob  Karen   16.125 0.0442  -3.6433 35.8933  False\nJustin  Karen     30.5 0.0001  10.7317 50.2683   True\n-----------------------------------------------------\n                 df      sum_sq      mean_sq          F    PR(&gt;F)\nC(Technician)   3.0  6115.09375  2038.364583  15.208129  0.000005\nResidual       28.0  3752.87500   134.031250        NaN       NaN\n\nBrand: 2\n Multiple Comparison of Means - Tukey HSD, FWER=0.01 \n=====================================================\ngroup1 group2 meandiff p-adj   lower    upper  reject\n-----------------------------------------------------\nAngela    Bob   40.875    0.0  15.6475 66.1025   True\nAngela Justin    13.75 0.2673 -11.4775 38.9775  False\nAngela  Karen     24.5 0.0127  -0.7275 49.7275  False\n   Bob Justin  -27.125 0.0052 -52.3525 -1.8975   True\n   Bob  Karen  -16.375 0.1434 -41.6025  8.8525  False\nJustin  Karen    10.75  0.477 -14.4775 35.9775  False\n-----------------------------------------------------\n                 df      sum_sq      mean_sq          F    PR(&gt;F)\nC(Technician)   3.0  7159.09375  2386.364583  10.932522  0.000063\nResidual       28.0  6111.87500   218.281250        NaN       NaN\n\nBrand: 3\n Multiple Comparison of Means - Tukey HSD, FWER=0.01 \n=====================================================\ngroup1 group2 meandiff p-adj   lower    upper  reject\n-----------------------------------------------------\nAngela    Bob     -6.5 0.7259 -27.7799 14.7799  False\nAngela Justin   -5.125 0.8433 -26.4049 16.1549  False\nAngela  Karen   35.375    0.0  14.0951 56.6549   True\n   Bob Justin    1.375 0.9961 -19.9049 22.6549  False\n   Bob  Karen   41.875    0.0  20.5951 63.1549   True\nJustin  Karen     40.5    0.0  19.2201 61.7799   True\n-----------------------------------------------------\n                 df    sum_sq      mean_sq         F        PR(&gt;F)\nC(Technician)   3.0  9431.125  3143.708333  20.24118  3.537879e-07\nResidual       28.0  4348.750   155.312500       NaN           NaN\n\n\n\nThere are differences between different technicians for each brand of disk drive"
  },
  {
    "objectID": "notes/analytics/07032023/index.html",
    "href": "notes/analytics/07032023/index.html",
    "title": "More Complex ANOVA & Regression",
    "section": "",
    "text": "flowchart LR\n    A[Continuous Target Variable] --&gt; B[One-Way ANOVA]\n    A --&gt; C[Two-Way ANOVA]\n    A --&gt; D[n-Way ANOVA]"
  },
  {
    "objectID": "notes/analytics/07032023/index.html#post-hoc-testing",
    "href": "notes/analytics/07032023/index.html#post-hoc-testing",
    "title": "More Complex ANOVA & Regression",
    "section": "4.1 Post-Hoc Testing",
    "text": "4.1 Post-Hoc Testing\nWe have statistical differences among the categories and we want to know where these differences exist.\n\n\nCode\ntukey_ames2 &lt;- TukeyHSD(ames_aov2)\nprint(tukey_ames2)\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Sale_Price ~ Heating_QC + Central_Air, data = train)\n\n$Heating_QC\n                       diff        lwr       upr     p adj\nFair-Poor          49176.42 -63650.448 162003.29 0.7571980\nTypical-Poor       67781.01 -42800.320 178362.35 0.4506761\nGood-Poor          87753.89 -23040.253 198548.03 0.1945181\nExcellent-Poor    146288.89  35818.859 256758.92 0.0028361\nTypical-Fair       18604.59  -6326.425  43535.61 0.2484556\nGood-Fair          38577.47  12718.894  64436.04 0.0004622\nExcellent-Fair     97112.47  72679.867 121545.07 0.0000000\nGood-Typical       19972.87   7050.230  32895.52 0.0002470\nExcellent-Typical  78507.88  68746.678  88269.07 0.0000000\nExcellent-Good     58535.00  46602.229  70467.78 0.0000000\n\n$Central_Air\n        diff      lwr      upr p adj\nY-N 43256.57 31508.27 55004.87     0\n\n\nCode\nplot(tukey_ames2, las = 1)\n\n\n\n\n\n\n\n\n\ndiff refers to the average difference in Sale_Price between the two categories\n\nKeep in mind that if you increase your sample size, you should decrease your significance level. P-values always go down with an increase in sample size."
  },
  {
    "objectID": "notes/analytics/07032023/index.html#r-code",
    "href": "notes/analytics/07032023/index.html#r-code",
    "title": "More Complex ANOVA & Regression",
    "section": "5.1 R Code",
    "text": "5.1 R Code\n\n\nCode\names_aov_int &lt;- aov(Sale_Price ~ Heating_QC * Central_Air, data = train)\nsummary(ames_aov_int)\n\n\n                         Df    Sum Sq   Mean Sq F value   Pr(&gt;F)    \nHeating_QC                4 2.891e+12 7.228e+11 147.897  &lt; 2e-16 ***\nCentral_Air               1 2.903e+11 2.903e+11  59.403 1.99e-14 ***\nHeating_QC:Central_Air    4 3.972e+10 9.930e+09   2.032   0.0875 .  \nResiduals              2041 9.975e+12 4.887e+09                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nWhen you’re looking at significance, make sure to look at the interaction’s significance first.\n\nIf interaction exists, we no longer care if the individual variables are significant or not because it’s the interaction that matters."
  },
  {
    "objectID": "notes/analytics/07032023/index.html#model-hierarchy",
    "href": "notes/analytics/07032023/index.html#model-hierarchy",
    "title": "More Complex ANOVA & Regression",
    "section": "5.2 Model Hierarchy",
    "text": "5.2 Model Hierarchy\nIdea of model hierarchy: If higher-order terms are significant, then we should keep all the main effect terms that are a part of the higher-order terms as well."
  },
  {
    "objectID": "notes/analytics/07032023/index.html#slicing",
    "href": "notes/analytics/07032023/index.html#slicing",
    "title": "More Complex ANOVA & Regression",
    "section": "5.3 Slicing",
    "text": "5.3 Slicing\nIf the interaction term was significant, the number of level pairs we would have to consider can be overwhelming. Slicing performs an F-test for means for one variable within the level of another variable.\nAn example is subsetting the data into Central_Air: Yes and Central_Air: No and then seeing the significance of Heating_QC:\n\n\nCode\nCA_aov &lt;- train %&gt;%\n    group_by(Central_Air) %&gt;%\n    nest() %&gt;%\n    mutate(aov = map(data, ~ summary(aov(Sale_Price ~ Heating_QC, data = .x))))\nprint(CA_aov$aov)\n\n\n[[1]]\n              Df    Sum Sq   Mean Sq F value Pr(&gt;F)    \nHeating_QC     4 2.242e+12 5.606e+11   108.5 &lt;2e-16 ***\nResiduals   1899 9.809e+12 5.165e+09                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n[[2]]\n             Df    Sum Sq   Mean Sq F value  Pr(&gt;F)   \nHeating_QC    4 1.774e+10 4.435e+09   3.793 0.00582 **\nResiduals   142 1.660e+11 1.169e+09                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "notes/analytics/07032023/index.html#assumptions",
    "href": "notes/analytics/07032023/index.html#assumptions",
    "title": "More Complex ANOVA & Regression",
    "section": "5.4 Assumptions",
    "text": "5.4 Assumptions\nSame as One-Way ANOVA:\n\nIndependence of observations\nEquality of variance\n\nLevene Test only available for interactions\n\nNormality of categories"
  },
  {
    "objectID": "notes/analytics/07172023/lab_12.html",
    "href": "notes/analytics/07172023/lab_12.html",
    "title": "Lab 12",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nsafety &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/safety.csv\")"
  },
  {
    "objectID": "notes/analytics/07172023/lab_12.html#a",
    "href": "notes/analytics/07172023/lab_12.html#a",
    "title": "Lab 12",
    "section": "1.1 a",
    "text": "1.1 a\n\nUnsafe is ordinal\nType is nominal\nRegion is ordinal\nWeight is ordinal\nSize is ordinal"
  },
  {
    "objectID": "notes/analytics/07172023/lab_12.html#b",
    "href": "notes/analytics/07172023/lab_12.html#b",
    "title": "Lab 12",
    "section": "1.2 b",
    "text": "1.2 b\n\n\nCode\ntable(safety$Region, safety$Unsafe)\n\n\n           \n             0  1\n  Asia      20 15\n  N America 46 15\n\n\nCode\nggplot(safety) +\n    geom_bar(aes(x = Region, fill = factor(Unsafe)))\n\n\n\n\n\n\nPercentage of cars classified as unsafe in the Asia region is 42.9 percent\nPercentage of cars classified as safe in the North America region is 75.4 percent\nAppropriate test to use is Mantel-Haenszel\n\n\\(H_0:\\) No linear association, \\(H_a:\\) Linear association exists\n\n\n\n\nCode\nlibrary(vcdExtra)\n\n\nLoading required package: vcd\n\n\nLoading required package: grid\n\n\nLoading required package: gnm\n\n\n\nAttaching package: 'vcdExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    summarise\n\n\nCode\nlibrary(DescTools)\n\nCMHtest(table(safety$Region, safety$Unsafe))$table[1, ]\n\n\n     Chisq         Df       Prob \n3.41813924 1.00000000 0.06448366 \n\n\nCode\nOddsRatio(table(safety$Region, safety$Unsafe))\n\n\n[1] 0.4347826\n\n\nCode\ntable(safety$Region, safety$Unsafe)\n\n\n           \n             0  1\n  Asia      20 15\n  N America 46 15\n\n\n\nAt an \\(\\alpha\\) level of 0.05, we do not reject the null hypothesis that there is no linear association between Region and Safety\nThere are 0.435 times the odds to be safe if it’s in the Asia region"
  },
  {
    "objectID": "notes/analytics/07172023/lab_12.html#c",
    "href": "notes/analytics/07172023/lab_12.html#c",
    "title": "Lab 12",
    "section": "1.3 c",
    "text": "1.3 c\nAppropriate test is Mantel-Haenszel\n\n\nCode\nCMHtest(table(safety$Size, safety$Unsafe))$table[1, ]\n\n\n       Chisq           Df         Prob \n2.770978e+01 1.000000e+00 1.409484e-07 \n\n\n\nWe reject the null hypothesis that there is no linear association between the two variables\n\n\n\nCode\ncor.test(\n    x = as.numeric(ordered(safety$Size)), \n    y = as.numeric(ordered(safety$Unsafe)), \n    method = \"spearman\"\n)\n\n\nWarning in cor.test.default(x = as.numeric(ordered(safety$Size)), y =\nas.numeric(ordered(safety$Unsafe)), : Cannot compute exact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  as.numeric(ordered(safety$Size)) and as.numeric(ordered(safety$Unsafe))\nS = 227423, p-value = 1.136e-08\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n-0.5424769 \n\n\n\nIt’s not too strong at \\(\\rho = -0.542\\)"
  },
  {
    "objectID": "notes/analytics/06292023/breakout_3.html",
    "href": "notes/analytics/06292023/breakout_3.html",
    "title": "1 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nbike &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/bike.csv\")\nglimpse(bike)\n\n\nRows: 17,379\nColumns: 16\n$ dteday     &lt;int&gt; 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 149…\n$ season     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ yr         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ mnth       &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ hr         &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ holiday    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ weekday    &lt;int&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,…\n$ workingday &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ weathersit &lt;int&gt; 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3,…\n$ temp       &lt;dbl&gt; 0.24, 0.22, 0.22, 0.24, 0.24, 0.24, 0.22, 0.20, 0.24, 0.32,…\n$ atemp      &lt;dbl&gt; 0.2879, 0.2727, 0.2727, 0.2879, 0.2879, 0.2576, 0.2727, 0.2…\n$ hum        &lt;dbl&gt; 0.81, 0.80, 0.80, 0.75, 0.75, 0.75, 0.80, 0.86, 0.75, 0.76,…\n$ windspeed  &lt;dbl&gt; 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0896, 0.0000, 0.0…\n$ casual     &lt;int&gt; 3, 8, 5, 3, 0, 0, 2, 1, 1, 8, 12, 26, 29, 47, 35, 40, 41, 1…\n$ registered &lt;int&gt; 13, 32, 27, 10, 1, 1, 0, 2, 7, 6, 24, 30, 55, 47, 71, 70, 5…\n$ cnt        &lt;int&gt; 16, 40, 32, 13, 1, 1, 2, 3, 8, 14, 36, 56, 84, 94, 106, 110…\n\n\n\n1 1\n\n\nCode\nbike_lm &lt;- lm(cnt ~ weathersit, data = bike)\n\nggplot(bike, aes(x = cnt, fill = factor(weathersit))) +\n    geom_density(alpha = 0.2, position = \"identity\") +\n    labs(x = \"Number of riders\")\n\n\n\n\n\nCode\nggplot(bike, aes(y = cnt, x = factor(weathersit), fill = factor(weathersit))) +\n    geom_boxplot() +\n    labs(y = \"Number of riders\", x = \"Weather Category\") +\n    stat_summary(fun = mean, geom = \"point\", shape = 2, size = 3, color = \"pink\", fill = \"red\") +\n    scale_fill_brewer(palette = \"Blues\") +\n    coord_flip()"
  },
  {
    "objectID": "notes/analytics/06292023/index.html",
    "href": "notes/analytics/06292023/index.html",
    "title": "Introduction to ANOVA and Regression",
    "section": "",
    "text": "The population model for our linear model is written as:\n\\[\ny = \\beta_0 + \\beta_1x_1 + \\cdots + \\beta_kx_k + \\varepsilon\n\\]\n\n\\(\\varepsilon\\) is the random error\nAll the modeled signal is the rest of the equation which is called the deterministic component\n\\(x_1, \\cdots, x_k\\) are the explanatory variables\n\\(y\\) is the response variable\n\nTypically linear models are used in an explanatory model fashion–we are trying to answer how our explanatory variables are related to our response. We are not predicting the response.\n\n\nBefore you look for any relationships, you should split into training, validation and test samples.\nDifferent rules of thumb for splits:\n\nLots of data? 50-40-10 split\nNot so much data? 70-20-10 split\nNot enough data? Use Cross-Validation\n\n\n\nModels will capture nuances of the data on which they’re built (training data)\nWhen these “patterns” do not hold up in validation or test, the model performance suffers. We call this overfitting.\n\n\n\nOverfitting Example\n\n\n\n\n\n\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(AmesHousing)\n\names &lt;- make_ordinal_ames()\nset.seed(123)\names &lt;- ames |&gt; mutate(id = row_number())\ntrain &lt;- ames |&gt; sample_frac(0.7)\ntest &lt;- anti_join(ames, train, by = \"id\")\n\ndim(train)\n\n\n[1] 2051   82\n\n\nCode\ndim(test)\n\n\n[1] 879  82"
  },
  {
    "objectID": "notes/analytics/06292023/index.html#honest-model-assessment",
    "href": "notes/analytics/06292023/index.html#honest-model-assessment",
    "title": "Introduction to ANOVA and Regression",
    "section": "",
    "text": "Before you look for any relationships, you should split into training, validation and test samples.\nDifferent rules of thumb for splits:\n\nLots of data? 50-40-10 split\nNot so much data? 70-20-10 split\nNot enough data? Use Cross-Validation\n\n\n\nModels will capture nuances of the data on which they’re built (training data)\nWhen these “patterns” do not hold up in validation or test, the model performance suffers. We call this overfitting.\n\n\n\nOverfitting Example"
  },
  {
    "objectID": "notes/analytics/06292023/index.html#train-test-split-in-r",
    "href": "notes/analytics/06292023/index.html#train-test-split-in-r",
    "title": "Introduction to ANOVA and Regression",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(AmesHousing)\n\names &lt;- make_ordinal_ames()\nset.seed(123)\names &lt;- ames |&gt; mutate(id = row_number())\ntrain &lt;- ames |&gt; sample_frac(0.7)\ntest &lt;- anti_join(ames, train, by = \"id\")\n\ndim(train)\n\n\n[1] 2051   82\n\n\nCode\ndim(test)\n\n\n[1] 879  82"
  },
  {
    "objectID": "notes/analytics/06292023/index.html#assumptions-for-anova",
    "href": "notes/analytics/06292023/index.html#assumptions-for-anova",
    "title": "Introduction to ANOVA and Regression",
    "section": "3.1 Assumptions for ANOVA",
    "text": "3.1 Assumptions for ANOVA\n\nObservations are independent\nEach group is normally distributed\n\nOr the residuals of the ANOVA model are normally distributed\n\nAll groups have equal variances (homeskedasticity)\n\nIf true, use “pooled” variance\nIf false, use Welch’s ANOVA\n\n\n\n3.1.1 Assessing ANOVA Assumptions\n\nGood data collection designs help the independence assumption\nInformal plots (QQ-Plots) or formal tests can verify the normally distributed assumption\nFormal test of equal variances or viewing residual plot to assess homoskedasticity"
  },
  {
    "objectID": "notes/analytics/06292023/index.html#anova-hypothesis-test-in-r",
    "href": "notes/analytics/06292023/index.html#anova-hypothesis-test-in-r",
    "title": "Introduction to ANOVA and Regression",
    "section": "3.2 ANOVA Hypothesis Test in R",
    "text": "3.2 ANOVA Hypothesis Test in R\n\\(H_0\\) is the means of each level of Exter-Qual are equal. \\(H_a\\) is at least one mean is different.\n\n\nCode\names_lm &lt;- lm(Sale_Price ~ Exter_Qual, data = train)\nanova(ames_lm)\n\n\nAnalysis of Variance Table\n\nResponse: Sale_Price\n             Df     Sum Sq    Mean Sq F value    Pr(&gt;F)    \nExter_Qual    3 6.6913e+12 2.2304e+12  701.83 &lt; 2.2e-16 ***\nResiduals  2047 6.5054e+12 3.1780e+09                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nThere appears to be a significant difference in mean sales price between the different levels of exterior quality.\n\n\n\nCode\ntrain$pred_anova &lt;- predict(ames_lm, data = train)\ntrain$resid_anova &lt;- resid(ames_lm, data = train)\n\nmodel_output = train |&gt; select(Sale_Price, pred_anova, resid_anova)\n\n\nAnd then to test assumptions:\n\n\nCode\npar(mfrow = c(2, 2))\nplot(ames_lm)\n\n\n\n\n\nTo formally test our variance, we have Levene’s Test which requires normality of underlying data and Fligner’s Test which does not require normality.\n\n\nCode\nlibrary(car)\n\n\nLoading required package: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\n\nCode\nleveneTest(Sale_Price ~ Exter_Qual, data = train)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n        Df F value    Pr(&gt;F)    \ngroup    3  76.879 &lt; 2.2e-16 ***\n      2047                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nfligner.test(Sale_Price ~ Exter_Qual, data = train)$p.value\n\n\n[1] 1.873388e-44"
  },
  {
    "objectID": "notes/analytics/06292023/index.html#kruskal-wallis-anova-in-r",
    "href": "notes/analytics/06292023/index.html#kruskal-wallis-anova-in-r",
    "title": "Introduction to ANOVA and Regression",
    "section": "5.1 Kruskal-Wallis ANOVA in R",
    "text": "5.1 Kruskal-Wallis ANOVA in R\n\n\nCode\nkruskal.test(Sale_Price ~ Exter_Qual, data = train)\n\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Sale_Price by Exter_Qual\nKruskal-Wallis chi-squared = 975.98, df = 3, p-value &lt; 2.2e-16"
  },
  {
    "objectID": "notes/analytics/06292023/index.html#tukeys-honest-significant-difference",
    "href": "notes/analytics/06292023/index.html#tukeys-honest-significant-difference",
    "title": "Introduction to ANOVA and Regression",
    "section": "7.1 Tukey’s Honest Significant Difference",
    "text": "7.1 Tukey’s Honest Significant Difference\nAppropriate for making all pairwise comparisons between groups.\nExperimentwise error rate is equal to \\(\\alpha\\) when all pairwise comparisons are made and less than \\(\\alpha\\) otherwise.\n\n\nCode\names_aov &lt;- aov(Sale_Price ~ Exter_Qual, data = train)\ntukey.ames &lt;- TukeyHSD(ames_aov)\nprint(tukey.ames)\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Sale_Price ~ Exter_Qual, data = train)\n\n$Exter_Qual\n                       diff       lwr       upr p adj\nTypical-Fair       57887.91  30194.31  85581.52 5e-07\nGood-Fair         144690.25 116739.87 172640.63 0e+00\nExcellent-Fair    291684.79 259752.41 323617.16 0e+00\nGood-Typical       86802.34  79910.03  93694.64 0e+00\nExcellent-Typical 233796.87 216886.62 250707.12 0e+00\nExcellent-Good    146994.54 129666.98 164322.10 0e+00\n\n\n\nConclusion is that all pairs are significantly different"
  },
  {
    "objectID": "notes/analytics/06292023/index.html#dunnetts-test-for-control-comparison",
    "href": "notes/analytics/06292023/index.html#dunnetts-test-for-control-comparison",
    "title": "Introduction to ANOVA and Regression",
    "section": "7.2 Dunnett’s Test for Control Comparison",
    "text": "7.2 Dunnett’s Test for Control Comparison\nIf you’re not making all pairwise comparisons, Tukey’s is overly conservative.\n\n\nCode\nlibrary(DescTools)\n\n\n\nAttaching package: 'DescTools'\n\n\nThe following object is masked from 'package:car':\n\n    Recode\n\n\nCode\nDunnettTest(x = train$Sale_Price, g = train$Exter_Qual, control = \"Typical\")\n\n\n\n  Dunnett's test for comparing several treatments with a control :  \n    95% family-wise confidence level\n\n$Typical\n                       diff    lwr.ci    upr.ci    pval    \nFair-Typical      -57887.91 -83628.55 -32147.28 2.6e-07 ***\nGood-Typical       86802.34  80396.08  93208.59 &lt; 2e-16 ***\nExcellent-Typical 233796.87 218079.15 249514.60 &lt; 2e-16 ***\n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "notes/analytics/06282023/lab_2.html",
    "href": "notes/analytics/06282023/lab_2.html",
    "title": "Yang MSA",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(UsingR)\n\n\nLoading required package: MASS\n\nAttaching package: 'MASS'\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\nLoading required package: HistData\nLoading required package: Hmisc\n\nAttaching package: 'Hmisc'\n\nThe following objects are masked from 'package:dplyr':\n\n    src, summarize\n\nThe following objects are masked from 'package:base':\n\n    format.pval, units\n\n\nCode\ndata(normtemp)\nglimpse(normtemp)\n\n\nRows: 130\nColumns: 3\n$ temperature &lt;dbl&gt; 96.3, 96.7, 96.9, 97.0, 97.1, 97.1, 97.1, 97.2, 97.3, 97.4…\n$ gender      &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ hr          &lt;int&gt; 70, 71, 74, 80, 73, 75, 82, 64, 69, 70, 68, 72, 78, 70, 75…\n\n\nCode\n?normtemp\n\n\n\nRevisit the NormTemp dataset from Lab 1, where we examined the observed mean body temperature (temperature) in comparison to the well-known “average” of 98.6\n\n\n\nCode\nt.test(normtemp$temperature, mu = 98.6)\n\n\n\n    One Sample t-test\n\ndata:  normtemp$temperature\nt = -5.4548, df = 129, p-value = 2.411e-07\nalternative hypothesis: true mean is not equal to 98.6\n95 percent confidence interval:\n 98.12200 98.37646\nsample estimates:\nmean of x \n 98.24923 \n\n\n\nThe p-value is 2.411e-07\nThe p-value is the probability that we observe our data given that the mean body temperature is 98.6\nGiven our low p-value at a significance level of \\(\\alpha = 0.05\\) we reject our null hypothesis. We believe the actual mean is significantly different from 98.6\nThe 95% confidence interval for temperature is [98.12200, 98.37646]\n\n\n\nCode\nfemales &lt;- normtemp[normtemp$gender == 2, ]\nt.test(females$temperature, mu = 98.6)\n\n\n\n    One Sample t-test\n\ndata:  females$temperature\nt = -2.2355, df = 64, p-value = 0.02888\nalternative hypothesis: true mean is not equal to 98.6\n95 percent confidence interval:\n 98.20962 98.57807\nsample estimates:\nmean of x \n 98.39385 \n\n\n\nGiven our p-value \\(&lt; \\alpha\\) our conclusion does not change\n\n\n\nCode\nggplot(normtemp, aes(sample = temperature, color = gender)) +\n    stat_qq() +\n    stat_qq_line()\n\n\nWarning: The following aesthetics were dropped during statistical transformation: colour\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\nThe following aesthetics were dropped during statistical transformation: colour\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\nApproximately Normal\n\n\n\nCode\nvar.test(temperature ~ gender, data = normtemp)\n\n\n\n    F test to compare two variances\n\ndata:  temperature by gender\nF = 0.88329, num df = 64, denom df = 64, p-value = 0.6211\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.5387604 1.4481404\nsample estimates:\nratio of variances \n         0.8832897 \n\n\n\nWe believe variances are equal\n\n\n\nCode\nt.test(temperature ~ gender, data = normtemp)\n\n\n\n    Welch Two Sample t-test\n\ndata:  temperature by gender\nt = -2.2854, df = 127.51, p-value = 0.02394\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -0.53964856 -0.03881298\nsample estimates:\nmean in group 1 mean in group 2 \n       98.10462        98.39385 \n\n\n\nAt a significance level of 0.05, we reject our null hypothesis that there is no difference in means between the two genders\n\n\nThe Airline dataset contains information regarding the number of international airline travelers (variable air) across different months of the year from 1949-1960. We are interested in knowing if during this time period there was a significant difference between air travel in the Summer months of June, July, and August vs. the remainder of the year? Use a statistical hypothesis test (alpha=0.05) to support your answer.\n\n\n\nCode\ndata(AirPassengers)\nlibrary(tseries)\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nCode\nlibrary(forecast)\ncycle(AirPassengers)\n\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n1949   1   2   3   4   5   6   7   8   9  10  11  12\n1950   1   2   3   4   5   6   7   8   9  10  11  12\n1951   1   2   3   4   5   6   7   8   9  10  11  12\n1952   1   2   3   4   5   6   7   8   9  10  11  12\n1953   1   2   3   4   5   6   7   8   9  10  11  12\n1954   1   2   3   4   5   6   7   8   9  10  11  12\n1955   1   2   3   4   5   6   7   8   9  10  11  12\n1956   1   2   3   4   5   6   7   8   9  10  11  12\n1957   1   2   3   4   5   6   7   8   9  10  11  12\n1958   1   2   3   4   5   6   7   8   9  10  11  12\n1959   1   2   3   4   5   6   7   8   9  10  11  12\n1960   1   2   3   4   5   6   7   8   9  10  11  12\n\n\n\n\nCode\nair1 = data.frame(AirPassengers)\nair2 = air1 |&gt; mutate(summer = ifelse(cycle(AirPassengers) %in% 6:8, 1, 0))\n\n\n\n\nCode\nggplot(air2, aes(sample = AirPassengers, color = factor(summer))) +\n    stat_qq() +\n    stat_qq_line()\n\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\nNormality not met. We will use a nonparametric test\n\n\n\nCode\nggplot(air2, aes(x = AirPassengers, color = factor(summer))) +\n    geom_density()\n\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\nAfter plotting the distributions of both groups, we can see a similar shape but not a similar enough variation between the two groups.\nWhen we are conducting the Wilcoxon test we can’t necessarily claim anything about the mean or median but moreso about the distributional dominance\n\n\n\nCode\nwilcox.test(AirPassengers ~ summer, data = air2)\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  AirPassengers by summer\nW = 1346.5, p-value = 0.00588\nalternative hypothesis: true location shift is not equal to 0\n\n\n\nAt a significance level of 0.05, we reject our null hypothesis that the true location shift is equal to 0"
  },
  {
    "objectID": "notes/communication/062623/index.html",
    "href": "notes/communication/062623/index.html",
    "title": "Communications: 06/26/2023",
    "section": "",
    "text": "Make eye contact\n\nIf you’re uncomfortable making eye contact, you can look at the hairline or some other area near the face\n\nPracticing natural gestures\n\nYou can practice holding something heavy while you’re pointing in a presentation\nIf you fidget with your hands, press thumb into the joint of the middle finger\n\nAlways make sure to find something interesting to you about your presentation–when you are excited, you can get the audience excited.\n\nStrong speakers are prepared, show enthusiasm and demonstrate knowledge."
  },
  {
    "objectID": "notes/communication/062623/index.html#slide-order",
    "href": "notes/communication/062623/index.html#slide-order",
    "title": "Communications: 06/26/2023",
    "section": "2.1 Slide Order",
    "text": "2.1 Slide Order\n\n\n\n\nflowchart LR\n    A[Title Slide] --&gt; B[\"BLUF (Bottom Line Up Front)\"] --&gt; C[Agenda]\n    C --&gt; D[Section 1] --&gt; G[Appendix]\n    C --&gt; E[Section 2] --&gt; G\n    C --&gt; F[Questions] --&gt; G\n\n\n\n\n\n\nUse visual elements in the sections to highlight / call out specific details in graphs or tables\nUse a milestone bar to help the audience keep track of the overall location"
  },
  {
    "objectID": "notes/programming/index.html",
    "href": "notes/programming/index.html",
    "title": "Programming",
    "section": "",
    "text": "r4ds: Introduction\n\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nr4ds: Visualization Introduction\n\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2023\n\n\nYang Chen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro_visualization/index.html",
    "href": "notes/programming/R/r4ds/intro_visualization/index.html",
    "title": "r4ds: Visualization Introduction",
    "section": "",
    "text": "The book focuses on utilizing ggplot2 to build out data visualizations. The underlying system of the package is the grammar of graphics which builds up visuals through a layered approach of defined components.\nGrammar of graphics has a layered hierarchy of components:\nWe load the tidyverse package to have ggplot available to us in our workspace.\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nCode\n# Dataset and colorblind color palette\nlibrary(palmerpenguins)\nlibrary(ggthemes)"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro_visualization/index.html#terms",
    "href": "notes/programming/R/r4ds/intro_visualization/index.html#terms",
    "title": "r4ds: Visualization Introduction",
    "section": "1.1 Terms",
    "text": "1.1 Terms\n\nVariable is quantity, quality, property that can be measured.\nValue is the state of variable when it is measured. Value may change from measurement to measurement.\nObservations are measurements made under similar conditions. Observations contain several values for different variables. Sometimes called a data point.\nTabular data organizes values according to their variables and an observation. Considered tidy if every value is placed in its own cell, every variable in its own column, each observation on a row.\n\n\n\n\nIndex\n\\(x_1\\)\n\\(x_2\\)\n\n\n\n\n0\n1\nApple\n\n\n1\n2\nBanana\n\n\n\nTo view a dataframe / tibble:\n\n\nCode\npenguins\n\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nUse glimpse for a transposed view of the data. This function helps us view the different variables we have in our dataset.\n\n\nCode\nglimpse(penguins)\n\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro_visualization/index.html#initial-ggplot",
    "href": "notes/programming/R/r4ds/intro_visualization/index.html#initial-ggplot",
    "title": "r4ds: Visualization Introduction",
    "section": "2.1 Initial ggplot",
    "text": "2.1 Initial ggplot\nBegin a plot by calling the ggplot function along with the data you have.\n\n\nCode\nggplot(data = penguins)\n\n\n\n\n\nThe next layer in the hierarchy is aesthetics. We now add an additional layer that maps visual properties to our dataset variables. We can map x to flipper length and y to body mass.\n\n\nCode\nggplot(penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g))\n\n\n\n\n\nNext layer in the hierarchy is what actually plots the data. We define a geom to initialize a geometric object to present data. A point geom is created using geom_point.\n\n\nCode\nggplot(penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) +\n    geom_point()\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nRelationship appears to be positive between flipper length and body mass from the plot!"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro_visualization/index.html#aesthetics-and-layers",
    "href": "notes/programming/R/r4ds/intro_visualization/index.html#aesthetics-and-layers",
    "title": "r4ds: Visualization Introduction",
    "section": "2.2 Aesthetics and Layers",
    "text": "2.2 Aesthetics and Layers\nWe can assign a variable to different parameters in the aes function to have ggplot automatically assign unique values of an aesthetic to a unique level of the variable.\n\n\nCode\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n    geom_point()\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "notes/index.html",
    "href": "notes/index.html",
    "title": "Notes",
    "section": "",
    "text": "Programming 🐍\nNotes on Python, R and fun little experiments using software!\n\n\nAnalytics 🔎\nNotes curated from my statistics and analytics courses taught by Dr. Aric LaBarr and Dr. Susan Simmons.\n\n\nCommunication 🙊\nAll about professional and technical communication taught by Dr. Sarah Egan Warren!\n\n\nPrimer 🐤\nMSA Summer Primer 2023 Notes"
  },
  {
    "objectID": "notes/primer/categorical_data/index.html",
    "href": "notes/primer/categorical_data/index.html",
    "title": "Categorical Data Analysis",
    "section": "",
    "text": "Type of Predictors | Type of Response\nCategorical\nContinuous\nContinuous and Categorical\n\n\n\n\nContinuous\nAnalysis of Variance\nOrdinary Least Squares Regression\nAnalysis of Covariance\n\n\nCategorical\nTests of Association\nLogistic Regression\nLogistic Regression"
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#qualitative-data-types",
    "href": "notes/primer/categorical_data/index.html#qualitative-data-types",
    "title": "Categorical Data Analysis",
    "section": "2.1 Qualitative Data Types",
    "text": "2.1 Qualitative Data Types\nNominal\n\nCategories with no logical ordering\n\nOrdinal\n\nCategories with a logical order / only two ways to order the categories (binary is ordinal)"
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#examining-categorical-variables",
    "href": "notes/primer/categorical_data/index.html#examining-categorical-variables",
    "title": "Categorical Data Analysis",
    "section": "2.2 Examining Categorical Variables",
    "text": "2.2 Examining Categorical Variables\nBy examining distributions of categorical variables we can\n\nDetermine the frequencies of data values\nRecognize possible associations among variables\n\nAssociation exists between two categorical variables if distribution of one variable changes when the level of the other variable changes.\nIf there is no association, distribution of first variable is the same regardless of the level of the other."
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#chi-square-tests",
    "href": "notes/primer/categorical_data/index.html#chi-square-tests",
    "title": "Categorical Data Analysis",
    "section": "3.1 Chi-Square Tests",
    "text": "3.1 Chi-Square Tests\n\n\\(H_0\\): No Association\nObserved freq \\(=\\) Expected freq.\n\\(H_a\\): Association\nObserved freq. \\(\\neq\\) Expected freq.\n\nExpected freq. are calculated by the formula\n\\[\n\\frac{\\text{Row Total} \\times \\text{Column Total}}{\\text{Sample Size}}\n\\]\n\n3.1.1 \\(\\chi^2\\) Distribution\n\nBounded below by zero\nRight skewed\nOne set of degrees of freedom\n\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import chi2\n\nx = np.arange(0, 20, 0.001)\n\nplt.plot(x, chi2.pdf(x, df=4))\n\n\n\n\n\nFigure 1: Plot of a \\(\\chi^2\\) distribution with d.f. 4\n\n\n\n\n\n\n3.1.2 Pearson \\(\\chi^2\\) Test\n\\[\nQ_P = \\sum_{i=1}^{R} \\sum_{j=1}^{C} \\frac{(Obs_{i,j} - Exp_{i,j})^2}{Exp_{i,j}}\n\\]\n\\[\nd.f. = (\\#\\text{Rows} - 1)(\\#\\text{Columns} - 1)\n\\]\n\n\n3.1.3 Likelihood Ratio \\(\\chi^2\\) Test\n\\[\nQ_{LR} = 2 \\times \\sum_{i=1}^{R}\\sum_{j=1}^{C} Obs_{i,j} \\times \\log{(\\frac{Obs_{i,j}}{Exp_{i,j}})}\n\\]\n\\[\nd.f. = (\\#\\text{Rows} - 1)(\\#\\text{Columns} - 1)\n\\]"
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#example",
    "href": "notes/primer/categorical_data/index.html#example",
    "title": "Categorical Data Analysis",
    "section": "3.2 Example",
    "text": "3.2 Example\n\nA manager of a major car dealership wants to determine if the membership of a client in the loyalty program is associated with the color of car that they buy. With this knowledge, it potentially could help the sales staff show different cars to different clients to help improve the likelihood of a sale. The manager pull information from the previous years sales.\n\n\n\nCalculate the expected counts in the right table\n\n\n\nRecall that expected frequency is given by the the product of row total and column total over sample size.\n\n\nCode\nd = {\n    'black': {'yes': 149, 'no': 101},\n    'white': {'yes': 101, 'no': 66},\n    'blue': {'yes': 72, 'no': 108},\n    'red': {'yes': 96, 'no': 161},\n    'green': {'yes': 39, 'no': 65}\n}\ndf_cars = pd.DataFrame(d).T\ndf_cars['total'] = df_cars['yes'] + df_cars['no']\ndf_cars['exp_y'] = df_cars['total'] * \\\n    df_cars['yes'].sum() / df_cars['total'].sum()\ndf_cars['exp_n'] = df_cars['total'] * \\\n    df_cars['no'].sum() / df_cars['total'].sum()\ndf_cars.head()\n\n\n\n\n\n\n\n\n\nyes\nno\ntotal\nexp_y\nexp_n\n\n\n\n\nblack\n149\n101\n250\n119.258873\n130.741127\n\n\nwhite\n101\n66\n167\n79.664927\n87.335073\n\n\nblue\n72\n108\n180\n85.866388\n94.133612\n\n\nred\n96\n161\n257\n122.598121\n134.401879\n\n\ngreen\n39\n65\n104\n49.611691\n54.388309\n\n\n\n\n\n\n\n\n\nCompute \\(Q_P\\) and \\(Q_{LR}\\) and summarize results.\n\n\n\n\nCode\ndef calculate_pearson(row):\n    return (row['yes'] - row['exp_y']) ** 2 / row['exp_y'] + (row['no'] - row['exp_n']) ** 2 / row['exp_n']\n\n\ndef calculate_likelihood(row):\n    return 2 * ((row['yes'] * np.log(row['yes'] / row['exp_y'])) + (row['no'] * np.log(row['no'] / row['exp_n'])))\n\n\nq_pearson = df_cars.apply(calculate_pearson, axis=1).sum()\nlikelihood = df_cars.apply(calculate_likelihood, axis=1).sum()\n\nprint(f'Q_p: {q_pearson}, Q_LR: {likelihood}')\n\n\nQ_p: 44.76457096344832, Q_LR: 45.07972866310165"
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#ordinal-compared-to-nominal-tests",
    "href": "notes/primer/categorical_data/index.html#ordinal-compared-to-nominal-tests",
    "title": "Categorical Data Analysis",
    "section": "3.3 Ordinal Compared to Nominal Tests",
    "text": "3.3 Ordinal Compared to Nominal Tests\n\nPearson and Likelihood Ratio \\(\\chi^2\\) tests can handle any type of categorical variable\nOrdinal variables provide extra information since order of the categories matters compared to nominal\nCan test for even more with ordinal vars. against other ordinal vars.–whether two ordinal vars. have a linear relationship as compared to just a general one\n\nHypothesis Statements:\n\n\\(H_0\\): No Linear Association\n\\(H_a\\): Linear Association"
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#mantel-haenszel-chi2-test",
    "href": "notes/primer/categorical_data/index.html#mantel-haenszel-chi2-test",
    "title": "Categorical Data Analysis",
    "section": "3.4 Mantel-Haenszel \\(\\chi^2\\) Test",
    "text": "3.4 Mantel-Haenszel \\(\\chi^2\\) Test\n\\[\nQ_{MH} = (n - 1)r^2\n\\]\n\n\\(r^2\\) is the Pearson correlation between row and column variables"
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#odds-ratio",
    "href": "notes/primer/categorical_data/index.html#odds-ratio",
    "title": "Categorical Data Analysis",
    "section": "4.1 Odds Ratio",
    "text": "4.1 Odds Ratio\nOdds ratio measure how much more likely, with respect to odds, a certain event occurs in one group relative to its occurrence in another group.\nOdds of an event occurring is not the same as the probability that an event occurs.\n\\[\n\\text{Odds} = \\frac{p}{1 - p}\n\\]\n\n4.1.1 Probability vs. Odds of an Outcome\n\n\n\n\nYes\nNo\n\n\n\n\nLoyal\n20\n60\n\n\nNon-Loyal\n10\n90\n\n\n\n\n\nCode\nd = {'yes': [20, 10], 'no': [60, 90]}\ndf_loyalty = pd.DataFrame(d, index=['Loyal', 'Non-Loyal'])\n\ndf_loyalty['prob_y'] = df_loyalty['yes'] / df_loyalty.iloc[:, :2].sum(axis=1)\ndf_loyalty['prob_n'] = df_loyalty['no'] / df_loyalty.iloc[:, :2].sum(axis=1)\ndf_loyalty['odds_y'] = (df_loyalty['prob_y'] / df_loyalty['prob_n']).round(3)\ndf_loyalty['odds_n'] = df_loyalty['prob_n'] / df_loyalty['prob_y']\n\ndf_loyalty.head()\nprint(\n    f'Odds Ratio, Loyal to Non-Loyal: {df_loyalty.loc[\"Loyal\", \"odds_y\"] / df_loyalty.loc[\"Non-Loyal\", \"odds_y\"]}')\n\n\nOdds Ratio, Loyal to Non-Loyal: 3.0\n\n\n\nLoyal program customers have 3 times the odds of buying the product as compared to customers not in the loyalty program."
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#cramers-v",
    "href": "notes/primer/categorical_data/index.html#cramers-v",
    "title": "Categorical Data Analysis",
    "section": "4.2 Cramer’s V",
    "text": "4.2 Cramer’s V\nWhen you have more than &gt;2 categories in one or both variables we use Cramer’s V.\n\\[\nV = \\sqrt{\\frac{(\\frac{Q_P}{n})}{\\min(\\#\\text{Rows} - 1, \\#\\text{Columns} - 1)}}\n\\]\n\nBounded between 0 and 1 (-1 and 1 for 2x2 scenario) where closer to 0 the weaker the relationship"
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#example-1",
    "href": "notes/primer/categorical_data/index.html#example-1",
    "title": "Categorical Data Analysis",
    "section": "4.3 Example",
    "text": "4.3 Example\n\nThe same manager as the previous example now wants to know the strength of the relationship between the color of car and loyalty program. Use the appropriate measure of association to calculate this.\n\n\n\nCode\nn = df_cars['total'].sum()\nrows, cols = df_cars.iloc[:, :2].shape\n\ncramer_v = np.sqrt((q_pearson / n) / np.min([rows - 1, cols - 1]))\nnp.round(cramer_v, 3)\n\n\n0.216"
  },
  {
    "objectID": "notes/primer/fundamental/index.html",
    "href": "notes/primer/fundamental/index.html",
    "title": "Fundamental Statistical Concepts",
    "section": "",
    "text": "There are three main pieces to statistics:"
  },
  {
    "objectID": "notes/primer/fundamental/index.html#common-types-of-bias",
    "href": "notes/primer/fundamental/index.html#common-types-of-bias",
    "title": "Fundamental Statistical Concepts",
    "section": "2.1 Common Types of Bias",
    "text": "2.1 Common Types of Bias\n\nSelection Bias\n\nUndercoverage: frame and population are not equal\nNonresponse: subject in sample cannot / will not respond or be measured\n\nSampling Bias\n\nConvenience Sampling: selecting subjects based on accessibility and ease\nVoluntary sampling: subjects volunteer themselves–may not be representative"
  },
  {
    "objectID": "notes/primer/fundamental/index.html#common-sampling-techniques",
    "href": "notes/primer/fundamental/index.html#common-sampling-techniques",
    "title": "Fundamental Statistical Concepts",
    "section": "2.2 Common Sampling Techniques",
    "text": "2.2 Common Sampling Techniques\n\n2.2.1 Simple Random Sampling (SRS)\nSample items from population such that every possible sample of specified sizes has an equal chance of being selected\n\n\n\nSimple Random Sampling\n\n\nAdvantages\n\nNo statistical bias\nNo prev. info about sample needed ahead of time\n\nDisadvantages\n\nExpensive\nHard to implement\nNeed list of population\n\n\n\n2.2.2 Stratified Random Sampling (STS)\nPopulation is divided into subgroups, called strata, so that each member in the population belongs to only one strata.\nSample items from every strata. The sample size between groups does not need to be the same (e.g. if we know groups in pop. are in a 20:80 ratio)\n\n\n\nStratified Random Sampling\n\n\nAdvantages\n\nSmaller sample sizes can achieve same accuracy as SRS\nMore info about parts of population\n\nDisadvantages\n\nNeed info about population ahead of time to split on\n\n\n\n2.2.3 Cluster Sampling\nSimilar to stratified where you group members of population into subgroups called clusters. You only talk to a sample of \\(m\\) clusters selected randomly.\nIn cluster sampling, you don’t necessarily believe there are differences between clusters.\n\n\n\nCluster Sampling\n\n\nAdvantages\n\nOvercome issues with travel, time, expense\nEasier to implement than SRS or STS\n\nDisadvantages\n\nNeed info about population ahead of time to split on–but not total list.\nMay have slight bias if random clusters aren’t representative\n\n\n\n2.2.4 Systematic Sampling\nSelect every \\(k^{th}\\) item in the populatino after randomly selecting a starting point between 1 and \\(k\\).\n\\(k\\) is determined as a ratio of population size over desired sample size.\n\n\n\nSystematic Sampling Starting Point Selection\n\n\n\n\n\nSystematic Sampling\n\n\nAdvantages\n\nVery easy to get sample\n\nDisadvantages\n\nMay be biased especialy if order of list of population matters"
  },
  {
    "objectID": "notes/primer/fundamental/index.html#example",
    "href": "notes/primer/fundamental/index.html#example",
    "title": "Fundamental Statistical Concepts",
    "section": "2.3 Example",
    "text": "2.3 Example\n\nA large worldwide financial company wnats to develop a new retirement plan for the company. They want to survey different managers of branches around the world to find out the most important strategies the new retirement plan should contain. They have 5000 branches worldwide and want to personally interview these branch managers. They have information about the banch size (small, medium, large) and the state/province location of the branch. They want to talk to 50 branch managers.\nDevelop four separate strategies to sample these branch managers based on the four different statistical sampling techniques discussed previously.\n\n\nSRS: Randomly sample 50 branches to interview the managers of\nSTS: Stratify by size and select random samples from every strata\nCluster: Randomly select sample of states/provinces, then select branches at random from those states/provinces\nSystematic: Select every 100th branch in list of branches starting from a random starting point between 1 and 100\n\n\n\nCode\n# Example of systematic sampling in Python\n\nimport numpy as np\nindexes = np.arange(5000)\nsample_size = 50\nk = len(indexes) // sample_size\n\nprint(f'k: {k}')\nprint(f'Sample Size: {sample_size}')\n\nstart = np.random.randint(k + 1)\nselected = indexes[start::k]\n\nprint(f'Length of selected: {len(selected)}')\nindexes[start::k]\n\n\nk: 100\nSample Size: 50\nLength of selected: 50\n\n\narray([  96,  196,  296,  396,  496,  596,  696,  796,  896,  996, 1096,\n       1196, 1296, 1396, 1496, 1596, 1696, 1796, 1896, 1996, 2096, 2196,\n       2296, 2396, 2496, 2596, 2696, 2796, 2896, 2996, 3096, 3196, 3296,\n       3396, 3496, 3596, 3696, 3796, 3896, 3996, 4096, 4196, 4296, 4396,\n       4496, 4596, 4696, 4796, 4896, 4996])"
  },
  {
    "objectID": "notes/primer/fundamental/index.html#qualitative-vs.-quantitative",
    "href": "notes/primer/fundamental/index.html#qualitative-vs.-quantitative",
    "title": "Fundamental Statistical Concepts",
    "section": "3.1 Qualitative vs. Quantitative",
    "text": "3.1 Qualitative vs. Quantitative\nQuantitative data are numeric data that define value of quantity.\nQualitative data are data whose measurement scale is inherently categorical.\n\nNominal data are categories with no logical ordering\nOrdinal data are categories with a logical order / only two ways to order the categories (binary is ordinal)"
  },
  {
    "objectID": "notes/primer/fundamental/index.html#time-series-vs.-cross-sectional",
    "href": "notes/primer/fundamental/index.html#time-series-vs.-cross-sectional",
    "title": "Fundamental Statistical Concepts",
    "section": "3.2 Time Series vs. Cross-sectional",
    "text": "3.2 Time Series vs. Cross-sectional\nTime series is a set of ordered data values observed at successive point in times. Each row might be indexed by time referring to a dependence in time.\nCross-sectional is a set of data values observed at a fixed point in time or where time is of no significance (could have time as a variable just that the response does not depend on it)."
  },
  {
    "objectID": "notes/primer/index.html",
    "href": "notes/primer/index.html",
    "title": "Primer",
    "section": "",
    "text": "Categorical Data Analysis\n\n\n\n\n\n\n\nprimer\n\n\n\n\n\n\n\n\n\n\n\nJun 14, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nAnalysis of Variance\n\n\n\n\n\n\n\nprimer\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nHypothesis Testing\n\n\n\n\n\n\n\nprimer\n\n\nhypothesis testing\n\n\nstatistics\n\n\n\n\n\n\n\n\n\n\n\nJun 7, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nConfidence Intervals\n\n\n\n\n\n\n\nprimer\n\n\nstatistics\n\n\n\n\n\n\n\n\n\n\n\nMay 30, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nProbability\n\n\n\n\n\n\n\nprimer\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nFundamental Statistical Concepts\n\n\n\n\n\n\n\nprimer\n\n\n\n\n\n\n\n\n\n\n\nMay 22, 2023\n\n\nYang Chen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/first_weeks/index.html",
    "href": "blog/first_weeks/index.html",
    "title": "First Weeks: Initial Thoughts",
    "section": "",
    "text": "How would I describe the Institute for Advanced Analytics? It’s fast, it’s scary, and it’s absolutely thrilling.\nComing in as a Master’s student, I’m not sure I knew what to expect entirely. Just a few months ago I had a vastly different vision of trekking out to California to be a full-time art student. But becoming a data science professional?\nIt seemed unlikely.\nTo be honest, I often feel like formal education has been a barrier rather than a support for practical learning. I’m sure many students have shared a similar opinion.\nHere, “education” takes on a vastly different meaning than compared to an undergraduate program. Team work is crucial at the Institute and your success in any assignment, project, and interaction is defined by the success of your team. From day one, it was crystal clear that the faculty were incredibly passionate in both data science and teaching. Genuine smiles, genuine knowledge, genuine experience–it’s hard to beat.\nI love the other students as well even if we might not know each other at all. Everybody brings in a wildly different background. We’re a medley of primary school teachers, engineers, therapists, PhD students and more coming together to bash our brains and personalities together. Despite the differences between all of us, we share a similar drive to solve difficult problems and be the best data professionals we can be. We’re not all friends and we might not have to be, but we all stand to learn something new every day from each other.\nI realize before coming here, I tended to avoid teamwork when I could. Now I actually look forward to it. I find myself using a more analytical mindset to validate approaches, project scope, and data design. Now that I’m working for longer periods of time with a group, I’m appreciating the push-and-pull dynamic that is produced when we are discussing how to move a project forward.\nIt’s not so simple as a “hero” figure pulling ahead to complete the assignment for everyone. Instead, each of us is learning to work with the friction or flow that is produced when trying to manage everyone’s expectations, emotions, work methods, and energies. There’s an ongoing process that we all have a part to play in; we can’t just hear, we need to listen to the thoughts and experiences of our teammates.\nYou also can’t beat the adrenaline rush that comes when we all figured out or won at something.\nIf there’s one key takeaway I have from the Institute it’s that data science can be a new art for me. I often find myself reflecting on what data science means to me. I’ve heard it being compared to art in many ways, but I never felt a coherent connection between the two disciplines until recently.\nI don’t think typing characters on a keyboard elicits the same feeling of dexterity as putting pencil to paper with broad, sweeping strokes. However, data science does have this wonderful ebb and flow between unstructured data and diverse analytics methods to understand the data. No one method is completely correct, but some can resolve the large shapes and lines in the dataset to a coherent story which can be important to me or any one who views the story. I absolutely believe this notion of data agrees with how I feel towards making art."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yang Chen",
    "section": "",
    "text": "Hiya, I’m Yang!\nI’m a data science Master’s student who’s passionate about AI, deep learning, and explainable data science. This is an open repository of notes, projects, and musings that I am gathering through my Master’s at the Institute for Advanced Analytics.\nI’m excited to share what I learn and hope you can join me for the ride! You can find me on LinkedIn, Github or through my main website"
  },
  {
    "objectID": "projects/summer_r/index.html",
    "href": "projects/summer_r/index.html",
    "title": "Getting to Know Your Classmates Data",
    "section": "",
    "text": "library(tidyverse)\nlibrary(stringr)\nlibrary(countrycode)\nlibrary(ggthemes)\n\n# setwd(\"summer_r\")\nclassmates &lt;- read.csv(\"data/Get_to_know_survey_2023.csv\")\nglimpse(classmates)\n\nRows: 96\nColumns: 7\n$ Birth_Month_Year        &lt;chr&gt; \"December, 1999\", \"7, 1998\", \"April, 1999\", \"N…\n$ State                   &lt;chr&gt; \"North Carolina\", \"Virginia\", \"North Carolina\"…\n$ Country                 &lt;chr&gt; \"United States\", \"United States\", \"United Stat…\n$ Languages               &lt;chr&gt; \"English\", \"English, Spanish\", \"English\", \"Eng…\n$ When_Hear_About_Program &lt;chr&gt; \"1-2 years\", \"1-2 years\", \"3-5 years\", \"Less t…\n$ How_Hear_About_Program  &lt;chr&gt; \"1. Recommended by professors\", \"2. Recommende…\n$ Hobbies                 &lt;chr&gt; \"Video Games, Sports\", \"Movies, Television Ser…"
  },
  {
    "objectID": "projects/summer_r/index.html#top-5-languages-visualized",
    "href": "projects/summer_r/index.html#top-5-languages-visualized",
    "title": "Getting to Know Your Classmates Data",
    "section": "Top 5 Languages Visualized",
    "text": "Top 5 Languages Visualized\n\nggplot(languages_top_5, aes(x = reorder(Languages, desc(n)), y = n, fill = Languages)) +\n    geom_col() +\n    labs(x = \"Languages\", y = \"Counts\", title = \"MSA Class of 2024: Top 5 Languages\") +\n    theme_economist()"
  },
  {
    "objectID": "projects/summer_r/index.html#wide-to-long-hobbies-column",
    "href": "projects/summer_r/index.html#wide-to-long-hobbies-column",
    "title": "Getting to Know Your Classmates Data",
    "section": "Wide to Long Hobbies Column",
    "text": "Wide to Long Hobbies Column\n\nclassmates &lt;- classmates %&gt;%\n    mutate(Hobbies = str_squish(Hobbies)) %&gt;%\n    separate_longer_delim(Hobbies, \", \")\n\nclassmates\n\n# A tibble: 502 × 9\n   Birth_Month_Year State          Country      Languages When_Hear_About_Prog…¹\n   &lt;chr&gt;            &lt;chr&gt;          &lt;chr&gt;        &lt;chr&gt;     &lt;chr&gt;                 \n 1 December, 1999   North Carolina United Stat… English   1-2 years             \n 2 December, 1999   North Carolina United Stat… English   1-2 years             \n 3 7, 1998          Virginia       United Stat… English   1-2 years             \n 4 7, 1998          Virginia       United Stat… English   1-2 years             \n 5 7, 1998          Virginia       United Stat… English   1-2 years             \n 6 7, 1998          Virginia       United Stat… English   1-2 years             \n 7 7, 1998          Virginia       United Stat… Spanish   1-2 years             \n 8 7, 1998          Virginia       United Stat… Spanish   1-2 years             \n 9 7, 1998          Virginia       United Stat… Spanish   1-2 years             \n10 7, 1998          Virginia       United Stat… Spanish   1-2 years             \n# ℹ 492 more rows\n# ℹ abbreviated name: ¹​When_Hear_About_Program\n# ℹ 4 more variables: How_Hear_About_Program &lt;chr&gt;, Hobbies &lt;chr&gt;,\n#   Birth_Month &lt;chr&gt;, Birth_Year &lt;chr&gt;\n\nclassmates_copy &lt;- classmates_copy %&gt;%\n    mutate(Hobbies = str_squish(Hobbies)) %&gt;%\n    separate_longer_delim(Hobbies, \", \")\n\nhobbies_top_5 &lt;- classmates_copy %&gt;%\n    filter(!is.na(Hobbies)) %&gt;%\n    count(Hobbies) %&gt;%\n    arrange(desc(n)) %&gt;%\n    head(n = 5)\n\nhobbies_top_5\n\n                          Hobbies  n\n1 Outside Recreational Activities 59\n2                          Sports 50\n3               Television Series 48\n4                          Movies 47\n5                           Music 34"
  },
  {
    "objectID": "projects/summer_r/index.html#top-5-hobbies-visualized",
    "href": "projects/summer_r/index.html#top-5-hobbies-visualized",
    "title": "Getting to Know Your Classmates Data",
    "section": "Top 5 Hobbies Visualized",
    "text": "Top 5 Hobbies Visualized\nNote: Using copy of older classmates data frame since we don’t want to “double-count” student hobbies after making the language column long. Maybe there’s a better way to do this through grouping.\n\nggplot(hobbies_top_5, aes(x = reorder(Hobbies, desc(n)), y = n, fill = Hobbies)) +\n    geom_col() +\n    labs(x = \"Hobbies\", y = \"Counts\", title = \"MSA Class of 2024: Top 5 Hobbies\") +\n    theme_economist()"
  },
  {
    "objectID": "projects/summer_r/index.html#standardizing-birth_month_year",
    "href": "projects/summer_r/index.html#standardizing-birth_month_year",
    "title": "Getting to Know Your Classmates Data",
    "section": "Standardizing Birth_Month_Year",
    "text": "Standardizing Birth_Month_Year\n\nclassmates &lt;- classmates %&gt;%\n    mutate(Birth_Month_Year = paste(Birth_Month, Birth_Year, sep = \", \"))\n\nclassmates %&gt;%\n    select(Birth_Month_Year)\n\n# A tibble: 502 × 1\n   Birth_Month_Year\n   &lt;chr&gt;           \n 1 December, 1999  \n 2 December, 1999  \n 3 July, 1998      \n 4 July, 1998      \n 5 July, 1998      \n 6 July, 1998      \n 7 July, 1998      \n 8 July, 1998      \n 9 July, 1998      \n10 July, 1998      \n# ℹ 492 more rows"
  },
  {
    "objectID": "projects/summer_r/index.html#student-countries-heatmap",
    "href": "projects/summer_r/index.html#student-countries-heatmap",
    "title": "Getting to Know Your Classmates Data",
    "section": "Student Countries Heatmap",
    "text": "Student Countries Heatmap\n\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\n\nselected_countries &lt;- classmates %&gt;%\n    select(Country) %&gt;%\n    distinct(Country) %&gt;%\n    arrange(Country)\nworld_data &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nselected_countries_data &lt;- world_data %&gt;%\n    inner_join(selected_countries, by = c(\"name\" = \"Country\"))\n\nggplot() +\n    geom_sf(data = world_data, color = \"grey50\", fill = \"lightblue\") +\n    geom_sf(data = selected_countries_data, fill = \"red\", alpha = 0.7) +\n    labs(\n        title = \"Countries of Origin\",\n        subtitle = \"MSA 2024\",\n        caption = \"Library: Natural Earth\"\n    ) +\n    theme_minimal()"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "First Weeks: Initial Thoughts\n\n\n\n\n\n\n\n\n\n\n\n\nJul 11, 2023\n\n\nYang Chen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notes/primer/probability/index.html",
    "href": "notes/primer/probability/index.html",
    "title": "Probability",
    "section": "",
    "text": "Probability is a numerical measure of the likelihood of that event’s occurrence. It takes on a value in the interval \\([0, 1]\\).\nA sample space is a collection of all possible outcomes in a random process. The sum of all probabilities in the sample space must sum to 1.\nAn event is a collection of one or more outcomes from a process whose result cannot be predicted. The probability of event \\(X\\) is expressed as \\(P(X)\\)\n\n\n\n\nEvent consisting of all sample points that are not in \\(A\\).\n\\[\nP(\\bar{A}) = 1 - P(A)\n\\]\n\n\n\nThe union of an event \\(A\\) and event \\(B\\) is the event containing all sample points in \\(A\\) or \\(B\\) or both.\n\\[\nA \\cup B\n\\]\n\n\n\nAll sample points that are in both \\(A\\) and \\(B\\).\n\\[\nA \\cap B\n\\]\n\n\n\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]\n\n\n\nMutually exclusive meants that events have no sample points in common–they do not intersect.\nThe events cannot both occur which turns the addition law into\n\\[\nP(A \\cup B) = P(A) + P(B)\n\\]\n\n\n\nProbability of an event given that another event has occurred.\n\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)}\n\\]\n\n\n\nWe derive this from the conditional property which expresses the intersection as a multiplication:\n\\[\n\\begin{align*}\nP(A \\cap B) &= P(A | B) \\cdot P(B) \\\\\n&= P(B | A) \\cdot P(A)\n\\end{align*}\n\\]\nIf events are independent then this becomes\n\\[\nP(A \\cap B) = P(A) \\cdot P(B)\n\\]"
  },
  {
    "objectID": "notes/primer/probability/index.html#basic-relationships",
    "href": "notes/primer/probability/index.html#basic-relationships",
    "title": "Probability",
    "section": "",
    "text": "Event consisting of all sample points that are not in \\(A\\).\n\\[\nP(\\bar{A}) = 1 - P(A)\n\\]\n\n\n\nThe union of an event \\(A\\) and event \\(B\\) is the event containing all sample points in \\(A\\) or \\(B\\) or both.\n\\[\nA \\cup B\n\\]\n\n\n\nAll sample points that are in both \\(A\\) and \\(B\\).\n\\[\nA \\cap B\n\\]\n\n\n\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]\n\n\n\nMutually exclusive meants that events have no sample points in common–they do not intersect.\nThe events cannot both occur which turns the addition law into\n\\[\nP(A \\cup B) = P(A) + P(B)\n\\]\n\n\n\nProbability of an event given that another event has occurred.\n\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)}\n\\]\n\n\n\nWe derive this from the conditional property which expresses the intersection as a multiplication:\n\\[\n\\begin{align*}\nP(A \\cap B) &= P(A | B) \\cdot P(B) \\\\\n&= P(B | A) \\cdot P(A)\n\\end{align*}\n\\]\nIf events are independent then this becomes\n\\[\nP(A \\cap B) = P(A) \\cdot P(B)\n\\]"
  },
  {
    "objectID": "notes/primer/probability/index.html#conditional-vs.-marginal-probabilities",
    "href": "notes/primer/probability/index.html#conditional-vs.-marginal-probabilities",
    "title": "Probability",
    "section": "2.1 Conditional vs. Marginal Probabilities",
    "text": "2.1 Conditional vs. Marginal Probabilities\nMarginal probabilities are considered unconditional probabilities–they are probabilities of events without any condition.\n\n2.1.1 Example\n\nLet’s take a look at promotion of people at a company with advanced degrees vs. those who don’t have them.\n\n\n\nCode\nimport pandas as pd\n\nd = {'yes': {'promoted': 288, 'not_promoted': 672},\n     'no': {'promoted': 36, 'not_promoted': 204}}\n\ndf = pd.DataFrame(d)\ndf\n\n\n\n\n\n\n\n\n\nyes\nno\n\n\n\n\npromoted\n288\n36\n\n\nnot_promoted\n672\n204\n\n\n\n\n\n\n\nOne marginal probability is the probability of an advanced degree:\n\n\nCode\nprob_adv_deg = df['yes'].sum() / (df['yes'].sum() + df['no'].sum())\nprob_adv_deg\n\n\n0.8\n\n\nOn the other hand, a conditional probability might be the probability of a promotion given that the employee has no advanced degree:\n\n\nCode\ncond_prob = df.loc['promoted', 'no'] / df['no'].sum()\ncond_prob\n\n\n0.15"
  },
  {
    "objectID": "notes/primer/confidence_intervals/index.html",
    "href": "notes/primer/confidence_intervals/index.html",
    "title": "Confidence Intervals",
    "section": "",
    "text": "Point estimators cannot be expected to provide exact values of population parameters. Intervals provide information about how close the point estimate is to the value of the parameter.\nConfidence intervals are interval estimates where we have a certain level of confidence in the interval.\nWhat does it mean when we are 95% confidence that the population mean is between 20 and 30?"
  },
  {
    "objectID": "notes/primer/confidence_intervals/index.html#student-t-distribution",
    "href": "notes/primer/confidence_intervals/index.html#student-t-distribution",
    "title": "Confidence Intervals",
    "section": "3.1 Student t Distribution",
    "text": "3.1 Student t Distribution\nThe t distribution is also symmetric, but has thicker tails than the Normal distribution.\nIt has \\(n - 1\\) degrees of freedom where the degrees of freedom are the number of independent pieces of information that go into the computation of \\(s\\).\nFor larger samples, the t distribution is approximately the standard Normal distribution.\n\n\nCode\nx = np.linspace(-4, 4, 100)\n\npdf = t.pdf(x, df=19)\nplt.plot(x, pdf)\n\n\n\n\n\nPlot of a t distribution with d.f. 19\n\n\n\n\nThe confidence interval for \\(\\bar{x}\\) is calculated as:\n\\[\n\\bar{x} \\pm t_{\\alpha/2} \\cdot \\frac{s}{\\sqrt{n}}\n\\]\nFor large samples (\\(n \\geq 50\\)) we can calculate the confidence interval for the mean from any population.\nFor small samples (\\(n &lt; 50\\)) we need to assume the population follows a Normal distribution."
  },
  {
    "objectID": "notes/primer/hypothesis_testing/index.html",
    "href": "notes/primer/hypothesis_testing/index.html",
    "title": "Hypothesis Testing",
    "section": "",
    "text": "According to the CLT, the the mean has a sampling distribution that follows a Normal distribution as long as the sample size is large enough.\nLet’s take the average age of our customers as an example. Initially, we believe that the average age of our customers is \\(\\mu = 25\\) years old with standard deviation \\(\\sigma = 10\\).\nWe sample 100 customers and collect their age.\n\n\nCode\nfrom scipy.stats import t\nimport numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\nmean = 25\nsd = 1\nalpha = 0.05\n\nx = np.linspace(20, 35, 1000)\n\ncrit_value = norm.ppf(1 - alpha / 2, loc=mean, scale=sd)\npdf = norm.pdf(x, loc=mean, scale=sd)\nplt.axvline(31, color='r')\n\nplt.plot(x, pdf)\n\n\n\n\n\nWhat is the probability we see a sample mean \\(\\bar{x} = 31\\) under our original assumption that the mean is 25?\nIt’s very low! \\(&lt; 0.0001\\) so we have to strongly question our original hypothesis. We may no longer think it is true given the data."
  },
  {
    "objectID": "notes/primer/hypothesis_testing/index.html#type-i-error",
    "href": "notes/primer/hypothesis_testing/index.html#type-i-error",
    "title": "Hypothesis Testing",
    "section": "7.1 Type I Error",
    "text": "7.1 Type I Error\n\nReject the null hypothesis when the null hypothesis was actually true (False rejection)\nProbability of making a Type I error in a hypothesis test is called the significance level"
  },
  {
    "objectID": "notes/primer/hypothesis_testing/index.html#type-ii-error",
    "href": "notes/primer/hypothesis_testing/index.html#type-ii-error",
    "title": "Hypothesis Testing",
    "section": "7.2 Type II Error",
    "text": "7.2 Type II Error\n\nAccepting the null hypothesis when the null hypothesis was actually false (False acceptance)\nProbability of not making a Type II error in a hypothesis test is called the power\nDifficult to control Type II error\nCan only control for Type I or Type II at a time"
  },
  {
    "objectID": "notes/primer/hypothesis_testing/index.html#conditions",
    "href": "notes/primer/hypothesis_testing/index.html#conditions",
    "title": "Hypothesis Testing",
    "section": "9.1 Conditions",
    "text": "9.1 Conditions\n\nThe hypothesis test is two-sided\n\\(C = 1 - \\alpha\\) where \\(C\\) is the confidence level and \\(\\alpha\\) is the significance level"
  },
  {
    "objectID": "notes/primer/anova/index.html",
    "href": "notes/primer/anova/index.html",
    "title": "Analysis of Variance",
    "section": "",
    "text": "One sample hypothesis tests are focused on one population parameter. However, sometimes we would like to compare multiple parameters against each other. This is the foundation of an analysis called analysis of variance (ANOVA).\nRecall the one-sample case:\n\\[\nH_0: \\mu\n\\begin{cases}\n\\geq \\\\\n= \\\\\n\\leq\n\\end{cases}\n\\ \\ \\mu_0\n\\]\n\\[\nH_a: \\mu\n\\begin{cases}\n&lt; \\\\\n\\neq \\\\\n&gt;\n\\end{cases}\n\\mu_0\n\\]\nIn the two-sample case, there are two parameters we are calculating so now we have an expression:\n\\[\nH_0: \\mu_1 - \\mu_2\n\\begin{cases}\n\\geq \\\\\n= \\\\\n\\leq\n\\end{cases}\n\\ 0\n\\]\n\\[\nH_a: \\mu_1 - \\mu_2\n\\begin{cases}\n&lt; \\\\\n\\neq \\\\\n&gt;\n\\end{cases}\n\\ 0\n\\]\n\n\n\nAssume two samples are independent of each other\nWe have to take into account whether the variances are equal or not\n\nDifferent hypothesis test structures depends on whether or not variances are equal\n\n\nRecall that our general test statistic is calculated as\n\\[\n\\begin{align*}\n\\text{Test Statistic} &= \\frac{\\text{Statistic} - \\text{Null Value}}{\\text{Standard Error}} \\\\\n\\ \\\\\n&= \\frac{(\\bar{x}_1 - \\bar{x}_2) - D_0}{s_p\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\n\\end{align*}\n\\]\n\n\\(s_p\\) is the pooled standard deviation\n\nWe then calculate our p-value based on the t-distribution with \\(d.f. = n_1 - 1 + n_2 - 1 = n_1 + n_2 - 2\\)\n\n\n\nUnder assumption of equal variances we have two estimates of population variance–\\(s_1^2\\) and \\(s_2^2\\). We should combine both to get our estimate:\n\\[\n\\begin{align*}\ns_p &= \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}} \\\\\n\\ \\\\\n&= \\sqrt{\\frac{\\sum (x_{1,i} - \\bar{x}_1)^2 + \\sum (x_{2,i} - \\bar{x}_2)^2}{n_1 + n_2 - 2}}\n\\end{align*}\n\\]\n\n\n\nEach population has an approximate Normal distribution\nVariances of two groups are equal\n\n\n\n\n\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\times s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}\n\\]\n\n\n\nHypothesis Statements:\n\nSame as the prior tests\n\nOur Test Statistic:\n\\[\n\\text{Test Statistic} = \\frac{(\\bar{x}_1 - \\bar{x}_2) - D_0}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n\\]\n\nStandard error changes since we need to test estimates of our two separate population variances separately \\(\\rightarrow\\) cannot “pool” them\n\nThe degrees of freedom on our t-test are a more complicated expression:\n\\[\nd.f. = \\frac{(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2})^2}{\\frac{(\\frac{s_1^2}{n_1})^2}{n_1 - 1} + \\frac{(\\frac{s_2^2}{n_2})^2}{n_2 - 1}}\n\\]\n\n\n\nFor different variances, we don’t use the pooled variance\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2}^* \\times \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}\n\\]\n\nStandard error changes using separate population variances\n\n\n\n\n\nA human resources manager of a large business firm is trying to determine if there exists gender bias in the pay scale of employees at the company. The manager assumes the variability of salaries between genders is different, but wants to test if makes have higher average salary than females. The manager samples 62 males and 77 females. The sample of males had an average salary of $87,547 with a s.d. of $5,910. The sample of females had an average salary of $78,289 with a s.d. of $6,276. Run a hypothesis test.\n\n\n\nCode\n# H_a: mu_1 &gt; mu_2 with mu_1 representing mean of males\n\nt &lt;- ((87547 - 78289) - 0) / sqrt(5910^2 / 62 + 6276^2 / 77)\nsprintf(\"Test statistic equals %.3f\", t)\n\n\n[1] \"Test statistic equals 8.930\"\n\n\nCode\ndf &lt;- (5910^2 / 62 + 6276^2 / 77)^2 / ((5910^2 / 62)^2 / 61 + (6276^2 / 77)^2 / 76)\nsprintf(\"Df: %d\", floor(df))\n\n\n[1] \"Df: 133\"\n\n\nCode\npt(t, df, lower.tail = FALSE)\n\n\n[1] 1.468658e-15"
  },
  {
    "objectID": "notes/primer/anova/index.html#assumptions",
    "href": "notes/primer/anova/index.html#assumptions",
    "title": "Analysis of Variance",
    "section": "",
    "text": "Assume two samples are independent of each other\nWe have to take into account whether the variances are equal or not\n\nDifferent hypothesis test structures depends on whether or not variances are equal\n\n\nRecall that our general test statistic is calculated as\n\\[\n\\begin{align*}\n\\text{Test Statistic} &= \\frac{\\text{Statistic} - \\text{Null Value}}{\\text{Standard Error}} \\\\\n\\ \\\\\n&= \\frac{(\\bar{x}_1 - \\bar{x}_2) - D_0}{s_p\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\n\\end{align*}\n\\]\n\n\\(s_p\\) is the pooled standard deviation\n\nWe then calculate our p-value based on the t-distribution with \\(d.f. = n_1 - 1 + n_2 - 1 = n_1 + n_2 - 2\\)"
  },
  {
    "objectID": "notes/primer/anova/index.html#pooled-standard-deviation",
    "href": "notes/primer/anova/index.html#pooled-standard-deviation",
    "title": "Analysis of Variance",
    "section": "",
    "text": "Under assumption of equal variances we have two estimates of population variance–\\(s_1^2\\) and \\(s_2^2\\). We should combine both to get our estimate:\n\\[\n\\begin{align*}\ns_p &= \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}} \\\\\n\\ \\\\\n&= \\sqrt{\\frac{\\sum (x_{1,i} - \\bar{x}_1)^2 + \\sum (x_{2,i} - \\bar{x}_2)^2}{n_1 + n_2 - 2}}\n\\end{align*}\n\\]\n\n\n\nEach population has an approximate Normal distribution\nVariances of two groups are equal"
  },
  {
    "objectID": "notes/primer/anova/index.html#confidence-interval",
    "href": "notes/primer/anova/index.html#confidence-interval",
    "title": "Analysis of Variance",
    "section": "",
    "text": "\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\times s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}\n\\]"
  },
  {
    "objectID": "notes/primer/anova/index.html#testing-difference-in-means---unequal-variances",
    "href": "notes/primer/anova/index.html#testing-difference-in-means---unequal-variances",
    "title": "Analysis of Variance",
    "section": "",
    "text": "Hypothesis Statements:\n\nSame as the prior tests\n\nOur Test Statistic:\n\\[\n\\text{Test Statistic} = \\frac{(\\bar{x}_1 - \\bar{x}_2) - D_0}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n\\]\n\nStandard error changes since we need to test estimates of our two separate population variances separately \\(\\rightarrow\\) cannot “pool” them\n\nThe degrees of freedom on our t-test are a more complicated expression:\n\\[\nd.f. = \\frac{(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2})^2}{\\frac{(\\frac{s_1^2}{n_1})^2}{n_1 - 1} + \\frac{(\\frac{s_2^2}{n_2})^2}{n_2 - 1}}\n\\]"
  },
  {
    "objectID": "notes/primer/anova/index.html#confidence-interval-1",
    "href": "notes/primer/anova/index.html#confidence-interval-1",
    "title": "Analysis of Variance",
    "section": "",
    "text": "For different variances, we don’t use the pooled variance\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2}^* \\times \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}\n\\]\n\nStandard error changes using separate population variances"
  },
  {
    "objectID": "notes/primer/anova/index.html#example---comparing-two-means",
    "href": "notes/primer/anova/index.html#example---comparing-two-means",
    "title": "Analysis of Variance",
    "section": "",
    "text": "A human resources manager of a large business firm is trying to determine if there exists gender bias in the pay scale of employees at the company. The manager assumes the variability of salaries between genders is different, but wants to test if makes have higher average salary than females. The manager samples 62 males and 77 females. The sample of males had an average salary of $87,547 with a s.d. of $5,910. The sample of females had an average salary of $78,289 with a s.d. of $6,276. Run a hypothesis test.\n\n\n\nCode\n# H_a: mu_1 &gt; mu_2 with mu_1 representing mean of males\n\nt &lt;- ((87547 - 78289) - 0) / sqrt(5910^2 / 62 + 6276^2 / 77)\nsprintf(\"Test statistic equals %.3f\", t)\n\n\n[1] \"Test statistic equals 8.930\"\n\n\nCode\ndf &lt;- (5910^2 / 62 + 6276^2 / 77)^2 / ((5910^2 / 62)^2 / 61 + (6276^2 / 77)^2 / 76)\nsprintf(\"Df: %d\", floor(df))\n\n\n[1] \"Df: 133\"\n\n\nCode\npt(t, df, lower.tail = FALSE)\n\n\n[1] 1.468658e-15"
  },
  {
    "objectID": "notes/primer/anova/index.html#example---comparing-two-variances",
    "href": "notes/primer/anova/index.html#example---comparing-two-variances",
    "title": "Analysis of Variance",
    "section": "2.1 Example - Comparing Two Variances",
    "text": "2.1 Example - Comparing Two Variances\n\nA human resources manager of a large business firm is trying to determine if there exists gender bias in the pay scale of employees at the company. The manager has no assumption about the variability of salaries between genders, but wants to test if makes have higher average salary than females. The manager samples 62 males and 77 females. The sample of males had an average salary of $87,547 with a s.d. of $5,910. The sample of females had an average salary of $78,289 with a s.d. of $6,276. Run a hypothesis test.\nNeed to first test if variances are equal or not before running test of means\n\n\n\nCode\nf &lt;- 6276^2 / 5910^2\nsprintf(\"F Statistic: %.3f\", f)\n\n\n[1] \"F Statistic: 1.128\"\n\n\nCode\ndf1 &lt;- 76\ndf2 &lt;- 61\n\npf(f, df1, df2, lower.tail = FALSE)\n\n\n[1] 0.3147624\n\n\nAt a significance level of 0.05 we would not reject the null hypothesis that our variances are different."
  },
  {
    "objectID": "notes/primer/anova/index.html#example---sources-of-variation",
    "href": "notes/primer/anova/index.html#example---sources-of-variation",
    "title": "Analysis of Variance",
    "section": "3.1 Example - Sources of Variation",
    "text": "3.1 Example - Sources of Variation\n\nYou have SAT scores for both boys and girls from a local school\nYou believe that the boys and girls have the same avg. test score, but want to test otherwise\nOf the 39 females, 32 of them are part of the accelerated math and language arts program\nOf the 39 males, 11 of them are part of the accelerated math and language arts program\n\nMatched samples are samples selected such that each data value from one sample is related (or matched / paired) with a corresponding data value from a second sample\nIn the previous example, we would match boys and girls who were in the accelerated program and ones who were not.\nOur focus turns from individual values in the populations and to the values of the differences in the populations. All assumptions and calculations are done on the differences, not individual samples.\n\\[\nH_0: \\mu_d\n\\begin{cases}\n\\geq \\\\\n= \\\\\n\\leq\n\\end{cases}\n\\ \\ D_0\n\\]\n\\[\nH_a: \\mu_d\n\\begin{cases}\n&lt; \\\\\n\\neq \\\\\n&gt;\n\\end{cases}\n\\ \\ D_0\n\\]\n\nAssumptions for matched pairs hypothesis test are same as for regular hypothesis test for means\nLarge sample (\\(n &gt; 50\\)) of differences\nSmall samples with differences having Normal distribution\n\nHypothesis Statements:\n\\[\nH_0: \\mu_d\n\\begin{cases}\n\\geq \\\\\n= \\\\\n\\leq\n\\end{cases}\n\\ \\ D_0\n\\hspace{2cm}\nH_a: \\mu_d\n\\begin{cases}\ntest\n\\end{cases}\n\\]\nTest Statistic:\n\\[\nt = \\frac{\\bar{x}_d - D_0}{\\frac{s_d}{\\sqrt{n_d}}}\n\\]\n\\[ d.f. = n_d - 1 \\]"
  },
  {
    "objectID": "notes/primer/anova/index.html#confidence-interval-2",
    "href": "notes/primer/anova/index.html#confidence-interval-2",
    "title": "Analysis of Variance",
    "section": "3.2 Confidence Interval",
    "text": "3.2 Confidence Interval\n\\[\n\\bar{x}_d \\pm t_{\\alpha/2}^* \\times \\frac{s_d}{\\sqrt{n_d}}\n\\]"
  },
  {
    "objectID": "notes/primer/anova/index.html#example---paired-samples",
    "href": "notes/primer/anova/index.html#example---paired-samples",
    "title": "Analysis of Variance",
    "section": "3.3 Example - Paired Samples",
    "text": "3.3 Example - Paired Samples\n\nA human resources manager of a large business firm is trying to determine if there exists gender bias in the pay scale of employees at the company. The manager samples 51 pairs of male and female employees where the pair has the same job title and experience at the company. The average difference in salaries is $2,131 with a s.d. of differences of $7,898. Run a hypothesis test.\n\n\n\nCode\nt &lt;- (2131 - 0) / (7898 / sqrt(51))\nsprintf(\"Test statistic: %.3f\", t)\n\n\n[1] \"Test statistic: 1.927\"\n\n\nCode\ndf &lt;- 50\n\npt(t, df, lower.tail = FALSE)\n\n\n[1] 0.02984447\n\n\nAt a significant level of 0.05 we reject the null hypothesis that there is no gender bias in the pay scale of employees at the company."
  },
  {
    "objectID": "notes/primer/anova/index.html#confidence-interval-3",
    "href": "notes/primer/anova/index.html#confidence-interval-3",
    "title": "Analysis of Variance",
    "section": "4.1 Confidence Interval",
    "text": "4.1 Confidence Interval\n\\[\n(p_1 - p_2) \\pm z^* \\times \\sqrt{\\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 - p_2)}{n_2}}\n\\]"
  },
  {
    "objectID": "notes/primer/anova/index.html#comprehensive-example",
    "href": "notes/primer/anova/index.html#comprehensive-example",
    "title": "Analysis of Variance",
    "section": "4.2 Comprehensive Example",
    "text": "4.2 Comprehensive Example\n\nA researcher at a large university on the west coast is interested in comparing some factors between upperclassmen (juniors and seniors) and underclassmen (freshmen and sophomores) in the undergraduate school. The researcher believes that more experience in college may help students perform better in the classroom. The researcher is interested in testing if the average GPA of upperclassmen is greater than the average GPA of underclassmen. The researcher sampled 89 underclassmen with an average GPA of 2.75 with a s.d. of 0.91 and 102 upperclassmen with an average GPA of 3.07 and a s.d. of 1.02.\n\n\n\nThe researcher did not use matched sampling. Do you agree with their decision?\n\n\nNo. There are other factors that can influence GPA like major that we could match on for equal comparison\n\n\nConduct a hypothesis test on the variances to see if they are equal.\n\n\n\\[\nH_0: \\frac{\\sigma_1^2}{\\sigma_2^2} \\leq 1\n\\hspace{2cm}\nH_a: \\frac{\\sigma_1^2}{\\sigma_2^2} &gt; 1\n\\]\n\n\nCode\nf &lt;- 1.02^2 / 0.91^2\nsprintf(\"F Statistic: %0.3f\", f)\n\n\n[1] \"F Statistic: 1.256\"\n\n\nCode\ndf1 &lt;- 101\ndf2 &lt;- 88\n\npf(f, df1, df2, lower.tail = FALSE)\n\n\n[1] 0.1367661\n\n\nBased on a significance level of 0.05 we do not reject the null hypothesis. We do not have enough evidence to say that the variances between the two populations is different.\n\n\nConduct the appropriate hypothesis test on the means to see if they are equal.\n\n\n\n\nCode\ns_p &lt;- sqrt(((101 * 1.02^2) + (88 * 0.91^2)) / (102 + 89 - 2))\nsprintf(\"Pooled std. dev: %0.3f\", s_p)\n\n\n[1] \"Pooled std. dev: 0.970\"\n\n\nCode\nt &lt;- ((3.07 - 2.75) - 0) / (s_p * sqrt(1 / 102 + 1 / 89))\nsprintf(\"Test Statistic: %0.3f\", t)\n\n\n[1] \"Test Statistic: 2.274\"\n\n\nCode\npt(t, 89 + 102 - 2, lower.tail = FALSE)\n\n\n[1] 0.01205843\n\n\nAt a significance level of 0.05 we reject our null hypothesis that more experience in college does not lead to higher GPA performance."
  },
  {
    "objectID": "notes/primer/anova/index.html#example-continued",
    "href": "notes/primer/anova/index.html#example-continued",
    "title": "Analysis of Variance",
    "section": "4.3 Example Continued",
    "text": "4.3 Example Continued\n\nSame researcher as before also believes that a higher proportion of upperclassmen live off campus compared to the proportion of underclassmen. While sampling the students in the previous sample, the researcher also asked whether the student lived off campus. Of the 89 underclassmen sampled, 27 lived off campus. Of the 102 upperclassmen sampled, 65 lived off campus.\n\n\nConstruct a 95% confidence interval for the difference between the proportion of upperclassmen living off campus to the proportion of underclassmen living off campus.\n\n\\[\nH_0: p_1 - p_2 \\leq 0 \\hspace{1cm} H_a: p_1 - p_2 &gt; 0\n\\]\n\n\nCode\np1 &lt;- 65 / 102\np2 &lt;- 27 / 89\nsprintf(\"Upper p: %0.3f, Under p: %0.3f\", p1, p2)\n\n\n[1] \"Upper p: 0.637, Under p: 0.303\"\n\n\nCode\np_mean &lt;- (102 * p1 + 89 * p2) / (102 + 89)\nsprintf(\"p_mean: %0.3f\", p_mean)\n\n\n[1] \"p_mean: 0.482\"\n\n\nCode\nz &lt;- ((p1 - p2) - 0) / sqrt(p_mean * (1 - p_mean) * (1 / 102 + 1 / 89))\nsprintf(\"Z Statistic: %0.3f\", z)\n\n\n[1] \"Z Statistic: 4.607\"\n\n\nCode\nz_crit &lt;- qnorm(0.05 / 2, lower.tail = FALSE)\nz_crit\n\n\n[1] 1.959964\n\n\nCode\nmargin &lt;- z_crit * sqrt(p1 * (1 - p1) / 102 + p2 * (1 - p2) / 89)\nmargin\n\n\n[1] 0.1335203\n\n\nCode\nsprintf(\"95 perc. CI: %0.3f plus-minus %0.3f\", p1 - p2, margin)\n\n\n[1] \"95 perc. CI: 0.334 plus-minus 0.134\"\n\n\n\nConduct the appropriate hypothesis test to test the researcher’s claim.\n\n\\[\nH_0: p_1 - p_2 \\leq 0 \\hspace{1cm} H_a: p_1 - p_2 &gt; 0\n\\]\n\n\nCode\npnorm(z, lower.tail = FALSE)\n\n\n[1] 2.044913e-06\n\n\nAt a significance level of 0.0005 we reject the null hypothesis that the proportion of upperclassmen living off campus is not greater than the proportion of underclassmen living off campus.\n\nCan you compare the confidence interval and the hypothesis test?\n\nNo as the hypothesis test is one-sided while the confidence interval is two-sided."
  },
  {
    "objectID": "notes/primer/anova/index.html#one-way-anova",
    "href": "notes/primer/anova/index.html#one-way-anova",
    "title": "Analysis of Variance",
    "section": "5.1 One-Way ANOVA",
    "text": "5.1 One-Way ANOVA\nSimplest form of ANOVA is the one-way model.\n\nIndependent samples are obtained from \\(k\\) levels (categories) of a single factor (explanatory variable), then testing whether the \\(k\\) levels have equal means.\nSimilar to regression analysis in that we have one categorical variable predicting continuous response\n\n\\[\nH_0: \\mu_1 = \\mu_2 = \\cdots = \\mu_k\n\\]\n\\[\nH_a: \\text{At least one mean different than another}\n\\]\n\n5.1.1 Assumptions\n\nNormally distributed categories\nEquality of variances between categories\nIndependence\n\nTest Statistic:\n\\[\nF = \\frac{s_{max}^2}{s_{min}^2}\n\\]\nThe p-value is calculated from Hartley-s F-max distribution which isn’t covered here.\n\n\n5.1.2 Sources of Variation\n\nWithin-Sample Variability\n\nVariability in response that exists within category of a variable\n\nWhat you categories cannot explain (like SSE)\n\n\nBetween-Sample Variability\n\nVariability in response that exists between categories of a variable\n\nWhat you categories can explain (like SSR)\n\n\n\n\n\n5.1.3 Sum of Squares Within\nWithin sample is variability that you cannot explain by just knowing which category your observation falls into\n\\[\nSSW = \\sum_{i=1}^k\\sum_{j=1}^{n_i} (x_{i,j} - \\bar{x}_i)^2\n\\]\n\n\n5.1.4 Sum of Squares Between\nBetween sample is variability that you can explain by just knowing which category your observation falls into\n\\[\nSSB = \\sum_{i=1}^k n_i(\\bar{x}_i - \\bar{\\bar{x}})^2\n\\]"
  },
  {
    "objectID": "notes/primer/anova/index.html#partitioning-variability-in-anova",
    "href": "notes/primer/anova/index.html#partitioning-variability-in-anova",
    "title": "Analysis of Variance",
    "section": "5.2 Partitioning Variability in ANOVA",
    "text": "5.2 Partitioning Variability in ANOVA\n\n\n\n\nflowchart LR\nA(Total Variability) --&gt; B(SSR + SSE)\nB --&gt; C[Variability Between Groups]\nB --&gt; D[Variability Within Groups]"
  },
  {
    "objectID": "notes/primer/anova/index.html#anova-f-test",
    "href": "notes/primer/anova/index.html#anova-f-test",
    "title": "Analysis of Variance",
    "section": "5.3 ANOVA F-test",
    "text": "5.3 ANOVA F-test\n\\[\n\\begin{align*}\nH_0&: \\mu_1 = \\mu_2 = \\cdots = \\mu_k \\\\\nH_a&: \\text{At least one mean different than another}\n\\end{align*}\n\\]\nTest follows an F-distribution and is calculated as\n\\[\nF = \\frac{(\\frac{SSB}{k - 1})}{(\\frac{SSW}{N - k})}\n\\]\n\n\\(k\\) categories would be \\(k - 1\\) variables in a regression model\n\\(N\\) is the total sample size across all categories"
  },
  {
    "objectID": "notes/primer/anova/index.html#one-way-anova-table",
    "href": "notes/primer/anova/index.html#one-way-anova-table",
    "title": "Analysis of Variance",
    "section": "5.4 One-Way ANOVA Table",
    "text": "5.4 One-Way ANOVA Table\n\n\n\nOne-Way ANOVA Table"
  },
  {
    "objectID": "notes/primer/anova/index.html#one-way-anova-example",
    "href": "notes/primer/anova/index.html#one-way-anova-example",
    "title": "Analysis of Variance",
    "section": "5.5 One-Way ANOVA Example",
    "text": "5.5 One-Way ANOVA Example\n\nA marketing analyst is interested in testing the effectiveness of 4 different commercials describing their company’s new product. The marketing analyst randomly assigns a commercial to each of 32 cities across the country and measures the average increase in sales of their new product at their stores. The marketing analyst wants to test if there is a difference in sales between the commercials.\n\n\n\nFill in the blanks on the ANOVA table.\n\n\n\n\n\nSource\nDF\nSS\nMS\nF-Value\nP-Value\n\n\n\n\nBetween\n3\n2.3236\n0.775\n22.794\n\n\n\nWithin\n28\n0.9587\n0.034\n\n\n\n\nTotal\n31\n3.2823\n\n\n\n\n\n\n\n\nCode\npf(22.794, 3, 28, lower.tail = FALSE)\n\n\n[1] 1.128339e-07"
  },
  {
    "objectID": "notes/primer/anova/index.html#multiple-comparisons-problem",
    "href": "notes/primer/anova/index.html#multiple-comparisons-problem",
    "title": "Analysis of Variance",
    "section": "6.1 Multiple Comparisons Problem",
    "text": "6.1 Multiple Comparisons Problem\n\nYou have a test which makes an error 5% of the time when performed.\n\n\nWhat is the probability of making an error on your first test?\n\n5%\n\nWhat is the probability of making an error on your second test?\n\n5%\n\nWhat is the probability of making at least one error in two tests?\n\n9.75%\n\n\n\n6.1.1 Different Types of Error\nComparison-wise error rate\n\nError rate for each individual test or comparison\n\nExperiment-wise error rate\n\nError rate across all comparisons–proportion of experiments/comparisons in which at least one error occurs\n\nTests and confidence intervals usually control for comparison-wise, \\(\\alpha\\), but ideally want to control for experiment-wise."
  },
  {
    "objectID": "notes/primer/anova/index.html#multiple-comparison-methods",
    "href": "notes/primer/anova/index.html#multiple-comparison-methods",
    "title": "Analysis of Variance",
    "section": "6.2 Multiple Comparison Methods",
    "text": "6.2 Multiple Comparison Methods\n\n\n\n\n\n\n\n\nNumber of Groups Compared\nNumber of Comparisons\nExperimentwise Error Rate\n\n\n\n\n2\n1\n0.05\n\n\n3\n3\n0.14\n\n\n4\n6\n0.26\n\n\n5\n10\n0.40\n\n\n\n\n\\(EER \\leq 1 - (1 - \\alpha)^{nc}\\) where \\(nc\\) is the number of comparisons\n\n\n\n\n\nflowchart LR\nA(Control Comparisonwise Error Rate) --&gt; B(Pairwise t-tests)\nC(Control Experimentwise Error Rate) --&gt; D[Compare All Pairs Tukey]"
  },
  {
    "objectID": "notes/primer/anova/index.html#tukeys-hsd-test",
    "href": "notes/primer/anova/index.html#tukeys-hsd-test",
    "title": "Analysis of Variance",
    "section": "6.3 Tukey’s HSD Test",
    "text": "6.3 Tukey’s HSD Test\nHSD represents the Honest Significant Difference or Critical Range\nWe use Tukey’s when we consider pairwise comparisons\n\nExperimentwise error rate is equal to \\(\\alpha\\) when all pairwise comparisons are considered\nExperimentwise error rate is less than \\(\\alpha\\) when fewer than all pairwise comparisons are considered\nReplaces margin of error calculation for a typical confidence interval for a difference in means with an adjusted margin of error\n\n\\[\n\\text{Critical Range (Margin of Error)} = q_a \\times \\sqrt{\\frac{MSW}{2} \\times (\\frac{1}{n_i} + \\frac{1}{n_j})}\n\\]\n\n\\(q_a\\) is from studentized range distribution"
  },
  {
    "objectID": "notes/primer/anova/index.html#randomized-blocking",
    "href": "notes/primer/anova/index.html#randomized-blocking",
    "title": "Analysis of Variance",
    "section": "7.1 Randomized Blocking",
    "text": "7.1 Randomized Blocking\n\n7.1.1 Sources of Variation\nGenerally, comparing many population means works well in certain situations\nThere are some instances where blocking is used to control for sources of variation that might distort conclusions"
  },
  {
    "objectID": "notes/primer/anova/index.html#example",
    "href": "notes/primer/anova/index.html#example",
    "title": "Analysis of Variance",
    "section": "7.2 Example",
    "text": "7.2 Example\n\nThe same marketing analyst as before is interested in testing the effectiveness of 4 different commercials describing their company’s new product. The marketing analyst randomly assigns a commercial to each of 32 cities across the country and measures the average increase in sales of their new product at their stores. The four commercial average sales were $1.2M for commercial A, $1.8M for B, $0.76M for C, and $1.3M for D. Where are the differences in sales?\n\n\nWhat if the new product is a warm coat and a majority of the cities seeing C were warm weather cities?\nThe same marketing analyst as before is interested in testing the effectiveness of 4 different commercials describing their company’s new product. Split (block) country into 8 regions. Show each commercial to one city in each region. Sample size still 32."
  },
  {
    "objectID": "notes/primer/anova/index.html#assumptions-2",
    "href": "notes/primer/anova/index.html#assumptions-2",
    "title": "Analysis of Variance",
    "section": "7.3 Assumptions",
    "text": "7.3 Assumptions\nSame as One-Way ANOVA:\n\nNormally distributed categories\nEquality of variances between categories\nIndependence\n\nBlocking can come from collection of data as well as the analysis of the data as a variable being added to the model.\nWhen a new variable is added, we get a new source of variation–sum of squares of blocking."
  },
  {
    "objectID": "notes/primer/anova/index.html#sum-of-squares-blocks",
    "href": "notes/primer/anova/index.html#sum-of-squares-blocks",
    "title": "Analysis of Variance",
    "section": "7.4 Sum of Squares Blocks",
    "text": "7.4 Sum of Squares Blocks\n\\[\nSSBL = \\sum_{j=1}^b k(\\bar{x}_j - \\bar{\\bar{x}})^2\n\\]\nThe sum of squares comes out of the error sum of squares and gets brought into the model–the SSW shrinks even more."
  },
  {
    "objectID": "notes/primer/anova/index.html#blocking-anova-table",
    "href": "notes/primer/anova/index.html#blocking-anova-table",
    "title": "Analysis of Variance",
    "section": "7.5 Blocking ANOVA Table",
    "text": "7.5 Blocking ANOVA Table\n\n\n\nBlocking ANOVA Table\n\n\n\nThe F-Value in the Blocking row is the F-test with \\(H_a\\) at least one block mean not equal"
  },
  {
    "objectID": "notes/primer/anova/index.html#post-hoc-analysis-for-blocking",
    "href": "notes/primer/anova/index.html#post-hoc-analysis-for-blocking",
    "title": "Analysis of Variance",
    "section": "7.6 Post-hoc Analysis for blocking",
    "text": "7.6 Post-hoc Analysis for blocking\nTukey-Kramer ANOVA comparisons do not work for blocking.\nInstead, we have Fisher’s Least Significant Difference. Fisher’s LSD is a recalculation of the margin of error for the difference in means confidence interval just like Tukey’s critical range.\n\\[\nLSD = t^* \\times \\sqrt{MSW} \\times \\sqrt{\\frac{2}{b}}\n\\]"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro/index.html",
    "href": "notes/programming/R/r4ds/intro/index.html",
    "title": "r4ds: Introduction",
    "section": "",
    "text": "Note\n\n\n\nThese notes are based on the second edition of the R for Data Science book by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund.\nAll quotes and examples are credited to the authors of this awesome book!"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro/index.html#import",
    "href": "notes/programming/R/r4ds/intro/index.html#import",
    "title": "r4ds: Introduction",
    "section": "1.1 Import",
    "text": "1.1 Import\nData comes from multiple sources:\n\nFiles\nDatabases\nWeb APIs\n\nIn the context of R, we are loading our data into a dataframe."
  },
  {
    "objectID": "notes/programming/R/r4ds/intro/index.html#tidy",
    "href": "notes/programming/R/r4ds/intro/index.html#tidy",
    "title": "r4ds: Introduction",
    "section": "1.2 Tidy",
    "text": "1.2 Tidy\nStore our data in a form that is consistent and allows us to focus on analyzing the problem rather than “fighting to get the data into the right form for different functions.”"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro/index.html#transform",
    "href": "notes/programming/R/r4ds/intro/index.html#transform",
    "title": "r4ds: Introduction",
    "section": "1.3 Transform",
    "text": "1.3 Transform\nIf we have a problem we are trying to analyze, then we use our problem space to guide observations of interest or create new variables from existing variables that relate to our problem.\n\n\n\n\nflowchart LR\n    Tidying --- C[ ]:::empty\n    Transforming --- C\n    C --&gt; Wrangling\n    classDef empty width:0px,height:0px;"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro/index.html#visualization-and-model",
    "href": "notes/programming/R/r4ds/intro/index.html#visualization-and-model",
    "title": "r4ds: Introduction",
    "section": "1.4 Visualization and Model",
    "text": "1.4 Visualization and Model\nWe represent our data in graphs, charts, and other displays to help us find or resolve questions about our data.\n“Models are complementary tools to visualization”. Models help us answer the questions we have.\n\nEvery model makes assumptions and they cannot answer their own assumptions"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro/index.html#communication",
    "href": "notes/programming/R/r4ds/intro/index.html#communication",
    "title": "r4ds: Introduction",
    "section": "1.5 Communication",
    "text": "1.5 Communication\nAfter the previous steps are at a satisfactory point, we have to communicate our results in a way that others can understand. This might mean in notebooks like this one or through presentations to a business client."
  },
  {
    "objectID": "notes/communication/index.html",
    "href": "notes/communication/index.html",
    "title": "Communication",
    "section": "",
    "text": "Communications: 06/26/2023\n\n\n\n\n\n\n\ncommunication\n\n\n\n\n\n\n\n\n\n\n\nJun 26, 2023\n\n\nYang Chen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notes/analytics/06282023/index.html",
    "href": "notes/analytics/06282023/index.html",
    "title": "Introduction to Statistical Inference",
    "section": "",
    "text": "Last time we talked about different statistical measures like mean and standard deviation. These are called point estimates.\nThere is variability among samples. However, we can have a margin of error for our estimate via the Central Limit Theorem"
  },
  {
    "objectID": "notes/analytics/06282023/index.html#procedure",
    "href": "notes/analytics/06282023/index.html#procedure",
    "title": "Introduction to Statistical Inference",
    "section": "3.1 Procedure",
    "text": "3.1 Procedure\n\nStart with a null hypothesis \\(H_0\\) about a parameter of interest. We assume \\(H_0\\) is true.\nSelect an acceptable significance level \\(\\alpha\\) which represents the likelihood that you incorrectly reject \\(H_0\\) (probability of Type I error)\nAlternative hypothesis \\(H_a\\) is the logical opposite. Note that alternative hypothesis is the “significantly different” statement–no equal signs should appear in alternative\nCollect data, compute statistic\nDetermine the probability that you observed a statistic as extreme or more extreme as the one you did assuming \\(H_0\\) is true \\(\\rightarrow\\) p-value\nIf p-value \\(\\leq \\alpha\\), reject \\(H_0\\) and fail to reject otherwise"
  },
  {
    "objectID": "notes/analytics/06282023/index.html#example-in-r",
    "href": "notes/analytics/06282023/index.html#example-in-r",
    "title": "Introduction to Statistical Inference",
    "section": "5.1 Example in R",
    "text": "5.1 Example in R\n\nWe want to know if the true Sales Price is different then $178,000.\nThe null hypothesis is \\(H_0\\): \\(\\mu = 178000\\) and the alternative is \\(H_a\\): \\(\\mu \\neq 178000\\). \\(\\alpha = 0.05\\)\n\n\n\nCode\nlibrary(AmesHousing)\n\names &lt;- make_ordinal_ames()\n\nt.test(ames$Sale_Price, mu = 178000)\n\n\n\n    One Sample t-test\n\ndata:  ames$Sale_Price\nt = 1.8945, df = 2929, p-value = 0.05825\nalternative hypothesis: true mean is not equal to 178000\n95 percent confidence interval:\n 177902.3 183689.9\nsample estimates:\nmean of x \n 180796.1 \n\n\nDo not reject the null hypothesis as p-value \\(&gt; \\alpha\\)\nTo conduct a directional t-test:\n\n\nCode\nt.test(ames$Sale_Price, mu = 178000, alternative = \"greater\")\n\n\n\n    One Sample t-test\n\ndata:  ames$Sale_Price\nt = 1.8945, df = 2929, p-value = 0.02913\nalternative hypothesis: true mean is greater than 178000\n95 percent confidence interval:\n 178367.7      Inf\nsample estimates:\nmean of x \n 180796.1 \n\n\nCode\nt.test(ames$Sale_Price, mu = 178000, alternative = \"less\")\n\n\n\n    One Sample t-test\n\ndata:  ames$Sale_Price\nt = 1.8945, df = 2929, p-value = 0.9709\nalternative hypothesis: true mean is less than 178000\n95 percent confidence interval:\n     -Inf 183224.4\nsample estimates:\nmean of x \n 180796.1"
  },
  {
    "objectID": "notes/analytics/06282023/index.html#assumptions",
    "href": "notes/analytics/06282023/index.html#assumptions",
    "title": "Introduction to Statistical Inference",
    "section": "6.1 Assumptions",
    "text": "6.1 Assumptions\n\nIndependent observations\nNormally distributed data for each group\nEqual variances for each group\n\nTested formally with F-test to determine which t-test to use"
  },
  {
    "objectID": "notes/analytics/06282023/index.html#f-test-for-equality-of-variances",
    "href": "notes/analytics/06282023/index.html#f-test-for-equality-of-variances",
    "title": "Introduction to Statistical Inference",
    "section": "6.2 F-Test for Equality of Variances",
    "text": "6.2 F-Test for Equality of Variances\n\n\\(H_0: \\sigma_1^2 = \\sigma_2^2\\)\n\\(H_a: \\sigma_1^2 \\neq \\sigma_2^2\\)\n\\(F = \\frac{\\max(s_1^2, s_2^2)}{\\min(s_1^2, s_2^2)}\\)"
  },
  {
    "objectID": "notes/analytics/06282023/index.html#two-sample-t-test-in-r",
    "href": "notes/analytics/06282023/index.html#two-sample-t-test-in-r",
    "title": "Introduction to Statistical Inference",
    "section": "6.3 Two-Sample t-test in R",
    "text": "6.3 Two-Sample t-test in R\nWe first need to verify the normality condition:\n\n\nCode\nggplot(ames, aes(sample = Sale_Price, color = Central_Air)) +\n    stat_qq() +\n    stat_qq_line()\n\n\n\n\n\nNormality seems to fail with houses that have central air conditioning. However, for illustration we will still conduct the two-sample t-test.\nNote that in practice if normality fails then some groups consider not even conducting a t-test when variances are equal–just go straight to variances are not equal.\n\n\nCode\nvar.test(Sale_Price ~ Central_Air, data = ames)\n\n\n\n    F test to compare two variances\n\ndata:  Sale_Price by Central_Air\nF = 0.2258, num df = 195, denom df = 2733, p-value &lt; 2.2e-16\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1854873 0.2800271\nsample estimates:\nratio of variances \n         0.2257977 \n\n\nReject \\(H_0\\) based on the p-value so we conclude that the variances are not equal.\n\n\nCode\nt.test(Sale_Price ~ Central_Air, data = ames, var.equal = FALSE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  Sale_Price by Central_Air\nt = -27.433, df = 336.06, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group N and group Y is not equal to 0\n95 percent confidence interval:\n -90625.69 -78498.92\nsample estimates:\nmean in group N mean in group Y \n       101890.5        186452.8 \n\n\nWith a regular two-sample t-test we reject the null hypothesis that the means are equal.\nHowever, our normality assumption wasn’t satisfied so we should use a nonparametric test that does not rely on normality."
  },
  {
    "objectID": "notes/analytics/06282023/index.html#wilcoxon-rank",
    "href": "notes/analytics/06282023/index.html#wilcoxon-rank",
    "title": "Introduction to Statistical Inference",
    "section": "6.4 Wilcoxon Rank",
    "text": "6.4 Wilcoxon Rank\nThe question we are answering with this test is, “Are the median sale prices of houses with and without central air the same?”\n\n\nCode\nwilcox.test(Sale_Price ~ Central_Air, data = ames)\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  Sale_Price by Central_Air\nW = 63164, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n6.4.1 Interpretations of Wilcoxon\n\n\n\n\n\n\n\nConditions\nInterpretation of Significant Mann-Whiteney-Wilcoxon Test\n\n\n\n\nGroup distributions are identical in shape, variance and symmetric\nDifference in means\n\n\nGroup distributions are identical in shape, variance, but not symmetric\nDifference in medians\n\n\nGroup distributions are not identical in shape, variance, and are not symmetric\nDifference in location (distributional dominance)"
  },
  {
    "objectID": "notes/analytics/06282023/breakout_2.html",
    "href": "notes/analytics/06282023/breakout_2.html",
    "title": "Yang MSA",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\ncovid &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/coviddata.csv\")\n\nglimpse(covid)\n\n\nRows: 1,551\nColumns: 5\n$ X                    &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15…\n$ zip                  &lt;int&gt; 90210, 90221, 90232, 90243, 90254, 90265, 90276, …\n$ region               &lt;chr&gt; \"West\", \"West\", \"West\", \"West\", \"West\", \"West\", \"…\n$ population           &lt;int&gt; 50509, 52659, 50305, 53724, 47560, 50325, 47920, …\n$ covidDeathsPerCapita &lt;dbl&gt; 19.075, 17.728, 18.022, 17.896, 17.165, 17.275, 1…\n\n\n\nYou’ve been asked to explore differences between rates of death from Covid in the east vs. the west. You download some data (covidPerCapita) from the CDC that has Covid death rates per capita (covidDeathsPerCapita) by zip code (zip). Not all zip codes are reporting, and even handling the data from those that do report is difficult so you select a random sample of zip codes in the east and the west.\n\nConduct a t-test for the difference of means in per capita deaths from Covid in the east region vs the west region. Don’t forget to verify assumptions. Note anything of interest to you, including the results of any tests performed, violations of assumptions, etc.\n\n\nVerifying normality:\n\n\nCode\nggplot(covid, aes(sample = covidDeathsPerCapita, color = region)) +\n    stat_qq() +\n    stat_qq_line()\n\n\n\n\n\n\nBoth regions are approximately normally distributed for per capita deaths\n\nTesting for difference in variances:\n\n\nCode\nvar.test(covidDeathsPerCapita ~ region, data = covid)$p.value\n\n\n[1] 0.1738449\n\n\n\nAt a p-value of 0.174 we do not reject the null hypothesis that the variances are not significantly different\nWe can proceed with a two-sample t-test with equal variances\n\n\n\nCode\nt.test(covidDeathsPerCapita ~ region, data = covid, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  covidDeathsPerCapita by region\nt = 53.6, df = 1549, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group East and group West is not equal to 0\n95 percent confidence interval:\n 1.928196 2.074681\nsample estimates:\nmean in group East mean in group West \n          20.00643           18.00500 \n\n\nWe have a very low p-value such that we reject the null hypothesis that our means are similar. We believe that the mean deaths are significantly different between the two regions.\nAlthough our tests from this sample allow us to conclude that the means are different, we have to be careful because our sample does not include all zip codes. Is our data balanced? Did we have issues with the way the data was sampled?\n\n\nCode\nt.test(covidDeathsPerCapita ~ region, data = covid, var.equal = TRUE, alternative = \"greater\")\n\n\n\n    Two Sample t-test\n\ndata:  covidDeathsPerCapita by region\nt = 53.6, df = 1549, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group East and group West is greater than 0\n95 percent confidence interval:\n 1.939983      Inf\nsample estimates:\nmean in group East mean in group West \n          20.00643           18.00500 \n\n\n\n\nCode\nlength(covid[covid$region == \"West\", ]) == length(covid[covid$region == \"East\", ])\n\n\n[1] TRUE"
  },
  {
    "objectID": "notes/analytics/06292023/lab_3.html",
    "href": "notes/analytics/06292023/lab_3.html",
    "title": "Yang MSA",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\ngarlic &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/garlic.csv\")\nglimpse(garlic)\n\n\nRows: 32\nColumns: 3\n$ BedID      &lt;int&gt; 101, 102, 103, 104, 105, 106, 107, 108, 201, 202, 203, 204,…\n$ Fertilizer &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,…\n$ BulbWt     &lt;dbl&gt; 0.2391642, 0.2582814, 0.2047856, 0.2433666, 0.2726395, 0.21…\n\n\nVerifying normality:\n\n\nCode\ngarlic_lm &lt;- lm(BulbWt ~ factor(Fertilizer), data = garlic)\nggplot(garlic, aes(x = BulbWt, fill = factor(Fertilizer))) +\n    geom_density(alpha = 0.2, position = \"identity\") +\n    labs(x = \"Bulb Weight\")\n\n\n\n\n\n\nGroups do not appear to be Normally distributed"
  },
  {
    "objectID": "notes/analytics/07172023/breakout_12.html",
    "href": "notes/analytics/07172023/breakout_12.html",
    "title": "Breakout 12",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nbike &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/bike.csv\")\n\nset.seed(123)\nbike &lt;- bike %&gt;%\n    mutate(id = row_number())\ntrain &lt;- bike %&gt;% sample_frac(0.7)\ntest &lt;- anti_join(bike, train, by = \"id\")\n\n\n\n\nCode\ntrain$casual_high &lt;- train$casual &gt;= train$registered\n\n\n\n\nCode\nlibrary(vcdExtra)\n\n\nLoading required package: vcd\n\n\nLoading required package: grid\n\n\nLoading required package: gnm\n\n\n\nAttaching package: 'vcdExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    summarise\n\n\nCode\nchisq.test(table(train$casual_high, train$season))\n\n\n\n    Pearson's Chi-squared test\n\ndata:  table(train$casual_high, train$season)\nX-squared = 29.74, df = 3, p-value = 1.565e-06\n\n\nCode\nCMHtest(table(train$casual_high, train$season))$table[1, ]\n\n\n     Chisq         Df       Prob \n5.50559131 1.00000000 0.01895577 \n\n\n\n\nCode\nlibrary(DescTools)\n\nCMHtest(table(train$casual_high, train$holiday))$table[1, ]\n\n\n       Chisq           Df         Prob \n3.830649e+01 1.000000e+00 6.046125e-10 \n\n\nCode\nOddsRatio(table(train$casual_high, train$holiday))\n\n\n[1] 3.455253\n\n\nCode\ntable(train$casual_high, train$holiday)\n\n\n       \n            0     1\n  FALSE 11544   338\n  TRUE    257    26\n\n\nCode\n((11544 / (11544 + 338)) / (338 / (11544 + 338))) / ((257 / (257 + 26)) / (26 / (257 + 26)))\n\n\n[1] 3.455253\n\n\n\nTimes where casual users are higher than the registered users have 3.455 times the odds of being a holiday"
  },
  {
    "objectID": "notes/analytics/07032023/breakout_5.html",
    "href": "notes/analytics/07032023/breakout_5.html",
    "title": "Breakout 5",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n\n\n\nCode\nbike = pd.read_csv('https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/bike.csv')\nbike.head()\n\n\n\n\n\n\n\n\n\ndteday\nseason\nyr\nmnth\nhr\nholiday\nweekday\nworkingday\nweathersit\ntemp\natemp\nhum\nwindspeed\ncasual\nregistered\ncnt\n\n\n\n\n0\n14975\n1\n0\n1\n0\n0\n6\n0\n1\n0.24\n0.2879\n0.81\n0.0\n3\n13\n16\n\n\n1\n14975\n1\n0\n1\n1\n0\n6\n0\n1\n0.22\n0.2727\n0.80\n0.0\n8\n32\n40\n\n\n2\n14975\n1\n0\n1\n2\n0\n6\n0\n1\n0.22\n0.2727\n0.80\n0.0\n5\n27\n32\n\n\n3\n14975\n1\n0\n1\n3\n0\n6\n0\n1\n0.24\n0.2879\n0.75\n0.0\n3\n10\n13\n\n\n4\n14975\n1\n0\n1\n4\n0\n6\n0\n1\n0.24\n0.2879\n0.75\n0.0\n0\n1\n1\n\n\n\n\n\n\n\n\n1 1\n\n\nCode\nbike_lm = smf.ols('cnt ~ C(workingday) * C(season)', bike).fit()\n\nsm.stats.anova_lm(bike_lm)\n\n\n\n\n\n\n\n\n\ndf\nsum_sq\nmean_sq\nF\nPR(&gt;F)\n\n\n\n\nC(workingday)\n1.0\n5.243871e+05\n5.243871e+05\n17.082764\n3.595344e-05\n\n\nC(season)\n3.0\n3.748219e+07\n1.249406e+07\n407.014449\n1.544102e-255\n\n\nC(workingday):C(season)\n3.0\n5.199753e+05\n1.733251e+05\n5.646347\n7.301192e-04\n\n\nResidual\n17371.0\n5.332350e+08\n3.069685e+04\nNaN\nNaN\n\n\n\n\n\n\n\n\nThe interaction between workingday and season seems to be significant towards predicting cnt\n\n\n\n2 2\nTalk with breakout group.\n\n\n3 3\n\n\nCode\ncasual_lm = smf.ols('casual ~ C(workingday) * C(season)', bike).fit()\n\nsm.stats.anova_lm(casual_lm)\n\n\n\n\n\n\n\n\n\ndf\nsum_sq\nmean_sq\nF\nPR(&gt;F)\n\n\n\n\nC(workingday)\n1.0\n3.826038e+06\n3.826038e+06\n1954.028610\n0.000000e+00\n\n\nC(season)\n3.0\n3.750852e+06\n1.250284e+06\n638.543326\n0.000000e+00\n\n\nC(workingday):C(season)\n3.0\n6.559238e+05\n2.186413e+05\n111.664154\n1.292550e-71\n\n\nResidual\n17371.0\n3.401286e+07\n1.958026e+03\nNaN\nNaN\n\n\n\n\n\n\n\n\nNot a significant interaction between workingday and season for casual bikers\n\n\n\nCode\nregistered_lm = smf.ols('registered ~ C(workingday) * C(season)', bike).fit()\n\nsm.stats.anova_lm(registered_lm)\n\n\n\n\n\n\n\n\n\ndf\nsum_sq\nmean_sq\nF\nPR(&gt;F)\n\n\n\n\nC(workingday)\n1.0\n7.183321e+06\n7.183321e+06\n335.449602\n3.121975e-74\n\n\nC(season)\n3.0\n1.885079e+07\n6.283597e+06\n293.433926\n7.848911e-186\n\n\nC(workingday):C(season)\n3.0\n9.621956e+04\n3.207319e+04\n1.497767\n2.129291e-01\n\n\nResidual\n17371.0\n3.719828e+08\n2.141401e+04\nNaN\nNaN\n\n\n\n\n\n\n\n\nSignificant interaction between workingday and season for registered bikers\n\n\n\nCode\nunique_season = bike['season'].unique()\n\nfor season in unique_season:\n    sliced_data = smf.ols(\"casual ~ C(workingday)\", bike[bike[\"season\"] == season]).fit()\n    print(sm.stats.anova_lm(sliced_data))\n\nfor season in unique_season:\n    sliced_data = smf.ols(\"registered ~ C(workingday)\", bike[bike[\"season\"] == season]).fit()\n    print(sm.stats.anova_lm(sliced_data))\n\n\n                   df        sum_sq        mean_sq          F        PR(&gt;F)\nC(workingday)     1.0  1.436979e+05  143697.866870  199.44088  2.751109e-44\nResidual       4240.0  3.054935e+06     720.503576        NaN           NaN\n                   df        sum_sq       mean_sq           F         PR(&gt;F)\nC(workingday)     1.0  2.044757e+06  2.044757e+06  720.507711  3.944648e-147\nResidual       4407.0  1.250680e+07  2.837939e+03         NaN            NaN\n                   df        sum_sq       mean_sq           F         PR(&gt;F)\nC(workingday)     1.0  1.623762e+06  1.623762e+06  700.640615  1.328288e-143\nResidual       4494.0  1.041502e+07  2.317539e+03         NaN            NaN\n                   df        sum_sq        mean_sq           F         PR(&gt;F)\nC(workingday)     1.0  9.299500e+05  929949.990208  489.501677  9.987658e-103\nResidual       4230.0  8.036108e+06    1899.789180         NaN            NaN\n                   df        sum_sq       mean_sq           F        PR(&gt;F)\nC(workingday)     1.0  1.278398e+06  1.278398e+06  120.723426  1.035371e-27\nResidual       4240.0  4.489940e+07  1.058948e+04         NaN           NaN\n                   df        sum_sq       mean_sq          F        PR(&gt;F)\nC(workingday)     1.0  1.351663e+06  1.351663e+06  58.687294  2.258053e-14\nResidual       4407.0  1.015003e+08  2.303161e+04        NaN           NaN\n                   df        sum_sq       mean_sq          F        PR(&gt;F)\nC(workingday)     1.0  2.328766e+06  2.328766e+06  85.657432  3.232019e-20\nResidual       4494.0  1.221782e+08  2.718697e+04        NaN           NaN\n                   df        sum_sq       mean_sq          F        PR(&gt;F)\nC(workingday)     1.0  1.629497e+06  1.629497e+06  66.658104  4.220264e-16\nResidual       4230.0  1.034048e+08  2.444559e+04        NaN           NaN\n\n\n\nFor each individual season, there is a significant difference between working days and non-working days in registered bikers"
  },
  {
    "objectID": "notes/analytics/07112023/lab_9.html",
    "href": "notes/analytics/07112023/lab_9.html",
    "title": "Lab 9",
    "section": "",
    "text": "1 1\n\n\nCode\nlibrary(AppliedPredictiveModeling)\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(lmtest)\n\n\nLoading required package: zoo\n\nAttaching package: 'zoo'\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nCode\ndata(FuelEconomy)\n\ncars2010 &lt;- cars2010 %&gt;%\n    mutate(idx = row_number())\nglimpse(cars2010)\n\n\nRows: 1,107\nColumns: 15\n$ EngDispl            &lt;dbl&gt; 4.7, 4.7, 4.2, 4.2, 5.2, 5.2, 2.0, 6.0, 3.0, 3.0, …\n$ NumCyl              &lt;int&gt; 8, 8, 8, 8, 10, 10, 4, 12, 6, 6, 6, 6, 16, 8, 8, 8…\n$ Transmission        &lt;fct&gt; AM6, M6, M6, AM6, AM6, M6, S6, S6, S6, M6, S7, M6,…\n$ FE                  &lt;dbl&gt; 28.0198, 25.6094, 26.8000, 25.0451, 24.8000, 23.90…\n$ AirAspirationMethod &lt;fct&gt; NaturallyAspirated, NaturallyAspirated, NaturallyA…\n$ NumGears            &lt;int&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 6, 7, 6, 6, 6, 6,…\n$ TransLockup         &lt;dbl&gt; 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,…\n$ TransCreeperGear    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ DriveDesc           &lt;fct&gt; TwoWheelDriveRear, TwoWheelDriveRear, AllWheelDriv…\n$ IntakeValvePerCyl   &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1,…\n$ ExhaustValvesPerCyl &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1,…\n$ CarlineClassDesc    &lt;fct&gt; 2Seaters, 2Seaters, 2Seaters, 2Seaters, 2Seaters, …\n$ VarValveTiming      &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,…\n$ VarValveLift        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,…\n$ idx                 &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,…\n\n\nCode\ncars2010.model &lt;- lm(FE ~ EngDispl + Transmission + AirAspirationMethod + TransLockup + TransCreeperGear + DriveDesc + IntakeValvePerCyl + CarlineClassDesc + VarValveLift, data = cars2010)\n\nx &lt;- seq(1:nrow(cars2010))\ncars2010.time &lt;- lm(FE ~ x, data = cars2010)\n\ndwtest(cars2010.time, alternative = \"greater\")\n\n\n\n    Durbin-Watson test\n\ndata:  cars2010.time\nDW = 0.71797, p-value &lt; 2.2e-16\nalternative hypothesis: true autocorrelation is greater than 0"
  },
  {
    "objectID": "notes/analytics/07112023/index.html",
    "href": "notes/analytics/07112023/index.html",
    "title": "Correlated Error Terms",
    "section": "",
    "text": "When we’re trying to understand correlated error terms, we need to know the source of our data:"
  },
  {
    "objectID": "notes/analytics/07112023/index.html#durbin-watson-statistic-first-order",
    "href": "notes/analytics/07112023/index.html#durbin-watson-statistic-first-order",
    "title": "Correlated Error Terms",
    "section": "1.1 Durbin-Watson Statistic (First-Order)",
    "text": "1.1 Durbin-Watson Statistic (First-Order)\nWe can also assess autocorrelation using the Durbin-Watson statistic which compares a residual against the previous time residual over the sum of residuals squared.\n\\[\nd = \\frac{\\sum_{t=2}^{T} (e_t - e_{t-1})^2}{\\sum_{t=1}^{T} e_t^2}\n\\]\n\nBounded in \\([0, 4]\\)\nWhen \\(d=2\\), fail to reject \\(H_0\\) and assume there is not enough evidence supporting autocorrelation\n\\(d &lt; 2\\), possible positive autocorrelation\n\\(d &gt; 2\\), possible negative autocorrelation"
  },
  {
    "objectID": "notes/analytics/07112023/index.html#diagnostic-statistics",
    "href": "notes/analytics/07112023/index.html#diagnostic-statistics",
    "title": "Correlated Error Terms",
    "section": "2.1 Diagnostic Statistics",
    "text": "2.1 Diagnostic Statistics\n\n\n\n\n\nflowchart LR\n    A[Detecting Outliers] --&gt; B[Standardized Residuals]\n    A --&gt; C[Studentized Residuals]\n    X[Detecting Influential Obs.] --&gt; D[Cook's D]\n    X --&gt; E[DFFITS]\n    X --&gt; F[DFBETAS]\n    X --&gt; G[Hat Values]\n\n\n\n\n\n\n\n2.1.1 Studentized Residuals\nDivide the residuals by their standard errors after deleting that one observation\n\n\\(\\abs(SR) &gt; 2\\) for datasets with a relatively small number of observations\n\\(\\abs(SR) &gt; 3\\) for datasets with relatively large number of observations\n\n\n\n2.1.2 Cook’s D\nMeasures the difference in the regression estimates when the \\(i^{th}\\) observation is left out\nCutoff formula:\n\\[\nD_i &gt; \\frac{4}{n - p - 1}\n\\]\n\n\\(p\\) is the number of parameters including the intercept\n\n\n\n2.1.3 DFFITS\nMeasures impact that the \\(i^{th}\\) observation has on predicted value\n\\[\n| DFFITS_i | &gt; 2\\sqrt{\\frac{p}{n}}\n\\]\n\n\n2.1.4 Hat Values\nFrom the normal equation, the estimate of the parameters is:\n\\[\nb = (X'X)^{-1}X'y\n\\]\nEstimated line is:\n\\[\n\\hat{y} = X(X'X)^{-1}X'y\n\\]\nWith the hat values being:\n\\[\nX(X'X)^{-1}X'\n\\]\nSuggested cutoff is:\n\\[\nh_{ii} &gt; \\frac{2p}{n}\n\\]\n\n\n2.1.5 DFBETA\nMeasure of change in the \\(j^{th}\\) parameter estimate with deletion of \\(i^{th}\\) observation.\nOne DFBETA per parameter per observation. Helps to explain which parameter coefficient the influence most lies.\n\\[\n| DFBETA_{ij} | &gt; 2 \\sqrt{\\frac{1}{n}}\n\\]"
  },
  {
    "objectID": "notes/analytics/07112023/index.html#scottish-hill-races",
    "href": "notes/analytics/07112023/index.html#scottish-hill-races",
    "title": "Correlated Error Terms",
    "section": "2.2 Scottish Hill Races",
    "text": "2.2 Scottish Hill Races\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nurl &lt;- \"http://www.statsci.org/data/general/hills.txt\"\nraces.table &lt;- read.table(url, header = TRUE, sep = \"\\t\")\n\nraces.table &lt;- races.table %&gt;%\n    mutate(idx = row_number())\n\nlm.model &lt;- lm(Time ~ Distance + Climb, data = races.table)\n\nggplot(lm.model, aes(x = races.table$idx, y = rstudent(lm.model))) +\n    geom_point(color = \"orange\") +\n    geom_line(y = -3) +\n    geom_line(y = 3) +\n    labs(title = \"External Studentized Residuals\", x = \"Observation\", y = \"Residuals\")"
  },
  {
    "objectID": "notes/analytics/07112023/index.html#how-to-handle-influential-observations",
    "href": "notes/analytics/07112023/index.html#how-to-handle-influential-observations",
    "title": "Correlated Error Terms",
    "section": "2.3 How to Handle Influential Observations",
    "text": "2.3 How to Handle Influential Observations\n\nRecheck data to ensure no transcription or data entry errors occurred.\nIf data is valid, maybe model is inadequate\n\nHigher-order terms may be necessary\nNonlinear model\n\nDetermine robustness of the inference by running analysis with and without influential observations\nRobust Regression\nWeighted Least Squares"
  },
  {
    "objectID": "notes/analytics/07112023/index.html#collinearity-diagnostics",
    "href": "notes/analytics/07112023/index.html#collinearity-diagnostics",
    "title": "Correlated Error Terms",
    "section": "3.1 Collinearity Diagnostics",
    "text": "3.1 Collinearity Diagnostics\nWe can look at correlation matrix of predictors, but there is also the variance inflation factor that we can consider:\n\\[\nVIF_i = \\frac{1}{1 - R_i^2}\n\\]\n\n\\(R_i^2\\) is the \\(R^2\\) value with all the other variables predicting \\(x_i\\)\n\\(VIF &gt; 10\\) indicate collinearity\n\n\n\nCode\nlibrary(car)\n\n\nLoading required package: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\n\nCode\ncor(mtcars)\n\n\n            mpg        cyl       disp         hp        drat         wt\nmpg   1.0000000 -0.8521620 -0.8475514 -0.7761684  0.68117191 -0.8676594\ncyl  -0.8521620  1.0000000  0.9020329  0.8324475 -0.69993811  0.7824958\ndisp -0.8475514  0.9020329  1.0000000  0.7909486 -0.71021393  0.8879799\nhp   -0.7761684  0.8324475  0.7909486  1.0000000 -0.44875912  0.6587479\ndrat  0.6811719 -0.6999381 -0.7102139 -0.4487591  1.00000000 -0.7124406\nwt   -0.8676594  0.7824958  0.8879799  0.6587479 -0.71244065  1.0000000\nqsec  0.4186840 -0.5912421 -0.4336979 -0.7082234  0.09120476 -0.1747159\nvs    0.6640389 -0.8108118 -0.7104159 -0.7230967  0.44027846 -0.5549157\nam    0.5998324 -0.5226070 -0.5912270 -0.2432043  0.71271113 -0.6924953\ngear  0.4802848 -0.4926866 -0.5555692 -0.1257043  0.69961013 -0.5832870\ncarb -0.5509251  0.5269883  0.3949769  0.7498125 -0.09078980  0.4276059\n            qsec         vs          am       gear        carb\nmpg   0.41868403  0.6640389  0.59983243  0.4802848 -0.55092507\ncyl  -0.59124207 -0.8108118 -0.52260705 -0.4926866  0.52698829\ndisp -0.43369788 -0.7104159 -0.59122704 -0.5555692  0.39497686\nhp   -0.70822339 -0.7230967 -0.24320426 -0.1257043  0.74981247\ndrat  0.09120476  0.4402785  0.71271113  0.6996101 -0.09078980\nwt   -0.17471588 -0.5549157 -0.69249526 -0.5832870  0.42760594\nqsec  1.00000000  0.7445354 -0.22986086 -0.2126822 -0.65624923\nvs    0.74453544  1.0000000  0.16834512  0.2060233 -0.56960714\nam   -0.22986086  0.1683451  1.00000000  0.7940588  0.05753435\ngear -0.21268223  0.2060233  0.79405876  1.0000000  0.27407284\ncarb -0.65624923 -0.5696071  0.05753435  0.2740728  1.00000000\n\n\nCode\nlm.model &lt;- lm(mpg ~ ., data = mtcars)\nv &lt;- vif(lm.model)\nv[v &gt; 10]\n\n\n     cyl     disp       wt \n15.37383 21.62024 15.16489"
  },
  {
    "objectID": "notes/analytics/07112023/index.html#dealing-with-multicollinearity",
    "href": "notes/analytics/07112023/index.html#dealing-with-multicollinearity",
    "title": "Correlated Error Terms",
    "section": "3.2 Dealing with Multicollinearity",
    "text": "3.2 Dealing with Multicollinearity\n\nExclude redundant independent variables\nRedefine variables\nUse biased regression techniques (e.g. LASSO)\nCenter the independent variables in polynomial regression models or models with interaction terms\n\nSubtract each value of the predictor by the mean of that column\n\n\nYou should be dealing with multicollinearity before you do any model selection.\nAny time you take or add variables in, you should be modifying one at a time and recalculating VIF at each step."
  },
  {
    "objectID": "notes/analytics/07102023/index.html",
    "href": "notes/analytics/07102023/index.html",
    "title": "Diagnostics",
    "section": "",
    "text": "Recall the assumptions of linear regression:\n\nMean of the Ys is accurately modeled by linear function of the Xs\n\\(\\varepsilon\\) is assumed to be Normal with a mean of 0\n\\(\\varepsilon\\) is assumed to have constant variance \\(\\sigma^2\\)\nErrors are independent\nNo perfect collinearity\n\nWe can investigate many of our assumptions through residuals in residuals vs. fitted values plots.\n\n\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(httpgd)\nlibrary(reticulate)\n\nuse_condaenv(condaenv = \"blues_clues\", required = TRUE)\n# hgd(port = 8888)\ndata_path &lt;- \"data/Salary.csv\"\nsalary &lt;- read.csv(data_path)\npar(mfrow = c(2, 2))\nsalary_lm &lt;- lm(Salary ~ YearsExperience, data = salary)\n\nggplot(salary_lm, aes(x = .fitted, y = .resid)) +\n    geom_point() +\n    geom_hline(yintercept = 0) +\n    labs(x = \"Predicted Values\", y = \"Residuals\")\n\n\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport seaborn as sns\nfrom pathlib import Path\n\nsalary = r.salary\nsalary\n\n\n    YearsExperience  Salary\n0               1.1   39343\n1               1.3   46205\n2               1.5   37731\n3               2.0   43525\n4               2.2   39891\n5               2.9   56642\n6               3.0   60150\n7               3.2   54445\n8               3.2   64445\n9               3.7   57189\n10              3.9   63218\n11              4.0   55794\n12              4.0   56957\n13              4.1   57081\n14              4.5   61111\n15              4.9   67938\n16              5.1   66029\n17              5.3   83088\n18              5.9   81363\n19              6.0   93940\n20              6.8   91738\n21              7.1   98273\n22              7.9  101302\n23              8.2  113812\n24              8.7  109431\n25              9.0  105582\n26              9.5  116969\n27              9.6  112635\n28             10.3  122391\n29             10.5  121872\n30             11.2  127345\n31             11.5  126756\n32             12.3  128765\n33             12.9  135675\n34             13.5  139465\n\n\nCode\n# sns.residplot(data=salary, x=\"YearsExperience\", y=\"Salary\", order=2)"
  },
  {
    "objectID": "notes/analytics/07102023/index.html#r-code",
    "href": "notes/analytics/07102023/index.html#r-code",
    "title": "Diagnostics",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(httpgd)\nlibrary(reticulate)\n\nuse_condaenv(condaenv = \"blues_clues\", required = TRUE)\n# hgd(port = 8888)\ndata_path &lt;- \"data/Salary.csv\"\nsalary &lt;- read.csv(data_path)\npar(mfrow = c(2, 2))\nsalary_lm &lt;- lm(Salary ~ YearsExperience, data = salary)\n\nggplot(salary_lm, aes(x = .fitted, y = .resid)) +\n    geom_point() +\n    geom_hline(yintercept = 0) +\n    labs(x = \"Predicted Values\", y = \"Residuals\")"
  },
  {
    "objectID": "notes/analytics/07102023/index.html#python-code",
    "href": "notes/analytics/07102023/index.html#python-code",
    "title": "Diagnostics",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport seaborn as sns\nfrom pathlib import Path\n\nsalary = r.salary\nsalary\n\n\n    YearsExperience  Salary\n0               1.1   39343\n1               1.3   46205\n2               1.5   37731\n3               2.0   43525\n4               2.2   39891\n5               2.9   56642\n6               3.0   60150\n7               3.2   54445\n8               3.2   64445\n9               3.7   57189\n10              3.9   63218\n11              4.0   55794\n12              4.0   56957\n13              4.1   57081\n14              4.5   61111\n15              4.9   67938\n16              5.1   66029\n17              5.3   83088\n18              5.9   81363\n19              6.0   93940\n20              6.8   91738\n21              7.1   98273\n22              7.9  101302\n23              8.2  113812\n24              8.7  109431\n25              9.0  105582\n26              9.5  116969\n27              9.6  112635\n28             10.3  122391\n29             10.5  121872\n30             11.2  127345\n31             11.5  126756\n32             12.3  128765\n33             12.9  135675\n34             13.5  139465\n\n\nCode\n# sns.residplot(data=salary, x=\"YearsExperience\", y=\"Salary\", order=2)"
  },
  {
    "objectID": "notes/analytics/07102023/index.html#r-code-1",
    "href": "notes/analytics/07102023/index.html#r-code-1",
    "title": "Diagnostics",
    "section": "4.1 R Code",
    "text": "4.1 R Code\n\n\nCode\nsalary_quad &lt;- lm(Salary ~ YearsExperience + I(YearsExperience^2), data = salary)\nsummary(salary_quad)\n\n\n\nCall:\nlm(formula = Salary ~ YearsExperience + I(YearsExperience^2), \n    data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9210.7 -4037.8  -467.7  3485.5 11052.0 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          21855.58    3630.80   6.019 1.03e-06 ***\nYearsExperience      11456.37    1217.28   9.411 9.79e-11 ***\nI(YearsExperience^2)  -193.90      84.45  -2.296   0.0284 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5733 on 32 degrees of freedom\nMultiple R-squared:  0.9701,    Adjusted R-squared:  0.9682 \nF-statistic:   519 on 2 and 32 DF,  p-value: &lt; 2.2e-16\n\n\nCode\nggplot(salary_quad, aes(x = .fitted, y = .resid)) +\n    geom_point() +\n    geom_hline(yintercept = 0) +\n    labs(x = \"Predicted Values\", y = \"Residuals\")\n\n\n\n\n\n\nIn R we use the I() function to create a higher order term\n\nWhen a straight line is inappropriate, we can consider:\n\nFit a polynomial/more complex regression\nTransform the dependent and/or independent variables to obtain linearity\nFit a nonlinear regression model if appropriate\nFit a nonparameetric regression model (e.g. LOESS)"
  },
  {
    "objectID": "notes/analytics/07062023/index.html",
    "href": "notes/analytics/07062023/index.html",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "Models with more than one predictor variable are called multiple regression models.\n\\[\ny = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\beta_kx_k + \\varepsilon\n\\]\nWe are still trying to minimize the sum of squared errors:\n\\[\nSSE = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n\\]\nLinear in MLR refers to the linear combination of variables in the model–not how they’re visualized in multiple dimensions.\nA model like \\(y = \\beta_0 + \\beta_1x_1 + \\beta_1x_1^2\\) is still a linear regression!"
  },
  {
    "objectID": "notes/analytics/07062023/index.html#r-code",
    "href": "notes/analytics/07062023/index.html#r-code",
    "title": "Multiple Linear Regression",
    "section": "1.1 R Code",
    "text": "1.1 R Code\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(AmesHousing)\nlibrary(reticulate)\n\nuse_condaenv(\"blues_clues\")\n\names &lt;- make_ordinal_ames()\nset.seed(123)\names &lt;- ames |&gt; mutate(id = row_number())\ntrain &lt;- ames |&gt; sample_frac(0.7)\ntest &lt;- anti_join(ames, train, by = \"id\")\n\names_lm2 &lt;- lm(Sale_Price ~ Gr_Liv_Area + TotRms_AbvGrd, train)\nsummary(ames_lm2)\n\n\n\nCall:\nlm(formula = Sale_Price ~ Gr_Liv_Area + TotRms_AbvGrd, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-528656  -30077   -1230   21427  361465 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    42562.657   5365.721   7.932 3.51e-15 ***\nGr_Liv_Area      136.982      4.207  32.558  &lt; 2e-16 ***\nTotRms_AbvGrd -10563.324   1370.007  -7.710 1.94e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 56630 on 2048 degrees of freedom\nMultiple R-squared:  0.5024,    Adjusted R-squared:  0.5019 \nF-statistic:  1034 on 2 and 2048 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "notes/analytics/07062023/index.html#python-code",
    "href": "notes/analytics/07062023/index.html#python-code",
    "title": "Multiple Linear Regression",
    "section": "1.2 Python Code",
    "text": "1.2 Python Code\n\n\nCode\nimport pandas as pd\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\names = pd.read_csv(\"../../../data/ames.csv\")\ntrain, test = train_test_split(ames, random_state=123)\ntrain.head()\n\n\n        Id  MSSubClass MSZoning  ...  SaleType  SaleCondition SalePrice\n1446  1447          20       RL  ...        WD         Normal    157900\n1123  1124          20       RL  ...        WD         Normal    118000\n186    187          80       RL  ...        WD         Normal    173000\n1020  1021          20       RL  ...        WD         Normal    176000\n67      68          20       RL  ...        WD         Normal    226000\n\n[5 rows x 81 columns]\n\n\n\n\nCode\names_lm2 = smf.ols(\"SalePrice ~ GrLivArea + TotRmsAbvGrd\", train).fit()\n\names_lm2.f_pvalue\n\n\n9.720219891564917e-163"
  },
  {
    "objectID": "notes/analytics/07062023/index.html#assumptions",
    "href": "notes/analytics/07062023/index.html#assumptions",
    "title": "Multiple Linear Regression",
    "section": "2.1 Assumptions",
    "text": "2.1 Assumptions\n\nThe mean of \\(y\\) is accurately modeled by a linear function of the independent variables\n\\(\\varepsilon\\) is Normal with a mean of 0\n\\(\\varepsilon\\) has a constant variance\nThe errors are independent\nNo perfect collinearity"
  },
  {
    "objectID": "notes/analytics/07062023/index.html#multicollinearity",
    "href": "notes/analytics/07062023/index.html#multicollinearity",
    "title": "Multiple Linear Regression",
    "section": "2.2 Multicollinearity",
    "text": "2.2 Multicollinearity\nMulticollinearity is when predictor variables are correlated with one another.\nNo perfect collinearity means no predictor variables as a perfect linear combination of each other. In practice, we only care when collinearity has a significant impact.\n\n2.2.1 R Code\n\n\nCode\npar(mfrow = c(2, 2))\nplot(ames_lm2)\n\n\n\n\n\n\n\n2.2.2 Python Code\n\n\nCode\ntrain[\"resid\"] = ames_lm2.resid\ntrain[\"predict\"] = ames_lm2.predict()\nax = sns.relplot(train, x=\"predict\", y=\"resid\")\nplt.show()\n\n\n\n\n\n\n\nCode\nsm.qqplot(train[\"resid\"])"
  },
  {
    "objectID": "notes/analytics/07062023/index.html#predict",
    "href": "notes/analytics/07062023/index.html#predict",
    "title": "Multiple Linear Regression",
    "section": "4.1 Predict",
    "text": "4.1 Predict\nDevelop a model to predict future values of a response variable based on its relationship with other predictor variables.\nThe parameters in the model and their statistical significance are secondary importance. Focus is on producing a model that can predict future values well.\nWe should take care to be aware of and address overfitting a model in this case."
  },
  {
    "objectID": "notes/analytics/07062023/index.html#explain",
    "href": "notes/analytics/07062023/index.html#explain",
    "title": "Multiple Linear Regression",
    "section": "4.2 Explain",
    "text": "4.2 Explain\nTo develop an understanding of relationships between the response and predictor.\nThe statistical significance of coefficients as well as the magnitudes and signs of coefficients are important."
  },
  {
    "objectID": "notes/analytics/07062023/index.html#adjusted-coefficient-of-determination",
    "href": "notes/analytics/07062023/index.html#adjusted-coefficient-of-determination",
    "title": "Multiple Linear Regression",
    "section": "5.1 Adjusted Coefficient of Determination",
    "text": "5.1 Adjusted Coefficient of Determination\n\\(R_a^2\\) penalizes a model for adding variables that do not provide useful information.\n\\[\n\\begin{align*}\nR_a^2 &= 1 - [(\\frac{n - 1}{n - k - 1})(\\frac{SSE}{TSS})] \\\\\n&= 1 - [(1 - R^2)(\\frac{n - 1}{n - k - 1})]\n\\end{align*}\n\\]\n\n\\(R_a^2 \\leq R^2\\)\n\nAlthough better at determining utility of model, we lose the interpretation as the coefficient can be negative."
  },
  {
    "objectID": "notes/analytics/07062023/lab_6.html",
    "href": "notes/analytics/07062023/lab_6.html",
    "title": "Lab 6",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(AppliedPredictiveModeling)\ndata(FuelEconomy)\nglimpse(cars2010)\n\n\nRows: 1,107\nColumns: 14\n$ EngDispl            &lt;dbl&gt; 4.7, 4.7, 4.2, 4.2, 5.2, 5.2, 2.0, 6.0, 3.0, 3.0, …\n$ NumCyl              &lt;int&gt; 8, 8, 8, 8, 10, 10, 4, 12, 6, 6, 6, 6, 16, 8, 8, 8…\n$ Transmission        &lt;fct&gt; AM6, M6, M6, AM6, AM6, M6, S6, S6, S6, M6, S7, M6,…\n$ FE                  &lt;dbl&gt; 28.0198, 25.6094, 26.8000, 25.0451, 24.8000, 23.90…\n$ AirAspirationMethod &lt;fct&gt; NaturallyAspirated, NaturallyAspirated, NaturallyA…\n$ NumGears            &lt;int&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 6, 7, 6, 6, 6, 6,…\n$ TransLockup         &lt;dbl&gt; 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,…\n$ TransCreeperGear    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ DriveDesc           &lt;fct&gt; TwoWheelDriveRear, TwoWheelDriveRear, AllWheelDriv…\n$ IntakeValvePerCyl   &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1,…\n$ ExhaustValvesPerCyl &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1,…\n$ CarlineClassDesc    &lt;fct&gt; 2Seaters, 2Seaters, 2Seaters, 2Seaters, 2Seaters, …\n$ VarValveTiming      &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,…\n$ VarValveLift        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,…\n\n\n\n\n\n\nCode\ncars2010 &lt;- cars2010 %&gt;%\n    mutate(across(!c(EngDispl, FE), as.factor))\ncars_lm &lt;- lm(FE ~ ., data = cars2010)\nsummary(cars_lm)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars2010)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6399  -1.6583   0.0582   1.5708  21.6002 \n\nCoefficients: (5 not defined because of singularities)\n                                                 Estimate Std. Error t value\n(Intercept)                                      35.95655    3.34991  10.734\nEngDispl                                         -2.24571    0.26269  -8.549\nNumCyl3                                          15.88136    5.11001   3.108\nNumCyl4                                           7.76711    3.94430   1.969\nNumCyl5                                           4.89858    3.97620   1.232\nNumCyl6                                           4.19528    3.94208   1.064\nNumCyl8                                           2.51528    3.98438   0.631\nNumCyl10                                         -0.01541    4.13445  -0.004\nNumCyl12                                         -1.02329    4.11855  -0.248\nNumCyl16                                         -0.31250    5.42018  -0.058\nTransmissionA4                                   -6.93754    2.27354  -3.051\nTransmissionA5                                   -6.53146    2.27928  -2.866\nTransmissionA6                                   -4.88712    2.27829  -2.145\nTransmissionA7                                    5.70476    2.44239   2.336\nTransmissionAM6                                  -9.48575    2.46325  -3.851\nTransmissionAM7                                   0.59731    2.65233   0.225\nTransmissionAV                                   -4.40251    2.28451  -1.927\nTransmissionAVS6                                 -6.72835    2.41754  -2.783\nTransmissionM5                                   -7.00105    2.27746  -3.074\nTransmissionM6                                   -7.03693    2.26627  -3.105\nTransmissionS4                                  -10.42310    2.42863  -4.292\nTransmissionS5                                   -7.17879    2.30519  -3.114\nTransmissionS6                                   -5.09671    2.26315  -2.252\nTransmissionS7                                    4.08689    2.51141   1.627\nTransmissionS8                                   -4.61764    4.02547  -1.147\nAirAspirationMethodSupercharged                  -1.66003    0.78945  -2.103\nAirAspirationMethodTurbocharged                  -1.12911    0.32214  -3.505\nNumGears4                                              NA         NA      NA\nNumGears5                                              NA         NA      NA\nNumGears6                                              NA         NA      NA\nNumGears7                                       -10.74200    3.27897  -3.276\nNumGears8                                         1.78308    3.19710   0.558\nTransLockup1                                     -0.89442    0.35715  -2.504\nTransCreeperGear1                                -1.04006    0.49553  -2.099\nDriveDescFourWheelDrive                          -0.45145    0.43461  -1.039\nDriveDescParttimeFourWheelDrive                  -0.29399    1.06503  -0.276\nDriveDescTwoWheelDriveFront                       4.31845    0.37701  11.455\nDriveDescTwoWheelDriveRear                        1.19634    0.37255   3.211\nIntakeValvePerCyl1                                6.33644    3.32150   1.908\nIntakeValvePerCyl2                                4.88952    3.21060   1.523\nIntakeValvePerCyl3                                     NA         NA      NA\nExhaustValvesPerCyl1                              1.54229    0.75433   2.045\nExhaustValvesPerCyl2                                   NA         NA      NA\nCarlineClassDesc2Seaters                          2.85693    1.17833   2.425\nCarlineClassDescCompactCars                       3.78908    1.09963   3.446\nCarlineClassDescLargeCars                         2.56219    1.13079   2.266\nCarlineClassDescMidsizeCars                       3.39390    1.09686   3.094\nCarlineClassDescMinicompactCars                   3.63416    1.19375   3.044\nCarlineClassDescSmallPickupTrucks2WD             -1.85140    1.25181  -1.479\nCarlineClassDescSmallPickupTrucks4WD             -0.95072    1.35268  -0.703\nCarlineClassDescSmallStationWagons                2.20724    1.13608   1.943\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.07995    1.36307  -1.526\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.51997    1.10807  -1.372\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.56991    1.12243  -0.508\nCarlineClassDescStandardPickupTrucks2WD          -1.74467    1.27006  -1.374\nCarlineClassDescStandardPickupTrucks4WD          -1.94205    1.30286  -1.491\nCarlineClassDescSubcompactCars                    3.43057    1.11242   3.084\nCarlineClassDescVansCargoTypes                   -4.07446    1.51702  -2.686\nCarlineClassDescVansPassengerType                -4.27396    1.95092  -2.191\nVarValveTiming1                                   0.15943    0.29071   0.548\nVarValveLift1                                     0.82579    0.30704   2.690\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                         &lt; 2e-16 ***\nNumCyl3                                         0.001935 ** \nNumCyl4                                         0.049193 *  \nNumCyl5                                         0.218234    \nNumCyl6                                         0.287469    \nNumCyl8                                         0.527992    \nNumCyl10                                        0.997028    \nNumCyl12                                        0.803827    \nNumCyl16                                        0.954034    \nTransmissionA4                                  0.002335 ** \nTransmissionA5                                  0.004245 ** \nTransmissionA6                                  0.032175 *  \nTransmissionA7                                  0.019693 *  \nTransmissionAM6                                 0.000125 ***\nTransmissionAM7                                 0.821867    \nTransmissionAV                                  0.054234 .  \nTransmissionAVS6                                0.005480 ** \nTransmissionM5                                  0.002166 ** \nTransmissionM6                                  0.001953 ** \nTransmissionS4                                  1.94e-05 ***\nTransmissionS5                                  0.001894 ** \nTransmissionS6                                  0.024526 *  \nTransmissionS7                                  0.103967    \nTransmissionS8                                  0.251599    \nAirAspirationMethodSupercharged                 0.035723 *  \nAirAspirationMethodTurbocharged                 0.000476 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001087 ** \nNumGears8                                       0.577155    \nTransLockup1                                    0.012420 *  \nTransCreeperGear1                               0.036067 *  \nDriveDescFourWheelDrive                         0.299167    \nDriveDescParttimeFourWheelDrive                 0.782571    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.001362 ** \nIntakeValvePerCyl1                              0.056702 .  \nIntakeValvePerCyl2                              0.128077    \nIntakeValvePerCyl3                                    NA    \nExhaustValvesPerCyl1                            0.041146 *  \nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.015495 *  \nCarlineClassDescCompactCars                     0.000592 ***\nCarlineClassDescLargeCars                       0.023664 *  \nCarlineClassDescMidsizeCars                     0.002026 ** \nCarlineClassDescMinicompactCars                 0.002390 ** \nCarlineClassDescSmallPickupTrucks2WD            0.139447    \nCarlineClassDescSmallPickupTrucks4WD            0.482307    \nCarlineClassDescSmallStationWagons              0.052300 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.127330    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.170443    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.611738    \nCarlineClassDescStandardPickupTrucks2WD         0.169828    \nCarlineClassDescStandardPickupTrucks4WD         0.136365    \nCarlineClassDescSubcompactCars                  0.002097 ** \nCarlineClassDescVansCargoTypes                  0.007349 ** \nCarlineClassDescVansPassengerType               0.028690 *  \nVarValveTiming1                                 0.583517    \nVarValveLift1                                   0.007269 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.14 on 1051 degrees of freedom\nMultiple R-squared:  0.8333,    Adjusted R-squared:  0.8246 \nF-statistic: 95.55 on 55 and 1051 DF,  p-value: &lt; 2.2e-16\n\n\n\nThe F p-value is significant meaning that our overall model is significant in predicting FE\nThe 13 variables explain 83.33 percent of variation in fuel economy\n\n\n\n\n\n\nCode\ncar::Anova(cars_lm)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              720.6    1 73.0842 &lt; 2.2e-16 ***\nNumCyl                889.6    6 15.0374 &lt; 2.2e-16 ***\nTransmission          707.7   12  5.9813 3.553e-10 ***\nAirAspirationMethod   151.2    2  7.6686 0.0004939 ***\nNumGears              109.2    2  5.5361 0.0040576 ** \nTransLockup            61.8    1  6.2715 0.0124202 *  \nTransCreeperGear       43.4    1  4.4052 0.0360667 *  \nDriveDesc            1535.0    4 38.9205 &lt; 2.2e-16 ***\nIntakeValvePerCyl      56.6    2  2.8720 0.0570315 .  \nExhaustValvesPerCyl    41.2    1  4.1803 0.0411460 *  \nCarlineClassDesc     3495.4   16 22.1561 &lt; 2.2e-16 ***\nVarValveTiming          3.0    1  0.3008 0.5835171    \nVarValveLift           71.3    1  7.2336 0.0072685 ** \nResiduals           10363.0 1051                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nHighest p-value is VarValveTiming with 0.584\n\n\n\n\n\n\nCode\ncars_2010_sub &lt;- cars2010 %&gt;%\n    select(-VarValveTiming)\n\ncars_lm2 &lt;- lm(FE ~ ., cars_2010_sub)\nsummary(cars_lm2)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars_2010_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6242  -1.6504   0.0541   1.5540  21.5852 \n\nCoefficients: (5 not defined because of singularities)\n                                                 Estimate Std. Error t value\n(Intercept)                                      35.99395    3.34810  10.751\nEngDispl                                         -2.26003    0.26130  -8.649\nNumCyl3                                          16.00965    5.10296   3.137\nNumCyl4                                           7.91363    3.93394   2.012\nNumCyl5                                           5.03429    3.96717   1.269\nNumCyl6                                           4.35537    3.92996   1.108\nNumCyl8                                           2.71420    3.96652   0.684\nNumCyl10                                          0.18914    4.11622   0.046\nNumCyl12                                         -0.81976    4.10043  -0.200\nNumCyl16                                         -0.08503    5.40249  -0.016\nTransmissionA4                                   -6.98768    2.27095  -3.077\nTransmissionA5                                   -6.53850    2.27848  -2.870\nTransmissionA6                                   -4.90059    2.27740  -2.152\nTransmissionA7                                    5.71566    2.44150   2.341\nTransmissionAM6                                  -9.49295    2.46240  -3.855\nTransmissionAM7                                   0.59242    2.65143   0.223\nTransmissionAV                                   -4.40233    2.28375  -1.928\nTransmissionAVS6                                 -6.72853    2.41673  -2.784\nTransmissionM5                                   -7.01977    2.27644  -3.084\nTransmissionM6                                   -7.04911    2.26540  -3.112\nTransmissionS4                                  -10.51052    2.42259  -4.339\nTransmissionS5                                   -7.20354    2.30398  -3.127\nTransmissionS6                                   -5.10605    2.26234  -2.257\nTransmissionS7                                    4.09144    2.51056   1.630\nTransmissionS8                                   -4.62893    4.02408  -1.150\nAirAspirationMethodSupercharged                  -1.67713    0.78857  -2.127\nAirAspirationMethodTurbocharged                  -1.13613    0.32177  -3.531\nNumGears4                                              NA         NA      NA\nNumGears5                                              NA         NA      NA\nNumGears6                                              NA         NA      NA\nNumGears7                                       -10.74376    3.27788  -3.278\nNumGears8                                         1.79152    3.19600   0.561\nTransLockup1                                     -0.89373    0.35703  -2.503\nTransCreeperGear1                                -1.09666    0.48450  -2.263\nDriveDescFourWheelDrive                          -0.44026    0.43399  -1.014\nDriveDescParttimeFourWheelDrive                  -0.25475    1.06227  -0.240\nDriveDescTwoWheelDriveFront                       4.32752    0.37652  11.494\nDriveDescTwoWheelDriveRear                        1.19041    0.37227   3.198\nIntakeValvePerCyl1                                6.36976    3.31984   1.919\nIntakeValvePerCyl2                                4.90088    3.20946   1.527\nIntakeValvePerCyl3                                     NA         NA      NA\nExhaustValvesPerCyl1                              1.49669    0.74949   1.997\nExhaustValvesPerCyl2                                   NA         NA      NA\nCarlineClassDesc2Seaters                          2.85888    1.17793   2.427\nCarlineClassDescCompactCars                       3.77775    1.09907   3.437\nCarlineClassDescLargeCars                         2.55092    1.13023   2.257\nCarlineClassDescMidsizeCars                       3.38958    1.09647   3.091\nCarlineClassDescMinicompactCars                   3.62150    1.19313   3.035\nCarlineClassDescSmallPickupTrucks2WD             -1.88501    1.24990  -1.508\nCarlineClassDescSmallPickupTrucks4WD             -0.99946    1.34930  -0.741\nCarlineClassDescSmallStationWagons                2.19864    1.13559   1.936\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.14681    1.35716  -1.582\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.52376    1.10769  -1.376\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.58904    1.12151  -0.525\nCarlineClassDescStandardPickupTrucks2WD          -1.76375    1.26916  -1.390\nCarlineClassDescStandardPickupTrucks4WD          -1.97791    1.30079  -1.521\nCarlineClassDescSubcompactCars                    3.42813    1.11204   3.083\nCarlineClassDescVansCargoTypes                   -4.03720    1.51499  -2.665\nCarlineClassDescVansPassengerType                -4.21030    1.94682  -2.163\nVarValveLift1                                     0.82139    0.30683   2.677\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                         &lt; 2e-16 ***\nNumCyl3                                         0.001752 ** \nNumCyl4                                         0.044513 *  \nNumCyl5                                         0.204726    \nNumCyl6                                         0.268007    \nNumCyl8                                         0.493951    \nNumCyl10                                        0.963360    \nNumCyl12                                        0.841581    \nNumCyl16                                        0.987446    \nTransmissionA4                                  0.002145 ** \nTransmissionA5                                  0.004191 ** \nTransmissionA6                                  0.031638 *  \nTransmissionA7                                  0.019416 *  \nTransmissionAM6                                 0.000123 ***\nTransmissionAM7                                 0.823240    \nTransmissionAV                                  0.054164 .  \nTransmissionAVS6                                0.005463 ** \nTransmissionM5                                  0.002098 ** \nTransmissionM6                                  0.001911 ** \nTransmissionS4                                  1.57e-05 ***\nTransmissionS5                                  0.001817 ** \nTransmissionS6                                  0.024214 *  \nTransmissionS7                                  0.103466    \nTransmissionS8                                  0.250279    \nAirAspirationMethodSupercharged                 0.033668 *  \nAirAspirationMethodTurbocharged                 0.000432 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001081 ** \nNumGears8                                       0.575223    \nTransLockup1                                    0.012458 *  \nTransCreeperGear1                               0.023808 *  \nDriveDescFourWheelDrive                         0.310604    \nDriveDescParttimeFourWheelDrive                 0.810521    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.001427 ** \nIntakeValvePerCyl1                              0.055293 .  \nIntakeValvePerCyl2                              0.127060    \nIntakeValvePerCyl3                                    NA    \nExhaustValvesPerCyl1                            0.046088 *  \nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.015390 *  \nCarlineClassDescCompactCars                     0.000611 ***\nCarlineClassDescLargeCars                       0.024213 *  \nCarlineClassDescMidsizeCars                     0.002045 ** \nCarlineClassDescMinicompactCars                 0.002462 ** \nCarlineClassDescSmallPickupTrucks2WD            0.131822    \nCarlineClassDescSmallPickupTrucks4WD            0.459026    \nCarlineClassDescSmallStationWagons              0.053120 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.113986    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.169229    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.599543    \nCarlineClassDescStandardPickupTrucks2WD         0.164913    \nCarlineClassDescStandardPickupTrucks4WD         0.128675    \nCarlineClassDescSubcompactCars                  0.002105 ** \nCarlineClassDescVansCargoTypes                  0.007821 ** \nCarlineClassDescVansPassengerType               0.030792 *  \nVarValveLift1                                   0.007544 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.139 on 1052 degrees of freedom\nMultiple R-squared:  0.8333,    Adjusted R-squared:  0.8247 \nF-statistic: 97.38 on 54 and 1052 DF,  p-value: &lt; 2.2e-16\n\n\nCode\ncar::Anova(cars_lm2)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              737.1    1 74.8066 &lt; 2.2e-16 ***\nNumCyl                887.9    6 15.0181 &lt; 2.2e-16 ***\nTransmission          712.6   12  6.0266 2.849e-10 ***\nAirAspirationMethod   153.8    2  7.8053 0.0004316 ***\nNumGears              109.2    2  5.5431 0.0040294 ** \nTransLockup            61.7    1  6.2661 0.0124578 *  \nTransCreeperGear       50.5    1  5.1234 0.0238082 *  \nDriveDesc            1545.6    4 39.2146 &lt; 2.2e-16 ***\nIntakeValvePerCyl      57.9    2  2.9386 0.0533736 .  \nExhaustValvesPerCyl    39.3    1  3.9878 0.0460877 *  \nCarlineClassDesc     3504.2   16 22.2267 &lt; 2.2e-16 ***\nVarValveLift           70.6    1  7.1663 0.0075441 ** \nResiduals           10366.0 1052                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nThe p-value for the model did not change significantly\n\\(R^2\\) did not change significantly and \\(R_a^2\\) increased a little\n\n\n\n\n\nDropping IntakeValvePerCyl:\n\n\nCode\ncars_2010_sub &lt;- cars_2010_sub %&gt;%\n    select(-IntakeValvePerCyl)\n\ncars_lm3 &lt;- lm(FE ~ ., cars_2010_sub)\nsummary(cars_lm3)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars_2010_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.5964  -1.7032   0.0413   1.5730  21.6235 \n\nCoefficients: (4 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                      36.0050     3.3542  10.734\nEngDispl                                         -2.1120     0.2530  -8.346\nNumCyl3                                          20.9056     3.9117   5.344\nNumCyl4                                          12.6843     2.2897   5.540\nNumCyl5                                           9.6779     2.3617   4.098\nNumCyl6                                           9.0036     2.3148   3.889\nNumCyl8                                           7.0608     2.4285   2.908\nNumCyl10                                          4.4870     2.6277   1.708\nNumCyl12                                          3.0682     2.6138   1.174\nNumCyl16                                          3.8516     4.3735   0.881\nTransmissionA4                                   -7.1007     2.2745  -3.122\nTransmissionA5                                   -6.7679     2.2799  -2.968\nTransmissionA6                                   -5.2017     2.2777  -2.284\nTransmissionA7                                    5.3619     2.4409   2.197\nTransmissionAM6                                  -9.5275     2.4663  -3.863\nTransmissionAM7                                   0.5339     2.6561   0.201\nTransmissionAV                                   -4.5677     2.2867  -1.998\nTransmissionAVS6                                 -6.9582     2.4186  -2.877\nTransmissionM5                                   -7.2063     2.2788  -3.162\nTransmissionM6                                   -7.1857     2.2683  -3.168\nTransmissionS4                                  -10.7361     2.4247  -4.428\nTransmissionS5                                   -7.3945     2.3063  -3.206\nTransmissionS6                                   -5.2347     2.2655  -2.311\nTransmissionS7                                    3.8448     2.5130   1.530\nTransmissionS8                                   -4.6021     4.0315  -1.142\nAirAspirationMethodSupercharged                  -1.8711     0.7825  -2.391\nAirAspirationMethodTurbocharged                  -1.1602     0.3221  -3.602\nNumGears4                                             NA         NA      NA\nNumGears5                                             NA         NA      NA\nNumGears6                                             NA         NA      NA\nNumGears7                                       -10.6135     3.2834  -3.233\nNumGears8                                         1.7231     3.2016   0.538\nTransLockup1                                     -0.9069     0.3576  -2.536\nTransCreeperGear1                                -1.2475     0.4777  -2.612\nDriveDescFourWheelDrive                          -0.4799     0.4345  -1.105\nDriveDescParttimeFourWheelDrive                  -0.3666     1.0628  -0.345\nDriveDescTwoWheelDriveFront                       4.3236     0.3772  11.462\nDriveDescTwoWheelDriveRear                        1.1403     0.3722   3.063\nExhaustValvesPerCyl1                              2.7454     0.3965   6.925\nExhaustValvesPerCyl2                                  NA         NA      NA\nCarlineClassDesc2Seaters                          2.7680     1.1781   2.350\nCarlineClassDescCompactCars                       3.7770     1.1011   3.430\nCarlineClassDescLargeCars                         2.5646     1.1323   2.265\nCarlineClassDescMidsizeCars                       3.3732     1.0985   3.071\nCarlineClassDescMinicompactCars                   3.6283     1.1952   3.036\nCarlineClassDescSmallPickupTrucks2WD             -1.9032     1.2522  -1.520\nCarlineClassDescSmallPickupTrucks4WD             -1.0239     1.3517  -0.757\nCarlineClassDescSmallStationWagons                2.1934     1.1377   1.928\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.1150     1.3596  -1.556\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.5296     1.1097  -1.378\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.5922     1.1235  -0.527\nCarlineClassDescStandardPickupTrucks2WD          -1.7232     1.2714  -1.355\nCarlineClassDescStandardPickupTrucks4WD          -1.9711     1.3031  -1.513\nCarlineClassDescSubcompactCars                    3.4139     1.1141   3.064\nCarlineClassDescVansCargoTypes                   -3.9331     1.5169  -2.593\nCarlineClassDescVansPassengerType                -4.0805     1.9494  -2.093\nVarValveLift1                                     0.8053     0.3070   2.623\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                         &lt; 2e-16 ***\nNumCyl3                                         1.11e-07 ***\nNumCyl4                                         3.83e-08 ***\nNumCyl5                                         4.49e-05 ***\nNumCyl6                                         0.000107 ***\nNumCyl8                                         0.003719 ** \nNumCyl10                                        0.088005 .  \nNumCyl12                                        0.240713    \nNumCyl16                                        0.378695    \nTransmissionA4                                  0.001846 ** \nTransmissionA5                                  0.003061 ** \nTransmissionA6                                  0.022584 *  \nTransmissionA7                                  0.028260 *  \nTransmissionAM6                                 0.000119 ***\nTransmissionAM7                                 0.840740    \nTransmissionAV                                  0.046025 *  \nTransmissionAVS6                                0.004096 ** \nTransmissionM5                                  0.001610 ** \nTransmissionM6                                  0.001580 ** \nTransmissionS4                                  1.05e-05 ***\nTransmissionS5                                  0.001385 ** \nTransmissionS6                                  0.021044 *  \nTransmissionS7                                  0.126328    \nTransmissionS8                                  0.253901    \nAirAspirationMethodSupercharged                 0.016962 *  \nAirAspirationMethodTurbocharged                 0.000331 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001265 ** \nNumGears8                                       0.590565    \nTransLockup1                                    0.011365 *  \nTransCreeperGear1                               0.009142 ** \nDriveDescFourWheelDrive                         0.269550    \nDriveDescParttimeFourWheelDrive                 0.730220    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.002245 ** \nExhaustValvesPerCyl1                            7.58e-12 ***\nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.018981 *  \nCarlineClassDescCompactCars                     0.000626 ***\nCarlineClassDescLargeCars                       0.023715 *  \nCarlineClassDescMidsizeCars                     0.002189 ** \nCarlineClassDescMinicompactCars                 0.002458 ** \nCarlineClassDescSmallPickupTrucks2WD            0.128836    \nCarlineClassDescSmallPickupTrucks4WD            0.448949    \nCarlineClassDescSmallStationWagons              0.054126 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.120096    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.168369    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.598240    \nCarlineClassDescStandardPickupTrucks2WD         0.175593    \nCarlineClassDescStandardPickupTrucks4WD         0.130664    \nCarlineClassDescSubcompactCars                  0.002237 ** \nCarlineClassDescVansCargoTypes                  0.009648 ** \nCarlineClassDescVansPassengerType               0.036568 *  \nVarValveLift1                                   0.008839 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.145 on 1054 degrees of freedom\nMultiple R-squared:  0.8324,    Adjusted R-squared:  0.8241 \nF-statistic: 100.6 on 52 and 1054 DF,  p-value: &lt; 2.2e-16\n\n\nCode\ncar::Anova(cars_lm3)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              688.9    1 69.6604 &lt; 2.2e-16 ***\nNumCyl               1000.0    6 16.8523 &lt; 2.2e-16 ***\nTransmission          699.4   12  5.8935 5.430e-10 ***\nAirAspirationMethod   169.7    2  8.5817 0.0002009 ***\nNumGears              106.5    2  5.3833 0.0047196 ** \nTransLockup            63.6    1  6.4299 0.0113653 *  \nTransCreeperGear       67.4    1  6.8201 0.0091419 ** \nDriveDesc            1559.4    4 39.4183 &lt; 2.2e-16 ***\nExhaustValvesPerCyl   474.2    1 47.9516 7.583e-12 ***\nCarlineClassDesc     3489.4   16 22.0517 &lt; 2.2e-16 ***\nVarValveLift           68.0    1  6.8807 0.0088387 ** \nResiduals           10423.9 1054                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCode\ncars_2010_sub &lt;- cars_2010_sub %&gt;%\n    select(-TransLockup)\n\ncars_lm4 &lt;- lm(FE ~ ., cars_2010_sub)\nsummary(cars_lm4)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars_2010_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6831  -1.7755   0.0193   1.5767  22.1002 \n\nCoefficients: (4 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                      35.5540     3.3581  10.588\nEngDispl                                         -2.0676     0.2531  -8.170\nNumCyl3                                          20.3570     3.9157   5.199\nNumCyl4                                          12.6350     2.2955   5.504\nNumCyl5                                           9.6799     2.3677   4.088\nNumCyl6                                           8.8784     2.3203   3.826\nNumCyl8                                           6.8252     2.4329   2.805\nNumCyl10                                          4.2129     2.6322   1.601\nNumCyl12                                          2.7488     2.6175   1.050\nNumCyl16                                          4.1444     4.3832   0.946\nTransmissionA4                                   -7.5779     2.2725  -3.335\nTransmissionA5                                   -7.2188     2.2788  -3.168\nTransmissionA6                                   -5.5830     2.2785  -2.450\nTransmissionA7                                    4.7030     2.4333   1.933\nTransmissionAM6                                  -9.6845     2.4718  -3.918\nTransmissionAM7                                   0.5441     2.6629   0.204\nTransmissionAV                                   -4.5705     2.2925  -1.994\nTransmissionAVS6                                 -6.8711     2.4245  -2.834\nTransmissionM5                                   -6.7947     2.2788  -2.982\nTransmissionM6                                   -6.8804     2.2710  -3.030\nTransmissionS4                                  -11.2457     2.4226  -4.642\nTransmissionS5                                   -7.8915     2.3038  -3.425\nTransmissionS6                                   -5.5467     2.2680  -2.446\nTransmissionS7                                    3.1101     2.5027   1.243\nTransmissionS8                                   -5.4739     4.0271  -1.359\nAirAspirationMethodSupercharged                  -1.7876     0.7838  -2.281\nAirAspirationMethodTurbocharged                  -1.1043     0.3222  -3.427\nNumGears4                                             NA         NA      NA\nNumGears5                                             NA         NA      NA\nNumGears6                                             NA         NA      NA\nNumGears7                                       -10.2165     3.2880  -3.107\nNumGears8                                         2.2205     3.2038   0.693\nTransCreeperGear1                                -1.2791     0.4788  -2.672\nDriveDescFourWheelDrive                          -0.4976     0.4355  -1.143\nDriveDescParttimeFourWheelDrive                  -0.4061     1.0655  -0.381\nDriveDescTwoWheelDriveFront                       4.3413     0.3781  11.482\nDriveDescTwoWheelDriveRear                        1.1035     0.3729   2.959\nExhaustValvesPerCyl1                              2.7948     0.3970   7.040\nExhaustValvesPerCyl2                                  NA         NA      NA\nCarlineClassDesc2Seaters                          2.8530     1.1807   2.416\nCarlineClassDescCompactCars                       3.7853     1.1039   3.429\nCarlineClassDescLargeCars                         2.5289     1.1351   2.228\nCarlineClassDescMidsizeCars                       3.3020     1.1009   2.999\nCarlineClassDescMinicompactCars                   3.7542     1.1972   3.136\nCarlineClassDescSmallPickupTrucks2WD             -1.9188     1.2554  -1.528\nCarlineClassDescSmallPickupTrucks4WD             -1.0621     1.3551  -0.784\nCarlineClassDescSmallStationWagons                2.1620     1.1405   1.896\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.2133     1.3625  -1.624\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.5927     1.1122  -1.432\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.6482     1.1262  -0.576\nCarlineClassDescStandardPickupTrucks2WD          -1.7299     1.2746  -1.357\nCarlineClassDescStandardPickupTrucks4WD          -2.0053     1.3064  -1.535\nCarlineClassDescSubcompactCars                    3.3939     1.1169   3.039\nCarlineClassDescVansCargoTypes                   -3.9518     1.5207  -2.599\nCarlineClassDescVansPassengerType                -4.0897     1.9544  -2.093\nVarValveLift1                                     0.8016     0.3078   2.604\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                        8.79e-16 ***\nNumCyl3                                         2.41e-07 ***\nNumCyl4                                         4.66e-08 ***\nNumCyl5                                         4.68e-05 ***\nNumCyl6                                         0.000138 ***\nNumCyl8                                         0.005119 ** \nNumCyl10                                        0.109781    \nNumCyl12                                        0.293871    \nNumCyl16                                        0.344606    \nTransmissionA4                                  0.000884 ***\nTransmissionA5                                  0.001580 ** \nTransmissionA6                                  0.014438 *  \nTransmissionA7                                  0.053532 .  \nTransmissionAM6                                 9.50e-05 ***\nTransmissionAM7                                 0.838126    \nTransmissionAV                                  0.046450 *  \nTransmissionAVS6                                0.004685 ** \nTransmissionM5                                  0.002933 ** \nTransmissionM6                                  0.002507 ** \nTransmissionS4                                  3.88e-06 ***\nTransmissionS5                                  0.000638 ***\nTransmissionS6                                  0.014620 *  \nTransmissionS7                                  0.214253    \nTransmissionS8                                  0.174354    \nAirAspirationMethodSupercharged                 0.022764 *  \nAirAspirationMethodTurbocharged                 0.000633 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001939 ** \nNumGears8                                       0.488417    \nTransCreeperGear1                               0.007665 ** \nDriveDescFourWheelDrive                         0.253447    \nDriveDescParttimeFourWheelDrive                 0.703142    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.003153 ** \nExhaustValvesPerCyl1                            3.46e-12 ***\nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.015841 *  \nCarlineClassDescCompactCars                     0.000629 ***\nCarlineClassDescLargeCars                       0.026094 *  \nCarlineClassDescMidsizeCars                     0.002770 ** \nCarlineClassDescMinicompactCars                 0.001761 ** \nCarlineClassDescSmallPickupTrucks2WD            0.126696    \nCarlineClassDescSmallPickupTrucks4WD            0.433337    \nCarlineClassDescSmallStationWagons              0.058280 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.104587    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.152446    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.565022    \nCarlineClassDescStandardPickupTrucks2WD         0.175017    \nCarlineClassDescStandardPickupTrucks4WD         0.125076    \nCarlineClassDescSubcompactCars                  0.002435 ** \nCarlineClassDescVansCargoTypes                  0.009490 ** \nCarlineClassDescVansPassengerType               0.036625 *  \nVarValveLift1                                   0.009338 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.153 on 1055 degrees of freedom\nMultiple R-squared:  0.8313,    Adjusted R-squared:  0.8232 \nF-statistic:   102 on 51 and 1055 DF,  p-value: &lt; 2.2e-16\n\n\nCode\ncar::Anova(cars_lm4)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              663.5    1 66.7421 8.786e-16 ***\nNumCyl               1037.6    6 17.3966 &lt; 2.2e-16 ***\nTransmission          638.4   12  5.3520 7.426e-09 ***\nAirAspirationMethod   155.0    2  7.7971  0.000435 ***\nNumGears              101.0    2  5.0780  0.006385 ** \nTransCreeperGear       71.0    1  7.1376  0.007665 ** \nDriveDesc            1586.1    4 39.8882 &lt; 2.2e-16 ***\nExhaustValvesPerCyl   492.7    1 49.5606 3.460e-12 ***\nCarlineClassDesc     3548.8   16 22.3123 &lt; 2.2e-16 ***\nVarValveLift           67.4    1  6.7819  0.009338 ** \nResiduals           10487.5 1055                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCode\ncars_2010_sub &lt;- cars_2010_sub %&gt;%\n    select(-VarValveLift)\n\ncars_lm5 &lt;- lm(FE ~ ., cars_2010_sub)\nsummary(cars_lm5)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars_2010_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.7951  -1.7259   0.0248   1.6395  22.0010 \n\nCoefficients: (4 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                      35.6506     3.3670  10.588\nEngDispl                                         -2.0915     0.2536  -8.247\nNumCyl3                                          20.1462     3.9256   5.132\nNumCyl4                                          12.9901     2.2977   5.653\nNumCyl5                                           9.9691     2.3716   4.204\nNumCyl6                                           9.2880     2.3213   4.001\nNumCyl8                                           7.1931     2.4355   2.953\nNumCyl10                                          4.2902     2.6392   1.626\nNumCyl12                                          2.9960     2.6229   1.142\nNumCyl16                                          4.2509     4.3950   0.967\nTransmissionA4                                   -7.9263     2.2748  -3.484\nTransmissionA5                                   -7.4632     2.2831  -3.269\nTransmissionA6                                   -5.9012     2.2815  -2.587\nTransmissionA7                                    4.9316     2.4383   2.023\nTransmissionAM6                                 -10.0571     2.4744  -4.064\nTransmissionAM7                                   0.4535     2.6700   0.170\nTransmissionAV                                   -4.8272     2.2967  -2.102\nTransmissionAVS6                                 -7.2674     2.4264  -2.995\nTransmissionM5                                   -7.0899     2.2822  -3.107\nTransmissionM6                                   -7.0372     2.2764  -3.091\nTransmissionS4                                  -11.2013     2.4291  -4.611\nTransmissionS5                                   -8.0730     2.3091  -3.496\nTransmissionS6                                   -5.7943     2.2722  -2.550\nTransmissionS7                                    3.4280     2.5065   1.368\nTransmissionS8                                   -5.5848     4.0379  -1.383\nAirAspirationMethodSupercharged                  -1.9893     0.7821  -2.544\nAirAspirationMethodTurbocharged                  -1.2457     0.3184  -3.912\nNumGears4                                             NA         NA      NA\nNumGears5                                             NA         NA      NA\nNumGears6                                             NA         NA      NA\nNumGears7                                       -10.6500     3.2928  -3.234\nNumGears8                                         2.0751     3.2121   0.646\nTransCreeperGear1                                -1.3661     0.4789  -2.852\nDriveDescFourWheelDrive                          -0.6841     0.4308  -1.588\nDriveDescParttimeFourWheelDrive                  -0.7039     1.0622  -0.663\nDriveDescTwoWheelDriveFront                       4.1905     0.3747  11.185\nDriveDescTwoWheelDriveRear                        0.9965     0.3717   2.681\nExhaustValvesPerCyl1                              2.7810     0.3980   6.986\nExhaustValvesPerCyl2                                  NA         NA      NA\nCarlineClassDesc2Seaters                          3.0982     1.1801   2.625\nCarlineClassDescCompactCars                       3.8878     1.1062   3.515\nCarlineClassDescLargeCars                         2.6874     1.1366   2.364\nCarlineClassDescMidsizeCars                       3.4001     1.1033   3.082\nCarlineClassDescMinicompactCars                   4.3247     1.1802   3.664\nCarlineClassDescSmallPickupTrucks2WD             -1.8684     1.2587  -1.484\nCarlineClassDescSmallPickupTrucks4WD             -0.9067     1.3575  -0.668\nCarlineClassDescSmallStationWagons                2.2224     1.1434   1.944\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.1858     1.3662  -1.600\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.5070     1.1148  -1.352\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.4822     1.1274  -0.428\nCarlineClassDescStandardPickupTrucks2WD          -1.6614     1.2778  -1.300\nCarlineClassDescStandardPickupTrucks4WD          -1.8270     1.3081  -1.397\nCarlineClassDescSubcompactCars                    3.6375     1.1160   3.259\nCarlineClassDescVansCargoTypes                   -3.8763     1.5246  -2.542\nCarlineClassDescVansPassengerType                -4.0117     1.9595  -2.047\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                        4.79e-16 ***\nNumCyl3                                         3.41e-07 ***\nNumCyl4                                         2.02e-08 ***\nNumCyl5                                         2.85e-05 ***\nNumCyl6                                         6.74e-05 ***\nNumCyl8                                         0.003212 ** \nNumCyl10                                        0.104342    \nNumCyl12                                        0.253614    \nNumCyl16                                        0.333656    \nTransmissionA4                                  0.000513 ***\nTransmissionA5                                  0.001115 ** \nTransmissionA6                                  0.009827 ** \nTransmissionA7                                  0.043374 *  \nTransmissionAM6                                 5.17e-05 ***\nTransmissionAM7                                 0.865169    \nTransmissionAV                                  0.035807 *  \nTransmissionAVS6                                0.002807 ** \nTransmissionM5                                  0.001944 ** \nTransmissionM6                                  0.002044 ** \nTransmissionS4                                  4.49e-06 ***\nTransmissionS5                                  0.000492 ***\nTransmissionS6                                  0.010908 *  \nTransmissionS7                                  0.171715    \nTransmissionS8                                  0.166927    \nAirAspirationMethodSupercharged                 0.011113 *  \nAirAspirationMethodTurbocharged                 9.74e-05 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001257 ** \nNumGears8                                       0.518403    \nTransCreeperGear1                               0.004423 ** \nDriveDescFourWheelDrive                         0.112532    \nDriveDescParttimeFourWheelDrive                 0.507654    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.007448 ** \nExhaustValvesPerCyl1                            4.98e-12 ***\nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.008782 ** \nCarlineClassDescCompactCars                     0.000459 ***\nCarlineClassDescLargeCars                       0.018235 *  \nCarlineClassDescMidsizeCars                     0.002111 ** \nCarlineClassDescMinicompactCars                 0.000260 ***\nCarlineClassDescSmallPickupTrucks2WD            0.137996    \nCarlineClassDescSmallPickupTrucks4WD            0.504354    \nCarlineClassDescSmallStationWagons              0.052206 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.109914    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.176714    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.668970    \nCarlineClassDescStandardPickupTrucks2WD         0.193828    \nCarlineClassDescStandardPickupTrucks4WD         0.162813    \nCarlineClassDescSubcompactCars                  0.001152 ** \nCarlineClassDescVansCargoTypes                  0.011149 *  \nCarlineClassDescVansPassengerType               0.040873 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.162 on 1056 degrees of freedom\nMultiple R-squared:  0.8303,    Adjusted R-squared:  0.8222 \nF-statistic: 103.3 on 50 and 1056 DF,  p-value: &lt; 2.2e-16\n\n\nCode\ncar::Anova(cars_lm5)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              679.8    1 68.0122 4.791e-16 ***\nNumCyl               1043.7    6 17.4026 &lt; 2.2e-16 ***\nTransmission          613.6   12  5.1154 2.307e-08 ***\nAirAspirationMethod   202.9    2 10.1494 4.305e-05 ***\nNumGears              108.9    2  5.4475  0.004429 ** \nTransCreeperGear       81.3    1  8.1365  0.004423 ** \nDriveDesc            1537.5    4 38.4558 &lt; 2.2e-16 ***\nExhaustValvesPerCyl   487.9    1 48.8110 4.982e-12 ***\nCarlineClassDesc     3715.0   16 23.2300 &lt; 2.2e-16 ***\nResiduals           10554.9 1056                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nBoth \\(R^2\\) and \\(R_a^2\\) decreased\n9 variables significant at the 0.008 level"
  },
  {
    "objectID": "notes/analytics/07062023/lab_6.html#a",
    "href": "notes/analytics/07062023/lab_6.html#a",
    "title": "Lab 6",
    "section": "",
    "text": "Code\ncars2010 &lt;- cars2010 %&gt;%\n    mutate(across(!c(EngDispl, FE), as.factor))\ncars_lm &lt;- lm(FE ~ ., data = cars2010)\nsummary(cars_lm)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars2010)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6399  -1.6583   0.0582   1.5708  21.6002 \n\nCoefficients: (5 not defined because of singularities)\n                                                 Estimate Std. Error t value\n(Intercept)                                      35.95655    3.34991  10.734\nEngDispl                                         -2.24571    0.26269  -8.549\nNumCyl3                                          15.88136    5.11001   3.108\nNumCyl4                                           7.76711    3.94430   1.969\nNumCyl5                                           4.89858    3.97620   1.232\nNumCyl6                                           4.19528    3.94208   1.064\nNumCyl8                                           2.51528    3.98438   0.631\nNumCyl10                                         -0.01541    4.13445  -0.004\nNumCyl12                                         -1.02329    4.11855  -0.248\nNumCyl16                                         -0.31250    5.42018  -0.058\nTransmissionA4                                   -6.93754    2.27354  -3.051\nTransmissionA5                                   -6.53146    2.27928  -2.866\nTransmissionA6                                   -4.88712    2.27829  -2.145\nTransmissionA7                                    5.70476    2.44239   2.336\nTransmissionAM6                                  -9.48575    2.46325  -3.851\nTransmissionAM7                                   0.59731    2.65233   0.225\nTransmissionAV                                   -4.40251    2.28451  -1.927\nTransmissionAVS6                                 -6.72835    2.41754  -2.783\nTransmissionM5                                   -7.00105    2.27746  -3.074\nTransmissionM6                                   -7.03693    2.26627  -3.105\nTransmissionS4                                  -10.42310    2.42863  -4.292\nTransmissionS5                                   -7.17879    2.30519  -3.114\nTransmissionS6                                   -5.09671    2.26315  -2.252\nTransmissionS7                                    4.08689    2.51141   1.627\nTransmissionS8                                   -4.61764    4.02547  -1.147\nAirAspirationMethodSupercharged                  -1.66003    0.78945  -2.103\nAirAspirationMethodTurbocharged                  -1.12911    0.32214  -3.505\nNumGears4                                              NA         NA      NA\nNumGears5                                              NA         NA      NA\nNumGears6                                              NA         NA      NA\nNumGears7                                       -10.74200    3.27897  -3.276\nNumGears8                                         1.78308    3.19710   0.558\nTransLockup1                                     -0.89442    0.35715  -2.504\nTransCreeperGear1                                -1.04006    0.49553  -2.099\nDriveDescFourWheelDrive                          -0.45145    0.43461  -1.039\nDriveDescParttimeFourWheelDrive                  -0.29399    1.06503  -0.276\nDriveDescTwoWheelDriveFront                       4.31845    0.37701  11.455\nDriveDescTwoWheelDriveRear                        1.19634    0.37255   3.211\nIntakeValvePerCyl1                                6.33644    3.32150   1.908\nIntakeValvePerCyl2                                4.88952    3.21060   1.523\nIntakeValvePerCyl3                                     NA         NA      NA\nExhaustValvesPerCyl1                              1.54229    0.75433   2.045\nExhaustValvesPerCyl2                                   NA         NA      NA\nCarlineClassDesc2Seaters                          2.85693    1.17833   2.425\nCarlineClassDescCompactCars                       3.78908    1.09963   3.446\nCarlineClassDescLargeCars                         2.56219    1.13079   2.266\nCarlineClassDescMidsizeCars                       3.39390    1.09686   3.094\nCarlineClassDescMinicompactCars                   3.63416    1.19375   3.044\nCarlineClassDescSmallPickupTrucks2WD             -1.85140    1.25181  -1.479\nCarlineClassDescSmallPickupTrucks4WD             -0.95072    1.35268  -0.703\nCarlineClassDescSmallStationWagons                2.20724    1.13608   1.943\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.07995    1.36307  -1.526\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.51997    1.10807  -1.372\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.56991    1.12243  -0.508\nCarlineClassDescStandardPickupTrucks2WD          -1.74467    1.27006  -1.374\nCarlineClassDescStandardPickupTrucks4WD          -1.94205    1.30286  -1.491\nCarlineClassDescSubcompactCars                    3.43057    1.11242   3.084\nCarlineClassDescVansCargoTypes                   -4.07446    1.51702  -2.686\nCarlineClassDescVansPassengerType                -4.27396    1.95092  -2.191\nVarValveTiming1                                   0.15943    0.29071   0.548\nVarValveLift1                                     0.82579    0.30704   2.690\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                         &lt; 2e-16 ***\nNumCyl3                                         0.001935 ** \nNumCyl4                                         0.049193 *  \nNumCyl5                                         0.218234    \nNumCyl6                                         0.287469    \nNumCyl8                                         0.527992    \nNumCyl10                                        0.997028    \nNumCyl12                                        0.803827    \nNumCyl16                                        0.954034    \nTransmissionA4                                  0.002335 ** \nTransmissionA5                                  0.004245 ** \nTransmissionA6                                  0.032175 *  \nTransmissionA7                                  0.019693 *  \nTransmissionAM6                                 0.000125 ***\nTransmissionAM7                                 0.821867    \nTransmissionAV                                  0.054234 .  \nTransmissionAVS6                                0.005480 ** \nTransmissionM5                                  0.002166 ** \nTransmissionM6                                  0.001953 ** \nTransmissionS4                                  1.94e-05 ***\nTransmissionS5                                  0.001894 ** \nTransmissionS6                                  0.024526 *  \nTransmissionS7                                  0.103967    \nTransmissionS8                                  0.251599    \nAirAspirationMethodSupercharged                 0.035723 *  \nAirAspirationMethodTurbocharged                 0.000476 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001087 ** \nNumGears8                                       0.577155    \nTransLockup1                                    0.012420 *  \nTransCreeperGear1                               0.036067 *  \nDriveDescFourWheelDrive                         0.299167    \nDriveDescParttimeFourWheelDrive                 0.782571    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.001362 ** \nIntakeValvePerCyl1                              0.056702 .  \nIntakeValvePerCyl2                              0.128077    \nIntakeValvePerCyl3                                    NA    \nExhaustValvesPerCyl1                            0.041146 *  \nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.015495 *  \nCarlineClassDescCompactCars                     0.000592 ***\nCarlineClassDescLargeCars                       0.023664 *  \nCarlineClassDescMidsizeCars                     0.002026 ** \nCarlineClassDescMinicompactCars                 0.002390 ** \nCarlineClassDescSmallPickupTrucks2WD            0.139447    \nCarlineClassDescSmallPickupTrucks4WD            0.482307    \nCarlineClassDescSmallStationWagons              0.052300 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.127330    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.170443    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.611738    \nCarlineClassDescStandardPickupTrucks2WD         0.169828    \nCarlineClassDescStandardPickupTrucks4WD         0.136365    \nCarlineClassDescSubcompactCars                  0.002097 ** \nCarlineClassDescVansCargoTypes                  0.007349 ** \nCarlineClassDescVansPassengerType               0.028690 *  \nVarValveTiming1                                 0.583517    \nVarValveLift1                                   0.007269 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.14 on 1051 degrees of freedom\nMultiple R-squared:  0.8333,    Adjusted R-squared:  0.8246 \nF-statistic: 95.55 on 55 and 1051 DF,  p-value: &lt; 2.2e-16\n\n\n\nThe F p-value is significant meaning that our overall model is significant in predicting FE\nThe 13 variables explain 83.33 percent of variation in fuel economy"
  },
  {
    "objectID": "notes/analytics/07062023/lab_6.html#b",
    "href": "notes/analytics/07062023/lab_6.html#b",
    "title": "Lab 6",
    "section": "",
    "text": "Code\ncar::Anova(cars_lm)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              720.6    1 73.0842 &lt; 2.2e-16 ***\nNumCyl                889.6    6 15.0374 &lt; 2.2e-16 ***\nTransmission          707.7   12  5.9813 3.553e-10 ***\nAirAspirationMethod   151.2    2  7.6686 0.0004939 ***\nNumGears              109.2    2  5.5361 0.0040576 ** \nTransLockup            61.8    1  6.2715 0.0124202 *  \nTransCreeperGear       43.4    1  4.4052 0.0360667 *  \nDriveDesc            1535.0    4 38.9205 &lt; 2.2e-16 ***\nIntakeValvePerCyl      56.6    2  2.8720 0.0570315 .  \nExhaustValvesPerCyl    41.2    1  4.1803 0.0411460 *  \nCarlineClassDesc     3495.4   16 22.1561 &lt; 2.2e-16 ***\nVarValveTiming          3.0    1  0.3008 0.5835171    \nVarValveLift           71.3    1  7.2336 0.0072685 ** \nResiduals           10363.0 1051                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nHighest p-value is VarValveTiming with 0.584"
  },
  {
    "objectID": "notes/analytics/07062023/lab_6.html#c",
    "href": "notes/analytics/07062023/lab_6.html#c",
    "title": "Lab 6",
    "section": "",
    "text": "Code\ncars_2010_sub &lt;- cars2010 %&gt;%\n    select(-VarValveTiming)\n\ncars_lm2 &lt;- lm(FE ~ ., cars_2010_sub)\nsummary(cars_lm2)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars_2010_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6242  -1.6504   0.0541   1.5540  21.5852 \n\nCoefficients: (5 not defined because of singularities)\n                                                 Estimate Std. Error t value\n(Intercept)                                      35.99395    3.34810  10.751\nEngDispl                                         -2.26003    0.26130  -8.649\nNumCyl3                                          16.00965    5.10296   3.137\nNumCyl4                                           7.91363    3.93394   2.012\nNumCyl5                                           5.03429    3.96717   1.269\nNumCyl6                                           4.35537    3.92996   1.108\nNumCyl8                                           2.71420    3.96652   0.684\nNumCyl10                                          0.18914    4.11622   0.046\nNumCyl12                                         -0.81976    4.10043  -0.200\nNumCyl16                                         -0.08503    5.40249  -0.016\nTransmissionA4                                   -6.98768    2.27095  -3.077\nTransmissionA5                                   -6.53850    2.27848  -2.870\nTransmissionA6                                   -4.90059    2.27740  -2.152\nTransmissionA7                                    5.71566    2.44150   2.341\nTransmissionAM6                                  -9.49295    2.46240  -3.855\nTransmissionAM7                                   0.59242    2.65143   0.223\nTransmissionAV                                   -4.40233    2.28375  -1.928\nTransmissionAVS6                                 -6.72853    2.41673  -2.784\nTransmissionM5                                   -7.01977    2.27644  -3.084\nTransmissionM6                                   -7.04911    2.26540  -3.112\nTransmissionS4                                  -10.51052    2.42259  -4.339\nTransmissionS5                                   -7.20354    2.30398  -3.127\nTransmissionS6                                   -5.10605    2.26234  -2.257\nTransmissionS7                                    4.09144    2.51056   1.630\nTransmissionS8                                   -4.62893    4.02408  -1.150\nAirAspirationMethodSupercharged                  -1.67713    0.78857  -2.127\nAirAspirationMethodTurbocharged                  -1.13613    0.32177  -3.531\nNumGears4                                              NA         NA      NA\nNumGears5                                              NA         NA      NA\nNumGears6                                              NA         NA      NA\nNumGears7                                       -10.74376    3.27788  -3.278\nNumGears8                                         1.79152    3.19600   0.561\nTransLockup1                                     -0.89373    0.35703  -2.503\nTransCreeperGear1                                -1.09666    0.48450  -2.263\nDriveDescFourWheelDrive                          -0.44026    0.43399  -1.014\nDriveDescParttimeFourWheelDrive                  -0.25475    1.06227  -0.240\nDriveDescTwoWheelDriveFront                       4.32752    0.37652  11.494\nDriveDescTwoWheelDriveRear                        1.19041    0.37227   3.198\nIntakeValvePerCyl1                                6.36976    3.31984   1.919\nIntakeValvePerCyl2                                4.90088    3.20946   1.527\nIntakeValvePerCyl3                                     NA         NA      NA\nExhaustValvesPerCyl1                              1.49669    0.74949   1.997\nExhaustValvesPerCyl2                                   NA         NA      NA\nCarlineClassDesc2Seaters                          2.85888    1.17793   2.427\nCarlineClassDescCompactCars                       3.77775    1.09907   3.437\nCarlineClassDescLargeCars                         2.55092    1.13023   2.257\nCarlineClassDescMidsizeCars                       3.38958    1.09647   3.091\nCarlineClassDescMinicompactCars                   3.62150    1.19313   3.035\nCarlineClassDescSmallPickupTrucks2WD             -1.88501    1.24990  -1.508\nCarlineClassDescSmallPickupTrucks4WD             -0.99946    1.34930  -0.741\nCarlineClassDescSmallStationWagons                2.19864    1.13559   1.936\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.14681    1.35716  -1.582\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.52376    1.10769  -1.376\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.58904    1.12151  -0.525\nCarlineClassDescStandardPickupTrucks2WD          -1.76375    1.26916  -1.390\nCarlineClassDescStandardPickupTrucks4WD          -1.97791    1.30079  -1.521\nCarlineClassDescSubcompactCars                    3.42813    1.11204   3.083\nCarlineClassDescVansCargoTypes                   -4.03720    1.51499  -2.665\nCarlineClassDescVansPassengerType                -4.21030    1.94682  -2.163\nVarValveLift1                                     0.82139    0.30683   2.677\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                         &lt; 2e-16 ***\nNumCyl3                                         0.001752 ** \nNumCyl4                                         0.044513 *  \nNumCyl5                                         0.204726    \nNumCyl6                                         0.268007    \nNumCyl8                                         0.493951    \nNumCyl10                                        0.963360    \nNumCyl12                                        0.841581    \nNumCyl16                                        0.987446    \nTransmissionA4                                  0.002145 ** \nTransmissionA5                                  0.004191 ** \nTransmissionA6                                  0.031638 *  \nTransmissionA7                                  0.019416 *  \nTransmissionAM6                                 0.000123 ***\nTransmissionAM7                                 0.823240    \nTransmissionAV                                  0.054164 .  \nTransmissionAVS6                                0.005463 ** \nTransmissionM5                                  0.002098 ** \nTransmissionM6                                  0.001911 ** \nTransmissionS4                                  1.57e-05 ***\nTransmissionS5                                  0.001817 ** \nTransmissionS6                                  0.024214 *  \nTransmissionS7                                  0.103466    \nTransmissionS8                                  0.250279    \nAirAspirationMethodSupercharged                 0.033668 *  \nAirAspirationMethodTurbocharged                 0.000432 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001081 ** \nNumGears8                                       0.575223    \nTransLockup1                                    0.012458 *  \nTransCreeperGear1                               0.023808 *  \nDriveDescFourWheelDrive                         0.310604    \nDriveDescParttimeFourWheelDrive                 0.810521    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.001427 ** \nIntakeValvePerCyl1                              0.055293 .  \nIntakeValvePerCyl2                              0.127060    \nIntakeValvePerCyl3                                    NA    \nExhaustValvesPerCyl1                            0.046088 *  \nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.015390 *  \nCarlineClassDescCompactCars                     0.000611 ***\nCarlineClassDescLargeCars                       0.024213 *  \nCarlineClassDescMidsizeCars                     0.002045 ** \nCarlineClassDescMinicompactCars                 0.002462 ** \nCarlineClassDescSmallPickupTrucks2WD            0.131822    \nCarlineClassDescSmallPickupTrucks4WD            0.459026    \nCarlineClassDescSmallStationWagons              0.053120 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.113986    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.169229    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.599543    \nCarlineClassDescStandardPickupTrucks2WD         0.164913    \nCarlineClassDescStandardPickupTrucks4WD         0.128675    \nCarlineClassDescSubcompactCars                  0.002105 ** \nCarlineClassDescVansCargoTypes                  0.007821 ** \nCarlineClassDescVansPassengerType               0.030792 *  \nVarValveLift1                                   0.007544 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.139 on 1052 degrees of freedom\nMultiple R-squared:  0.8333,    Adjusted R-squared:  0.8247 \nF-statistic: 97.38 on 54 and 1052 DF,  p-value: &lt; 2.2e-16\n\n\nCode\ncar::Anova(cars_lm2)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              737.1    1 74.8066 &lt; 2.2e-16 ***\nNumCyl                887.9    6 15.0181 &lt; 2.2e-16 ***\nTransmission          712.6   12  6.0266 2.849e-10 ***\nAirAspirationMethod   153.8    2  7.8053 0.0004316 ***\nNumGears              109.2    2  5.5431 0.0040294 ** \nTransLockup            61.7    1  6.2661 0.0124578 *  \nTransCreeperGear       50.5    1  5.1234 0.0238082 *  \nDriveDesc            1545.6    4 39.2146 &lt; 2.2e-16 ***\nIntakeValvePerCyl      57.9    2  2.9386 0.0533736 .  \nExhaustValvesPerCyl    39.3    1  3.9878 0.0460877 *  \nCarlineClassDesc     3504.2   16 22.2267 &lt; 2.2e-16 ***\nVarValveLift           70.6    1  7.1663 0.0075441 ** \nResiduals           10366.0 1052                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nThe p-value for the model did not change significantly\n\\(R^2\\) did not change significantly and \\(R_a^2\\) increased a little"
  },
  {
    "objectID": "notes/analytics/07062023/lab_6.html#d",
    "href": "notes/analytics/07062023/lab_6.html#d",
    "title": "Lab 6",
    "section": "",
    "text": "Dropping IntakeValvePerCyl:\n\n\nCode\ncars_2010_sub &lt;- cars_2010_sub %&gt;%\n    select(-IntakeValvePerCyl)\n\ncars_lm3 &lt;- lm(FE ~ ., cars_2010_sub)\nsummary(cars_lm3)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars_2010_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.5964  -1.7032   0.0413   1.5730  21.6235 \n\nCoefficients: (4 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                      36.0050     3.3542  10.734\nEngDispl                                         -2.1120     0.2530  -8.346\nNumCyl3                                          20.9056     3.9117   5.344\nNumCyl4                                          12.6843     2.2897   5.540\nNumCyl5                                           9.6779     2.3617   4.098\nNumCyl6                                           9.0036     2.3148   3.889\nNumCyl8                                           7.0608     2.4285   2.908\nNumCyl10                                          4.4870     2.6277   1.708\nNumCyl12                                          3.0682     2.6138   1.174\nNumCyl16                                          3.8516     4.3735   0.881\nTransmissionA4                                   -7.1007     2.2745  -3.122\nTransmissionA5                                   -6.7679     2.2799  -2.968\nTransmissionA6                                   -5.2017     2.2777  -2.284\nTransmissionA7                                    5.3619     2.4409   2.197\nTransmissionAM6                                  -9.5275     2.4663  -3.863\nTransmissionAM7                                   0.5339     2.6561   0.201\nTransmissionAV                                   -4.5677     2.2867  -1.998\nTransmissionAVS6                                 -6.9582     2.4186  -2.877\nTransmissionM5                                   -7.2063     2.2788  -3.162\nTransmissionM6                                   -7.1857     2.2683  -3.168\nTransmissionS4                                  -10.7361     2.4247  -4.428\nTransmissionS5                                   -7.3945     2.3063  -3.206\nTransmissionS6                                   -5.2347     2.2655  -2.311\nTransmissionS7                                    3.8448     2.5130   1.530\nTransmissionS8                                   -4.6021     4.0315  -1.142\nAirAspirationMethodSupercharged                  -1.8711     0.7825  -2.391\nAirAspirationMethodTurbocharged                  -1.1602     0.3221  -3.602\nNumGears4                                             NA         NA      NA\nNumGears5                                             NA         NA      NA\nNumGears6                                             NA         NA      NA\nNumGears7                                       -10.6135     3.2834  -3.233\nNumGears8                                         1.7231     3.2016   0.538\nTransLockup1                                     -0.9069     0.3576  -2.536\nTransCreeperGear1                                -1.2475     0.4777  -2.612\nDriveDescFourWheelDrive                          -0.4799     0.4345  -1.105\nDriveDescParttimeFourWheelDrive                  -0.3666     1.0628  -0.345\nDriveDescTwoWheelDriveFront                       4.3236     0.3772  11.462\nDriveDescTwoWheelDriveRear                        1.1403     0.3722   3.063\nExhaustValvesPerCyl1                              2.7454     0.3965   6.925\nExhaustValvesPerCyl2                                  NA         NA      NA\nCarlineClassDesc2Seaters                          2.7680     1.1781   2.350\nCarlineClassDescCompactCars                       3.7770     1.1011   3.430\nCarlineClassDescLargeCars                         2.5646     1.1323   2.265\nCarlineClassDescMidsizeCars                       3.3732     1.0985   3.071\nCarlineClassDescMinicompactCars                   3.6283     1.1952   3.036\nCarlineClassDescSmallPickupTrucks2WD             -1.9032     1.2522  -1.520\nCarlineClassDescSmallPickupTrucks4WD             -1.0239     1.3517  -0.757\nCarlineClassDescSmallStationWagons                2.1934     1.1377   1.928\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.1150     1.3596  -1.556\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.5296     1.1097  -1.378\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.5922     1.1235  -0.527\nCarlineClassDescStandardPickupTrucks2WD          -1.7232     1.2714  -1.355\nCarlineClassDescStandardPickupTrucks4WD          -1.9711     1.3031  -1.513\nCarlineClassDescSubcompactCars                    3.4139     1.1141   3.064\nCarlineClassDescVansCargoTypes                   -3.9331     1.5169  -2.593\nCarlineClassDescVansPassengerType                -4.0805     1.9494  -2.093\nVarValveLift1                                     0.8053     0.3070   2.623\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                         &lt; 2e-16 ***\nNumCyl3                                         1.11e-07 ***\nNumCyl4                                         3.83e-08 ***\nNumCyl5                                         4.49e-05 ***\nNumCyl6                                         0.000107 ***\nNumCyl8                                         0.003719 ** \nNumCyl10                                        0.088005 .  \nNumCyl12                                        0.240713    \nNumCyl16                                        0.378695    \nTransmissionA4                                  0.001846 ** \nTransmissionA5                                  0.003061 ** \nTransmissionA6                                  0.022584 *  \nTransmissionA7                                  0.028260 *  \nTransmissionAM6                                 0.000119 ***\nTransmissionAM7                                 0.840740    \nTransmissionAV                                  0.046025 *  \nTransmissionAVS6                                0.004096 ** \nTransmissionM5                                  0.001610 ** \nTransmissionM6                                  0.001580 ** \nTransmissionS4                                  1.05e-05 ***\nTransmissionS5                                  0.001385 ** \nTransmissionS6                                  0.021044 *  \nTransmissionS7                                  0.126328    \nTransmissionS8                                  0.253901    \nAirAspirationMethodSupercharged                 0.016962 *  \nAirAspirationMethodTurbocharged                 0.000331 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001265 ** \nNumGears8                                       0.590565    \nTransLockup1                                    0.011365 *  \nTransCreeperGear1                               0.009142 ** \nDriveDescFourWheelDrive                         0.269550    \nDriveDescParttimeFourWheelDrive                 0.730220    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.002245 ** \nExhaustValvesPerCyl1                            7.58e-12 ***\nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.018981 *  \nCarlineClassDescCompactCars                     0.000626 ***\nCarlineClassDescLargeCars                       0.023715 *  \nCarlineClassDescMidsizeCars                     0.002189 ** \nCarlineClassDescMinicompactCars                 0.002458 ** \nCarlineClassDescSmallPickupTrucks2WD            0.128836    \nCarlineClassDescSmallPickupTrucks4WD            0.448949    \nCarlineClassDescSmallStationWagons              0.054126 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.120096    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.168369    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.598240    \nCarlineClassDescStandardPickupTrucks2WD         0.175593    \nCarlineClassDescStandardPickupTrucks4WD         0.130664    \nCarlineClassDescSubcompactCars                  0.002237 ** \nCarlineClassDescVansCargoTypes                  0.009648 ** \nCarlineClassDescVansPassengerType               0.036568 *  \nVarValveLift1                                   0.008839 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.145 on 1054 degrees of freedom\nMultiple R-squared:  0.8324,    Adjusted R-squared:  0.8241 \nF-statistic: 100.6 on 52 and 1054 DF,  p-value: &lt; 2.2e-16\n\n\nCode\ncar::Anova(cars_lm3)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              688.9    1 69.6604 &lt; 2.2e-16 ***\nNumCyl               1000.0    6 16.8523 &lt; 2.2e-16 ***\nTransmission          699.4   12  5.8935 5.430e-10 ***\nAirAspirationMethod   169.7    2  8.5817 0.0002009 ***\nNumGears              106.5    2  5.3833 0.0047196 ** \nTransLockup            63.6    1  6.4299 0.0113653 *  \nTransCreeperGear       67.4    1  6.8201 0.0091419 ** \nDriveDesc            1559.4    4 39.4183 &lt; 2.2e-16 ***\nExhaustValvesPerCyl   474.2    1 47.9516 7.583e-12 ***\nCarlineClassDesc     3489.4   16 22.0517 &lt; 2.2e-16 ***\nVarValveLift           68.0    1  6.8807 0.0088387 ** \nResiduals           10423.9 1054                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCode\ncars_2010_sub &lt;- cars_2010_sub %&gt;%\n    select(-TransLockup)\n\ncars_lm4 &lt;- lm(FE ~ ., cars_2010_sub)\nsummary(cars_lm4)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars_2010_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6831  -1.7755   0.0193   1.5767  22.1002 \n\nCoefficients: (4 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                      35.5540     3.3581  10.588\nEngDispl                                         -2.0676     0.2531  -8.170\nNumCyl3                                          20.3570     3.9157   5.199\nNumCyl4                                          12.6350     2.2955   5.504\nNumCyl5                                           9.6799     2.3677   4.088\nNumCyl6                                           8.8784     2.3203   3.826\nNumCyl8                                           6.8252     2.4329   2.805\nNumCyl10                                          4.2129     2.6322   1.601\nNumCyl12                                          2.7488     2.6175   1.050\nNumCyl16                                          4.1444     4.3832   0.946\nTransmissionA4                                   -7.5779     2.2725  -3.335\nTransmissionA5                                   -7.2188     2.2788  -3.168\nTransmissionA6                                   -5.5830     2.2785  -2.450\nTransmissionA7                                    4.7030     2.4333   1.933\nTransmissionAM6                                  -9.6845     2.4718  -3.918\nTransmissionAM7                                   0.5441     2.6629   0.204\nTransmissionAV                                   -4.5705     2.2925  -1.994\nTransmissionAVS6                                 -6.8711     2.4245  -2.834\nTransmissionM5                                   -6.7947     2.2788  -2.982\nTransmissionM6                                   -6.8804     2.2710  -3.030\nTransmissionS4                                  -11.2457     2.4226  -4.642\nTransmissionS5                                   -7.8915     2.3038  -3.425\nTransmissionS6                                   -5.5467     2.2680  -2.446\nTransmissionS7                                    3.1101     2.5027   1.243\nTransmissionS8                                   -5.4739     4.0271  -1.359\nAirAspirationMethodSupercharged                  -1.7876     0.7838  -2.281\nAirAspirationMethodTurbocharged                  -1.1043     0.3222  -3.427\nNumGears4                                             NA         NA      NA\nNumGears5                                             NA         NA      NA\nNumGears6                                             NA         NA      NA\nNumGears7                                       -10.2165     3.2880  -3.107\nNumGears8                                         2.2205     3.2038   0.693\nTransCreeperGear1                                -1.2791     0.4788  -2.672\nDriveDescFourWheelDrive                          -0.4976     0.4355  -1.143\nDriveDescParttimeFourWheelDrive                  -0.4061     1.0655  -0.381\nDriveDescTwoWheelDriveFront                       4.3413     0.3781  11.482\nDriveDescTwoWheelDriveRear                        1.1035     0.3729   2.959\nExhaustValvesPerCyl1                              2.7948     0.3970   7.040\nExhaustValvesPerCyl2                                  NA         NA      NA\nCarlineClassDesc2Seaters                          2.8530     1.1807   2.416\nCarlineClassDescCompactCars                       3.7853     1.1039   3.429\nCarlineClassDescLargeCars                         2.5289     1.1351   2.228\nCarlineClassDescMidsizeCars                       3.3020     1.1009   2.999\nCarlineClassDescMinicompactCars                   3.7542     1.1972   3.136\nCarlineClassDescSmallPickupTrucks2WD             -1.9188     1.2554  -1.528\nCarlineClassDescSmallPickupTrucks4WD             -1.0621     1.3551  -0.784\nCarlineClassDescSmallStationWagons                2.1620     1.1405   1.896\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.2133     1.3625  -1.624\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.5927     1.1122  -1.432\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.6482     1.1262  -0.576\nCarlineClassDescStandardPickupTrucks2WD          -1.7299     1.2746  -1.357\nCarlineClassDescStandardPickupTrucks4WD          -2.0053     1.3064  -1.535\nCarlineClassDescSubcompactCars                    3.3939     1.1169   3.039\nCarlineClassDescVansCargoTypes                   -3.9518     1.5207  -2.599\nCarlineClassDescVansPassengerType                -4.0897     1.9544  -2.093\nVarValveLift1                                     0.8016     0.3078   2.604\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                        8.79e-16 ***\nNumCyl3                                         2.41e-07 ***\nNumCyl4                                         4.66e-08 ***\nNumCyl5                                         4.68e-05 ***\nNumCyl6                                         0.000138 ***\nNumCyl8                                         0.005119 ** \nNumCyl10                                        0.109781    \nNumCyl12                                        0.293871    \nNumCyl16                                        0.344606    \nTransmissionA4                                  0.000884 ***\nTransmissionA5                                  0.001580 ** \nTransmissionA6                                  0.014438 *  \nTransmissionA7                                  0.053532 .  \nTransmissionAM6                                 9.50e-05 ***\nTransmissionAM7                                 0.838126    \nTransmissionAV                                  0.046450 *  \nTransmissionAVS6                                0.004685 ** \nTransmissionM5                                  0.002933 ** \nTransmissionM6                                  0.002507 ** \nTransmissionS4                                  3.88e-06 ***\nTransmissionS5                                  0.000638 ***\nTransmissionS6                                  0.014620 *  \nTransmissionS7                                  0.214253    \nTransmissionS8                                  0.174354    \nAirAspirationMethodSupercharged                 0.022764 *  \nAirAspirationMethodTurbocharged                 0.000633 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001939 ** \nNumGears8                                       0.488417    \nTransCreeperGear1                               0.007665 ** \nDriveDescFourWheelDrive                         0.253447    \nDriveDescParttimeFourWheelDrive                 0.703142    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.003153 ** \nExhaustValvesPerCyl1                            3.46e-12 ***\nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.015841 *  \nCarlineClassDescCompactCars                     0.000629 ***\nCarlineClassDescLargeCars                       0.026094 *  \nCarlineClassDescMidsizeCars                     0.002770 ** \nCarlineClassDescMinicompactCars                 0.001761 ** \nCarlineClassDescSmallPickupTrucks2WD            0.126696    \nCarlineClassDescSmallPickupTrucks4WD            0.433337    \nCarlineClassDescSmallStationWagons              0.058280 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.104587    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.152446    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.565022    \nCarlineClassDescStandardPickupTrucks2WD         0.175017    \nCarlineClassDescStandardPickupTrucks4WD         0.125076    \nCarlineClassDescSubcompactCars                  0.002435 ** \nCarlineClassDescVansCargoTypes                  0.009490 ** \nCarlineClassDescVansPassengerType               0.036625 *  \nVarValveLift1                                   0.009338 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.153 on 1055 degrees of freedom\nMultiple R-squared:  0.8313,    Adjusted R-squared:  0.8232 \nF-statistic:   102 on 51 and 1055 DF,  p-value: &lt; 2.2e-16\n\n\nCode\ncar::Anova(cars_lm4)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              663.5    1 66.7421 8.786e-16 ***\nNumCyl               1037.6    6 17.3966 &lt; 2.2e-16 ***\nTransmission          638.4   12  5.3520 7.426e-09 ***\nAirAspirationMethod   155.0    2  7.7971  0.000435 ***\nNumGears              101.0    2  5.0780  0.006385 ** \nTransCreeperGear       71.0    1  7.1376  0.007665 ** \nDriveDesc            1586.1    4 39.8882 &lt; 2.2e-16 ***\nExhaustValvesPerCyl   492.7    1 49.5606 3.460e-12 ***\nCarlineClassDesc     3548.8   16 22.3123 &lt; 2.2e-16 ***\nVarValveLift           67.4    1  6.7819  0.009338 ** \nResiduals           10487.5 1055                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCode\ncars_2010_sub &lt;- cars_2010_sub %&gt;%\n    select(-VarValveLift)\n\ncars_lm5 &lt;- lm(FE ~ ., cars_2010_sub)\nsummary(cars_lm5)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars_2010_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.7951  -1.7259   0.0248   1.6395  22.0010 \n\nCoefficients: (4 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                      35.6506     3.3670  10.588\nEngDispl                                         -2.0915     0.2536  -8.247\nNumCyl3                                          20.1462     3.9256   5.132\nNumCyl4                                          12.9901     2.2977   5.653\nNumCyl5                                           9.9691     2.3716   4.204\nNumCyl6                                           9.2880     2.3213   4.001\nNumCyl8                                           7.1931     2.4355   2.953\nNumCyl10                                          4.2902     2.6392   1.626\nNumCyl12                                          2.9960     2.6229   1.142\nNumCyl16                                          4.2509     4.3950   0.967\nTransmissionA4                                   -7.9263     2.2748  -3.484\nTransmissionA5                                   -7.4632     2.2831  -3.269\nTransmissionA6                                   -5.9012     2.2815  -2.587\nTransmissionA7                                    4.9316     2.4383   2.023\nTransmissionAM6                                 -10.0571     2.4744  -4.064\nTransmissionAM7                                   0.4535     2.6700   0.170\nTransmissionAV                                   -4.8272     2.2967  -2.102\nTransmissionAVS6                                 -7.2674     2.4264  -2.995\nTransmissionM5                                   -7.0899     2.2822  -3.107\nTransmissionM6                                   -7.0372     2.2764  -3.091\nTransmissionS4                                  -11.2013     2.4291  -4.611\nTransmissionS5                                   -8.0730     2.3091  -3.496\nTransmissionS6                                   -5.7943     2.2722  -2.550\nTransmissionS7                                    3.4280     2.5065   1.368\nTransmissionS8                                   -5.5848     4.0379  -1.383\nAirAspirationMethodSupercharged                  -1.9893     0.7821  -2.544\nAirAspirationMethodTurbocharged                  -1.2457     0.3184  -3.912\nNumGears4                                             NA         NA      NA\nNumGears5                                             NA         NA      NA\nNumGears6                                             NA         NA      NA\nNumGears7                                       -10.6500     3.2928  -3.234\nNumGears8                                         2.0751     3.2121   0.646\nTransCreeperGear1                                -1.3661     0.4789  -2.852\nDriveDescFourWheelDrive                          -0.6841     0.4308  -1.588\nDriveDescParttimeFourWheelDrive                  -0.7039     1.0622  -0.663\nDriveDescTwoWheelDriveFront                       4.1905     0.3747  11.185\nDriveDescTwoWheelDriveRear                        0.9965     0.3717   2.681\nExhaustValvesPerCyl1                              2.7810     0.3980   6.986\nExhaustValvesPerCyl2                                  NA         NA      NA\nCarlineClassDesc2Seaters                          3.0982     1.1801   2.625\nCarlineClassDescCompactCars                       3.8878     1.1062   3.515\nCarlineClassDescLargeCars                         2.6874     1.1366   2.364\nCarlineClassDescMidsizeCars                       3.4001     1.1033   3.082\nCarlineClassDescMinicompactCars                   4.3247     1.1802   3.664\nCarlineClassDescSmallPickupTrucks2WD             -1.8684     1.2587  -1.484\nCarlineClassDescSmallPickupTrucks4WD             -0.9067     1.3575  -0.668\nCarlineClassDescSmallStationWagons                2.2224     1.1434   1.944\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.1858     1.3662  -1.600\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.5070     1.1148  -1.352\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.4822     1.1274  -0.428\nCarlineClassDescStandardPickupTrucks2WD          -1.6614     1.2778  -1.300\nCarlineClassDescStandardPickupTrucks4WD          -1.8270     1.3081  -1.397\nCarlineClassDescSubcompactCars                    3.6375     1.1160   3.259\nCarlineClassDescVansCargoTypes                   -3.8763     1.5246  -2.542\nCarlineClassDescVansPassengerType                -4.0117     1.9595  -2.047\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                        4.79e-16 ***\nNumCyl3                                         3.41e-07 ***\nNumCyl4                                         2.02e-08 ***\nNumCyl5                                         2.85e-05 ***\nNumCyl6                                         6.74e-05 ***\nNumCyl8                                         0.003212 ** \nNumCyl10                                        0.104342    \nNumCyl12                                        0.253614    \nNumCyl16                                        0.333656    \nTransmissionA4                                  0.000513 ***\nTransmissionA5                                  0.001115 ** \nTransmissionA6                                  0.009827 ** \nTransmissionA7                                  0.043374 *  \nTransmissionAM6                                 5.17e-05 ***\nTransmissionAM7                                 0.865169    \nTransmissionAV                                  0.035807 *  \nTransmissionAVS6                                0.002807 ** \nTransmissionM5                                  0.001944 ** \nTransmissionM6                                  0.002044 ** \nTransmissionS4                                  4.49e-06 ***\nTransmissionS5                                  0.000492 ***\nTransmissionS6                                  0.010908 *  \nTransmissionS7                                  0.171715    \nTransmissionS8                                  0.166927    \nAirAspirationMethodSupercharged                 0.011113 *  \nAirAspirationMethodTurbocharged                 9.74e-05 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001257 ** \nNumGears8                                       0.518403    \nTransCreeperGear1                               0.004423 ** \nDriveDescFourWheelDrive                         0.112532    \nDriveDescParttimeFourWheelDrive                 0.507654    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.007448 ** \nExhaustValvesPerCyl1                            4.98e-12 ***\nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.008782 ** \nCarlineClassDescCompactCars                     0.000459 ***\nCarlineClassDescLargeCars                       0.018235 *  \nCarlineClassDescMidsizeCars                     0.002111 ** \nCarlineClassDescMinicompactCars                 0.000260 ***\nCarlineClassDescSmallPickupTrucks2WD            0.137996    \nCarlineClassDescSmallPickupTrucks4WD            0.504354    \nCarlineClassDescSmallStationWagons              0.052206 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.109914    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.176714    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.668970    \nCarlineClassDescStandardPickupTrucks2WD         0.193828    \nCarlineClassDescStandardPickupTrucks4WD         0.162813    \nCarlineClassDescSubcompactCars                  0.001152 ** \nCarlineClassDescVansCargoTypes                  0.011149 *  \nCarlineClassDescVansPassengerType               0.040873 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.162 on 1056 degrees of freedom\nMultiple R-squared:  0.8303,    Adjusted R-squared:  0.8222 \nF-statistic: 103.3 on 50 and 1056 DF,  p-value: &lt; 2.2e-16\n\n\nCode\ncar::Anova(cars_lm5)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              679.8    1 68.0122 4.791e-16 ***\nNumCyl               1043.7    6 17.4026 &lt; 2.2e-16 ***\nTransmission          613.6   12  5.1154 2.307e-08 ***\nAirAspirationMethod   202.9    2 10.1494 4.305e-05 ***\nNumGears              108.9    2  5.4475  0.004429 ** \nTransCreeperGear       81.3    1  8.1365  0.004423 ** \nDriveDesc            1537.5    4 38.4558 &lt; 2.2e-16 ***\nExhaustValvesPerCyl   487.9    1 48.8110 4.982e-12 ***\nCarlineClassDesc     3715.0   16 23.2300 &lt; 2.2e-16 ***\nResiduals           10554.9 1056                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nBoth \\(R^2\\) and \\(R_a^2\\) decreased\n9 variables significant at the 0.008 level"
  },
  {
    "objectID": "notes/analytics/07072023/index.html",
    "href": "notes/analytics/07072023/index.html",
    "title": "Model Selection",
    "section": "",
    "text": "Information criteria are metrics that are commonly used to “select” variables for the model.\nSelection algorithm is an automated technique to evaluate variables based on some selection criteria.\n\nStepwise Selection (forward, backward, stepwise)\nAll-regression Selection (\\(R^2\\), \\(R_a^2\\), Mallow’s \\(C_p\\))\n\nAll-regression selection tends to be unusable for datasets of a large size so we focus on stepwise selection for now."
  },
  {
    "objectID": "notes/analytics/07072023/index.html#akaike-information-criterion",
    "href": "notes/analytics/07072023/index.html#akaike-information-criterion",
    "title": "Model Selection",
    "section": "3.1 Akaike Information Criterion",
    "text": "3.1 Akaike Information Criterion\n\\[\nAIC = -2\\log(L) + 2k\n\\]\nCrude, large-sample approximation of leave-one-out cross-validation."
  },
  {
    "objectID": "notes/analytics/07072023/index.html#bayesian-information-criterion",
    "href": "notes/analytics/07072023/index.html#bayesian-information-criterion",
    "title": "Model Selection",
    "section": "3.2 Bayesian Information Criterion",
    "text": "3.2 Bayesian Information Criterion\nFavors smaller models and penalizes model complexity more.\n\\[\nBIC = -2\\log(L) + k\\log(n)\n\\]"
  },
  {
    "objectID": "notes/analytics/07072023/index.html#r-code",
    "href": "notes/analytics/07072023/index.html#r-code",
    "title": "Model Selection",
    "section": "4.1 R Code",
    "text": "4.1 R Code\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(AmesHousing)\n\names &lt;- make_ordinal_ames()\ntrain &lt;- sample_frac(ames, 0.7)\ntrain_sel &lt;- train %&gt;%\n    select(Sale_Price, Lot_Area, Street, Bldg_Type, House_Style, Overall_Qual, Roof_Style, Central_Air, First_Flr_SF, Second_Flr_SF, Full_Bath, Half_Bath, Fireplaces, Garage_Area, Gr_Liv_Area, TotRms_AbvGrd) %&gt;%\n    replace(is.na(.), 0)\n\n\n\n\nCode\nfull.model &lt;- lm(Sale_Price ~ ., data = train_sel)\nempty.model &lt;- lm(Sale_Price ~ 1, data = train_sel)\n\nfor.model &lt;- step(\n    empty.model,\n    scope = list(\n        lower = empty.model,\n        upper = full.model\n    ),\n    direction = \"forward\",\n    k = 2,\n    trace = FALSE\n)\nfor.model\n\n\n\nCall:\nlm(formula = Sale_Price ~ Overall_Qual + Gr_Liv_Area + Garage_Area + \n    House_Style + Bldg_Type + Fireplaces + Full_Bath + Half_Bath + \n    Central_Air + Roof_Style + Lot_Area + TotRms_AbvGrd + Second_Flr_SF + \n    First_Flr_SF, data = train_sel)\n\nCoefficients:\n                (Intercept)               Overall_Qual.L  \n                  5.330e+04                    2.253e+05  \n             Overall_Qual.Q               Overall_Qual.C  \n                  6.775e+04                    2.059e+04  \n             Overall_Qual^4               Overall_Qual^5  \n                 -2.690e+04                   -2.221e+04  \n             Overall_Qual^6               Overall_Qual^7  \n                 -2.060e+04                   -5.623e+03  \n             Overall_Qual^8               Overall_Qual^9  \n                 -1.912e+03                   -1.680e+03  \n                Gr_Liv_Area                  Garage_Area  \n                  1.753e+01                    3.572e+01  \nHouse_StyleOne_and_Half_Unf         House_StyleOne_Story  \n                  1.578e+04                    2.329e+04  \n          House_StyleSFoyer              House_StyleSLvl  \n                  3.737e+04                    9.080e+03  \nHouse_StyleTwo_and_Half_Fin  House_StyleTwo_and_Half_Unf  \n                 -4.085e+03                   -1.131e+04  \n       House_StyleTwo_Story            Bldg_TypeTwoFmCon  \n                 -6.782e+02                   -1.065e+04  \n            Bldg_TypeDuplex               Bldg_TypeTwnhs  \n                 -3.016e+04                   -1.742e+04  \n            Bldg_TypeTwnhsE                   Fireplaces  \n                 -1.108e+04                    8.431e+03  \n                  Full_Bath                    Half_Bath  \n                  1.624e+04                    1.241e+04  \n               Central_AirY              Roof_StyleGable  \n                  1.313e+04                   -5.028e+03  \n          Roof_StyleGambrel                Roof_StyleHip  \n                 -7.271e+03                    1.284e+03  \n          Roof_StyleMansard               Roof_StyleShed  \n                 -4.436e+04                    1.637e+04  \n                   Lot_Area                TotRms_AbvGrd  \n                  4.253e-01                   -1.944e+03  \n              Second_Flr_SF                 First_Flr_SF  \n                  3.561e+01                    2.954e+01  \n\n\n\nGood practice to specify the full and empty models\nk = 2 is selecting the AIC criteria"
  },
  {
    "objectID": "notes/analytics/07072023/index.html#python-code",
    "href": "notes/analytics/07072023/index.html#python-code",
    "title": "Model Selection",
    "section": "4.2 Python Code",
    "text": "4.2 Python Code\n\n\nCode\n# from sklearn.feature_selection import SequentialFeatureSelector\n# import statsmodels.formula.api as smf\n\n# model = \n\n\nThe model obtained through forward selection is not necessarily a model where all variables are significant."
  },
  {
    "objectID": "notes/analytics/07072023/index.html#other-criteria",
    "href": "notes/analytics/07072023/index.html#other-criteria",
    "title": "Model Selection",
    "section": "4.3 Other Criteria",
    "text": "4.3 Other Criteria\nUsing k = qchisq(0.05, 1, lower.tail = FALSE) would replace the selection criteria with p-value selection. \\(\\alpha = 0.05\\) in this case.\nk = log(nrow(train_sel)) would use the BIC criterion."
  },
  {
    "objectID": "notes/analytics/07072023/index.html#r-code-1",
    "href": "notes/analytics/07072023/index.html#r-code-1",
    "title": "Model Selection",
    "section": "5.1 R Code",
    "text": "5.1 R Code\n\n\nCode\nfull.model &lt;- lm(Sale_Price ~ ., data = train_sel)\nempty.model &lt;- lm(Sale_Price ~ 1, data = train_sel)\n\nback.model &lt;- step(\n    full.model,\n    scope = list(\n        lower = empty.model,\n        upper = full.model\n    ),\n    direction = \"backward\",\n    k = 2,\n    trace = FALSE\n)\n\nback.model\n\n\n\nCall:\nlm(formula = Sale_Price ~ Lot_Area + Bldg_Type + House_Style + \n    Overall_Qual + Roof_Style + Central_Air + First_Flr_SF + \n    Second_Flr_SF + Full_Bath + Half_Bath + Fireplaces + Garage_Area + \n    TotRms_AbvGrd, data = train_sel)\n\nCoefficients:\n                (Intercept)                     Lot_Area  \n                  5.388e+04                    4.264e-01  \n          Bldg_TypeTwoFmCon              Bldg_TypeDuplex  \n                 -1.086e+04                   -3.034e+04  \n             Bldg_TypeTwnhs              Bldg_TypeTwnhsE  \n                 -1.738e+04                   -1.104e+04  \nHouse_StyleOne_and_Half_Unf         House_StyleOne_Story  \n                  1.502e+04                    2.238e+04  \n          House_StyleSFoyer              House_StyleSLvl  \n                  3.660e+04                    8.380e+03  \nHouse_StyleTwo_and_Half_Fin  House_StyleTwo_and_Half_Unf  \n                  2.183e+03                   -1.147e+04  \n       House_StyleTwo_Story               Overall_Qual.L  \n                 -8.826e+02                    2.251e+05  \n             Overall_Qual.Q               Overall_Qual.C  \n                  6.802e+04                    2.088e+04  \n             Overall_Qual^4               Overall_Qual^5  \n                 -2.693e+04                   -2.205e+04  \n             Overall_Qual^6               Overall_Qual^7  \n                 -2.053e+04                   -5.511e+03  \n             Overall_Qual^8               Overall_Qual^9  \n                 -1.940e+03                   -1.637e+03  \n            Roof_StyleGable            Roof_StyleGambrel  \n                 -5.125e+03                   -7.271e+03  \n              Roof_StyleHip            Roof_StyleMansard  \n                  1.201e+03                   -4.423e+04  \n             Roof_StyleShed                 Central_AirY  \n                  1.660e+04                    1.313e+04  \n               First_Flr_SF                Second_Flr_SF  \n                  4.688e+01                    5.205e+01  \n                  Full_Bath                    Half_Bath  \n                  1.636e+04                    1.244e+04  \n                 Fireplaces                  Garage_Area  \n                  8.452e+03                    3.572e+01  \n              TotRms_AbvGrd  \n                 -1.841e+03  \n\n\nIt’s good idea to perform different types of selection to get an idea of what features to include in your final model."
  },
  {
    "objectID": "notes/analytics/07072023/index.html#r-code-2",
    "href": "notes/analytics/07072023/index.html#r-code-2",
    "title": "Model Selection",
    "section": "6.1 R Code",
    "text": "6.1 R Code\n\n\nCode\nfull.model &lt;- lm(Sale_Price ~ ., data = train_sel)\nempty.model &lt;- lm(Sale_Price ~ 1, data = train_sel)\nstep.model &lt;- step(empty.model,\n    scope = list(\n        lower = empty.model,\n        upper = full.model\n    ),\n    direction = \"both\", k = 2\n)\n\n\nStart:  AIC=46305.12\nSale_Price ~ 1\n\n                Df  Sum of Sq        RSS   AIC\n+ Overall_Qual   9 8.9476e+12 4.1305e+12 43959\n+ Gr_Liv_Area    1 6.3401e+12 6.7380e+12 44947\n+ Garage_Area    1 5.0342e+12 8.0439e+12 45310\n+ First_Flr_SF   1 4.8282e+12 8.2498e+12 45362\n+ Full_Bath      1 3.7035e+12 9.3746e+12 45624\n+ TotRms_AbvGrd  1 3.0848e+12 9.9933e+12 45755\n+ Fireplaces     1 2.9205e+12 1.0158e+13 45789\n+ Half_Bath      1 1.2011e+12 1.1877e+13 46110\n+ Lot_Area       1 1.1005e+12 1.1978e+13 46127\n+ Roof_Style     5 1.0249e+12 1.2053e+13 46148\n+ Second_Flr_SF  1 9.6666e+11 1.2111e+13 46150\n+ Central_Air    1 9.5773e+11 1.2120e+13 46151\n+ House_Style    7 9.7642e+11 1.2102e+13 46160\n+ Bldg_Type      4 4.2909e+11 1.2649e+13 46245\n+ Street         1 4.2397e+10 1.3036e+13 46300\n&lt;none&gt;                        1.3078e+13 46305\n\nStep:  AIC=43959.27\nSale_Price ~ Overall_Qual\n\n                Df  Sum of Sq        RSS   AIC\n+ Gr_Liv_Area    1 1.0152e+12 3.1153e+12 43383\n+ First_Flr_SF   1 5.5472e+11 3.5758e+12 43665\n+ Garage_Area    1 4.9681e+11 3.6337e+12 43698\n+ TotRms_AbvGrd  1 4.3713e+11 3.6934e+12 43732\n+ Lot_Area       1 4.1512e+11 3.7154e+12 43744\n+ Full_Bath      1 4.0213e+11 3.7284e+12 43751\n+ Fireplaces     1 3.9096e+11 3.7395e+12 43757\n+ Bldg_Type      4 2.0899e+11 3.9215e+12 43861\n+ Second_Flr_SF  1 1.7145e+11 3.9591e+12 43874\n+ Half_Bath      1 1.5042e+11 3.9801e+12 43885\n+ Central_Air    1 8.9320e+10 4.0412e+12 43916\n+ Roof_Style     5 6.1841e+10 4.0687e+12 43938\n+ House_Style    7 6.8610e+10 4.0619e+12 43939\n&lt;none&gt;                        4.1305e+12 43959\n+ Street         1 1.5665e+09 4.1289e+12 43960\n- Overall_Qual   9 8.9476e+12 1.3078e+13 46305\n\nStep:  AIC=43382.72\nSale_Price ~ Overall_Qual + Gr_Liv_Area\n\n                Df  Sum of Sq        RSS   AIC\n+ Garage_Area    1 2.2659e+11 2.8887e+12 43230\n+ House_Style    7 2.4266e+11 2.8726e+12 43230\n+ First_Flr_SF   1 1.3334e+11 2.9819e+12 43295\n+ Lot_Area       1 1.1765e+11 2.9976e+12 43306\n+ Second_Flr_SF  1 1.1675e+11 2.9985e+12 43306\n+ Fireplaces     1 1.1490e+11 3.0004e+12 43308\n+ Central_Air    1 1.1387e+11 3.0014e+12 43308\n+ Bldg_Type      4 1.0718e+11 3.0081e+12 43319\n+ Roof_Style     5 6.8802e+10 3.0465e+12 43347\n+ TotRms_AbvGrd  1 3.6007e+10 3.0793e+12 43361\n+ Full_Bath      1 2.8920e+10 3.0864e+12 43366\n&lt;none&gt;                        3.1153e+12 43383\n+ Half_Bath      1 1.4348e+08 3.1151e+12 43385\n+ Street         1 8.2390e+07 3.1152e+12 43385\n- Gr_Liv_Area    1 1.0152e+12 4.1305e+12 43959\n- Overall_Qual   9 3.6227e+12 6.7380e+12 44947\n\nStep:  AIC=43229.83\nSale_Price ~ Overall_Qual + Gr_Liv_Area + Garage_Area\n\n                Df  Sum of Sq        RSS   AIC\n+ House_Style    7 1.4770e+11 2.7410e+12 43136\n+ Fireplaces     1 1.0316e+11 2.7855e+12 43157\n+ Bldg_Type      4 8.5347e+10 2.8033e+12 43176\n+ First_Flr_SF   1 7.2287e+10 2.8164e+12 43180\n+ Lot_Area       1 6.9953e+10 2.8187e+12 43182\n+ Central_Air    1 6.5148e+10 2.8235e+12 43185\n+ Second_Flr_SF  1 6.1995e+10 2.8267e+12 43187\n+ Roof_Style     5 5.7473e+10 2.8312e+12 43199\n+ TotRms_AbvGrd  1 2.4600e+10 2.8641e+12 43214\n+ Full_Bath      1 1.7808e+10 2.8709e+12 43219\n&lt;none&gt;                        2.8887e+12 43230\n+ Half_Bath      1 1.1099e+09 2.8876e+12 43231\n+ Street         1 2.8613e+08 2.8884e+12 43232\n- Garage_Area    1 2.2659e+11 3.1153e+12 43383\n- Gr_Liv_Area    1 7.4501e+11 3.6337e+12 43698\n- Overall_Qual   9 2.4655e+12 5.3542e+12 44477\n\nStep:  AIC=43136.19\nSale_Price ~ Overall_Qual + Gr_Liv_Area + Garage_Area + House_Style\n\n                Df  Sum of Sq        RSS   AIC\n+ Bldg_Type      4 1.0290e+11 2.6381e+12 43066\n+ Fireplaces     1 7.7192e+10 2.6638e+12 43080\n+ Central_Air    1 4.8657e+10 2.6923e+12 43101\n+ Lot_Area       1 3.9464e+10 2.7015e+12 43108\n+ Half_Bath      1 3.5572e+10 2.7054e+12 43111\n+ Roof_Style     5 3.1060e+10 2.7099e+12 43123\n+ TotRms_AbvGrd  1 1.3204e+10 2.7278e+12 43128\n+ Full_Bath      1 1.2058e+10 2.7289e+12 43129\n+ Second_Flr_SF  1 6.9797e+09 2.7340e+12 43133\n+ First_Flr_SF   1 3.8725e+09 2.7371e+12 43135\n&lt;none&gt;                        2.7410e+12 43136\n+ Street         1 2.0718e+08 2.7408e+12 43138\n- House_Style    7 1.4770e+11 2.8887e+12 43230\n- Garage_Area    1 1.3162e+11 2.8726e+12 43230\n- Gr_Liv_Area    1 8.3802e+11 3.5790e+12 43681\n- Overall_Qual   9 2.1377e+12 4.8787e+12 44301\n\nStep:  AIC=43065.72\nSale_Price ~ Overall_Qual + Gr_Liv_Area + Garage_Area + House_Style + \n    Bldg_Type\n\n                Df  Sum of Sq        RSS   AIC\n+ Fireplaces     1 5.3177e+10 2.5849e+12 43026\n+ Full_Bath      1 4.0451e+10 2.5976e+12 43036\n+ Central_Air    1 3.6220e+10 2.6019e+12 43039\n+ Half_Bath      1 3.3930e+10 2.6042e+12 43041\n+ Lot_Area       1 2.2522e+10 2.6156e+12 43050\n+ Roof_Style     5 3.0791e+10 2.6073e+12 43052\n+ TotRms_AbvGrd  1 7.2496e+09 2.6308e+12 43062\n+ Second_Flr_SF  1 4.5385e+09 2.6336e+12 43064\n&lt;none&gt;                        2.6381e+12 43066\n+ First_Flr_SF   1 1.9205e+09 2.6362e+12 43066\n+ Street         1 1.7948e+04 2.6381e+12 43068\n- Bldg_Type      4 1.0290e+11 2.7410e+12 43136\n- Garage_Area    1 1.1463e+11 2.7527e+12 43151\n- House_Style    7 1.6525e+11 2.8033e+12 43176\n- Gr_Liv_Area    1 7.9533e+11 3.4334e+12 43604\n- Overall_Qual   9 1.8395e+12 4.4776e+12 44133\n\nStep:  AIC=43025.95\nSale_Price ~ Overall_Qual + Gr_Liv_Area + Garage_Area + House_Style + \n    Bldg_Type + Fireplaces\n\n                Df  Sum of Sq        RSS   AIC\n+ Full_Bath      1 5.3553e+10 2.5314e+12 42985\n+ Central_Air    1 3.1588e+10 2.5533e+12 43003\n+ Half_Bath      1 2.5824e+10 2.5591e+12 43007\n+ Roof_Style     5 2.7477e+10 2.5574e+12 43014\n+ Lot_Area       1 1.3273e+10 2.5716e+12 43017\n+ Second_Flr_SF  1 7.4034e+09 2.5775e+12 43022\n+ TotRms_AbvGrd  1 5.8138e+09 2.5791e+12 43023\n+ First_Flr_SF   1 4.1856e+09 2.5807e+12 43025\n&lt;none&gt;                        2.5849e+12 43026\n+ Street         1 7.3457e+07 2.5848e+12 43028\n- Fireplaces     1 5.3177e+10 2.6381e+12 43066\n- Bldg_Type      4 7.8883e+10 2.6638e+12 43080\n- Garage_Area    1 1.1515e+11 2.7001e+12 43113\n- House_Style    7 1.3884e+11 2.7238e+12 43119\n- Gr_Liv_Area    1 5.8394e+11 3.1689e+12 43442\n- Overall_Qual   9 1.7721e+12 4.3571e+12 44079\n\nStep:  AIC=42985.01\nSale_Price ~ Overall_Qual + Gr_Liv_Area + Garage_Area + House_Style + \n    Bldg_Type + Fireplaces + Full_Bath\n\n                Df  Sum of Sq        RSS   AIC\n+ Half_Bath      1 5.1361e+10 2.4800e+12 42945\n+ Central_Air    1 2.9070e+10 2.5023e+12 42963\n+ Roof_Style     5 2.5503e+10 2.5059e+12 42974\n+ Lot_Area       1 1.5436e+10 2.5159e+12 42974\n+ TotRms_AbvGrd  1 9.0738e+09 2.5223e+12 42980\n+ Second_Flr_SF  1 4.9499e+09 2.5264e+12 42983\n&lt;none&gt;                        2.5314e+12 42985\n+ First_Flr_SF   1 2.3771e+09 2.5290e+12 42985\n+ Street         1 4.7039e+06 2.5314e+12 42987\n- Full_Bath      1 5.3553e+10 2.5849e+12 43026\n- Fireplaces     1 6.6280e+10 2.5976e+12 43036\n- Bldg_Type      4 1.0804e+11 2.6394e+12 43063\n- Garage_Area    1 1.0246e+11 2.6338e+12 43064\n- House_Style    7 1.3246e+11 2.6638e+12 43076\n- Gr_Liv_Area    1 3.7608e+11 2.9074e+12 43267\n- Overall_Qual   9 1.6798e+12 4.2112e+12 44011\n\nStep:  AIC=42944.97\nSale_Price ~ Overall_Qual + Gr_Liv_Area + Garage_Area + House_Style + \n    Bldg_Type + Fireplaces + Full_Bath + Half_Bath\n\n                Df  Sum of Sq        RSS   AIC\n+ Central_Air    1 2.0333e+10 2.4597e+12 42930\n+ Roof_Style     5 2.7959e+10 2.4520e+12 42932\n+ Lot_Area       1 1.4545e+10 2.4655e+12 42935\n+ TotRms_AbvGrd  1 6.7754e+09 2.4732e+12 42941\n&lt;none&gt;                        2.4800e+12 42945\n+ Second_Flr_SF  1 1.0041e+09 2.4790e+12 42946\n+ First_Flr_SF   1 1.3791e+08 2.4799e+12 42947\n+ Street         1 6.0636e+06 2.4800e+12 42947\n- Half_Bath      1 5.1361e+10 2.5314e+12 42985\n- Fireplaces     1 5.7280e+10 2.5373e+12 42990\n- Full_Bath      1 7.9091e+10 2.5591e+12 43007\n- Garage_Area    1 9.3927e+10 2.5739e+12 43019\n- Bldg_Type      4 1.1726e+11 2.5973e+12 43032\n- House_Style    7 1.7564e+11 2.6556e+12 43071\n- Gr_Liv_Area    1 3.2037e+11 2.8004e+12 43192\n- Overall_Qual   9 1.6443e+12 4.1243e+12 43970\n\nStep:  AIC=42930.08\nSale_Price ~ Overall_Qual + Gr_Liv_Area + Garage_Area + House_Style + \n    Bldg_Type + Fireplaces + Full_Bath + Half_Bath + Central_Air\n\n                Df  Sum of Sq        RSS   AIC\n+ Roof_Style     5 2.5288e+10 2.4344e+12 42919\n+ Lot_Area       1 1.3407e+10 2.4463e+12 42921\n+ TotRms_AbvGrd  1 6.4358e+09 2.4532e+12 42927\n&lt;none&gt;                        2.4597e+12 42930\n+ Second_Flr_SF  1 1.0474e+09 2.4586e+12 42931\n+ First_Flr_SF   1 1.5556e+08 2.4595e+12 42932\n+ Street         1 2.4334e+07 2.4596e+12 42932\n- Central_Air    1 2.0333e+10 2.4800e+12 42945\n- Half_Bath      1 4.2625e+10 2.5023e+12 42963\n- Fireplaces     1 5.3799e+10 2.5135e+12 42972\n- Full_Bath      1 7.3774e+10 2.5334e+12 42989\n- Garage_Area    1 8.0640e+10 2.5403e+12 42994\n- Bldg_Type      4 1.0761e+11 2.5673e+12 43010\n- House_Style    7 1.5748e+11 2.6172e+12 43043\n- Gr_Liv_Area    1 3.2463e+11 2.7843e+12 43182\n- Overall_Qual   9 1.6390e+12 4.0986e+12 43959\n\nStep:  AIC=42918.89\nSale_Price ~ Overall_Qual + Gr_Liv_Area + Garage_Area + House_Style + \n    Bldg_Type + Fireplaces + Full_Bath + Half_Bath + Central_Air + \n    Roof_Style\n\n                Df  Sum of Sq        RSS   AIC\n+ Lot_Area       1 1.2743e+10 2.4216e+12 42910\n+ TotRms_AbvGrd  1 6.7674e+09 2.4276e+12 42915\n&lt;none&gt;                        2.4344e+12 42919\n+ Second_Flr_SF  1 1.7805e+09 2.4326e+12 42919\n+ First_Flr_SF   1 5.0223e+08 2.4339e+12 42920\n+ Street         1 9.9104e+06 2.4344e+12 42921\n- Roof_Style     5 2.5288e+10 2.4597e+12 42930\n- Central_Air    1 1.7662e+10 2.4520e+12 42932\n- Half_Bath      1 4.5653e+10 2.4800e+12 42955\n- Fireplaces     1 4.9680e+10 2.4841e+12 42958\n- Full_Bath      1 7.3391e+10 2.5078e+12 42978\n- Garage_Area    1 8.1710e+10 2.5161e+12 42985\n- Bldg_Type      4 1.0676e+11 2.5411e+12 42999\n- House_Style    7 1.3844e+11 2.5728e+12 43018\n- Gr_Liv_Area    1 3.1155e+11 2.7459e+12 43164\n- Overall_Qual   9 1.5294e+12 3.9638e+12 43901\n\nStep:  AIC=42910.12\nSale_Price ~ Overall_Qual + Gr_Liv_Area + Garage_Area + House_Style + \n    Bldg_Type + Fireplaces + Full_Bath + Half_Bath + Central_Air + \n    Roof_Style + Lot_Area\n\n                Df  Sum of Sq        RSS   AIC\n+ TotRms_AbvGrd  1 5.7682e+09 2.4159e+12 42907\n+ Second_Flr_SF  1 3.1200e+09 2.4185e+12 42909\n&lt;none&gt;                        2.4216e+12 42910\n+ First_Flr_SF   1 1.3587e+09 2.4203e+12 42911\n+ Street         1 5.9804e+08 2.4210e+12 42912\n- Lot_Area       1 1.2743e+10 2.4344e+12 42919\n- Roof_Style     5 2.4624e+10 2.4463e+12 42921\n- Central_Air    1 1.6739e+10 2.4384e+12 42922\n- Fireplaces     1 4.1776e+10 2.4634e+12 42943\n- Half_Bath      1 4.4895e+10 2.4665e+12 42946\n- Garage_Area    1 7.3052e+10 2.4947e+12 42969\n- Full_Bath      1 7.5383e+10 2.4970e+12 42971\n- Bldg_Type      4 9.2243e+10 2.5139e+12 42979\n- House_Style    7 1.2271e+11 2.5443e+12 42998\n- Gr_Liv_Area    1 2.6745e+11 2.6891e+12 43123\n- Overall_Qual   9 1.5420e+12 3.9636e+12 43903\n\nStep:  AIC=42907.23\nSale_Price ~ Overall_Qual + Gr_Liv_Area + Garage_Area + House_Style + \n    Bldg_Type + Fireplaces + Full_Bath + Half_Bath + Central_Air + \n    Roof_Style + Lot_Area + TotRms_AbvGrd\n\n                Df  Sum of Sq        RSS   AIC\n+ Second_Flr_SF  1 2.7018e+09 2.4132e+12 42907\n&lt;none&gt;                        2.4159e+12 42907\n+ First_Flr_SF   1 1.1092e+09 2.4148e+12 42908\n+ Street         1 7.2720e+08 2.4151e+12 42909\n- TotRms_AbvGrd  1 5.7682e+09 2.4216e+12 42910\n- Lot_Area       1 1.1744e+10 2.4276e+12 42915\n- Roof_Style     5 2.5174e+10 2.4410e+12 42918\n- Central_Air    1 1.6622e+10 2.4325e+12 42919\n- Fireplaces     1 4.1377e+10 2.4572e+12 42940\n- Half_Bath      1 4.3214e+10 2.4591e+12 42942\n- Garage_Area    1 7.0918e+10 2.4868e+12 42965\n- Full_Bath      1 7.7707e+10 2.4936e+12 42970\n- Bldg_Type      4 8.8794e+10 2.5047e+12 42973\n- House_Style    7 1.1290e+11 2.5288e+12 42987\n- Gr_Liv_Area    1 2.1986e+11 2.6357e+12 43084\n- Overall_Qual   9 1.5465e+12 3.9624e+12 43904\n\nStep:  AIC=42906.94\nSale_Price ~ Overall_Qual + Gr_Liv_Area + Garage_Area + House_Style + \n    Bldg_Type + Fireplaces + Full_Bath + Half_Bath + Central_Air + \n    Roof_Style + Lot_Area + TotRms_AbvGrd + Second_Flr_SF\n\n                Df  Sum of Sq        RSS   AIC\n+ First_Flr_SF   1 2.8791e+09 2.4103e+12 42906\n&lt;none&gt;                        2.4132e+12 42907\n- Second_Flr_SF  1 2.7018e+09 2.4159e+12 42907\n+ Street         1 7.8632e+08 2.4124e+12 42908\n- TotRms_AbvGrd  1 5.3500e+09 2.4185e+12 42909\n- Lot_Area       1 1.2960e+10 2.4261e+12 42916\n- Central_Air    1 1.6592e+10 2.4298e+12 42919\n- Roof_Style     5 2.6112e+10 2.4393e+12 42919\n- Half_Bath      1 3.8564e+10 2.4517e+12 42937\n- Fireplaces     1 4.2596e+10 2.4558e+12 42941\n- House_Style    7 7.6515e+10 2.4897e+12 42957\n- Garage_Area    1 7.2255e+10 2.4854e+12 42965\n- Full_Bath      1 7.3494e+10 2.4867e+12 42966\n- Bldg_Type      4 8.4464e+10 2.4976e+12 42969\n- Gr_Liv_Area    1 1.6479e+11 2.5780e+12 43040\n- Overall_Qual   9 1.5317e+12 3.9448e+12 43897\n\nStep:  AIC=42906.49\nSale_Price ~ Overall_Qual + Gr_Liv_Area + Garage_Area + House_Style + \n    Bldg_Type + Fireplaces + Full_Bath + Half_Bath + Central_Air + \n    Roof_Style + Lot_Area + TotRms_AbvGrd + Second_Flr_SF + First_Flr_SF\n\n                Df  Sum of Sq        RSS   AIC\n- Gr_Liv_Area    1 1.0372e+09 2.4113e+12 42905\n&lt;none&gt;                        2.4103e+12 42906\n- First_Flr_SF   1 2.8791e+09 2.4132e+12 42907\n+ Street         1 7.8646e+08 2.4095e+12 42908\n- Second_Flr_SF  1 4.4717e+09 2.4148e+12 42908\n- TotRms_AbvGrd  1 5.2917e+09 2.4156e+12 42909\n- Lot_Area       1 1.2404e+10 2.4227e+12 42915\n- Roof_Style     5 2.5899e+10 2.4362e+12 42918\n- Central_Air    1 1.6608e+10 2.4269e+12 42919\n- Half_Bath      1 3.8533e+10 2.4488e+12 42937\n- Fireplaces     1 4.1774e+10 2.4521e+12 42940\n- House_Style    7 6.6546e+10 2.4768e+12 42948\n- Garage_Area    1 7.0948e+10 2.4812e+12 42964\n- Full_Bath      1 7.3833e+10 2.4841e+12 42966\n- Bldg_Type      4 8.5619e+10 2.4959e+12 42970\n- Overall_Qual   9 1.5155e+12 3.9258e+12 43889\n\nStep:  AIC=42905.37\nSale_Price ~ Overall_Qual + Garage_Area + House_Style + Bldg_Type + \n    Fireplaces + Full_Bath + Half_Bath + Central_Air + Roof_Style + \n    Lot_Area + TotRms_AbvGrd + Second_Flr_SF + First_Flr_SF\n\n                Df  Sum of Sq        RSS   AIC\n&lt;none&gt;                        2.4113e+12 42905\n+ Gr_Liv_Area    1 1.0372e+09 2.4103e+12 42906\n+ Street         1 8.1161e+08 2.4105e+12 42907\n- TotRms_AbvGrd  1 4.8155e+09 2.4161e+12 42907\n- Lot_Area       1 1.2471e+10 2.4238e+12 42914\n- Roof_Style     5 2.5833e+10 2.4372e+12 42917\n- Central_Air    1 1.6592e+10 2.4279e+12 42917\n- Half_Bath      1 3.8729e+10 2.4501e+12 42936\n- Fireplaces     1 4.1997e+10 2.4533e+12 42939\n- House_Style    7 6.5585e+10 2.4769e+12 42946\n- Garage_Area    1 7.0916e+10 2.4822e+12 42963\n- Full_Bath      1 7.5174e+10 2.4865e+12 42966\n- Bldg_Type      4 8.6350e+10 2.4977e+12 42970\n- Second_Flr_SF  1 1.1648e+11 2.5278e+12 43000\n- First_Flr_SF   1 1.6663e+11 2.5780e+12 43040\n- Overall_Qual   9 1.5148e+12 3.9261e+12 43887"
  },
  {
    "objectID": "notes/analytics/07072023/lab_7.html",
    "href": "notes/analytics/07072023/lab_7.html",
    "title": "Lab 7",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(AppliedPredictiveModeling)\ndata(FuelEconomy)\n\ncars2010 &lt;- cars2010 %&gt;%\n    mutate(across(!c(EngDispl, FE), as.factor))\n\n\n\n1 a\n\n\nCode\nfull.model &lt;- lm(FE ~ ., data = cars2010)\nempty.model &lt;- lm(FE ~ 1, data = cars2010)\n\nfor.model &lt;- step(empty.model,\n    scope = list(\n        lower = empty.model,\n        upper = full.model\n    ), direction = \"forward\", k = qchisq(0.10, 1, lower.tail = FALSE)\n)\n\n\nStart:  AIC=4462.12\nFE ~ 1\n\n                      Df Sum of Sq   RSS    AIC\n+ EngDispl             1     38551 23629 3393.7\n+ NumCyl               8     37510 24669 3460.4\n+ DriveDesc            4     27081 35099 3839.9\n+ CarlineClassDesc    16     20274 41906 4068.6\n+ Transmission        15     10894 51285 4289.5\n+ ExhaustValvesPerCyl  2      7168 55012 4331.9\n+ IntakeValvePerCyl    3      5212 56968 4373.3\n+ TransLockup          1      4598 57582 4379.8\n+ NumGears             5      3807 58372 4405.7\n+ VarValveTiming       1       971 61209 4447.4\n+ AirAspirationMethod  2       819 61361 4452.9\n+ VarValveLift         1       576 61604 4454.5\n+ TransCreeperGear     1       301 61878 4459.4\n&lt;none&gt;                             62180 4462.1\n\nStep:  AIC=3393.74\nFE ~ EngDispl\n\n                      Df Sum of Sq   RSS    AIC\n+ CarlineClassDesc    16    6046.9 17582 3109.8\n+ DriveDesc            4    5489.6 18139 3111.9\n+ NumCyl               8    2065.5 21564 3314.1\n+ Transmission        15    1837.0 21792 3344.7\n+ NumGears             5     944.9 22684 3362.1\n+ IntakeValvePerCyl    3     796.8 22832 3363.9\n+ ExhaustValvesPerCyl  2     682.3 22947 3366.7\n+ TransLockup          1     556.5 23072 3370.1\n+ VarValveTiming       1     316.8 23312 3381.5\n+ TransCreeperGear     1     147.1 23482 3389.5\n+ AirAspirationMethod  2     183.5 23446 3390.5\n&lt;none&gt;                             23629 3393.7\n+ VarValveLift         1      49.3 23580 3394.1\n\nStep:  AIC=3109.81\nFE ~ EngDispl + CarlineClassDesc\n\n                      Df Sum of Sq   RSS    AIC\n+ NumCyl               8   3095.27 14487 2917.1\n+ DriveDesc            4   2769.57 14812 2930.9\n+ Transmission        15   2214.76 15367 3001.3\n+ IntakeValvePerCyl    3   1583.01 15999 3013.5\n+ ExhaustValvesPerCyl  2   1321.06 16261 3028.8\n+ NumGears             5    785.78 16796 3072.7\n+ AirAspirationMethod  2    554.30 17028 3079.8\n+ TransLockup          1    157.41 17425 3102.6\n+ VarValveTiming       1     47.86 17534 3109.5\n+ TransCreeperGear     1     44.15 17538 3109.7\n&lt;none&gt;                             17582 3109.8\n+ VarValveLift         1      2.69 17579 3112.3\n\nStep:  AIC=2917.09\nFE ~ EngDispl + CarlineClassDesc + NumCyl\n\n                      Df Sum of Sq   RSS    AIC\n+ DriveDesc            4   2018.52 12468 2761.8\n+ Transmission        15   1373.88 13113 2847.4\n+ IntakeValvePerCyl    2    550.79 13936 2879.6\n+ ExhaustValvesPerCyl  1    472.21 14015 2883.1\n+ AirAspirationMethod  2    417.97 14069 2890.1\n+ NumGears             5    469.35 14018 2894.2\n+ TransLockup          1     57.39 14430 2915.4\n&lt;none&gt;                             14487 2917.1\n+ VarValveTiming       1     34.17 14453 2917.2\n+ TransCreeperGear     1      9.42 14477 2919.1\n+ VarValveLift         1      7.55 14479 2919.2\n\nStep:  AIC=2761.81\nFE ~ EngDispl + CarlineClassDesc + NumCyl + DriveDesc\n\n                      Df Sum of Sq   RSS    AIC\n+ Transmission        15   1139.29 11329 2696.3\n+ NumGears             5    504.45 11964 2729.6\n+ IntakeValvePerCyl    2    399.50 12069 2731.2\n+ ExhaustValvesPerCyl  1    336.65 12132 2734.2\n+ AirAspirationMethod  2    114.72 12354 2757.0\n+ VarValveLift         1     61.68 12407 2759.0\n+ TransLockup          1     60.82 12408 2759.1\n&lt;none&gt;                             12468 2761.8\n+ VarValveTiming       1     27.11 12441 2762.1\n+ TransCreeperGear     1     13.62 12455 2763.3\n\nStep:  AIC=2696.32\nFE ~ EngDispl + CarlineClassDesc + NumCyl + DriveDesc + Transmission\n\n                      Df Sum of Sq   RSS    AIC\n+ IntakeValvePerCyl    2    461.88 10867 2655.7\n+ ExhaustValvesPerCyl  1    383.34 10946 2660.9\n+ NumGears             2    153.67 11175 2686.6\n+ VarValveLift         1    113.24 11216 2687.9\n+ AirAspirationMethod  2    107.19 11222 2691.2\n+ TransLockup          1     58.68 11270 2693.3\n&lt;none&gt;                             11329 2696.3\n+ TransCreeperGear     1     24.24 11305 2696.7\n+ VarValveTiming       1      0.83 11328 2698.9\n\nStep:  AIC=2655.65\nFE ~ EngDispl + CarlineClassDesc + NumCyl + DriveDesc + Transmission + \n    IntakeValvePerCyl\n\n                      Df Sum of Sq   RSS    AIC\n+ VarValveLift         1   137.817 10729 2644.2\n+ AirAspirationMethod  2   159.280 10708 2644.7\n+ NumGears             2   122.472 10745 2648.5\n+ TransCreeperGear     1    43.328 10824 2653.9\n+ TransLockup          1    43.023 10824 2654.0\n&lt;none&gt;                             10867 2655.7\n+ ExhaustValvesPerCyl  1    10.801 10856 2657.2\n+ VarValveTiming       1     9.160 10858 2657.4\n\nStep:  AIC=2644.23\nFE ~ EngDispl + CarlineClassDesc + NumCyl + DriveDesc + Transmission + \n    IntakeValvePerCyl + VarValveLift\n\n                      Df Sum of Sq   RSS    AIC\n+ AirAspirationMethod  2   112.550 10617 2638.0\n+ NumGears             2   110.633 10619 2638.2\n+ TransLockup          1    46.480 10683 2642.1\n+ TransCreeperGear     1    33.554 10696 2643.5\n&lt;none&gt;                             10729 2644.2\n+ ExhaustValvesPerCyl  1    12.071 10717 2645.7\n+ VarValveTiming       1     9.141 10720 2646.0\n\nStep:  AIC=2637.96\nFE ~ EngDispl + CarlineClassDesc + NumCyl + DriveDesc + Transmission + \n    IntakeValvePerCyl + VarValveLift + AirAspirationMethod\n\n                      Df Sum of Sq   RSS    AIC\n+ NumGears             2   113.576 10503 2631.5\n+ TransLockup          1    59.507 10557 2634.4\n+ TransCreeperGear     1    36.860 10580 2636.8\n+ ExhaustValvesPerCyl  1    27.327 10589 2637.8\n&lt;none&gt;                             10617 2638.0\n+ VarValveTiming       1     5.601 10611 2640.1\n\nStep:  AIC=2631.47\nFE ~ EngDispl + CarlineClassDesc + NumCyl + DriveDesc + Transmission + \n    IntakeValvePerCyl + VarValveLift + AirAspirationMethod + \n    NumGears\n\n                      Df Sum of Sq   RSS    AIC\n+ TransLockup          1    65.211 10438 2627.3\n+ TransCreeperGear     1    34.620 10469 2630.5\n&lt;none&gt;                             10503 2631.5\n+ ExhaustValvesPerCyl  1    22.284 10481 2631.8\n+ VarValveTiming       1     5.577 10498 2633.6\n\nStep:  AIC=2627.28\nFE ~ EngDispl + CarlineClassDesc + NumCyl + DriveDesc + Transmission + \n    IntakeValvePerCyl + VarValveLift + AirAspirationMethod + \n    NumGears + TransLockup\n\n                      Df Sum of Sq   RSS    AIC\n+ TransCreeperGear     1    32.717 10405 2626.5\n&lt;none&gt;                             10438 2627.3\n+ ExhaustValvesPerCyl  1    21.528 10416 2627.7\n+ VarValveTiming       1     5.583 10432 2629.4\n\nStep:  AIC=2626.51\nFE ~ EngDispl + CarlineClassDesc + NumCyl + DriveDesc + Transmission + \n    IntakeValvePerCyl + VarValveLift + AirAspirationMethod + \n    NumGears + TransLockup + TransCreeperGear\n\n                      Df Sum of Sq   RSS    AIC\n+ ExhaustValvesPerCyl  1    39.294 10366 2625.0\n&lt;none&gt;                             10405 2626.5\n+ VarValveTiming       1     1.042 10404 2629.1\n\nStep:  AIC=2625.03\nFE ~ EngDispl + CarlineClassDesc + NumCyl + DriveDesc + Transmission + \n    IntakeValvePerCyl + VarValveLift + AirAspirationMethod + \n    NumGears + TransLockup + TransCreeperGear + ExhaustValvesPerCyl\n\n                 Df Sum of Sq   RSS    AIC\n&lt;none&gt;                        10366 2625.0\n+ VarValveTiming  1    2.9656 10363 2627.4\n\n\n\nFirst variable added is EngDispl\nLast variable added was ExhaustValvesPerCyl\n\n\n\n2 b\n\n\nCode\nstep.model &lt;- step(empty.model,\n    scope = list(\n        lower = empty.model,\n        upper = full.model\n    ), direction = \"both\", k = log(nrow(cars2010))\n)\n\n\nStart:  AIC=4466.42\nFE ~ 1\n\n                      Df Sum of Sq   RSS    AIC\n+ EngDispl             1     38551 23629 3402.3\n+ NumCyl               8     37510 24669 3499.1\n+ DriveDesc            4     27081 35099 3861.4\n+ CarlineClassDesc    16     20274 41906 4141.7\n+ ExhaustValvesPerCyl  2      7168 55012 4344.9\n+ Transmission        15     10894 51285 4358.3\n+ TransLockup          1      4598 57582 4388.4\n+ IntakeValvePerCyl    3      5212 56968 4390.5\n+ NumGears             5      3807 58372 4431.5\n+ VarValveTiming       1       971 61209 4456.0\n+ VarValveLift         1       576 61604 4463.1\n+ AirAspirationMethod  2       819 61361 4465.8\n&lt;none&gt;                             62180 4466.4\n+ TransCreeperGear     1       301 61878 4468.1\n\nStep:  AIC=3402.35\nFE ~ EngDispl\n\n                      Df Sum of Sq   RSS    AIC\n+ DriveDesc            4      5490 18139 3137.7\n+ CarlineClassDesc    16      6047 17582 3187.3\n+ NumCyl               8      2066 21564 3357.2\n+ TransLockup          1       556 23073 3383.0\n+ ExhaustValvesPerCyl  2       682 22947 3383.9\n+ IntakeValvePerCyl    3       797 22832 3385.4\n+ NumGears             5       945 22684 3392.2\n+ VarValveTiming       1       317 23312 3394.4\n&lt;none&gt;                             23629 3402.3\n+ TransCreeperGear     1       147 23482 3402.4\n+ VarValveLift         1        49 23580 3407.0\n+ AirAspirationMethod  2       183 23446 3407.7\n+ Transmission        15      1837 21792 3417.9\n- EngDispl             1     38551 62180 4466.4\n\nStep:  AIC=3137.71\nFE ~ EngDispl + DriveDesc\n\n                      Df Sum of Sq   RSS    AIC\n+ CarlineClassDesc    16    3326.9 14813 3025.6\n+ NumCyl               8    1406.8 16733 3104.4\n+ NumGears             5    1076.1 17063 3105.1\n+ Transmission        15    1951.3 16188 3116.9\n+ TransLockup          1     429.3 17710 3118.2\n+ VarValveLift         1     342.4 17797 3123.6\n+ ExhaustValvesPerCyl  2     382.7 17757 3128.1\n+ IntakeValvePerCyl    3     481.3 17658 3129.0\n+ VarValveTiming       1     217.9 17921 3131.3\n&lt;none&gt;                             18139 3137.7\n+ TransCreeperGear     1      93.7 18046 3139.0\n+ AirAspirationMethod  2       8.5 18131 3151.2\n- DriveDesc            4    5489.6 23629 3402.3\n- EngDispl             1   16959.3 35099 3861.4\n\nStep:  AIC=3025.57\nFE ~ EngDispl + DriveDesc + CarlineClassDesc\n\n                      Df Sum of Sq   RSS    AIC\n+ NumCyl               8    2344.2 12468 2890.9\n+ IntakeValvePerCyl    3    1195.8 13617 2953.4\n+ ExhaustValvesPerCyl  2     957.0 13856 2965.6\n+ Transmission        15    1652.0 13161 2999.8\n+ NumGears             5     597.2 14215 3015.1\n+ TransLockup          1     104.8 14708 3024.7\n+ VarValveLift         1     100.8 14712 3025.0\n&lt;none&gt;                             14812 3025.6\n+ AirAspirationMethod  2     153.2 14659 3028.1\n+ TransCreeperGear     1      38.4 14774 3029.7\n+ VarValveTiming       1      35.8 14777 3029.9\n- CarlineClassDesc    16    3326.9 18139 3137.7\n- DriveDesc            4    2769.6 17582 3187.3\n- EngDispl             1   12424.8 27237 3692.8\n\nStep:  AIC=2890.92\nFE ~ EngDispl + DriveDesc + CarlineClassDesc + NumCyl\n\n                      Df Sum of Sq   RSS    AIC\n+ ExhaustValvesPerCyl  1     336.6 12132 2867.6\n+ IntakeValvePerCyl    2     399.5 12069 2868.9\n+ NumGears             5     504.5 11964 2880.2\n+ Transmission        15    1139.3 11329 2890.0\n&lt;none&gt;                             12468 2890.9\n+ VarValveLift         1      61.7 12407 2892.4\n+ TransLockup          1      60.8 12408 2892.5\n+ AirAspirationMethod  2     114.7 12354 2894.7\n+ VarValveTiming       1      27.1 12441 2895.5\n+ TransCreeperGear     1      13.6 12455 2896.7\n- EngDispl             1     481.6 12950 2925.9\n- NumCyl               8    2344.2 14812 3025.6\n- DriveDesc            4    2018.5 14487 3029.0\n- CarlineClassDesc    16    4264.3 16733 3104.4\n\nStep:  AIC=2867.63\nFE ~ EngDispl + DriveDesc + CarlineClassDesc + NumCyl + ExhaustValvesPerCyl\n\n                      Df Sum of Sq   RSS    AIC\n+ NumGears             5     645.1 11487 2842.2\n+ Transmission        15    1186.0 10946 2858.9\n+ VarValveTiming       1      94.5 12037 2866.0\n+ VarValveLift         1      87.9 12044 2866.6\n&lt;none&gt;                             12132 2867.6\n+ AirAspirationMethod  2     150.1 11982 2867.9\n+ TransLockup          1      61.3 12070 2869.0\n+ TransCreeperGear     1      57.8 12074 2869.4\n+ IntakeValvePerCyl    2      71.1 12061 2875.2\n- ExhaustValvesPerCyl  1     336.6 12468 2890.9\n- EngDispl             1     674.5 12806 2920.5\n- NumCyl               7    1723.9 13856 2965.7\n- DriveDesc            4    1883.0 14015 2999.3\n- CarlineClassDesc    16    4578.1 16710 3109.9\n\nStep:  AIC=2842.19\nFE ~ EngDispl + DriveDesc + CarlineClassDesc + NumCyl + ExhaustValvesPerCyl + \n    NumGears\n\n                      Df Sum of Sq   RSS    AIC\n+ AirAspirationMethod  2     230.4 11256 2833.8\n+ VarValveLift         1      89.3 11397 2840.6\n&lt;none&gt;                             11487 2842.2\n+ TransCreeperGear     1      70.1 11416 2842.4\n+ VarValveTiming       1      29.7 11457 2846.3\n+ IntakeValvePerCyl    2      78.0 11409 2848.7\n+ TransLockup          1       5.1 11482 2848.7\n+ Transmission        12     657.4 10829 2861.1\n- NumGears             5     645.1 12132 2867.6\n- ExhaustValvesPerCyl  1     477.3 11964 2880.2\n- EngDispl             1     701.9 12188 2900.8\n- NumCyl               7    1661.8 13148 2942.7\n- DriveDesc            4    2012.5 13499 2992.9\n- CarlineClassDesc    16    3701.5 15188 3039.3\n\nStep:  AIC=2833.79\nFE ~ EngDispl + DriveDesc + CarlineClassDesc + NumCyl + ExhaustValvesPerCyl + \n    NumGears + AirAspirationMethod\n\n                      Df Sum of Sq   RSS    AIC\n+ TransCreeperGear     1      87.8 11168 2832.1\n&lt;none&gt;                             11256 2833.8\n+ VarValveLift         1      53.0 11203 2835.6\n+ VarValveTiming       1      24.0 11232 2838.4\n+ TransLockup          1       5.2 11251 2840.3\n+ IntakeValvePerCyl    2      65.5 11191 2841.3\n- AirAspirationMethod  2     230.4 11487 2842.2\n+ Transmission        12     620.0 10636 2855.2\n- NumGears             5     725.4 11982 2867.9\n- ExhaustValvesPerCyl  1     561.0 11817 2880.6\n- EngDispl             1     800.7 12057 2902.8\n- NumCyl               7    1623.7 12880 2933.9\n- DriveDesc            4    1659.9 12916 2958.0\n- CarlineClassDesc    16    3863.1 15119 3048.3\n\nStep:  AIC=2832.13\nFE ~ EngDispl + DriveDesc + CarlineClassDesc + NumCyl + ExhaustValvesPerCyl + \n    NumGears + AirAspirationMethod + TransCreeperGear\n\n                      Df Sum of Sq   RSS    AIC\n&lt;none&gt;                             11168 2832.1\n- TransCreeperGear     1      87.8 11256 2833.8\n+ VarValveLift         1      42.5 11126 2834.9\n+ VarValveTiming       1       8.2 11160 2838.3\n+ TransLockup          1       2.9 11166 2838.9\n+ IntakeValvePerCyl    2      44.3 11124 2841.8\n- AirAspirationMethod  2     248.0 11416 2842.4\n+ Transmission        12     613.6 10555 2853.7\n- NumGears             5     748.6 11917 2868.9\n- ExhaustValvesPerCyl  1     633.5 11802 2886.2\n- EngDispl             1     852.6 12021 2906.6\n- NumCyl               7    1544.6 12713 2926.5\n- DriveDesc            4    1648.4 12817 2956.5\n- CarlineClassDesc    16    3835.2 15004 3046.8\n\n\n\n8 variables remain after stepwise\nDid not get the same models between the two different methods. Stepwise had less"
  },
  {
    "objectID": "notes/analytics/07132023/lab_11.html",
    "href": "notes/analytics/07132023/lab_11.html",
    "title": "Lab 11",
    "section": "",
    "text": "Code\nlibrary(AppliedPredictiveModeling)\nlibrary(glmnet)\n\n\nLoading required package: Matrix\n\n\nLoaded glmnet 4.1-7\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::expand() masks Matrix::expand()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ tidyr::pack()   masks Matrix::pack()\n✖ tidyr::unpack() masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\ndata(FuelEconomy)\nstr(cars2010)\n\n\n'data.frame':   1107 obs. of  14 variables:\n $ EngDispl           : num  4.7 4.7 4.2 4.2 5.2 5.2 2 6 3 3 ...\n $ NumCyl             : int  8 8 8 8 10 10 4 12 6 6 ...\n $ Transmission       : Factor w/ 16 levels \"Other\",\"A4\",\"A5\",..: 6 11 11 6 6 11 14 14 14 11 ...\n $ FE                 : num  28 25.6 26.8 25 24.8 ...\n $ AirAspirationMethod: Factor w/ 3 levels \"NaturallyAspirated\",..: 1 1 1 1 1 1 3 3 1 1 ...\n $ NumGears           : int  6 6 6 6 6 6 6 6 6 6 ...\n $ TransLockup        : num  1 1 1 1 0 0 0 0 1 0 ...\n $ TransCreeperGear   : num  0 0 0 0 0 0 0 0 0 0 ...\n $ DriveDesc          : Factor w/ 5 levels \"AllWheelDrive\",..: 5 5 1 1 1 1 1 1 5 5 ...\n $ IntakeValvePerCyl  : int  2 2 2 2 2 2 2 2 2 2 ...\n $ ExhaustValvesPerCyl: int  2 2 2 2 2 2 2 2 2 2 ...\n $ CarlineClassDesc   : Factor w/ 17 levels \"Other\",\"2Seaters\",..: 2 2 2 2 2 2 2 2 2 2 ...\n $ VarValveTiming     : num  1 1 1 1 1 1 1 1 1 1 ...\n $ VarValveLift       : num  0 0 0 0 0 0 0 0 1 1 ...\n\n\n\n\n\n\nCode\ncars2010 &lt;- cars2010 %&gt;%\n    mutate(across(!c(EngDispl, FE), as.factor))\n\nx &lt;- model.matrix(FE ~ ., data = cars2010)[, -1]\ny &lt;- cars2010$FE\ncars2010_lasso &lt;- glmnet(x = x, y = y, data = cars2010, alpha = 1)\nplot(cars2010_lasso, xvar = \"lambda\")\n\n\n\n\n\n\n\n\n\n\nCode\ncars2010_lasso_cv &lt;- cv.glmnet(x = x, y = y, data = cars2010, alpha = 1)\nsprintf(\"Lambda Min: %f\", cars2010_lasso_cv$lambda.min)\n\n\n[1] \"Lambda Min: 0.002870\"\n\n\nCode\nsprintf(\"Lambda 1se: %f\", cars2010_lasso_cv$lambda.1se)\n\n\n[1] \"Lambda 1se: 0.089694\"\n\n\nCode\ncoef(cars2010_lasso, s = c(cars2010_lasso_cv$lambda.min, cars2010_lasso_cv$lambda.1se))\n\n\n61 x 2 sparse Matrix of class \"dgCMatrix\"\n                                                        s1          s2\n(Intercept)                                     33.4330547 41.56381395\nEngDispl                                        -2.2515600 -2.64871030\nNumCyl3                                         19.8714674 16.08294170\nNumCyl4                                          5.2098276  2.80326601\nNumCyl5                                          2.3303954  .         \nNumCyl6                                          1.6471031  .         \nNumCyl8                                          .         -0.35233930\nNumCyl10                                        -2.4760490 -1.94293929\nNumCyl12                                        -3.6066709 -3.09165724\nNumCyl16                                        -2.6386639  .         \nTransmissionA4                                  -0.1289561  .         \nTransmissionA5                                   .         -0.07118433\nTransmissionA6                                   .          0.79992685\nTransmissionA7                                   4.4293541  1.14687576\nTransmissionAM6                                 -4.5233550 -2.33569908\nTransmissionAM7                                 -0.5109815 -1.95260587\nTransmissionAV                                  -0.3407425  1.89085628\nTransmissionAVS6                                -2.6423257  .         \nTransmissionM5                                  -0.4234284  .         \nTransmissionM6                                  -2.1092755  .         \nTransmissionS4                                  -3.5982691 -2.56675152\nTransmissionS5                                  -0.6341689 -0.41170358\nTransmissionS6                                  -0.1991123  0.71462465\nTransmissionS7                                   2.7936830  .         \nTransmissionS8                                   .          0.55519141\nAirAspirationMethodSupercharged                 -1.6299305 -0.53737070\nAirAspirationMethodTurbocharged                 -1.1035917 -0.50635048\nNumGears4                                       -2.7678389 -0.50071284\nNumGears5                                       -2.5004485 -0.01449604\nNumGears6                                       -0.8704482  .         \nNumGears7                                       -5.4460909  .         \nNumGears8                                        1.2124264  1.45221734\nTransLockup1                                    -0.8704252 -0.42999697\nTransCreeperGear1                               -1.0218821 -0.31196410\nDriveDescFourWheelDrive                         -0.4425424 -0.21511866\nDriveDescParttimeFourWheelDrive                 -0.2721910  .         \nDriveDescTwoWheelDriveFront                      4.3169571  4.38229982\nDriveDescTwoWheelDriveRear                       1.1841530  1.01500559\nIntakeValvePerCyl1                               7.2995450  1.80802827\nIntakeValvePerCyl2                               5.8560566  .         \nIntakeValvePerCyl3                               0.9449583 -1.14286876\nExhaustValvesPerCyl1                             1.7407865  0.23026484\nExhaustValvesPerCyl2                             0.1803456  .         \nCarlineClassDesc2Seaters                         2.6478930  .         \nCarlineClassDescCompactCars                      3.6646287  1.65977465\nCarlineClassDescLargeCars                        2.4052064  0.16740538\nCarlineClassDescMidsizeCars                      3.2705073  1.29425446\nCarlineClassDescMinicompactCars                  3.4615403  1.05171759\nCarlineClassDescSmallPickupTrucks2WD            -1.9551276 -2.77622589\nCarlineClassDescSmallPickupTrucks4WD            -1.0733032 -2.11462468\nCarlineClassDescSmallStationWagons               2.0462284  .         \nCarlineClassDescSpecialPurposeVehicleminivan2WD -2.1765509 -2.68080231\nCarlineClassDescSpecialPurposeVehicleSUV2WD     -1.6494719 -2.77273354\nCarlineClassDescSpecialPurposeVehicleSUV4WD     -0.7147677 -2.28453688\nCarlineClassDescStandardPickupTrucks2WD         -1.8678699 -2.35575424\nCarlineClassDescStandardPickupTrucks4WD         -2.0868842 -2.99063494\nCarlineClassDescSubcompactCars                   3.2417627  0.78507486\nCarlineClassDescVansCargoTypes                  -4.2072695 -4.47865259\nCarlineClassDescVansPassengerType               -4.4006003 -4.32429849\nVarValveTiming1                                  0.1832049  0.12552736\nVarValveLift1                                    0.8687307  0.95165030"
  },
  {
    "objectID": "notes/analytics/07132023/lab_11.html#a",
    "href": "notes/analytics/07132023/lab_11.html#a",
    "title": "Lab 11",
    "section": "",
    "text": "Code\ncars2010 &lt;- cars2010 %&gt;%\n    mutate(across(!c(EngDispl, FE), as.factor))\n\nx &lt;- model.matrix(FE ~ ., data = cars2010)[, -1]\ny &lt;- cars2010$FE\ncars2010_lasso &lt;- glmnet(x = x, y = y, data = cars2010, alpha = 1)\nplot(cars2010_lasso, xvar = \"lambda\")"
  },
  {
    "objectID": "notes/analytics/07132023/lab_11.html#b",
    "href": "notes/analytics/07132023/lab_11.html#b",
    "title": "Lab 11",
    "section": "",
    "text": "Code\ncars2010_lasso_cv &lt;- cv.glmnet(x = x, y = y, data = cars2010, alpha = 1)\nsprintf(\"Lambda Min: %f\", cars2010_lasso_cv$lambda.min)\n\n\n[1] \"Lambda Min: 0.002870\"\n\n\nCode\nsprintf(\"Lambda 1se: %f\", cars2010_lasso_cv$lambda.1se)\n\n\n[1] \"Lambda 1se: 0.089694\"\n\n\nCode\ncoef(cars2010_lasso, s = c(cars2010_lasso_cv$lambda.min, cars2010_lasso_cv$lambda.1se))\n\n\n61 x 2 sparse Matrix of class \"dgCMatrix\"\n                                                        s1          s2\n(Intercept)                                     33.4330547 41.56381395\nEngDispl                                        -2.2515600 -2.64871030\nNumCyl3                                         19.8714674 16.08294170\nNumCyl4                                          5.2098276  2.80326601\nNumCyl5                                          2.3303954  .         \nNumCyl6                                          1.6471031  .         \nNumCyl8                                          .         -0.35233930\nNumCyl10                                        -2.4760490 -1.94293929\nNumCyl12                                        -3.6066709 -3.09165724\nNumCyl16                                        -2.6386639  .         \nTransmissionA4                                  -0.1289561  .         \nTransmissionA5                                   .         -0.07118433\nTransmissionA6                                   .          0.79992685\nTransmissionA7                                   4.4293541  1.14687576\nTransmissionAM6                                 -4.5233550 -2.33569908\nTransmissionAM7                                 -0.5109815 -1.95260587\nTransmissionAV                                  -0.3407425  1.89085628\nTransmissionAVS6                                -2.6423257  .         \nTransmissionM5                                  -0.4234284  .         \nTransmissionM6                                  -2.1092755  .         \nTransmissionS4                                  -3.5982691 -2.56675152\nTransmissionS5                                  -0.6341689 -0.41170358\nTransmissionS6                                  -0.1991123  0.71462465\nTransmissionS7                                   2.7936830  .         \nTransmissionS8                                   .          0.55519141\nAirAspirationMethodSupercharged                 -1.6299305 -0.53737070\nAirAspirationMethodTurbocharged                 -1.1035917 -0.50635048\nNumGears4                                       -2.7678389 -0.50071284\nNumGears5                                       -2.5004485 -0.01449604\nNumGears6                                       -0.8704482  .         \nNumGears7                                       -5.4460909  .         \nNumGears8                                        1.2124264  1.45221734\nTransLockup1                                    -0.8704252 -0.42999697\nTransCreeperGear1                               -1.0218821 -0.31196410\nDriveDescFourWheelDrive                         -0.4425424 -0.21511866\nDriveDescParttimeFourWheelDrive                 -0.2721910  .         \nDriveDescTwoWheelDriveFront                      4.3169571  4.38229982\nDriveDescTwoWheelDriveRear                       1.1841530  1.01500559\nIntakeValvePerCyl1                               7.2995450  1.80802827\nIntakeValvePerCyl2                               5.8560566  .         \nIntakeValvePerCyl3                               0.9449583 -1.14286876\nExhaustValvesPerCyl1                             1.7407865  0.23026484\nExhaustValvesPerCyl2                             0.1803456  .         \nCarlineClassDesc2Seaters                         2.6478930  .         \nCarlineClassDescCompactCars                      3.6646287  1.65977465\nCarlineClassDescLargeCars                        2.4052064  0.16740538\nCarlineClassDescMidsizeCars                      3.2705073  1.29425446\nCarlineClassDescMinicompactCars                  3.4615403  1.05171759\nCarlineClassDescSmallPickupTrucks2WD            -1.9551276 -2.77622589\nCarlineClassDescSmallPickupTrucks4WD            -1.0733032 -2.11462468\nCarlineClassDescSmallStationWagons               2.0462284  .         \nCarlineClassDescSpecialPurposeVehicleminivan2WD -2.1765509 -2.68080231\nCarlineClassDescSpecialPurposeVehicleSUV2WD     -1.6494719 -2.77273354\nCarlineClassDescSpecialPurposeVehicleSUV4WD     -0.7147677 -2.28453688\nCarlineClassDescStandardPickupTrucks2WD         -1.8678699 -2.35575424\nCarlineClassDescStandardPickupTrucks4WD         -2.0868842 -2.99063494\nCarlineClassDescSubcompactCars                   3.2417627  0.78507486\nCarlineClassDescVansCargoTypes                  -4.2072695 -4.47865259\nCarlineClassDescVansPassengerType               -4.4006003 -4.32429849\nVarValveTiming1                                  0.1832049  0.12552736\nVarValveLift1                                    0.8687307  0.95165030"
  },
  {
    "objectID": "notes/analytics/07182023/index.html",
    "href": "notes/analytics/07182023/index.html",
    "title": "Introduction to Logistic Regression",
    "section": "",
    "text": "Code\nlibrary(AmesHousing)\nlibrary(tidyverse)\nlibrary(reticulate)\n\nuse_condaenv(\"blues_clues\")\n\nset.seed(123)\names &lt;- make_ordinal_ames()\n\names &lt;- ames %&gt;%\n    mutate(id = row_number())\ntrain &lt;- ames %&gt;% sample_frac(0.7)\ntrain &lt;- train %&gt;%\n    mutate(Bonus = ifelse(Sale_Price &gt; 175000, 1, 0))\n\n\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport statsmodels.formula.api as smf\n\ntrain = r.train\n\n\nLogistic regression is one of many classification models that can help us predict a specific class in a categorical variable.\nOne of the most common targets we will be trying to predict is a binary target variable (Yes / No, 1 / 0)."
  },
  {
    "objectID": "notes/analytics/07182023/index.html#logit-link-function",
    "href": "notes/analytics/07182023/index.html#logit-link-function",
    "title": "Introduction to Logistic Regression",
    "section": "3.1 Logit Link Function",
    "text": "3.1 Logit Link Function\nTo create linear model, a logit function is applied to the probabilities:\n\\[\n\\log(\\frac{p_i}{1 - p_i}) = \\beta_0 + \\beta_1x_{1,i} + \\cdots + \\beta_k x_{k,i}\n\\]\n\n\\(\\frac{p_i}{1 - p_i}\\) is the odds of an outcome happening\nThe relationship between parameters and logits are linear\nLogits unbounded"
  },
  {
    "objectID": "notes/analytics/07182023/index.html#assumptions",
    "href": "notes/analytics/07182023/index.html#assumptions",
    "title": "Introduction to Logistic Regression",
    "section": "3.2 Assumptions",
    "text": "3.2 Assumptions\n\nIndependence of observations\nLogit is linearly related to variables"
  },
  {
    "objectID": "notes/analytics/07182023/index.html#r-code",
    "href": "notes/analytics/07182023/index.html#r-code",
    "title": "Introduction to Logistic Regression",
    "section": "3.3 R Code",
    "text": "3.3 R Code\n\n\nCode\names_logit &lt;- glm(Bonus ~ Gr_Liv_Area, data = train, family = binomial())\n\nsummary(ames_logit)\n\n\n\nCall:\nglm(formula = Bonus ~ Gr_Liv_Area, family = binomial(), data = train)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -6.1348858  0.2757473  -22.25   &lt;2e-16 ***\nGr_Liv_Area  0.0038463  0.0001799   21.38   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2775.8  on 2050  degrees of freedom\nResidual deviance: 1926.4  on 2049  degrees of freedom\nAIC: 1930.4\n\nNumber of Fisher Scoring iterations: 5"
  },
  {
    "objectID": "notes/analytics/07182023/index.html#python-code",
    "href": "notes/analytics/07182023/index.html#python-code",
    "title": "Introduction to Logistic Regression",
    "section": "3.4 Python Code",
    "text": "3.4 Python Code\n\n\nCode\names_logit = smf.logit(\"Bonus ~ Gr_Liv_Area\", data=train).fit()\n\n\nOptimization terminated successfully.\n         Current function value: 0.469614\n         Iterations 7\n\n\nCode\names_logit.summary()\n\n\n\nLogit Regression Results\n\n\nDep. Variable:\nBonus\nNo. Observations:\n2051\n\n\nModel:\nLogit\nDf Residuals:\n2049\n\n\nMethod:\nMLE\nDf Model:\n1\n\n\nDate:\nTue, 18 Jul 2023\nPseudo R-squ.:\n0.3060\n\n\nTime:\n14:14:54\nLog-Likelihood:\n-963.18\n\n\nconverged:\nTrue\nLL-Null:\n-1387.9\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n9.553e-187\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nIntercept\n-6.1349\n0.276\n-22.248\n0.000\n-6.675\n-5.594\n\n\nGr_Liv_Area\n0.0038\n0.000\n21.375\n0.000\n0.003\n0.004"
  },
  {
    "objectID": "notes/analytics/07182023/index.html#r-code-1",
    "href": "notes/analytics/07182023/index.html#r-code-1",
    "title": "Introduction to Logistic Regression",
    "section": "4.1 R Code",
    "text": "4.1 R Code\n\n\nCode\n100 * (exp(cbind(coef(ames_logit), confint(ames_logit))) - 1)\n\n\nWaiting for profiling to be done...\n\n\n                              2.5 %      97.5 %\n(Intercept) -99.7834027 -99.8755103 -99.6328865\nGr_Liv_Area   0.3853699   0.3508132   0.4216532\n\n\nThe reason we subtract by 1 is that 1 is the center point of odds. We subtract to help center back around 0.\nEvery additional square foot of greater living area increases the expected odds of being bonus eligible by 0.38%.\nIn practice, a client will care more about this interpretation of how an outcome odds changes rather than the pure technical details behind how a model was built."
  },
  {
    "objectID": "notes/analytics/07182023/index.html#categorical-variable-interpretation",
    "href": "notes/analytics/07182023/index.html#categorical-variable-interpretation",
    "title": "Introduction to Logistic Regression",
    "section": "4.2 Categorical Variable Interpretation",
    "text": "4.2 Categorical Variable Interpretation\n\n\nCode\names_logit2 &lt;- glm(Bonus ~ Gr_Liv_Area + Central_Air + factor(Fireplaces), data = train, family = binomial())\n\n100 * (exp(cbind(coef(ames_logit2), confint(ames_logit2))) - 1)\n\n\nWaiting for profiling to be done...\n\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\n                                         2.5 %        97.5 %\n(Intercept)         -9.999532e+01  -99.9988238   -99.9843742\nGr_Liv_Area          3.766413e-01    0.3376191     0.4175879\nCentral_AirY         3.429115e+03 1264.8396218 11177.2021479\nfactor(Fireplaces)1  1.670410e+02  108.9856565   241.6360910\nfactor(Fireplaces)2  9.607987e+01   22.4764491   214.9571145\nfactor(Fireplaces)3 -3.914247e+00  -81.9507819   497.4825425\nfactor(Fireplaces)4  8.308750e+05 -100.0000000            NA\n\n\nCode\nexp(cbind(coef(ames_logit2), confint(ames_logit2)))\n\n\nWaiting for profiling to be done...\n\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\n                                        2.5 %       97.5 %\n(Intercept)         4.678435e-05 1.176215e-05 1.562580e-04\nGr_Liv_Area         1.003766e+00 1.003376e+00 1.004176e+00\nCentral_AirY        3.529115e+01 1.364840e+01 1.127720e+02\nfactor(Fireplaces)1 2.670410e+00 2.089857e+00 3.416361e+00\nfactor(Fireplaces)2 1.960799e+00 1.224764e+00 3.149571e+00\nfactor(Fireplaces)3 9.608575e-01 1.804922e-01 5.974825e+00\nfactor(Fireplaces)4 8.309750e+03 1.523733e-25           NA\n\n\nCode\ncoef(ames_logit2)\n\n\n        (Intercept)         Gr_Liv_Area        Central_AirY factor(Fireplaces)1 \n       -9.969961800         0.003759338         3.563632363         0.982231915 \nfactor(Fireplaces)2 factor(Fireplaces)3 factor(Fireplaces)4 \n        0.673351875        -0.039929137         9.025184862 \n\n\nHomes with central air increases the expected odds of being bonus eligible by 3416% compared to those without central air.\nA more believable way of saying this would be \\(e^{3.56} = 35.16\\) times more likely to be bonus eligible than compared to those without central air."
  },
  {
    "objectID": "notes/analytics/07182023/index.html#concordant",
    "href": "notes/analytics/07182023/index.html#concordant",
    "title": "Introduction to Logistic Regression",
    "section": "5.1 Concordant",
    "text": "5.1 Concordant\n0 and 1 pair where bonus eligible home (1) has a higher predicted probability than the non-bonus eligible home (0).\nDoes not matter what the actual predicted probability values are as long as the bonus eligible home has a higher predicted probability than the non-bonus eligible home."
  },
  {
    "objectID": "notes/analytics/07182023/index.html#discordant",
    "href": "notes/analytics/07182023/index.html#discordant",
    "title": "Introduction to Logistic Regression",
    "section": "5.2 Discordant",
    "text": "5.2 Discordant\n0 and 1 pair where bonus eligible home (1) has a lower predicted probability than the non-bonus eligible home (0)\nModel unsuccessfully ordered the homes."
  },
  {
    "objectID": "notes/analytics/07182023/index.html#tied-pair",
    "href": "notes/analytics/07182023/index.html#tied-pair",
    "title": "Introduction to Logistic Regression",
    "section": "5.3 Tied Pair",
    "text": "5.3 Tied Pair\n0 and 1 pair where the bonus eligible home has the same predicted probability as the non-bonus eligible home."
  },
  {
    "objectID": "notes/analytics/07182023/index.html#concordance",
    "href": "notes/analytics/07182023/index.html#concordance",
    "title": "Introduction to Logistic Regression",
    "section": "5.4 Concordance",
    "text": "5.4 Concordance\n\n\nCode\nlibrary(survival)\n\nconcordance(ames_logit)\n\n\nCall:\nconcordance.lm(object = ames_logit)\n\nn= 2051 \nConcordance= 0.8632 se= 0.007744\nconcordant discordant     tied.x     tied.y    tied.xy \n    877810     138829        601    1083029       2006 \n\n\nModel correctly ranks bonus eligible homes ahead of non-bonus eligible homes 86.3% of the time. This does not mean that our model is accurate 86.3% of the time."
  },
  {
    "objectID": "notes/analytics/06272023/index.html",
    "href": "notes/analytics/06272023/index.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Our variables are quantities or qualities of interest. These are also called:\n\nAttributes\nFeatures\nPredictors/Targets\nFactors\nInputs/Outputs\nCovariates\n\n\n\nQuantitative variables have a quantity value associated with them. These are intervals, numerics or ratios.\n\nTime\nTemperature\nPrice\n\n\n\n\nCategorical variables are inherently described by categories instead of quantities.\nThere are two types of categorical variables:\n\nNominal\n\nSoda, Milk, Tea\n\nOrdinal\n\nHave logical orderings associated with them\nSmall, Medium, Large\n\n\nWith ordinal variables, you can treat them as either nominal or quantitative. You have to make the decision.\nCategorical Dummy Variables:\n\n\n\nSmall\nMedium\nLarge\n\n\n\n\n1\n0\n0\n\n\n0\n1\n0\n\n\n0\n0\n1\n\n\n\nThe table shows an example of one-hot encoding. We can achieve this in R using the onehot package:\n\n\nCode\nlibrary(onehot)\n\nset.seed(41)\ndat &lt;- data.frame(\n    y = c(rnorm(10, 2), rnorm(10, 1), rnorm(10, 0)),\n    x1 = factor(rep(c(\"A\", \"B\", \"C\"), each = 10)),\n    x2 = factor(rep(c(\"Z\", \"X\", \"Y\", \"W\", \"V\", \"U\"), each = 5))\n)\n\nencoder &lt;- onehot(dat)\ndummies &lt;- predict(encoder, dat)\nhead(dummies)\n\n\n            y x1=A x1=B x1=C x2=U x2=V x2=W x2=X x2=Y x2=Z\n[1,] 1.205632    1    0    0    0    0    0    0    0    1\n[2,] 2.197258    1    0    0    0    0    0    0    0    1\n[3,] 3.001704    1    0    0    0    0    0    0    0    1\n[4,] 3.288825    1    0    0    0    0    0    0    0    1\n[5,] 2.905753    1    0    0    0    0    0    0    0    1\n[6,] 2.493667    1    0    0    0    0    0    1    0    0\n\n\nAnd in Python:\n\n\nCode\nimport numpy as np\nfrom numpy import random\nimport pandas as pd\n\nx1 = np.repeat([\"A\", \"B\", \"C\"], 10)\nx2 = np.repeat([\"Z\", \"X\", \"Y\", \"W\", \"V\", \"U\"], 5)\n\nrandom.seed(41)\ny = np.concatenate([random.normal(2.0, 1.0, 10), random.normal(1.0, 1.0, 10), random.normal(0.0, 1.0, 10)])\narray = np.array([x1, x2, y])\narray2 = np.transpose(array)\n\ndf = pd.DataFrame(data = array2, columns = [\"x1\", \"x2\", \"y\"])\ndf.head()\n\n\n  x1 x2                   y\n0  A  Z  1.7292876769326795\n1  A  Z    2.10484805260974\n2  A  Z   2.250527815723572\n3  A  Z  1.0748000347219233\n4  A  Z   2.567143660285906\n\n\n\n\nCode\none_hot_encoded_data = pd.get_dummies(df, columns = ['x1', 'x2'])\none_hot_encoded_data.head()\n\n\n                    y  x1_A   x1_B   x1_C  ...   x2_W   x2_X   x2_Y  x2_Z\n0  1.7292876769326795  True  False  False  ...  False  False  False  True\n1    2.10484805260974  True  False  False  ...  False  False  False  True\n2   2.250527815723572  True  False  False  ...  False  False  False  True\n3  1.0748000347219233  True  False  False  ...  False  False  False  True\n4   2.567143660285906  True  False  False  ...  False  False  False  True\n\n[5 rows x 10 columns]\n\n\nThe levels are given values if treated quantitatively:\n\n\n\nSize\nSize\n\n\n\n\nS\n1\n\n\nM\n2\n\n\nL\n3\n\n\n\nIn addition, we also could do optimal scaling to represent the scale of the ordinal variables. This requires a careful definition of a “1-unit” change in the variable.\n\n\n\nEducation\nEducation\n\n\n\n\nNo HS degree\n1\n\n\nGED\n2\n\n\nHS Diploma\n3\n\n\nBachelors\n10\n\n\nMasters\n16\n\n\nPhD\n20"
  },
  {
    "objectID": "notes/analytics/06272023/index.html#quantiative-variables",
    "href": "notes/analytics/06272023/index.html#quantiative-variables",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Quantitative variables have a quantity value associated with them. These are intervals, numerics or ratios.\n\nTime\nTemperature\nPrice"
  },
  {
    "objectID": "notes/analytics/06272023/index.html#categorical-variables",
    "href": "notes/analytics/06272023/index.html#categorical-variables",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Categorical variables are inherently described by categories instead of quantities.\nThere are two types of categorical variables:\n\nNominal\n\nSoda, Milk, Tea\n\nOrdinal\n\nHave logical orderings associated with them\nSmall, Medium, Large\n\n\nWith ordinal variables, you can treat them as either nominal or quantitative. You have to make the decision.\nCategorical Dummy Variables:\n\n\n\nSmall\nMedium\nLarge\n\n\n\n\n1\n0\n0\n\n\n0\n1\n0\n\n\n0\n0\n1\n\n\n\nThe table shows an example of one-hot encoding. We can achieve this in R using the onehot package:\n\n\nCode\nlibrary(onehot)\n\nset.seed(41)\ndat &lt;- data.frame(\n    y = c(rnorm(10, 2), rnorm(10, 1), rnorm(10, 0)),\n    x1 = factor(rep(c(\"A\", \"B\", \"C\"), each = 10)),\n    x2 = factor(rep(c(\"Z\", \"X\", \"Y\", \"W\", \"V\", \"U\"), each = 5))\n)\n\nencoder &lt;- onehot(dat)\ndummies &lt;- predict(encoder, dat)\nhead(dummies)\n\n\n            y x1=A x1=B x1=C x2=U x2=V x2=W x2=X x2=Y x2=Z\n[1,] 1.205632    1    0    0    0    0    0    0    0    1\n[2,] 2.197258    1    0    0    0    0    0    0    0    1\n[3,] 3.001704    1    0    0    0    0    0    0    0    1\n[4,] 3.288825    1    0    0    0    0    0    0    0    1\n[5,] 2.905753    1    0    0    0    0    0    0    0    1\n[6,] 2.493667    1    0    0    0    0    0    1    0    0\n\n\nAnd in Python:\n\n\nCode\nimport numpy as np\nfrom numpy import random\nimport pandas as pd\n\nx1 = np.repeat([\"A\", \"B\", \"C\"], 10)\nx2 = np.repeat([\"Z\", \"X\", \"Y\", \"W\", \"V\", \"U\"], 5)\n\nrandom.seed(41)\ny = np.concatenate([random.normal(2.0, 1.0, 10), random.normal(1.0, 1.0, 10), random.normal(0.0, 1.0, 10)])\narray = np.array([x1, x2, y])\narray2 = np.transpose(array)\n\ndf = pd.DataFrame(data = array2, columns = [\"x1\", \"x2\", \"y\"])\ndf.head()\n\n\n  x1 x2                   y\n0  A  Z  1.7292876769326795\n1  A  Z    2.10484805260974\n2  A  Z   2.250527815723572\n3  A  Z  1.0748000347219233\n4  A  Z   2.567143660285906\n\n\n\n\nCode\none_hot_encoded_data = pd.get_dummies(df, columns = ['x1', 'x2'])\none_hot_encoded_data.head()\n\n\n                    y  x1_A   x1_B   x1_C  ...   x2_W   x2_X   x2_Y  x2_Z\n0  1.7292876769326795  True  False  False  ...  False  False  False  True\n1    2.10484805260974  True  False  False  ...  False  False  False  True\n2   2.250527815723572  True  False  False  ...  False  False  False  True\n3  1.0748000347219233  True  False  False  ...  False  False  False  True\n4   2.567143660285906  True  False  False  ...  False  False  False  True\n\n[5 rows x 10 columns]\n\n\nThe levels are given values if treated quantitatively:\n\n\n\nSize\nSize\n\n\n\n\nS\n1\n\n\nM\n2\n\n\nL\n3\n\n\n\nIn addition, we also could do optimal scaling to represent the scale of the ordinal variables. This requires a careful definition of a “1-unit” change in the variable.\n\n\n\nEducation\nEducation\n\n\n\n\nNo HS degree\n1\n\n\nGED\n2\n\n\nHS Diploma\n3\n\n\nBachelors\n10\n\n\nMasters\n16\n\n\nPhD\n20"
  },
  {
    "objectID": "notes/analytics/06272023/index.html#measures-of-central-tendency",
    "href": "notes/analytics/06272023/index.html#measures-of-central-tendency",
    "title": "Exploratory Data Analysis",
    "section": "2.1 Measures of Central Tendency",
    "text": "2.1 Measures of Central Tendency\n\n2.1.1 Mean\n\\[\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i\n\\]\n\n\n2.1.2 Median\nMiddle value. 50th percentile. Unaffected by outliers. In a right-skew, median is lower than the mean. In a left-skew, median is higher than the mean.\n\n\n2.1.3 Mode\nMost frequent value. Typical for categorical data"
  },
  {
    "objectID": "notes/analytics/06272023/index.html#measures-of-location",
    "href": "notes/analytics/06272023/index.html#measures-of-location",
    "title": "Exploratory Data Analysis",
    "section": "2.2 Measures of Location",
    "text": "2.2 Measures of Location\nPercentiles are a point, \\(x_p\\), in your data for which \\(p\\%\\) of the data is \\(\\leq x_p\\).\nQuantiles are the same thing as percentiles. The 10th percentile is the 0.10 quantile."
  },
  {
    "objectID": "notes/analytics/06272023/index.html#measures-of-spreaddispersion",
    "href": "notes/analytics/06272023/index.html#measures-of-spreaddispersion",
    "title": "Exploratory Data Analysis",
    "section": "2.3 Measures of Spread/Dispersion",
    "text": "2.3 Measures of Spread/Dispersion\nRange is \\(\\text{max}(data) - \\text{min}(data)\\)\n\n2.3.1 Interquartile Range\nIQR is the difference between third and first quartile. What is the range of the middle 50% of data.\n\n\n2.3.2 Variance \\(\\sigma^2\\) and Standard Deviation \nDispersion of the data around the mean. Average squared deviation from the mean.\n\\[\ns^2 = \\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\n\\]\n\nThe \\(n - 1\\) comes from the degrees of freedom. In theory this will make this an unbiased estimator of the variance."
  },
  {
    "objectID": "notes/analytics/06272023/index.html#measure-of-shape",
    "href": "notes/analytics/06272023/index.html#measure-of-shape",
    "title": "Exploratory Data Analysis",
    "section": "2.4 Measure of Shape",
    "text": "2.4 Measure of Shape\n\n2.4.1 Modality\nModality is the number of humps a distribution has. A Normal distribution is unimodal.\n\n\n2.4.2 Skew\nIs the distribution symmetric? Or does it have a longer tail on one side?\n\n\n\nLeft-skew and Right-skew\n\n\n\n\n2.4.3 Kurtosis\nDoes the distribution have thicker/thinner tails than a Normal distribution with same mean and variance?\nA leptokurtic distribution has more data in the tails than a Normal distribution.\nA platykurtic distribution has less data in the tails than a Normal distribution.\nThis only makes sense if you have a symmetric distribution."
  },
  {
    "objectID": "notes/analytics/06272023/index.html#the-normal-distribution",
    "href": "notes/analytics/06272023/index.html#the-normal-distribution",
    "title": "Exploratory Data Analysis",
    "section": "2.5 The Normal Distribution",
    "text": "2.5 The Normal Distribution\nA Normal distribution is a distribution that is\n\nSymmetric\nFully defined by the mean and standard deviation\nBell-shaped / Unimodal\nMean = Median = Mode\nAsymptotic to the x-axis (bounds are \\(-\\infty\\) and \\(\\infty\\))\nKurtosis = 3 (kurtosis often reported as excess kurtosis = kurtosis - 3)\nSkew = 0 (there is no skew)\n\n\n\nCode\nfrom scipy.stats import norm\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(-4, 4, 100)\n\nmean = 0\nsd = 1\n\ny = norm.pdf(x, mean, sd)\n\nplt.plot(x, y)"
  },
  {
    "objectID": "notes/analytics/06272023/index.html#graphical-displays-of-distributions",
    "href": "notes/analytics/06272023/index.html#graphical-displays-of-distributions",
    "title": "Exploratory Data Analysis",
    "section": "3.1 Graphical Displays of Distributions",
    "text": "3.1 Graphical Displays of Distributions\n\n3.1.1 Histograms\nEach bar in the histogram represents a group of values (bin).\nThe height of the bar represents the frequency of percent of values in the bin. You can specify the number of width of the bins as desired.\n\n3.1.1.1 R Code\n\n\nCode\nlibrary(ggplot2)\n\nggplot(ames, aes(x = Sale_Price / 1000)) +\n    geom_histogram(mapping = aes(y = after_stat(density)), alpha = 0.5) +\n    geom_density(alpha = 0.2) +\n    labs(x = \"Sales Price (Thousands $)\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n3.1.1.2 Python Code\nNote this is a different Ames Housing dataset.\n\n\nCode\nimport seaborn as sns\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n\names_py = pd.read_csv(\"../../../data/ames.csv\")\nax = sns.histplot(x = ames_py['SalePrice'] / 1000, kde = True, data = ames_py, color = \"blue\")\nax.set(\n    xlabel = 'Sales Price (Thousands $)',\n    ylabel = 'Frequency',\n    title = 'Histogram of Sales Price in Thousands of Dollars'\n)\nplt.show()\n\n\n\n\n\n\n\nCode\nax = sns.displot(ames_py, x = ames_py['SalePrice'] / 1000, kde=True)\nax.set(\n    xlabel = 'Sales Price (Thousands $)',\n    ylabel = 'Frequency')\n\n\n\n\n\nThe distribution is right-skewed so the mean is greater than the median housing price.\n\n\n\n3.1.2 Normal Probability Plots (QQ-Plots)\nUsed to compare two distributions, typically to verify that a variable is approx. Normal.\nCompare observed quantiles to theoretical quantiles of a Normal distribution with the same mean and variance.\nIf the points follow the line diagonal line, the distribution is Normal.\n\n\n\nQQ-Plot Problem Indicators\n\n\n\nQuadratic patterns indicate problems with skew\nCubic patterns indicate problems with kurtosis\n\n\n3.1.2.1 R Code\n\n\nCode\nggplot(ames, aes(sample = Sale_Price / 1000)) +\n    stat_qq() +\n    stat_qq_line() +\n    labs(x = \"theoretical\", y = \"observed\")\n\n\n\n\n\n\n\n3.1.2.2 Python Code\n\n\nCode\nimport statsmodels.api as sma\n\nsma.qqplot(ames_py['SalePrice'] / 1000, line='45', fit = True)\n\n\n\n\n\n\n\n\n3.1.3 Box Plots\n\n\n\nBox Plot\n\n\n\n3.1.3.1 R Code\n\n\nCode\nggplot(ames, aes(y = Sale_Price / 1000, x = Central_Air, fill = Central_Air)) +\n    geom_boxplot() +\n    labs(y = \"Sales Price (Thousands $)\", x = \"Central Air\") +\n    scale_fill_brewer(palette = \"Accent\") +\n    theme_classic() +\n    coord_flip()\n\n\n\n\n\n\n\n3.1.3.2 Python Code\n\n\nCode\nax = sns.boxplot(ames_py, x = ames_py['SalePrice'] / 1000)\nax.set(\n    xlabel='Sales Price (Thousands $)',\n    title='Boxplot of Sales Price in Thousands of Dollars')\nplt.show()\n\n\n\n\n\n\n\nCode\nax = sns.catplot(ames_py, x='CentralAir', y='SalePrice', kind='box')\nplt.show()"
  },
  {
    "objectID": "notes/analytics/06272023/index.html#defining-anomalous-observations",
    "href": "notes/analytics/06272023/index.html#defining-anomalous-observations",
    "title": "Exploratory Data Analysis",
    "section": "3.2 Defining Anomalous Observations",
    "text": "3.2 Defining Anomalous Observations\n\n3.2.1 Standard Deviations from the Mean\nFor symmetric distributions and particularly for the Normal distribution, it’s common to consider observations more than 3 standard deviations from the mean as anomalous.\n\n\n3.2.2 Box-Plot Definition\nBox plots define outliers as poitns that are \\(1.5 \\times IQR\\) above the third quartile or less than \\(1.5 \\times IQR\\) below the first quartile.\nThere are more definitions but these are the first couple we are considering now."
  },
  {
    "objectID": "notes/analytics/06272023/breakout_1.html",
    "href": "notes/analytics/06272023/breakout_1.html",
    "title": "Breakout 1",
    "section": "",
    "text": "1 Loading the Data\n\n\nCode\nbike &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/bike.csv\")\nstr(bike)\n\n\n'data.frame':   17379 obs. of  16 variables:\n $ dteday    : int  14975 14975 14975 14975 14975 14975 14975 14975 14975 14975 ...\n $ season    : int  1 1 1 1 1 1 1 1 1 1 ...\n $ yr        : int  0 0 0 0 0 0 0 0 0 0 ...\n $ mnth      : int  1 1 1 1 1 1 1 1 1 1 ...\n $ hr        : int  0 1 2 3 4 5 6 7 8 9 ...\n $ holiday   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ weekday   : int  6 6 6 6 6 6 6 6 6 6 ...\n $ workingday: int  0 0 0 0 0 0 0 0 0 0 ...\n $ weathersit: int  1 1 1 1 1 2 1 1 1 1 ...\n $ temp      : num  0.24 0.22 0.22 0.24 0.24 0.24 0.22 0.2 0.24 0.32 ...\n $ atemp     : num  0.288 0.273 0.273 0.288 0.288 ...\n $ hum       : num  0.81 0.8 0.8 0.75 0.75 0.75 0.8 0.86 0.75 0.76 ...\n $ windspeed : num  0 0 0 0 0 0.0896 0 0 0 0 ...\n $ casual    : int  3 8 5 3 0 0 2 1 1 8 ...\n $ registered: int  13 32 27 10 1 1 0 2 7 6 ...\n $ cnt       : int  16 40 32 13 1 1 2 3 8 14 ...\n\n\nCode\ntable(bike$season)\n\n\n\n   1    2    3    4 \n4242 4409 4496 4232 \n\n\n\n\n2 Plotting the Distribution\n\n\nCode\nlibrary(ggplot2)\nggplot(bike, aes(x = cnt)) +\n    geom_histogram(fill = \"blue\") +\n    labs(x = \"Bike Rentals\", title = \"Histogram of Bike Rentals\", y = \"Frequency\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n3 Getting Summary Statistics\n\n\nCode\nsummary(bike$cnt)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    1.0    40.0   142.0   189.5   281.0   977.0 \n\n\nCode\nsd(bike$cnt)\n\n\n[1] 181.3876\n\n\nCode\nquantile(bike$cnt, probs = c(0.10, 0.40, 0.80))\n\n\n10% 40% 80% \n  9  98 321 \n\n\n\n\nCode\nggplot(bike, aes(x = cnt)) +\n    geom_histogram(fill = \"red\", binwidth = 50) +\n    labs(x = \"Bike Rentals\", title = \"Histogram of Bike Rentals\", y = \"Frequency\")\n\n\n\n\n\nCode\nggplot(bike, aes(x = cnt)) +\n    geom_histogram(fill = \"purple\", binwidth = 100) +\n    labs(x = \"Bike Rentals\", title = \"Histogram of Bike Rentals\", y = \"Frequency\")\n\n\n\n\n\nCode\nggplot(bike, aes(x = cnt)) +\n    geom_histogram(fill = \"pink\", binwidth = 250) +\n    labs(x = \"Bike Rentals\", title = \"Histogram of Bike Rentals\", y = \"Frequency\")\n\n\n\n\n\nWe can overlay a density estimator on our histogram:\n\n\nCode\nggplot(bike, aes(x = cnt)) +\n    geom_histogram(aes(y = after_stat(!!str2lang(\"density\"))), alpha = 0.2) +\n    geom_density() +\n    labs(x = \"Bike Rentals\", title = \"Histogram of Bike Rentals\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nUsing a QQ-Plot we can also see that the distribution is right-skewed:\n\n\nCode\nggplot(bike, aes(sample = cnt)) +\n    stat_qq(shape = 2) +\n    stat_qq_line()\n\n\n\n\n\n\n\n4 Associations\n\n\nCode\nggplot(bike, aes(x = factor(season), y = cnt, fill = factor(season))) +\n    geom_boxplot() +\n    scale_x_discrete(labels = c(\"Spring\", \"Summer\", \"Fall\", \"Winter\")) +\n    labs(x = \"Season\", y = \"Bike Rentals\", fill = \"Season\")\n\n\n\n\n\nSpring seems to have the fewest number of bike rentals. There are anomalous observations for count within each season."
  },
  {
    "objectID": "notes/analytics/06302023/breakout_4.html",
    "href": "notes/analytics/06302023/breakout_4.html",
    "title": "1",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/bike.csv\")\n\ndf.head()\n\n\n\n\n\n\n\n\n\ndteday\nseason\nyr\nmnth\nhr\nholiday\nweekday\nworkingday\nweathersit\ntemp\natemp\nhum\nwindspeed\ncasual\nregistered\ncnt\n\n\n\n\n0\n14975\n1\n0\n1\n0\n0\n6\n0\n1\n0.24\n0.2879\n0.81\n0.0\n3\n13\n16\n\n\n1\n14975\n1\n0\n1\n1\n0\n6\n0\n1\n0.22\n0.2727\n0.80\n0.0\n8\n32\n40\n\n\n2\n14975\n1\n0\n1\n2\n0\n6\n0\n1\n0.22\n0.2727\n0.80\n0.0\n5\n27\n32\n\n\n3\n14975\n1\n0\n1\n3\n0\n6\n0\n1\n0.24\n0.2879\n0.75\n0.0\n3\n10\n13\n\n\n4\n14975\n1\n0\n1\n4\n0\n6\n0\n1\n0.24\n0.2879\n0.75\n0.0\n0\n1\n1\n\n\n\n\n\n\n\n\n\nCode\nnp.corrcoef(df[['temp', 'atemp', 'hum', 'windspeed', 'cnt']])\n\n\narray([[1.        , 0.9996723 , 0.99977045, ..., 0.99927588, 0.99933747,\n        0.99944454],\n       [0.9996723 , 1.        , 0.99999127, ..., 0.99992236, 0.99994156,\n        0.99997001],\n       [0.99977045, 0.99999127, 1.        , ..., 0.99986162, 0.99988766,\n        0.99992905],\n       ...,\n       [0.99927588, 0.99992236, 0.99986162, ..., 1.        , 0.99999853,\n        0.99998878],\n       [0.99933747, 0.99994156, 0.99988766, ..., 0.99999853, 1.        ,\n        0.99999501],\n       [0.99944454, 0.99997001, 0.99992905, ..., 0.99998878, 0.99999501,\n        1.        ]])\n\n\n\n\nCode\nax = sns.pairplot(df[['temp', 'atemp', 'hum', 'windspeed', 'cnt']])\n\nplt.show()\n\n\n\n\n\n\nStrong linear relationship between temp and atemp\n\n\n1 2\nPicking atemp\n\n\nCode\nslr = smf.ols('cnt ~ atemp', df).fit()\nslr.summary()\nslr.rsquared\n\n\n0.16074430690746544\n\n\n\natemp explains about 16% of the variability in cnt\natemp has a coefficient of 423.1802. For every unit increase in atemp the cnt increases by 423.1802 all other variables held constant"
  }
]