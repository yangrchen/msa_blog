[
  {
    "objectID": "notes/analytics/06302023/lab_4.html",
    "href": "notes/analytics/06302023/lab_4.html",
    "title": "1 1",
    "section": "",
    "text": "1 1\n\n\nCode\nlibrary(AppliedPredictiveModeling)\ndata(FuelEconomy)\n\n\n\n\nCode\ncor(cars2010[, c(\"EngDispl\", \"NumCyl\", \"ExhaustValvesPerCyl\", \"VarValveTiming\", \"FE\")])\n\n\n                       EngDispl       NumCyl ExhaustValvesPerCyl VarValveTiming\nEngDispl             1.00000000  0.906260027          -0.4784380   -0.068256030\nNumCyl               0.90626003  1.000000000          -0.3398518    0.005399291\nExhaustValvesPerCyl -0.47843804 -0.339851831           1.0000000    0.279339052\nVarValveTiming      -0.06825603  0.005399291           0.2793391    1.000000000\nFE                  -0.78739383 -0.740217981           0.3356529    0.124952779\n                            FE\nEngDispl            -0.7873938\nNumCyl              -0.7402180\nExhaustValvesPerCyl  0.3356529\nVarValveTiming       0.1249528\nFE                   1.0000000\n\n\nCode\npairs(cars2010[, c(\"EngDispl\", \"NumCyl\", \"ExhaustValvesPerCyl\", \"VarValveTiming\", \"FE\")])\n\n\n\n\n\nCode\nengdispl_lm &lt;- lm(FE ~ EngDispl, data = cars2010)\npar(nfrow = c(2, 2))\n\n\nWarning in par(nfrow = c(2, 2)): \"nfrow\" is not a graphical parameter\n\n\nCode\nplot(engdispl_lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsummary(engdispl_lm)\n\n\n\nCall:\nlm(formula = FE ~ EngDispl, data = cars2010)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-14.486  -3.192  -0.365   2.671  27.215 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  50.5632     0.3985  126.89   &lt;2e-16 ***\nEngDispl     -4.5209     0.1065  -42.46   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.624 on 1105 degrees of freedom\nMultiple R-squared:   0.62, Adjusted R-squared:  0.6196 \nF-statistic:  1803 on 1 and 1105 DF,  p-value: &lt; 2.2e-16\n\n\n\nHighest correlation with FE is EnglDispl\n\n\n\nCode\ncor.test(cars2010$FE, cars2010$EngDispl)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  cars2010$FE and cars2010$EngDispl\nt = -42.46, df = 1105, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.8087913 -0.7639144\nsample estimates:\n       cor \n-0.7873938 \n\n\n\nP-value is significant at a 0.05 level and we have evidence that the correlation coefficient is not equal to 0\n\n\n\nCode\ncor(cars2010[, c(\"EngDispl\", \"NumCyl\", \"ExhaustValvesPerCyl\", \"VarValveTiming\")])\n\n\n                       EngDispl       NumCyl ExhaustValvesPerCyl VarValveTiming\nEngDispl             1.00000000  0.906260027          -0.4784380   -0.068256030\nNumCyl               0.90626003  1.000000000          -0.3398518    0.005399291\nExhaustValvesPerCyl -0.47843804 -0.339851831           1.0000000    0.279339052\nVarValveTiming      -0.06825603  0.005399291           0.2793391    1.000000000\n\n\n\nEnglDispl and NumCyl have a large correlation between one another\n\n\n\nCode\nslr &lt;- lm(FE ~ EngDispl, cars2010)\nsummary(slr)$r.squared\n\n\n[1] 0.619989\n\n\n\nF-statistic is 1803 with a p-value of 2.2e-16. Overall model is significant\n\\(y = 50.5632 - 4.5209x_1\\)\n\\(R^2\\) is 0.620 which means that 62% of the variability in FE can be explained by EngDispl alone\n\n\n\n2 2\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(ggplot2)\nicecream &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/icecream.csv\", sep = \" \")\nglimpse(icecream)\n\n\nRows: 50\nColumns: 2\n$ Temperature &lt;int&gt; 65, 87, 78, 68, 98, 86, 62, 86, 71, 85, 78, 90, 63, 80, 80…\n$ Sales       &lt;dbl&gt; 180.25, 218.75, 202.44, 176.50, 212.18, 210.68, 165.30, 22…\n\n\n\n\nCode\nsales_slr &lt;- lm(Sales ~ Temperature, icecream)\npar(mfrow = c(2, 2))\nplot(sales_slr)\n\n\n\n\n\nCode\nggplot(icecream, aes(x = Temperature, y = Sales)) +\n    geom_point() +\n    stat_smooth(method = \"lm\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nCode\nsummary(sales_slr)\n\n\n\nCall:\nlm(formula = Sales ~ Temperature, data = icecream)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-21.603  -8.159   1.005   7.212  23.666 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 119.3895    10.1931  11.713 1.12e-15 ***\nTemperature   1.0889     0.1241   8.771 1.54e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.07 on 48 degrees of freedom\nMultiple R-squared:  0.6158,    Adjusted R-squared:  0.6078 \nF-statistic: 76.94 on 1 and 48 DF,  p-value: 1.543e-11\n\n\n\nResiduals seem to be Normally distributed from the QQ-Plot\nError variance is constant and does not show a pattern\nLinearity of the mean\nOverall F-test is significant so Temperature seems to be significant in explaining Sales\nParameter estimate for Temperature is 1.0889\n\n\n\n3 3\n\n\nCode\nminntemp &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/minntemp.csv\", sep = \" \")\nglimpse(minntemp)\n\n\nRows: 795\nColumns: 3\n$ Temp   &lt;dbl&gt; 73.04, 73.04, 73.04, 69.98, 69.08, 69.98, 69.98, 71.96, 75.02, …\n$ TimeSq &lt;int&gt; 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, …\n$ Time   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, …\n\n\n\n\nCode\ntemp_slr &lt;- lm(Temp ~ Time, minntemp)\npar(mfrow = c(2, 2))\nplot(temp_slr)\n\n\n\n\n\nCode\nggplot(minntemp, aes(x = Time, y = Temp)) +\n    geom_point() +\n    stat_smooth(method = \"lm\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nCode\nsummary(temp_slr)\n\n\n\nCall:\nlm(formula = Temp ~ Time, data = minntemp)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-20.8189  -5.4495  -0.5359   5.1432  21.1455 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 70.755366   0.588230 120.285   &lt;2e-16 ***\nTime         0.002301   0.001280   1.797   0.0727 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.285 on 793 degrees of freedom\nMultiple R-squared:  0.004056,  Adjusted R-squared:  0.0028 \nF-statistic: 3.229 on 1 and 793 DF,  p-value: 0.07271\n\n\n\nNo linearity of the mean, seems quadratic\nNo constant variance\nNormally distributed errors\nNo statistical evidence that time is related to temperature at a confidence level of 0.05"
  },
  {
    "objectID": "notes/analytics/06302023/index.html",
    "href": "notes/analytics/06302023/index.html",
    "title": "Ordinary Least Squares Regression",
    "section": "",
    "text": "Pearson’s correlation measures linear relationships.\n\n\n\nPearson’s Correlation Scenarios\n\n\n\n\nParameter representing population correlation is \\(\\rho\\) and is estimated by \\(r\\)\n\\(H_0: \\rho = 0\\)\nHowever, rejecting \\(H_0\\) only means that \\(\\rho\\) is not exactly 0 so we need to see if the relationship is practically significant.\nNote that outliers affect correlation and correlation does not imply causation.\n\n\n\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(AmesHousing)\n\names &lt;- make_ordinal_ames()\nset.seed(123)\names &lt;- ames |&gt; mutate(id = row_number())\ntrain &lt;- ames |&gt; sample_frac(0.7)\ntest &lt;- anti_join(ames, train, by = \"id\")\n\ndim(train)\n\n\n[1] 2051   82\n\n\nCode\ndim(test)\n\n\n[1] 879  82\n\n\n\n\nCode\ncor.test(train$Gr_Liv_Area, train$Sale_Price)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  train$Gr_Liv_Area and train$Sale_Price\nt = 44.185, df = 2049, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6756538 0.7200229\nsample estimates:\n     cor \n0.698509 \n\n\n\n\n\n\n\nCode\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\n\ndata = pd.read_csv(\"data/AmesHousing.csv\")\n\ntrain, test = train_test_split(data, test_size=0.3, random_state=123)\n\n\n\n\nCode\nnp.corrcoef(train['Gr Liv Area'], train['SalePrice'])\n\n\narray([[1.        , 0.69584201],\n       [0.69584201, 1.        ]])\n\n\nCode\nnp.corrcoef(train[['Year Built', 'Total Bsmt SF', '1st Flr SF', 'Gr Liv Area']], rowvar=False)\n\n\narray([[1.        , 0.42722628, 0.32717559, 0.23863599],\n       [0.42722628, 1.        , 0.80658329, 0.45383515],\n       [0.32717559, 0.80658329, 1.        , 0.57135986],\n       [0.23863599, 0.45383515, 0.57135986, 1.        ]])\n\n\n\n\n\nA strong correlation does not mean that a change in one variable causes a change in the other."
  },
  {
    "objectID": "notes/analytics/06302023/index.html#hypothesis-test-for-correlation",
    "href": "notes/analytics/06302023/index.html#hypothesis-test-for-correlation",
    "title": "Ordinary Least Squares Regression",
    "section": "",
    "text": "Parameter representing population correlation is \\(\\rho\\) and is estimated by \\(r\\)\n\\(H_0: \\rho = 0\\)\nHowever, rejecting \\(H_0\\) only means that \\(\\rho\\) is not exactly 0 so we need to see if the relationship is practically significant.\nNote that outliers affect correlation and correlation does not imply causation."
  },
  {
    "objectID": "notes/analytics/06302023/index.html#test-of-correlation-in-r",
    "href": "notes/analytics/06302023/index.html#test-of-correlation-in-r",
    "title": "Ordinary Least Squares Regression",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(AmesHousing)\n\names &lt;- make_ordinal_ames()\nset.seed(123)\names &lt;- ames |&gt; mutate(id = row_number())\ntrain &lt;- ames |&gt; sample_frac(0.7)\ntest &lt;- anti_join(ames, train, by = \"id\")\n\ndim(train)\n\n\n[1] 2051   82\n\n\nCode\ndim(test)\n\n\n[1] 879  82\n\n\n\n\nCode\ncor.test(train$Gr_Liv_Area, train$Sale_Price)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  train$Gr_Liv_Area and train$Sale_Price\nt = 44.185, df = 2049, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6756538 0.7200229\nsample estimates:\n     cor \n0.698509"
  },
  {
    "objectID": "notes/analytics/06302023/index.html#pearson-in-python",
    "href": "notes/analytics/06302023/index.html#pearson-in-python",
    "title": "Ordinary Least Squares Regression",
    "section": "",
    "text": "Code\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\n\ndata = pd.read_csv(\"data/AmesHousing.csv\")\n\ntrain, test = train_test_split(data, test_size=0.3, random_state=123)\n\n\n\n\nCode\nnp.corrcoef(train['Gr Liv Area'], train['SalePrice'])\n\n\narray([[1.        , 0.69584201],\n       [0.69584201, 1.        ]])\n\n\nCode\nnp.corrcoef(train[['Year Built', 'Total Bsmt SF', '1st Flr SF', 'Gr Liv Area']], rowvar=False)\n\n\narray([[1.        , 0.42722628, 0.32717559, 0.23863599],\n       [0.42722628, 1.        , 0.80658329, 0.45383515],\n       [0.32717559, 0.80658329, 1.        , 0.57135986],\n       [0.23863599, 0.45383515, 0.57135986, 1.        ]])"
  },
  {
    "objectID": "notes/analytics/06302023/index.html#correlation-does-not-imply-causation",
    "href": "notes/analytics/06302023/index.html#correlation-does-not-imply-causation",
    "title": "Ordinary Least Squares Regression",
    "section": "",
    "text": "A strong correlation does not mean that a change in one variable causes a change in the other."
  },
  {
    "objectID": "notes/analytics/06302023/index.html#explained-vs.-unexplained-variability",
    "href": "notes/analytics/06302023/index.html#explained-vs.-unexplained-variability",
    "title": "Ordinary Least Squares Regression",
    "section": "2.1 Explained vs. Unexplained Variability",
    "text": "2.1 Explained vs. Unexplained Variability\nWe are trying to explain variation in the response variable. We can’t explain all of it due to random, uncontrollable error but we can model it.\n\n\n\nVariability Explained in SLR\n\n\nWith linear regression, we are trying to minimize a loss function called sum of squared errors:\n\\[\nSSE = \\sum_{i=1}^{n} (y_i - \\hat{y}_i) ^2\n\\]\n\nThis makes up the amount of unexplained variability in our model"
  },
  {
    "objectID": "notes/analytics/06302023/index.html#the-baseline-model",
    "href": "notes/analytics/06302023/index.html#the-baseline-model",
    "title": "Ordinary Least Squares Regression",
    "section": "2.2 The Baseline Model",
    "text": "2.2 The Baseline Model\n\n\\(H_0: \\beta_1 = 0\\)\n\\(H_a: \\beta_1 \\neq 0\\)\n\nFor SLR, the global F-Test, parameter t-test and the test of Pearson’s correlation are all equivalent.\nWhen we can’t reject the null hypothesis we are essentially saying that the independent variable doesn’t explain any of the variability in the response."
  },
  {
    "objectID": "notes/analytics/06302023/index.html#assumptions-of-simple-linear-regression",
    "href": "notes/analytics/06302023/index.html#assumptions-of-simple-linear-regression",
    "title": "Ordinary Least Squares Regression",
    "section": "2.3 Assumptions of Simple Linear Regression",
    "text": "2.3 Assumptions of Simple Linear Regression\n\nLinearity of the mean\n\nAs I change values in the independent variable, the line should go through the mean of the response linearly\n\nErrors are normally distributed\nErrors have equal variance (homoskedasticity)\nErrors are independent\n\n\n2.3.1 Testing of Assumptions\n\nNormality can use a histogram, QQ-Plot or normality test\nEqual variances can use residuals versus predicted values\nIndependence can look at residual plots for potential autocorrelation\nLinearity in the mean can be tested through a residual plot and finding that there is no pattern in residual plot\n\n\n\nCode\nslr &lt;- lm(Sale_Price ~ Gr_Liv_Area, data = train)\npar(mfrow = c(2, 2))\n\nplot(slr)\n\n\n\n\n\nCode\nsummary(slr)\n\n\n\nCall:\nlm(formula = Sale_Price ~ Gr_Liv_Area, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-478762  -30030   -1405   22273  335855 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 14045.872   3942.503   3.563 0.000375 ***\nGr_Liv_Area   110.726      2.506  44.185  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 57430 on 2049 degrees of freedom\nMultiple R-squared:  0.4879,    Adjusted R-squared:  0.4877 \nF-statistic:  1952 on 1 and 2049 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nCode\nimport statsmodels.formula.api as smf\n\ntrain = train.rename(columns={\"Gr Liv Area\": \"Gr_Liv_Area\"})\nmodel_slr = smf.ols(\"SalePrice ~ Gr_Liv_Area\", data=train).fit()\n\nmodel_slr.pvalues\n\n\nIntercept       8.540663e-05\nGr_Liv_Area    6.980208e-297\ndtype: float64"
  },
  {
    "objectID": "notes/analytics/06272023/lab_1.html",
    "href": "notes/analytics/06272023/lab_1.html",
    "title": "Lab 1",
    "section": "",
    "text": "Code\nlibrary(UsingR)\n\n\nLoading required package: MASS\n\n\nLoading required package: HistData\n\n\nLoading required package: Hmisc\n\n\n\nAttaching package: 'Hmisc'\n\n\nThe following objects are masked from 'package:base':\n\n    format.pval, units\n\n\nCode\nlibrary(ggplot2)\ndata(normtemp)\nstr(normtemp)\n\n\n'data.frame':   130 obs. of  3 variables:\n $ temperature: num  96.3 96.7 96.9 97 97.1 97.1 97.1 97.2 97.3 97.4 ...\n $ gender     : int  1 1 1 1 1 1 1 1 1 1 ...\n $ hr         : int  70 71 74 80 73 75 82 64 69 70 ...\n\n\n\n\nUse the normtemp dataset to answer the following:\n\nDetermine the following statistics for the variable temperature\n\n\n\nCode\nsummary(normtemp$temperature)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  96.30   97.80   98.30   98.25   98.70  100.80 \n\n\n\nDoes temperature appear to be normally distributed?\n\n\n\nCode\nggplot(normtemp, aes(sample = temperature)) +\n    stat_qq(col = \"blue\") +\n    stat_qq_line() +\n    labs(x = \"theoretical\", y = \"observed\")\n\n\n\n\n\nBased on the QQ-Plot, temperature appears to be approximately Normal. However, we should be wary that the distribution is tending towards a platykurtic distribution\n\nCreate box plots for temperature. Are there any outliers? Display a reference line at 98.6.\nFor horizontal line: geom_hline(yintercept=98.6)\nFor vertical line: geom_vline(xintercept=98.6)\n\n\n\nCode\nggplot(normtemp, aes(x = temperature)) +\n    geom_boxplot(outlier.color = \"red\") +\n    labs(x = \"Temperature\", title = \"Box-Plot of Temperature\") +\n    geom_vline(xintercept = 98.6, col = \"blue\")\n\n\n\n\n\nThree observations appear to be outliers (colored in red) for temperature. After plotting the reference line at 98.6 degrees, we can visually see that the median is actually lower than 98.6.\n\n\nUsing the Ameshousing dataset from our in-class examples, run some distributional analysis on Sale_Price, Log(Sale_Price), and Gr_Liv_Area.\n\nCreate histograms of these three variables.\n\nOverlay a kernel density estimator of the variables.\n\n\n\n\nCode\nlibrary(AmesHousing)\n\names &lt;- make_ordinal_ames()\n\n\n\n\nCode\nggplot(ames, aes(x = Sale_Price)) +\n    geom_histogram(aes(y = after_stat(!!str2lang(\"density\"))), fill = \"pink\", alpha = 0.4) +\n    geom_density() +\n    labs(x = \"Sales Price (USD)\", title = \"Histogram of Housing Sales Price\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nCode\nggplot(ames, aes(x = log(Sale_Price))) +\n    geom_histogram(aes(y = after_stat(!!str2lang(\"density\"))), fill = \"blue\", alpha = 0.4) +\n    geom_density() +\n    labs(x = \"Sales Price (USD)\", title = \"Histogram of Log(Sales Price)\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nCode\nggplot(ames, aes(x = Gr_Liv_Area)) +\n    geom_histogram(aes(y = after_stat(!!str2lang(\"density\"))), fill = \"purple\", alpha = 0.4) +\n    geom_density() +\n    labs(x = \"Sales Price (USD)\", title = \"Histogram of Living Area\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nCreate a QQ Plot for both Sale_Price and Log(Sale_Price). Based on these exploratory procedures, which version of the price information would you say is closer to being normally distributed?\n\n\n\nCode\nggplot(ames, aes(sample = Sale_Price)) +\n    stat_qq(col = \"blue\", shape = 8, size = 1) +\n    stat_qq_line() +\n    labs(x = \"theoretical\", y = \"observed\", title = \"QQ-Plot of Sale Price\")\n\n\n\n\n\nCode\nggplot(ames, aes(sample = log(Sale_Price))) +\n    stat_qq(col = \"blue\", shape = 8, size = 1) +\n    stat_qq_line()\n\n\n\n\n\nCode\nlabs(x = \"theoretical\", y = \"observed\", title = \"QQ-Plot of Log(Sale Price)\")\n\n\n$x\n[1] \"theoretical\"\n\n$y\n[1] \"observed\"\n\n$title\n[1] \"QQ-Plot of Log(Sale Price)\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\nThe Log(Sale Price) QQ-Plot shows a much closer similarity to a Normal distribution than just Sale Price.\n\n\nUsing the Ameshousing dataset from our in-class examples, determine the following:\n\nWhat type of variables are each of these columns (Nominal, Ordinal, or Continuous/Quantitative)? Keep in mind that the way they are represented in the R dataset may not be appropriate, so you should make this determination using your own judgement based on the data you are looking at.\n\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ lubridate 1.9.2     ✔ tibble    3.2.1\n✔ purrr     1.0.1     ✔ tidyr     1.3.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()    masks stats::filter()\n✖ dplyr::lag()       masks stats::lag()\n✖ dplyr::select()    masks MASS::select()\n✖ dplyr::src()       masks Hmisc::src()\n✖ dplyr::summarize() masks Hmisc::summarize()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nglimpse(ames)\n\n\nRows: 2,930\nColumns: 81\n$ MS_SubClass        &lt;fct&gt; One_Story_1946_and_Newer_All_Styles, One_Story_1946…\n$ MS_Zoning          &lt;fct&gt; Residential_Low_Density, Residential_High_Density, …\n$ Lot_Frontage       &lt;dbl&gt; 141, 80, 81, 93, 74, 78, 41, 43, 39, 60, 75, 0, 63,…\n$ Lot_Area           &lt;int&gt; 31770, 11622, 14267, 11160, 13830, 9978, 4920, 5005…\n$ Street             &lt;fct&gt; Pave, Pave, Pave, Pave, Pave, Pave, Pave, Pave, Pav…\n$ Alley              &lt;fct&gt; No_Alley_Access, No_Alley_Access, No_Alley_Access, …\n$ Lot_Shape          &lt;ord&gt; Slightly_Irregular, Regular, Slightly_Irregular, Re…\n$ Land_Contour       &lt;ord&gt; Lvl, Lvl, Lvl, Lvl, Lvl, Lvl, Lvl, HLS, Lvl, Lvl, L…\n$ Utilities          &lt;ord&gt; AllPub, AllPub, AllPub, AllPub, AllPub, AllPub, All…\n$ Lot_Config         &lt;fct&gt; Corner, Inside, Corner, Corner, Inside, Inside, Ins…\n$ Land_Slope         &lt;ord&gt; Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, G…\n$ Neighborhood       &lt;fct&gt; North_Ames, North_Ames, North_Ames, North_Ames, Gil…\n$ Condition_1        &lt;fct&gt; Norm, Feedr, Norm, Norm, Norm, Norm, Norm, Norm, No…\n$ Condition_2        &lt;fct&gt; Norm, Norm, Norm, Norm, Norm, Norm, Norm, Norm, Nor…\n$ Bldg_Type          &lt;fct&gt; OneFam, OneFam, OneFam, OneFam, OneFam, OneFam, Twn…\n$ House_Style        &lt;fct&gt; One_Story, One_Story, One_Story, One_Story, Two_Sto…\n$ Overall_Qual       &lt;ord&gt; Above_Average, Average, Above_Average, Good, Averag…\n$ Overall_Cond       &lt;ord&gt; Average, Above_Average, Above_Average, Average, Ave…\n$ Year_Built         &lt;int&gt; 1960, 1961, 1958, 1968, 1997, 1998, 2001, 1992, 199…\n$ Year_Remod_Add     &lt;int&gt; 1960, 1961, 1958, 1968, 1998, 1998, 2001, 1992, 199…\n$ Roof_Style         &lt;fct&gt; Hip, Gable, Hip, Hip, Gable, Gable, Gable, Gable, G…\n$ Roof_Matl          &lt;fct&gt; CompShg, CompShg, CompShg, CompShg, CompShg, CompSh…\n$ Exterior_1st       &lt;fct&gt; BrkFace, VinylSd, Wd Sdng, BrkFace, VinylSd, VinylS…\n$ Exterior_2nd       &lt;fct&gt; Plywood, VinylSd, Wd Sdng, BrkFace, VinylSd, VinylS…\n$ Mas_Vnr_Type       &lt;fct&gt; Stone, None, BrkFace, None, None, BrkFace, None, No…\n$ Mas_Vnr_Area       &lt;dbl&gt; 112, 0, 108, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6…\n$ Exter_Qual         &lt;ord&gt; Typical, Typical, Typical, Good, Typical, Typical, …\n$ Exter_Cond         &lt;ord&gt; Typical, Typical, Typical, Typical, Typical, Typica…\n$ Foundation         &lt;fct&gt; CBlock, CBlock, CBlock, CBlock, PConc, PConc, PConc…\n$ Bsmt_Qual          &lt;ord&gt; Typical, Typical, Typical, Typical, Good, Typical, …\n$ Bsmt_Cond          &lt;ord&gt; Good, Typical, Typical, Typical, Typical, Typical, …\n$ Bsmt_Exposure      &lt;ord&gt; Gd, No, No, No, No, No, Mn, No, No, No, No, No, No,…\n$ BsmtFin_Type_1     &lt;ord&gt; BLQ, Rec, ALQ, ALQ, GLQ, GLQ, GLQ, ALQ, GLQ, Unf, U…\n$ BsmtFin_SF_1       &lt;dbl&gt; 2, 6, 1, 1, 3, 3, 3, 1, 3, 7, 7, 1, 7, 3, 3, 1, 3, …\n$ BsmtFin_Type_2     &lt;ord&gt; Unf, LwQ, Unf, Unf, Unf, Unf, Unf, Unf, Unf, Unf, U…\n$ BsmtFin_SF_2       &lt;dbl&gt; 0, 144, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1120, 0…\n$ Bsmt_Unf_SF        &lt;dbl&gt; 441, 270, 406, 1045, 137, 324, 722, 1017, 415, 994,…\n$ Total_Bsmt_SF      &lt;dbl&gt; 1080, 882, 1329, 2110, 928, 926, 1338, 1280, 1595, …\n$ Heating            &lt;fct&gt; GasA, GasA, GasA, GasA, GasA, GasA, GasA, GasA, Gas…\n$ Heating_QC         &lt;ord&gt; Fair, Typical, Typical, Excellent, Good, Excellent,…\n$ Central_Air        &lt;fct&gt; Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, …\n$ Electrical         &lt;ord&gt; SBrkr, SBrkr, SBrkr, SBrkr, SBrkr, SBrkr, SBrkr, SB…\n$ First_Flr_SF       &lt;int&gt; 1656, 896, 1329, 2110, 928, 926, 1338, 1280, 1616, …\n$ Second_Flr_SF      &lt;int&gt; 0, 0, 0, 0, 701, 678, 0, 0, 0, 776, 892, 0, 676, 0,…\n$ Low_Qual_Fin_SF    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Gr_Liv_Area        &lt;int&gt; 1656, 896, 1329, 2110, 1629, 1604, 1338, 1280, 1616…\n$ Bsmt_Full_Bath     &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, …\n$ Bsmt_Half_Bath     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Full_Bath          &lt;int&gt; 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 2, …\n$ Half_Bath          &lt;int&gt; 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, …\n$ Bedroom_AbvGr      &lt;int&gt; 3, 2, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 2, 1, 4, 4, …\n$ Kitchen_AbvGr      &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ Kitchen_Qual       &lt;ord&gt; Typical, Typical, Good, Excellent, Typical, Good, G…\n$ TotRms_AbvGrd      &lt;int&gt; 7, 5, 6, 8, 6, 7, 6, 5, 5, 7, 7, 6, 7, 5, 4, 12, 8,…\n$ Functional         &lt;ord&gt; Typ, Typ, Typ, Typ, Typ, Typ, Typ, Typ, Typ, Typ, T…\n$ Fireplaces         &lt;int&gt; 2, 0, 0, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, …\n$ Fireplace_Qu       &lt;ord&gt; Good, No_Fireplace, No_Fireplace, Typical, Typical,…\n$ Garage_Type        &lt;fct&gt; Attchd, Attchd, Attchd, Attchd, Attchd, Attchd, Att…\n$ Garage_Finish      &lt;ord&gt; Fin, Unf, Unf, Fin, Fin, Fin, Fin, RFn, RFn, Fin, F…\n$ Garage_Cars        &lt;dbl&gt; 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, …\n$ Garage_Area        &lt;dbl&gt; 528, 730, 312, 522, 482, 470, 582, 506, 608, 442, 4…\n$ Garage_Qual        &lt;ord&gt; Typical, Typical, Typical, Typical, Typical, Typica…\n$ Garage_Cond        &lt;ord&gt; Typical, Typical, Typical, Typical, Typical, Typica…\n$ Paved_Drive        &lt;ord&gt; Partial_Pavement, Paved, Paved, Paved, Paved, Paved…\n$ Wood_Deck_SF       &lt;int&gt; 210, 140, 393, 0, 212, 360, 0, 0, 237, 140, 157, 48…\n$ Open_Porch_SF      &lt;int&gt; 62, 0, 36, 0, 34, 36, 0, 82, 152, 60, 84, 21, 75, 0…\n$ Enclosed_Porch     &lt;int&gt; 0, 0, 0, 0, 0, 0, 170, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Three_season_porch &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Screen_Porch       &lt;int&gt; 0, 120, 0, 0, 0, 0, 0, 144, 0, 0, 0, 0, 0, 0, 140, …\n$ Pool_Area          &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Pool_QC            &lt;ord&gt; No_Pool, No_Pool, No_Pool, No_Pool, No_Pool, No_Poo…\n$ Fence              &lt;ord&gt; No_Fence, Minimum_Privacy, No_Fence, No_Fence, Mini…\n$ Misc_Feature       &lt;fct&gt; None, None, Gar2, None, None, None, None, None, Non…\n$ Misc_Val           &lt;int&gt; 0, 0, 12500, 0, 0, 0, 0, 0, 0, 0, 0, 500, 0, 0, 0, …\n$ Mo_Sold            &lt;int&gt; 5, 6, 6, 4, 3, 6, 4, 1, 3, 6, 4, 3, 5, 2, 6, 6, 6, …\n$ Year_Sold          &lt;int&gt; 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 201…\n$ Sale_Type          &lt;fct&gt; WD , WD , WD , WD , WD , WD , WD , WD , WD , WD , W…\n$ Sale_Condition     &lt;fct&gt; Normal, Normal, Normal, Normal, Normal, Normal, Nor…\n$ Sale_Price         &lt;int&gt; 215000, 105000, 172000, 244000, 189900, 195500, 213…\n$ Longitude          &lt;dbl&gt; -93.61975, -93.61976, -93.61939, -93.61732, -93.638…\n$ Latitude           &lt;dbl&gt; 42.05403, 42.05301, 42.05266, 42.05125, 42.06090, 4…\n\n\n\nOverall_Qual is an ordinal variable as it represents categories that could be ordered based on the rated quality of the house\nLot_Shape is an ordinal variable. It represents categories that could be ordered based on the rated lot shape. For example, Slightly_Irregular could be ordered after Irregular\nHeating_QC is an ordinal variable. It represents the categories of heating quality that could be ordered. For example, Excellent would represent a higher order than Good\nLot_Area is a quantitative variable as it represents a continuous quantity of the area of the lot"
  },
  {
    "objectID": "notes/analytics/index.html",
    "href": "notes/analytics/index.html",
    "title": "Analytics",
    "section": "",
    "text": "Multiple Linear Regression\n\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nMore Complex ANOVA & Regression\n\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nOrdinary Least Squares Regression\n\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\n\n\nJun 30, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nIntroduction to ANOVA and Regression\n\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\n\n\nJun 29, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nIntroduction to Statistical Inference\n\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\n\n\nJun 28, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nExploratory Data Analysis\n\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2023\n\n\nYang Chen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notes/analytics/07062023/breakout_6.html",
    "href": "notes/analytics/07062023/breakout_6.html",
    "title": "Breakout 6",
    "section": "",
    "text": "1 1\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nbike &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/bike.csv\")\n\nset.seed(123)\nbike &lt;- bike %&gt;% mutate(id = row_number())\ntrain &lt;- bike %&gt;% sample_frac(0.7)\ntest &lt;- anti_join(bike, train, by = \"id\")\ndim(train)\n\n\n[1] 12165    17\n\n\nCode\ndim(test)\n\n\n[1] 5214   17\n\n\n\n\n2 2\n\n\nCode\nbike_lm &lt;- lm(cnt ~ temp + hum + windspeed, train)\nsummary(bike_lm)\n\n\n\nCall:\nlm(formula = cnt ~ temp + hum + windspeed, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-327.84 -102.59  -32.51   65.79  707.92 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  172.430      7.443  23.166   &lt;2e-16 ***\ntemp         365.042      7.458  48.946   &lt;2e-16 ***\nhum         -268.340      7.776 -34.508   &lt;2e-16 ***\nwindspeed     22.749     12.208   1.863   0.0624 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 157.5 on 12161 degrees of freedom\nMultiple R-squared:  0.2489,    Adjusted R-squared:  0.2487 \nF-statistic:  1343 on 3 and 12161 DF,  p-value: &lt; 2.2e-16\n\n\n\n\\(R_a^2 is 0.2487\\)\nThe variables temp, hum are significant at the 0.01 level\n\n\n\n3 3\n\n\nCode\nbike_lm2 &lt;- lm(cnt ~ atemp + hum + windspeed, train)\nsummary(bike_lm2)\n\n\n\nCall:\nlm(formula = cnt ~ atemp + hum + windspeed, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-349.42 -102.16  -32.60   65.91  702.10 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  155.087      7.631  20.323  &lt; 2e-16 ***\natemp        411.554      8.365  49.198  &lt; 2e-16 ***\nhum         -270.493      7.766 -34.831  &lt; 2e-16 ***\nwindspeed     45.606     12.225   3.731 0.000192 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 157.4 on 12161 degrees of freedom\nMultiple R-squared:  0.2502,    Adjusted R-squared:   0.25 \nF-statistic:  1352 on 3 and 12161 DF,  p-value: &lt; 2.2e-16\n\n\n\n\\(R_a^2\\) is 0.25\natemp, hum, and windspeed are all significant at the 0.01 level\n\n\n\n4 4\nOur second model with atemp has a higher \\(R_a^2\\) value."
  },
  {
    "objectID": "notes/analytics/07032023/lab_5.html",
    "href": "notes/analytics/07032023/lab_5.html",
    "title": "Lab 5",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndrugdose = pd.read_csv('https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/drug.csv')\n\ndrugdose.T.head()\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n\n\n\n\nPatientID\n69\n162\n181\n209\n308\n331\n340\n350\n360\n363\n...\n9679\n9682\n9693\n9714\n9735\n9865\n9878\n9941\n9947\n9990\n\n\nDrugDose\n2\n4\n1\n4\n2\n4\n4\n1\n2\n4\n...\n2\n2\n4\n2\n1\n3\n1\n2\n1\n2\n\n\nDisease\nB\nA\nB\nA\nA\nC\nC\nB\nB\nA\n...\nB\nB\nA\nC\nC\nB\nC\nB\nA\nC\n\n\nBloodP\n13\n-47\n12\n-4\n4\n37\n-19\n-9\n-17\n-41\n...\n15\n21\n6\n-32\n-7\n-24\n19\n23\n5\n-24\n\n\n\n\n4 rows × 170 columns"
  },
  {
    "objectID": "notes/analytics/07032023/lab_5.html#a",
    "href": "notes/analytics/07032023/lab_5.html#a",
    "title": "Lab 5",
    "section": "1.1 a",
    "text": "1.1 a\n\n\nCode\nax = sns.catplot(\n    drugdose, kind=\"bar\",\n    x=\"DrugDose\", y=\"BloodP\", hue=\"Disease\",\n    errorbar=None, palette=\"dark\", alpha=.6, height=6\n)\n\n\n\n\n\n\nThere seems to be a significant difference in blood pressure for the 100mg drug dose with disease B as well as the 200mg drug dose with disease B"
  },
  {
    "objectID": "notes/analytics/07032023/lab_5.html#b",
    "href": "notes/analytics/07032023/lab_5.html#b",
    "title": "Lab 5",
    "section": "1.2 b",
    "text": "1.2 b\n\n\nCode\ndrug_lm = smf.ols('BloodP ~ C(DrugDose) * C(Disease)', drugdose).fit()\n\nsm.stats.anova_lm(drug_lm, typ=2)\n\n\n\n\n\n\n\n\n\nsum_sq\ndf\nF\nPR(&gt;F)\n\n\n\n\nC(DrugDose)\n202.577573\n3.0\n0.156057\n9.256570e-01\n\n\nC(Disease)\n19276.486901\n2.0\n22.274702\n3.005823e-09\n\n\nC(DrugDose):C(Disease)\n17146.316981\n6.0\n6.604404\n3.021199e-06\n\n\nResidual\n68366.458868\n158.0\nNaN\nNaN\n\n\n\n\n\n\n\n\nInteraction between DrugDose and Disease seems to be significant in explaining BloodP"
  },
  {
    "objectID": "notes/analytics/07032023/lab_5.html#c",
    "href": "notes/analytics/07032023/lab_5.html#c",
    "title": "Lab 5",
    "section": "1.3 c",
    "text": "1.3 c\n\n\nCode\nunique_disease = np.sort(drugdose['Disease'].unique())\n\nfor disease in unique_disease:\n    sliced_data = smf.ols('BloodP ~ C(DrugDose)', drugdose[drugdose['Disease'] == disease]).fit()\n    print(f'\\nDisease: {disease}')\n    print(sm.stats.anova_lm(sliced_data)['PR(&gt;F)'])\n\n\n\nDisease: A\nC(DrugDose)    0.001123\nResidual            NaN\nName: PR(&gt;F), dtype: float64\n\nDisease: B\nC(DrugDose)    0.00027\nResidual           NaN\nName: PR(&gt;F), dtype: float64\n\nDisease: C\nC(DrugDose)    0.81447\nResidual           NaN\nName: PR(&gt;F), dtype: float64\n\n\n\nFor diseases A and B there seems to be significant differences in drug dose on blood pressure. Disease C does not seem to have a significant difference in drug dose on blood pressure."
  },
  {
    "objectID": "notes/analytics/07032023/lab_5.html#a-1",
    "href": "notes/analytics/07032023/lab_5.html#a-1",
    "title": "Lab 5",
    "section": "2.1 a",
    "text": "2.1 a\n\n\nCode\ndisks_lm = smf.ols('Time ~ C(Technician) * C(Brand)', disks).fit()\n\nprint(disks_lm.summary())\nsm.stats.anova_lm(disks_lm, typ=2)\n\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   Time   R-squared:                       0.619\nModel:                            OLS   Adj. R-squared:                  0.569\nMethod:                 Least Squares   F-statistic:                     12.38\nDate:                Tue, 04 Jul 2023   Prob (F-statistic):           1.66e-13\nTime:                        20:05:50   Log-Likelihood:                -376.10\nNo. Observations:                  96   AIC:                             776.2\nDf Residuals:                      84   BIC:                             807.0\nDf Model:                          11                                         \nCovariance Type:            nonrobust                                         \n=========================================================================================================\n                                            coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------------------------------\nIntercept                                37.5000      4.599      8.154      0.000      28.354      46.646\nC(Technician)[T.Bob]                     19.3750      6.504      2.979      0.004       6.441      32.309\nC(Technician)[T.Justin]                   5.0000      6.504      0.769      0.444      -7.934      17.934\nC(Technician)[T.Karen]                   35.5000      6.504      5.458      0.000      22.566      48.434\nC(Brand)[T.2]                            -6.2500      6.504     -0.961      0.339     -19.184       6.684\nC(Brand)[T.3]                            12.1250      6.504      1.864      0.066      -0.809      25.059\nC(Technician)[T.Bob]:C(Brand)[T.2]       21.5000      9.198      2.337      0.022       3.209      39.791\nC(Technician)[T.Justin]:C(Brand)[T.2]     8.7500      9.198      0.951      0.344      -9.541      27.041\nC(Technician)[T.Karen]:C(Brand)[T.2]    -11.0000      9.198     -1.196      0.235     -29.291       7.291\nC(Technician)[T.Bob]:C(Brand)[T.3]      -25.8750      9.198     -2.813      0.006     -44.166      -7.584\nC(Technician)[T.Justin]:C(Brand)[T.3]   -10.1250      9.198     -1.101      0.274     -28.416       8.166\nC(Technician)[T.Karen]:C(Brand)[T.3]     -0.1250      9.198     -0.014      0.989     -18.416      18.166\n==============================================================================\nOmnibus:                        2.790   Durbin-Watson:                   2.199\nProb(Omnibus):                  0.248   Jarque-Bera (JB):                2.505\nSkew:                           0.396   Prob(JB):                        0.286\nKurtosis:                       2.997   Cond. No.                         17.9\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\n\n\n\n\nsum_sq\ndf\nF\nPR(&gt;F)\n\n\n\n\nC(Technician)\n14797.875000\n3.0\n29.151194\n5.153348e-13\n\n\nC(Brand)\n343.145833\n2.0\n1.013974\n3.671708e-01\n\n\nC(Technician):C(Brand)\n7907.437500\n6.0\n7.788660\n1.122763e-06\n\n\nResidual\n14213.500000\n84.0\nNaN\nNaN\n\n\n\n\n\n\n\n\nAt a significant level of \\(\\alpha = 0.05\\), the overall F-test is significant in our model\nSimilarly, the interaction is also significant"
  },
  {
    "objectID": "notes/analytics/07032023/lab_5.html#b-1",
    "href": "notes/analytics/07032023/lab_5.html#b-1",
    "title": "Lab 5",
    "section": "2.2 b",
    "text": "2.2 b\nSince our interaction is significant, we no longer care about the significance of our main effects. With model hierarchy, we keep the main effects in our model as well"
  },
  {
    "objectID": "notes/analytics/07032023/lab_5.html#c-1",
    "href": "notes/analytics/07032023/lab_5.html#c-1",
    "title": "Lab 5",
    "section": "2.3 c",
    "text": "2.3 c\n\n\nCode\nimport statsmodels.stats.multicomp as mc\n\nunique_brands = np.sort(disks['Brand'].unique())\n\nfor b in unique_brands:\n    sliced_data = disks[disks['Brand'] == b]\n    sliced_ols = smf.ols('Time ~ C(Technician)', sliced_data).fit()\n    print(f'\\nBrand: {b}')\n    print(mc.MultiComparison(sliced_data['Time'], sliced_data['Technician']).tukeyhsd(alpha=0.01))\n    print(sm.stats.anova_lm(sliced_ols))\n\n\n\nBrand: 1\n Multiple Comparison of Means - Tukey HSD, FWER=0.01 \n=====================================================\ngroup1 group2 meandiff p-adj   lower    upper  reject\n-----------------------------------------------------\nAngela    Bob   19.375 0.0118  -0.3933 39.1433  False\nAngela Justin      5.0 0.8233 -14.7683 24.7683  False\nAngela  Karen     35.5    0.0  15.7317 55.2683   True\n   Bob Justin  -14.375 0.0847 -34.1433  5.3933  False\n   Bob  Karen   16.125 0.0442  -3.6433 35.8933  False\nJustin  Karen     30.5 0.0001  10.7317 50.2683   True\n-----------------------------------------------------\n                 df      sum_sq      mean_sq          F    PR(&gt;F)\nC(Technician)   3.0  6115.09375  2038.364583  15.208129  0.000005\nResidual       28.0  3752.87500   134.031250        NaN       NaN\n\nBrand: 2\n Multiple Comparison of Means - Tukey HSD, FWER=0.01 \n=====================================================\ngroup1 group2 meandiff p-adj   lower    upper  reject\n-----------------------------------------------------\nAngela    Bob   40.875    0.0  15.6475 66.1025   True\nAngela Justin    13.75 0.2673 -11.4775 38.9775  False\nAngela  Karen     24.5 0.0127  -0.7275 49.7275  False\n   Bob Justin  -27.125 0.0052 -52.3525 -1.8975   True\n   Bob  Karen  -16.375 0.1434 -41.6025  8.8525  False\nJustin  Karen    10.75  0.477 -14.4775 35.9775  False\n-----------------------------------------------------\n                 df      sum_sq      mean_sq          F    PR(&gt;F)\nC(Technician)   3.0  7159.09375  2386.364583  10.932522  0.000063\nResidual       28.0  6111.87500   218.281250        NaN       NaN\n\nBrand: 3\n Multiple Comparison of Means - Tukey HSD, FWER=0.01 \n=====================================================\ngroup1 group2 meandiff p-adj   lower    upper  reject\n-----------------------------------------------------\nAngela    Bob     -6.5 0.7259 -27.7799 14.7799  False\nAngela Justin   -5.125 0.8433 -26.4049 16.1549  False\nAngela  Karen   35.375    0.0  14.0951 56.6549   True\n   Bob Justin    1.375 0.9961 -19.9049 22.6549  False\n   Bob  Karen   41.875    0.0  20.5951 63.1549   True\nJustin  Karen     40.5    0.0  19.2201 61.7799   True\n-----------------------------------------------------\n                 df    sum_sq      mean_sq         F        PR(&gt;F)\nC(Technician)   3.0  9431.125  3143.708333  20.24118  3.537879e-07\nResidual       28.0  4348.750   155.312500       NaN           NaN\n\n\n\nThere are differences between different technicians for each brand of disk drive"
  },
  {
    "objectID": "notes/analytics/07032023/index.html",
    "href": "notes/analytics/07032023/index.html",
    "title": "More Complex ANOVA & Regression",
    "section": "",
    "text": "flowchart LR\n    A[Continuous Target Variable] --&gt; B[One-Way ANOVA]\n    A --&gt; C[Two-Way ANOVA]\n    A --&gt; D[n-Way ANOVA]"
  },
  {
    "objectID": "notes/analytics/07032023/index.html#post-hoc-testing",
    "href": "notes/analytics/07032023/index.html#post-hoc-testing",
    "title": "More Complex ANOVA & Regression",
    "section": "4.1 Post-Hoc Testing",
    "text": "4.1 Post-Hoc Testing\nWe have statistical differences among the categories and we want to know where these differences exist.\n\n\nCode\ntukey_ames2 &lt;- TukeyHSD(ames_aov2)\nprint(tukey_ames2)\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Sale_Price ~ Heating_QC + Central_Air, data = train)\n\n$Heating_QC\n                       diff        lwr       upr     p adj\nFair-Poor          49176.42 -63650.448 162003.29 0.7571980\nTypical-Poor       67781.01 -42800.320 178362.35 0.4506761\nGood-Poor          87753.89 -23040.253 198548.03 0.1945181\nExcellent-Poor    146288.89  35818.859 256758.92 0.0028361\nTypical-Fair       18604.59  -6326.425  43535.61 0.2484556\nGood-Fair          38577.47  12718.894  64436.04 0.0004622\nExcellent-Fair     97112.47  72679.867 121545.07 0.0000000\nGood-Typical       19972.87   7050.230  32895.52 0.0002470\nExcellent-Typical  78507.88  68746.678  88269.07 0.0000000\nExcellent-Good     58535.00  46602.229  70467.78 0.0000000\n\n$Central_Air\n        diff      lwr      upr p adj\nY-N 43256.57 31508.27 55004.87     0\n\n\nCode\nplot(tukey_ames2, las = 1)\n\n\n\n\n\n\n\n\n\ndiff refers to the average difference in Sale_Price between the two categories\n\nKeep in mind that if you increase your sample size, you should decrease your significance level. P-values always go down with an increase in sample size."
  },
  {
    "objectID": "notes/analytics/07032023/index.html#r-code",
    "href": "notes/analytics/07032023/index.html#r-code",
    "title": "More Complex ANOVA & Regression",
    "section": "5.1 R Code",
    "text": "5.1 R Code\n\n\nCode\names_aov_int &lt;- aov(Sale_Price ~ Heating_QC * Central_Air, data = train)\nsummary(ames_aov_int)\n\n\n                         Df    Sum Sq   Mean Sq F value   Pr(&gt;F)    \nHeating_QC                4 2.891e+12 7.228e+11 147.897  &lt; 2e-16 ***\nCentral_Air               1 2.903e+11 2.903e+11  59.403 1.99e-14 ***\nHeating_QC:Central_Air    4 3.972e+10 9.930e+09   2.032   0.0875 .  \nResiduals              2041 9.975e+12 4.887e+09                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nWhen you’re looking at significance, make sure to look at the interaction’s significance first.\n\nIf interaction exists, we no longer care if the individual variables are significant or not because it’s the interaction that matters."
  },
  {
    "objectID": "notes/analytics/07032023/index.html#model-hierarchy",
    "href": "notes/analytics/07032023/index.html#model-hierarchy",
    "title": "More Complex ANOVA & Regression",
    "section": "5.2 Model Hierarchy",
    "text": "5.2 Model Hierarchy\nIdea of model hierarchy: If higher-order terms are significant, then we should keep all the main effect terms that are a part of the higher-order terms as well."
  },
  {
    "objectID": "notes/analytics/07032023/index.html#slicing",
    "href": "notes/analytics/07032023/index.html#slicing",
    "title": "More Complex ANOVA & Regression",
    "section": "5.3 Slicing",
    "text": "5.3 Slicing\nIf the interaction term was significant, the number of level pairs we would have to consider can be overwhelming. Slicing performs an F-test for means for one variable within the level of another variable.\nAn example is subsetting the data into Central_Air: Yes and Central_Air: No and then seeing the significance of Heating_QC:\n\n\nCode\nCA_aov &lt;- train %&gt;%\n    group_by(Central_Air) %&gt;%\n    nest() %&gt;%\n    mutate(aov = map(data, ~ summary(aov(Sale_Price ~ Heating_QC, data = .x))))\nprint(CA_aov$aov)\n\n\n[[1]]\n              Df    Sum Sq   Mean Sq F value Pr(&gt;F)    \nHeating_QC     4 2.242e+12 5.606e+11   108.5 &lt;2e-16 ***\nResiduals   1899 9.809e+12 5.165e+09                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n[[2]]\n             Df    Sum Sq   Mean Sq F value  Pr(&gt;F)   \nHeating_QC    4 1.774e+10 4.435e+09   3.793 0.00582 **\nResiduals   142 1.660e+11 1.169e+09                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "notes/analytics/07032023/index.html#assumptions",
    "href": "notes/analytics/07032023/index.html#assumptions",
    "title": "More Complex ANOVA & Regression",
    "section": "5.4 Assumptions",
    "text": "5.4 Assumptions\nSame as One-Way ANOVA:\n\nIndependence of observations\nEquality of variance\n\nLevene Test only available for interactions\n\nNormality of categories"
  },
  {
    "objectID": "notes/analytics/06292023/lab_3.html",
    "href": "notes/analytics/06292023/lab_3.html",
    "title": "Yang MSA",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\ngarlic &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/garlic.csv\")\nglimpse(garlic)\n\n\nRows: 32\nColumns: 3\n$ BedID      &lt;int&gt; 101, 102, 103, 104, 105, 106, 107, 108, 201, 202, 203, 204,…\n$ Fertilizer &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,…\n$ BulbWt     &lt;dbl&gt; 0.2391642, 0.2582814, 0.2047856, 0.2433666, 0.2726395, 0.21…\n\n\nVerifying normality:\n\n\nCode\ngarlic_lm &lt;- lm(BulbWt ~ factor(Fertilizer), data = garlic)\nggplot(garlic, aes(x = BulbWt, fill = factor(Fertilizer))) +\n    geom_density(alpha = 0.2, position = \"identity\") +\n    labs(x = \"Bulb Weight\")\n\n\n\n\n\n\nGroups do not appear to be Normally distributed"
  },
  {
    "objectID": "notes/analytics/06282023/breakout_2.html",
    "href": "notes/analytics/06282023/breakout_2.html",
    "title": "Yang MSA",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\ncovid &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/coviddata.csv\")\n\nglimpse(covid)\n\n\nRows: 1,551\nColumns: 5\n$ X                    &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15…\n$ zip                  &lt;int&gt; 90210, 90221, 90232, 90243, 90254, 90265, 90276, …\n$ region               &lt;chr&gt; \"West\", \"West\", \"West\", \"West\", \"West\", \"West\", \"…\n$ population           &lt;int&gt; 50509, 52659, 50305, 53724, 47560, 50325, 47920, …\n$ covidDeathsPerCapita &lt;dbl&gt; 19.075, 17.728, 18.022, 17.896, 17.165, 17.275, 1…\n\n\n\nYou’ve been asked to explore differences between rates of death from Covid in the east vs. the west. You download some data (covidPerCapita) from the CDC that has Covid death rates per capita (covidDeathsPerCapita) by zip code (zip). Not all zip codes are reporting, and even handling the data from those that do report is difficult so you select a random sample of zip codes in the east and the west.\n\nConduct a t-test for the difference of means in per capita deaths from Covid in the east region vs the west region. Don’t forget to verify assumptions. Note anything of interest to you, including the results of any tests performed, violations of assumptions, etc.\n\n\nVerifying normality:\n\n\nCode\nggplot(covid, aes(sample = covidDeathsPerCapita, color = region)) +\n    stat_qq() +\n    stat_qq_line()\n\n\n\n\n\n\nBoth regions are approximately normally distributed for per capita deaths\n\nTesting for difference in variances:\n\n\nCode\nvar.test(covidDeathsPerCapita ~ region, data = covid)$p.value\n\n\n[1] 0.1738449\n\n\n\nAt a p-value of 0.174 we do not reject the null hypothesis that the variances are not significantly different\nWe can proceed with a two-sample t-test with equal variances\n\n\n\nCode\nt.test(covidDeathsPerCapita ~ region, data = covid, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  covidDeathsPerCapita by region\nt = 53.6, df = 1549, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group East and group West is not equal to 0\n95 percent confidence interval:\n 1.928196 2.074681\nsample estimates:\nmean in group East mean in group West \n          20.00643           18.00500 \n\n\nWe have a very low p-value such that we reject the null hypothesis that our means are similar. We believe that the mean deaths are significantly different between the two regions.\nAlthough our tests from this sample allow us to conclude that the means are different, we have to be careful because our sample does not include all zip codes. Is our data balanced? Did we have issues with the way the data was sampled?\n\n\nCode\nt.test(covidDeathsPerCapita ~ region, data = covid, var.equal = TRUE, alternative = \"greater\")\n\n\n\n    Two Sample t-test\n\ndata:  covidDeathsPerCapita by region\nt = 53.6, df = 1549, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group East and group West is greater than 0\n95 percent confidence interval:\n 1.939983      Inf\nsample estimates:\nmean in group East mean in group West \n          20.00643           18.00500 \n\n\n\n\nCode\nlength(covid[covid$region == \"West\", ]) == length(covid[covid$region == \"East\", ])\n\n\n[1] TRUE"
  },
  {
    "objectID": "notes/analytics/06282023/index.html",
    "href": "notes/analytics/06282023/index.html",
    "title": "Introduction to Statistical Inference",
    "section": "",
    "text": "Last time we talked about different statistical measures like mean and standard deviation. These are called point estimates.\nThere is variability among samples. However, we can have a margin of error for our estimate via the Central Limit Theorem"
  },
  {
    "objectID": "notes/analytics/06282023/index.html#procedure",
    "href": "notes/analytics/06282023/index.html#procedure",
    "title": "Introduction to Statistical Inference",
    "section": "3.1 Procedure",
    "text": "3.1 Procedure\n\nStart with a null hypothesis \\(H_0\\) about a parameter of interest. We assume \\(H_0\\) is true.\nSelect an acceptable significance level \\(\\alpha\\) which represents the likelihood that you incorrectly reject \\(H_0\\) (probability of Type I error)\nAlternative hypothesis \\(H_a\\) is the logical opposite. Note that alternative hypothesis is the “significantly different” statement–no equal signs should appear in alternative\nCollect data, compute statistic\nDetermine the probability that you observed a statistic as extreme or more extreme as the one you did assuming \\(H_0\\) is true \\(\\rightarrow\\) p-value\nIf p-value \\(\\leq \\alpha\\), reject \\(H_0\\) and fail to reject otherwise"
  },
  {
    "objectID": "notes/analytics/06282023/index.html#example-in-r",
    "href": "notes/analytics/06282023/index.html#example-in-r",
    "title": "Introduction to Statistical Inference",
    "section": "5.1 Example in R",
    "text": "5.1 Example in R\n\nWe want to know if the true Sales Price is different then $178,000.\nThe null hypothesis is \\(H_0\\): \\(\\mu = 178000\\) and the alternative is \\(H_a\\): \\(\\mu \\neq 178000\\). \\(\\alpha = 0.05\\)\n\n\n\nCode\nlibrary(AmesHousing)\n\names &lt;- make_ordinal_ames()\n\nt.test(ames$Sale_Price, mu = 178000)\n\n\n\n    One Sample t-test\n\ndata:  ames$Sale_Price\nt = 1.8945, df = 2929, p-value = 0.05825\nalternative hypothesis: true mean is not equal to 178000\n95 percent confidence interval:\n 177902.3 183689.9\nsample estimates:\nmean of x \n 180796.1 \n\n\nDo not reject the null hypothesis as p-value \\(&gt; \\alpha\\)\nTo conduct a directional t-test:\n\n\nCode\nt.test(ames$Sale_Price, mu = 178000, alternative = \"greater\")\n\n\n\n    One Sample t-test\n\ndata:  ames$Sale_Price\nt = 1.8945, df = 2929, p-value = 0.02913\nalternative hypothesis: true mean is greater than 178000\n95 percent confidence interval:\n 178367.7      Inf\nsample estimates:\nmean of x \n 180796.1 \n\n\nCode\nt.test(ames$Sale_Price, mu = 178000, alternative = \"less\")\n\n\n\n    One Sample t-test\n\ndata:  ames$Sale_Price\nt = 1.8945, df = 2929, p-value = 0.9709\nalternative hypothesis: true mean is less than 178000\n95 percent confidence interval:\n     -Inf 183224.4\nsample estimates:\nmean of x \n 180796.1"
  },
  {
    "objectID": "notes/analytics/06282023/index.html#assumptions",
    "href": "notes/analytics/06282023/index.html#assumptions",
    "title": "Introduction to Statistical Inference",
    "section": "6.1 Assumptions",
    "text": "6.1 Assumptions\n\nIndependent observations\nNormally distributed data for each group\nEqual variances for each group\n\nTested formally with F-test to determine which t-test to use"
  },
  {
    "objectID": "notes/analytics/06282023/index.html#f-test-for-equality-of-variances",
    "href": "notes/analytics/06282023/index.html#f-test-for-equality-of-variances",
    "title": "Introduction to Statistical Inference",
    "section": "6.2 F-Test for Equality of Variances",
    "text": "6.2 F-Test for Equality of Variances\n\n\\(H_0: \\sigma_1^2 = \\sigma_2^2\\)\n\\(H_a: \\sigma_1^2 \\neq \\sigma_2^2\\)\n\\(F = \\frac{\\max(s_1^2, s_2^2)}{\\min(s_1^2, s_2^2)}\\)"
  },
  {
    "objectID": "notes/analytics/06282023/index.html#two-sample-t-test-in-r",
    "href": "notes/analytics/06282023/index.html#two-sample-t-test-in-r",
    "title": "Introduction to Statistical Inference",
    "section": "6.3 Two-Sample t-test in R",
    "text": "6.3 Two-Sample t-test in R\nWe first need to verify the normality condition:\n\n\nCode\nggplot(ames, aes(sample = Sale_Price, color = Central_Air)) +\n    stat_qq() +\n    stat_qq_line()\n\n\n\n\n\nNormality seems to fail with houses that have central air conditioning. However, for illustration we will still conduct the two-sample t-test.\nNote that in practice if normality fails then some groups consider not even conducting a t-test when variances are equal–just go straight to variances are not equal.\n\n\nCode\nvar.test(Sale_Price ~ Central_Air, data = ames)\n\n\n\n    F test to compare two variances\n\ndata:  Sale_Price by Central_Air\nF = 0.2258, num df = 195, denom df = 2733, p-value &lt; 2.2e-16\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1854873 0.2800271\nsample estimates:\nratio of variances \n         0.2257977 \n\n\nReject \\(H_0\\) based on the p-value so we conclude that the variances are not equal.\n\n\nCode\nt.test(Sale_Price ~ Central_Air, data = ames, var.equal = FALSE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  Sale_Price by Central_Air\nt = -27.433, df = 336.06, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group N and group Y is not equal to 0\n95 percent confidence interval:\n -90625.69 -78498.92\nsample estimates:\nmean in group N mean in group Y \n       101890.5        186452.8 \n\n\nWith a regular two-sample t-test we reject the null hypothesis that the means are equal.\nHowever, our normality assumption wasn’t satisfied so we should use a nonparametric test that does not rely on normality."
  },
  {
    "objectID": "notes/analytics/06282023/index.html#wilcoxon-rank",
    "href": "notes/analytics/06282023/index.html#wilcoxon-rank",
    "title": "Introduction to Statistical Inference",
    "section": "6.4 Wilcoxon Rank",
    "text": "6.4 Wilcoxon Rank\nThe question we are answering with this test is, “Are the median sale prices of houses with and without central air the same?”\n\n\nCode\nwilcox.test(Sale_Price ~ Central_Air, data = ames)\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  Sale_Price by Central_Air\nW = 63164, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n6.4.1 Interpretations of Wilcoxon\n\n\n\n\n\n\n\nConditions\nInterpretation of Significant Mann-Whiteney-Wilcoxon Test\n\n\n\n\nGroup distributions are identical in shape, variance and symmetric\nDifference in means\n\n\nGroup distributions are identical in shape, variance, but not symmetric\nDifference in medians\n\n\nGroup distributions are not identical in shape, variance, and are not symmetric\nDifference in location (distributional dominance)"
  },
  {
    "objectID": "notes/communication/index.html",
    "href": "notes/communication/index.html",
    "title": "Communication",
    "section": "",
    "text": "Communications: 06/26/2023\n\n\n\n\n\n\n\ncommunication\n\n\n\n\n\n\n\n\n\n\n\nJun 26, 2023\n\n\nYang Chen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro/index.html",
    "href": "notes/programming/R/r4ds/intro/index.html",
    "title": "r4ds: Introduction",
    "section": "",
    "text": "Note\n\n\n\nThese notes are based on the second edition of the R for Data Science book by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund.\nAll quotes and examples are credited to the authors of this awesome book!"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro/index.html#import",
    "href": "notes/programming/R/r4ds/intro/index.html#import",
    "title": "r4ds: Introduction",
    "section": "1.1 Import",
    "text": "1.1 Import\nData comes from multiple sources:\n\nFiles\nDatabases\nWeb APIs\n\nIn the context of R, we are loading our data into a dataframe."
  },
  {
    "objectID": "notes/programming/R/r4ds/intro/index.html#tidy",
    "href": "notes/programming/R/r4ds/intro/index.html#tidy",
    "title": "r4ds: Introduction",
    "section": "1.2 Tidy",
    "text": "1.2 Tidy\nStore our data in a form that is consistent and allows us to focus on analyzing the problem rather than “fighting to get the data into the right form for different functions.”"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro/index.html#transform",
    "href": "notes/programming/R/r4ds/intro/index.html#transform",
    "title": "r4ds: Introduction",
    "section": "1.3 Transform",
    "text": "1.3 Transform\nIf we have a problem we are trying to analyze, then we use our problem space to guide observations of interest or create new variables from existing variables that relate to our problem.\n\n\n\n\nflowchart LR\n    Tidying --- C[ ]:::empty\n    Transforming --- C\n    C --&gt; Wrangling\n    classDef empty width:0px,height:0px;"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro/index.html#visualization-and-model",
    "href": "notes/programming/R/r4ds/intro/index.html#visualization-and-model",
    "title": "r4ds: Introduction",
    "section": "1.4 Visualization and Model",
    "text": "1.4 Visualization and Model\nWe represent our data in graphs, charts, and other displays to help us find or resolve questions about our data.\n“Models are complementary tools to visualization”. Models help us answer the questions we have.\n\nEvery model makes assumptions and they cannot answer their own assumptions"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro/index.html#communication",
    "href": "notes/programming/R/r4ds/intro/index.html#communication",
    "title": "r4ds: Introduction",
    "section": "1.5 Communication",
    "text": "1.5 Communication\nAfter the previous steps are at a satisfactory point, we have to communicate our results in a way that others can understand. This might mean in notebooks like this one or through presentations to a business client."
  },
  {
    "objectID": "notes/index.html",
    "href": "notes/index.html",
    "title": "Notes",
    "section": "",
    "text": "Programming 🐍\nNotes on Python, R and fun little experiments using software!\n\n\nAnalytics 🔎\nNotes curated from my statistics and analytics courses taught by Dr. Aric LaBarr and Dr. Susan Simmons.\n\n\nCommunication 🙊\nAll about professional and technical communication taught by Dr. Sarah Egan Warren!\n\n\nPrimer 🐤\nMSA Summer Primer 2023 Notes"
  },
  {
    "objectID": "notes/primer/categorical_data/index.html",
    "href": "notes/primer/categorical_data/index.html",
    "title": "Categorical Data Analysis",
    "section": "",
    "text": "Type of Predictors | Type of Response\nCategorical\nContinuous\nContinuous and Categorical\n\n\n\n\nContinuous\nAnalysis of Variance\nOrdinary Least Squares Regression\nAnalysis of Covariance\n\n\nCategorical\nTests of Association\nLogistic Regression\nLogistic Regression"
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#qualitative-data-types",
    "href": "notes/primer/categorical_data/index.html#qualitative-data-types",
    "title": "Categorical Data Analysis",
    "section": "2.1 Qualitative Data Types",
    "text": "2.1 Qualitative Data Types\nNominal\n\nCategories with no logical ordering\n\nOrdinal\n\nCategories with a logical order / only two ways to order the categories (binary is ordinal)"
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#examining-categorical-variables",
    "href": "notes/primer/categorical_data/index.html#examining-categorical-variables",
    "title": "Categorical Data Analysis",
    "section": "2.2 Examining Categorical Variables",
    "text": "2.2 Examining Categorical Variables\nBy examining distributions of categorical variables we can\n\nDetermine the frequencies of data values\nRecognize possible associations among variables\n\nAssociation exists between two categorical variables if distribution of one variable changes when the level of the other variable changes.\nIf there is no association, distribution of first variable is the same regardless of the level of the other."
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#chi-square-tests",
    "href": "notes/primer/categorical_data/index.html#chi-square-tests",
    "title": "Categorical Data Analysis",
    "section": "3.1 Chi-Square Tests",
    "text": "3.1 Chi-Square Tests\n\n\\(H_0\\): No Association\nObserved freq \\(=\\) Expected freq.\n\\(H_a\\): Association\nObserved freq. \\(\\neq\\) Expected freq.\n\nExpected freq. are calculated by the formula\n\\[\n\\frac{\\text{Row Total} \\times \\text{Column Total}}{\\text{Sample Size}}\n\\]\n\n3.1.1 \\(\\chi^2\\) Distribution\n\nBounded below by zero\nRight skewed\nOne set of degrees of freedom\n\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import chi2\n\nx = np.arange(0, 20, 0.001)\n\nplt.plot(x, chi2.pdf(x, df=4))\n\n\n\n\n\nFigure 1: Plot of a \\(\\chi^2\\) distribution with d.f. 4\n\n\n\n\n\n\n3.1.2 Pearson \\(\\chi^2\\) Test\n\\[\nQ_P = \\sum_{i=1}^{R} \\sum_{j=1}^{C} \\frac{(Obs_{i,j} - Exp_{i,j})^2}{Exp_{i,j}}\n\\]\n\\[\nd.f. = (\\#\\text{Rows} - 1)(\\#\\text{Columns} - 1)\n\\]\n\n\n3.1.3 Likelihood Ratio \\(\\chi^2\\) Test\n\\[\nQ_{LR} = 2 \\times \\sum_{i=1}^{R}\\sum_{j=1}^{C} Obs_{i,j} \\times \\log{(\\frac{Obs_{i,j}}{Exp_{i,j}})}\n\\]\n\\[\nd.f. = (\\#\\text{Rows} - 1)(\\#\\text{Columns} - 1)\n\\]"
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#example",
    "href": "notes/primer/categorical_data/index.html#example",
    "title": "Categorical Data Analysis",
    "section": "3.2 Example",
    "text": "3.2 Example\n\nA manager of a major car dealership wants to determine if the membership of a client in the loyalty program is associated with the color of car that they buy. With this knowledge, it potentially could help the sales staff show different cars to different clients to help improve the likelihood of a sale. The manager pull information from the previous years sales.\n\n\n\nCalculate the expected counts in the right table\n\n\n\nRecall that expected frequency is given by the the product of row total and column total over sample size.\n\n\nCode\nd = {\n    'black': {'yes': 149, 'no': 101},\n    'white': {'yes': 101, 'no': 66},\n    'blue': {'yes': 72, 'no': 108},\n    'red': {'yes': 96, 'no': 161},\n    'green': {'yes': 39, 'no': 65}\n}\ndf_cars = pd.DataFrame(d).T\ndf_cars['total'] = df_cars['yes'] + df_cars['no']\ndf_cars['exp_y'] = df_cars['total'] * \\\n    df_cars['yes'].sum() / df_cars['total'].sum()\ndf_cars['exp_n'] = df_cars['total'] * \\\n    df_cars['no'].sum() / df_cars['total'].sum()\ndf_cars.head()\n\n\n\n\n\n\n\n\n\nyes\nno\ntotal\nexp_y\nexp_n\n\n\n\n\nblack\n149\n101\n250\n119.258873\n130.741127\n\n\nwhite\n101\n66\n167\n79.664927\n87.335073\n\n\nblue\n72\n108\n180\n85.866388\n94.133612\n\n\nred\n96\n161\n257\n122.598121\n134.401879\n\n\ngreen\n39\n65\n104\n49.611691\n54.388309\n\n\n\n\n\n\n\n\n\nCompute \\(Q_P\\) and \\(Q_{LR}\\) and summarize results.\n\n\n\n\nCode\ndef calculate_pearson(row):\n    return (row['yes'] - row['exp_y']) ** 2 / row['exp_y'] + (row['no'] - row['exp_n']) ** 2 / row['exp_n']\n\n\ndef calculate_likelihood(row):\n    return 2 * ((row['yes'] * np.log(row['yes'] / row['exp_y'])) + (row['no'] * np.log(row['no'] / row['exp_n'])))\n\n\nq_pearson = df_cars.apply(calculate_pearson, axis=1).sum()\nlikelihood = df_cars.apply(calculate_likelihood, axis=1).sum()\n\nprint(f'Q_p: {q_pearson}, Q_LR: {likelihood}')\n\n\nQ_p: 44.76457096344832, Q_LR: 45.07972866310165"
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#ordinal-compared-to-nominal-tests",
    "href": "notes/primer/categorical_data/index.html#ordinal-compared-to-nominal-tests",
    "title": "Categorical Data Analysis",
    "section": "3.3 Ordinal Compared to Nominal Tests",
    "text": "3.3 Ordinal Compared to Nominal Tests\n\nPearson and Likelihood Ratio \\(\\chi^2\\) tests can handle any type of categorical variable\nOrdinal variables provide extra information since order of the categories matters compared to nominal\nCan test for even more with ordinal vars. against other ordinal vars.–whether two ordinal vars. have a linear relationship as compared to just a general one\n\nHypothesis Statements:\n\n\\(H_0\\): No Linear Association\n\\(H_a\\): Linear Association"
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#mantel-haenszel-chi2-test",
    "href": "notes/primer/categorical_data/index.html#mantel-haenszel-chi2-test",
    "title": "Categorical Data Analysis",
    "section": "3.4 Mantel-Haenszel \\(\\chi^2\\) Test",
    "text": "3.4 Mantel-Haenszel \\(\\chi^2\\) Test\n\\[\nQ_{MH} = (n - 1)r^2\n\\]\n\n\\(r^2\\) is the Pearson correlation between row and column variables"
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#odds-ratio",
    "href": "notes/primer/categorical_data/index.html#odds-ratio",
    "title": "Categorical Data Analysis",
    "section": "4.1 Odds Ratio",
    "text": "4.1 Odds Ratio\nOdds ratio measure how much more likely, with respect to odds, a certain event occurs in one group relative to its occurrence in another group.\nOdds of an event occurring is not the same as the probability that an event occurs.\n\\[\n\\text{Odds} = \\frac{p}{1 - p}\n\\]\n\n4.1.1 Probability vs. Odds of an Outcome\n\n\n\n\nYes\nNo\n\n\n\n\nLoyal\n20\n60\n\n\nNon-Loyal\n10\n90\n\n\n\n\n\nCode\nd = {'yes': [20, 10], 'no': [60, 90]}\ndf_loyalty = pd.DataFrame(d, index=['Loyal', 'Non-Loyal'])\n\ndf_loyalty['prob_y'] = df_loyalty['yes'] / df_loyalty.iloc[:, :2].sum(axis=1)\ndf_loyalty['prob_n'] = df_loyalty['no'] / df_loyalty.iloc[:, :2].sum(axis=1)\ndf_loyalty['odds_y'] = (df_loyalty['prob_y'] / df_loyalty['prob_n']).round(3)\ndf_loyalty['odds_n'] = df_loyalty['prob_n'] / df_loyalty['prob_y']\n\ndf_loyalty.head()\nprint(\n    f'Odds Ratio, Loyal to Non-Loyal: {df_loyalty.loc[\"Loyal\", \"odds_y\"] / df_loyalty.loc[\"Non-Loyal\", \"odds_y\"]}')\n\n\nOdds Ratio, Loyal to Non-Loyal: 3.0\n\n\n\nLoyal program customers have 3 times the odds of buying the product as compared to customers not in the loyalty program."
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#cramers-v",
    "href": "notes/primer/categorical_data/index.html#cramers-v",
    "title": "Categorical Data Analysis",
    "section": "4.2 Cramer’s V",
    "text": "4.2 Cramer’s V\nWhen you have more than &gt;2 categories in one or both variables we use Cramer’s V.\n\\[\nV = \\sqrt{\\frac{(\\frac{Q_P}{n})}{\\min(\\#\\text{Rows} - 1, \\#\\text{Columns} - 1)}}\n\\]\n\nBounded between 0 and 1 (-1 and 1 for 2x2 scenario) where closer to 0 the weaker the relationship"
  },
  {
    "objectID": "notes/primer/categorical_data/index.html#example-1",
    "href": "notes/primer/categorical_data/index.html#example-1",
    "title": "Categorical Data Analysis",
    "section": "4.3 Example",
    "text": "4.3 Example\n\nThe same manager as the previous example now wants to know the strength of the relationship between the color of car and loyalty program. Use the appropriate measure of association to calculate this.\n\n\n\nCode\nn = df_cars['total'].sum()\nrows, cols = df_cars.iloc[:, :2].shape\n\ncramer_v = np.sqrt((q_pearson / n) / np.min([rows - 1, cols - 1]))\nnp.round(cramer_v, 3)\n\n\n0.216"
  },
  {
    "objectID": "notes/primer/fundamental/index.html",
    "href": "notes/primer/fundamental/index.html",
    "title": "Fundamental Statistical Concepts",
    "section": "",
    "text": "There are three main pieces to statistics:"
  },
  {
    "objectID": "notes/primer/fundamental/index.html#common-types-of-bias",
    "href": "notes/primer/fundamental/index.html#common-types-of-bias",
    "title": "Fundamental Statistical Concepts",
    "section": "2.1 Common Types of Bias",
    "text": "2.1 Common Types of Bias\n\nSelection Bias\n\nUndercoverage: frame and population are not equal\nNonresponse: subject in sample cannot / will not respond or be measured\n\nSampling Bias\n\nConvenience Sampling: selecting subjects based on accessibility and ease\nVoluntary sampling: subjects volunteer themselves–may not be representative"
  },
  {
    "objectID": "notes/primer/fundamental/index.html#common-sampling-techniques",
    "href": "notes/primer/fundamental/index.html#common-sampling-techniques",
    "title": "Fundamental Statistical Concepts",
    "section": "2.2 Common Sampling Techniques",
    "text": "2.2 Common Sampling Techniques\n\n2.2.1 Simple Random Sampling (SRS)\nSample items from population such that every possible sample of specified sizes has an equal chance of being selected\n\n\n\nSimple Random Sampling\n\n\nAdvantages\n\nNo statistical bias\nNo prev. info about sample needed ahead of time\n\nDisadvantages\n\nExpensive\nHard to implement\nNeed list of population\n\n\n\n2.2.2 Stratified Random Sampling (STS)\nPopulation is divided into subgroups, called strata, so that each member in the population belongs to only one strata.\nSample items from every strata. The sample size between groups does not need to be the same (e.g. if we know groups in pop. are in a 20:80 ratio)\n\n\n\nStratified Random Sampling\n\n\nAdvantages\n\nSmaller sample sizes can achieve same accuracy as SRS\nMore info about parts of population\n\nDisadvantages\n\nNeed info about population ahead of time to split on\n\n\n\n2.2.3 Cluster Sampling\nSimilar to stratified where you group members of population into subgroups called clusters. You only talk to a sample of \\(m\\) clusters selected randomly.\nIn cluster sampling, you don’t necessarily believe there are differences between clusters.\n\n\n\nCluster Sampling\n\n\nAdvantages\n\nOvercome issues with travel, time, expense\nEasier to implement than SRS or STS\n\nDisadvantages\n\nNeed info about population ahead of time to split on–but not total list.\nMay have slight bias if random clusters aren’t representative\n\n\n\n2.2.4 Systematic Sampling\nSelect every \\(k^{th}\\) item in the populatino after randomly selecting a starting point between 1 and \\(k\\).\n\\(k\\) is determined as a ratio of population size over desired sample size.\n\n\n\nSystematic Sampling Starting Point Selection\n\n\n\n\n\nSystematic Sampling\n\n\nAdvantages\n\nVery easy to get sample\n\nDisadvantages\n\nMay be biased especialy if order of list of population matters"
  },
  {
    "objectID": "notes/primer/fundamental/index.html#example",
    "href": "notes/primer/fundamental/index.html#example",
    "title": "Fundamental Statistical Concepts",
    "section": "2.3 Example",
    "text": "2.3 Example\n\nA large worldwide financial company wnats to develop a new retirement plan for the company. They want to survey different managers of branches around the world to find out the most important strategies the new retirement plan should contain. They have 5000 branches worldwide and want to personally interview these branch managers. They have information about the banch size (small, medium, large) and the state/province location of the branch. They want to talk to 50 branch managers.\nDevelop four separate strategies to sample these branch managers based on the four different statistical sampling techniques discussed previously.\n\n\nSRS: Randomly sample 50 branches to interview the managers of\nSTS: Stratify by size and select random samples from every strata\nCluster: Randomly select sample of states/provinces, then select branches at random from those states/provinces\nSystematic: Select every 100th branch in list of branches starting from a random starting point between 1 and 100\n\n\n\nCode\n# Example of systematic sampling in Python\n\nimport numpy as np\nindexes = np.arange(5000)\nsample_size = 50\nk = len(indexes) // sample_size\n\nprint(f'k: {k}')\nprint(f'Sample Size: {sample_size}')\n\nstart = np.random.randint(k + 1)\nselected = indexes[start::k]\n\nprint(f'Length of selected: {len(selected)}')\nindexes[start::k]\n\n\nk: 100\nSample Size: 50\nLength of selected: 50\n\n\narray([  96,  196,  296,  396,  496,  596,  696,  796,  896,  996, 1096,\n       1196, 1296, 1396, 1496, 1596, 1696, 1796, 1896, 1996, 2096, 2196,\n       2296, 2396, 2496, 2596, 2696, 2796, 2896, 2996, 3096, 3196, 3296,\n       3396, 3496, 3596, 3696, 3796, 3896, 3996, 4096, 4196, 4296, 4396,\n       4496, 4596, 4696, 4796, 4896, 4996])"
  },
  {
    "objectID": "notes/primer/fundamental/index.html#qualitative-vs.-quantitative",
    "href": "notes/primer/fundamental/index.html#qualitative-vs.-quantitative",
    "title": "Fundamental Statistical Concepts",
    "section": "3.1 Qualitative vs. Quantitative",
    "text": "3.1 Qualitative vs. Quantitative\nQuantitative data are numeric data that define value of quantity.\nQualitative data are data whose measurement scale is inherently categorical.\n\nNominal data are categories with no logical ordering\nOrdinal data are categories with a logical order / only two ways to order the categories (binary is ordinal)"
  },
  {
    "objectID": "notes/primer/fundamental/index.html#time-series-vs.-cross-sectional",
    "href": "notes/primer/fundamental/index.html#time-series-vs.-cross-sectional",
    "title": "Fundamental Statistical Concepts",
    "section": "3.2 Time Series vs. Cross-sectional",
    "text": "3.2 Time Series vs. Cross-sectional\nTime series is a set of ordered data values observed at successive point in times. Each row might be indexed by time referring to a dependence in time.\nCross-sectional is a set of data values observed at a fixed point in time or where time is of no significance (could have time as a variable just that the response does not depend on it)."
  },
  {
    "objectID": "notes/primer/index.html",
    "href": "notes/primer/index.html",
    "title": "Primer",
    "section": "",
    "text": "Categorical Data Analysis\n\n\n\n\n\n\n\nprimer\n\n\n\n\n\n\n\n\n\n\n\nJun 14, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nAnalysis of Variance\n\n\n\n\n\n\n\nprimer\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nHypothesis Testing\n\n\n\n\n\n\n\nprimer\n\n\nhypothesis testing\n\n\nstatistics\n\n\n\n\n\n\n\n\n\n\n\nJun 7, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nConfidence Intervals\n\n\n\n\n\n\n\nprimer\n\n\nstatistics\n\n\n\n\n\n\n\n\n\n\n\nMay 30, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nProbability\n\n\n\n\n\n\n\nprimer\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nFundamental Statistical Concepts\n\n\n\n\n\n\n\nprimer\n\n\n\n\n\n\n\n\n\n\n\nMay 22, 2023\n\n\nYang Chen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yang Chen",
    "section": "",
    "text": "Hiya, I’m Yang!\nI’m a data science Master’s student who’s passionate about AI, deep learning, and explainable data science. This is an open repository of notes, projects, and musings that I am gathering through my Master’s at the Institute for Advanced Analytics.\nI’m excited to share what I learn and hope you can join me for the ride! You can find me on LinkedIn, Github or through my main website"
  },
  {
    "objectID": "projects/summer_r/index.html",
    "href": "projects/summer_r/index.html",
    "title": "Getting to Know Your Classmates Data",
    "section": "",
    "text": "library(tidyverse)\nlibrary(stringr)\nlibrary(countrycode)\nlibrary(ggthemes)\n\n# setwd(\"summer_r\")\nclassmates &lt;- read.csv(\"data/Get_to_know_survey_2023.csv\")\nglimpse(classmates)\n\nRows: 96\nColumns: 7\n$ Birth_Month_Year        &lt;chr&gt; \"December, 1999\", \"7, 1998\", \"April, 1999\", \"N…\n$ State                   &lt;chr&gt; \"North Carolina\", \"Virginia\", \"North Carolina\"…\n$ Country                 &lt;chr&gt; \"United States\", \"United States\", \"United Stat…\n$ Languages               &lt;chr&gt; \"English\", \"English, Spanish\", \"English\", \"Eng…\n$ When_Hear_About_Program &lt;chr&gt; \"1-2 years\", \"1-2 years\", \"3-5 years\", \"Less t…\n$ How_Hear_About_Program  &lt;chr&gt; \"1. Recommended by professors\", \"2. Recommende…\n$ Hobbies                 &lt;chr&gt; \"Video Games, Sports\", \"Movies, Television Ser…"
  },
  {
    "objectID": "projects/summer_r/index.html#top-5-languages-visualized",
    "href": "projects/summer_r/index.html#top-5-languages-visualized",
    "title": "Getting to Know Your Classmates Data",
    "section": "Top 5 Languages Visualized",
    "text": "Top 5 Languages Visualized\n\nggplot(languages_top_5, aes(x = reorder(Languages, desc(n)), y = n, fill = Languages)) +\n    geom_col() +\n    labs(x = \"Languages\", y = \"Counts\", title = \"MSA Class of 2024: Top 5 Languages\") +\n    theme_economist()"
  },
  {
    "objectID": "projects/summer_r/index.html#wide-to-long-hobbies-column",
    "href": "projects/summer_r/index.html#wide-to-long-hobbies-column",
    "title": "Getting to Know Your Classmates Data",
    "section": "Wide to Long Hobbies Column",
    "text": "Wide to Long Hobbies Column\n\nclassmates &lt;- classmates %&gt;%\n    mutate(Hobbies = str_squish(Hobbies)) %&gt;%\n    separate_longer_delim(Hobbies, \", \")\n\nclassmates\n\n# A tibble: 502 × 9\n   Birth_Month_Year State          Country      Languages When_Hear_About_Prog…¹\n   &lt;chr&gt;            &lt;chr&gt;          &lt;chr&gt;        &lt;chr&gt;     &lt;chr&gt;                 \n 1 December, 1999   North Carolina United Stat… English   1-2 years             \n 2 December, 1999   North Carolina United Stat… English   1-2 years             \n 3 7, 1998          Virginia       United Stat… English   1-2 years             \n 4 7, 1998          Virginia       United Stat… English   1-2 years             \n 5 7, 1998          Virginia       United Stat… English   1-2 years             \n 6 7, 1998          Virginia       United Stat… English   1-2 years             \n 7 7, 1998          Virginia       United Stat… Spanish   1-2 years             \n 8 7, 1998          Virginia       United Stat… Spanish   1-2 years             \n 9 7, 1998          Virginia       United Stat… Spanish   1-2 years             \n10 7, 1998          Virginia       United Stat… Spanish   1-2 years             \n# ℹ 492 more rows\n# ℹ abbreviated name: ¹​When_Hear_About_Program\n# ℹ 4 more variables: How_Hear_About_Program &lt;chr&gt;, Hobbies &lt;chr&gt;,\n#   Birth_Month &lt;chr&gt;, Birth_Year &lt;chr&gt;\n\nclassmates_copy &lt;- classmates_copy %&gt;%\n    mutate(Hobbies = str_squish(Hobbies)) %&gt;%\n    separate_longer_delim(Hobbies, \", \")\n\nhobbies_top_5 &lt;- classmates_copy %&gt;%\n    filter(!is.na(Hobbies)) %&gt;%\n    count(Hobbies) %&gt;%\n    arrange(desc(n)) %&gt;%\n    head(n = 5)\n\nhobbies_top_5\n\n                          Hobbies  n\n1 Outside Recreational Activities 59\n2                          Sports 50\n3               Television Series 48\n4                          Movies 47\n5                           Music 34"
  },
  {
    "objectID": "projects/summer_r/index.html#top-5-hobbies-visualized",
    "href": "projects/summer_r/index.html#top-5-hobbies-visualized",
    "title": "Getting to Know Your Classmates Data",
    "section": "Top 5 Hobbies Visualized",
    "text": "Top 5 Hobbies Visualized\nNote: Using copy of older classmates data frame since we don’t want to “double-count” student hobbies after making the language column long. Maybe there’s a better way to do this through grouping.\n\nggplot(hobbies_top_5, aes(x = reorder(Hobbies, desc(n)), y = n, fill = Hobbies)) +\n    geom_col() +\n    labs(x = \"Hobbies\", y = \"Counts\", title = \"MSA Class of 2024: Top 5 Hobbies\") +\n    theme_economist()"
  },
  {
    "objectID": "projects/summer_r/index.html#standardizing-birth_month_year",
    "href": "projects/summer_r/index.html#standardizing-birth_month_year",
    "title": "Getting to Know Your Classmates Data",
    "section": "Standardizing Birth_Month_Year",
    "text": "Standardizing Birth_Month_Year\n\nclassmates &lt;- classmates %&gt;%\n    mutate(Birth_Month_Year = paste(Birth_Month, Birth_Year, sep = \", \"))\n\nclassmates %&gt;%\n    select(Birth_Month_Year)\n\n# A tibble: 502 × 1\n   Birth_Month_Year\n   &lt;chr&gt;           \n 1 December, 1999  \n 2 December, 1999  \n 3 July, 1998      \n 4 July, 1998      \n 5 July, 1998      \n 6 July, 1998      \n 7 July, 1998      \n 8 July, 1998      \n 9 July, 1998      \n10 July, 1998      \n# ℹ 492 more rows"
  },
  {
    "objectID": "projects/summer_r/index.html#student-countries-heatmap",
    "href": "projects/summer_r/index.html#student-countries-heatmap",
    "title": "Getting to Know Your Classmates Data",
    "section": "Student Countries Heatmap",
    "text": "Student Countries Heatmap\n\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\n\nselected_countries &lt;- classmates %&gt;%\n    select(Country) %&gt;%\n    distinct(Country) %&gt;%\n    arrange(Country)\nworld_data &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nselected_countries_data &lt;- world_data %&gt;%\n    inner_join(selected_countries, by = c(\"name\" = \"Country\"))\n\nggplot() +\n    geom_sf(data = world_data, color = \"grey50\", fill = \"lightblue\") +\n    geom_sf(data = selected_countries_data, fill = \"red\", alpha = 0.7) +\n    labs(\n        title = \"Countries of Origin\",\n        subtitle = \"MSA 2024\",\n        caption = \"Library: Natural Earth\"\n    ) +\n    theme_minimal()"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "notes/primer/probability/index.html",
    "href": "notes/primer/probability/index.html",
    "title": "Probability",
    "section": "",
    "text": "Probability is a numerical measure of the likelihood of that event’s occurrence. It takes on a value in the interval \\([0, 1]\\).\nA sample space is a collection of all possible outcomes in a random process. The sum of all probabilities in the sample space must sum to 1.\nAn event is a collection of one or more outcomes from a process whose result cannot be predicted. The probability of event \\(X\\) is expressed as \\(P(X)\\)\n\n\n\n\nEvent consisting of all sample points that are not in \\(A\\).\n\\[\nP(\\bar{A}) = 1 - P(A)\n\\]\n\n\n\nThe union of an event \\(A\\) and event \\(B\\) is the event containing all sample points in \\(A\\) or \\(B\\) or both.\n\\[\nA \\cup B\n\\]\n\n\n\nAll sample points that are in both \\(A\\) and \\(B\\).\n\\[\nA \\cap B\n\\]\n\n\n\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]\n\n\n\nMutually exclusive meants that events have no sample points in common–they do not intersect.\nThe events cannot both occur which turns the addition law into\n\\[\nP(A \\cup B) = P(A) + P(B)\n\\]\n\n\n\nProbability of an event given that another event has occurred.\n\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)}\n\\]\n\n\n\nWe derive this from the conditional property which expresses the intersection as a multiplication:\n\\[\n\\begin{align*}\nP(A \\cap B) &= P(A | B) \\cdot P(B) \\\\\n&= P(B | A) \\cdot P(A)\n\\end{align*}\n\\]\nIf events are independent then this becomes\n\\[\nP(A \\cap B) = P(A) \\cdot P(B)\n\\]"
  },
  {
    "objectID": "notes/primer/probability/index.html#basic-relationships",
    "href": "notes/primer/probability/index.html#basic-relationships",
    "title": "Probability",
    "section": "",
    "text": "Event consisting of all sample points that are not in \\(A\\).\n\\[\nP(\\bar{A}) = 1 - P(A)\n\\]\n\n\n\nThe union of an event \\(A\\) and event \\(B\\) is the event containing all sample points in \\(A\\) or \\(B\\) or both.\n\\[\nA \\cup B\n\\]\n\n\n\nAll sample points that are in both \\(A\\) and \\(B\\).\n\\[\nA \\cap B\n\\]\n\n\n\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]\n\n\n\nMutually exclusive meants that events have no sample points in common–they do not intersect.\nThe events cannot both occur which turns the addition law into\n\\[\nP(A \\cup B) = P(A) + P(B)\n\\]\n\n\n\nProbability of an event given that another event has occurred.\n\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)}\n\\]\n\n\n\nWe derive this from the conditional property which expresses the intersection as a multiplication:\n\\[\n\\begin{align*}\nP(A \\cap B) &= P(A | B) \\cdot P(B) \\\\\n&= P(B | A) \\cdot P(A)\n\\end{align*}\n\\]\nIf events are independent then this becomes\n\\[\nP(A \\cap B) = P(A) \\cdot P(B)\n\\]"
  },
  {
    "objectID": "notes/primer/probability/index.html#conditional-vs.-marginal-probabilities",
    "href": "notes/primer/probability/index.html#conditional-vs.-marginal-probabilities",
    "title": "Probability",
    "section": "2.1 Conditional vs. Marginal Probabilities",
    "text": "2.1 Conditional vs. Marginal Probabilities\nMarginal probabilities are considered unconditional probabilities–they are probabilities of events without any condition.\n\n2.1.1 Example\n\nLet’s take a look at promotion of people at a company with advanced degrees vs. those who don’t have them.\n\n\n\nCode\nimport pandas as pd\n\nd = {'yes': {'promoted': 288, 'not_promoted': 672},\n     'no': {'promoted': 36, 'not_promoted': 204}}\n\ndf = pd.DataFrame(d)\ndf\n\n\n\n\n\n\n\n\n\nyes\nno\n\n\n\n\npromoted\n288\n36\n\n\nnot_promoted\n672\n204\n\n\n\n\n\n\n\nOne marginal probability is the probability of an advanced degree:\n\n\nCode\nprob_adv_deg = df['yes'].sum() / (df['yes'].sum() + df['no'].sum())\nprob_adv_deg\n\n\n0.8\n\n\nOn the other hand, a conditional probability might be the probability of a promotion given that the employee has no advanced degree:\n\n\nCode\ncond_prob = df.loc['promoted', 'no'] / df['no'].sum()\ncond_prob\n\n\n0.15"
  },
  {
    "objectID": "notes/primer/confidence_intervals/index.html",
    "href": "notes/primer/confidence_intervals/index.html",
    "title": "Confidence Intervals",
    "section": "",
    "text": "Point estimators cannot be expected to provide exact values of population parameters. Intervals provide information about how close the point estimate is to the value of the parameter.\nConfidence intervals are interval estimates where we have a certain level of confidence in the interval.\nWhat does it mean when we are 95% confidence that the population mean is between 20 and 30?"
  },
  {
    "objectID": "notes/primer/confidence_intervals/index.html#student-t-distribution",
    "href": "notes/primer/confidence_intervals/index.html#student-t-distribution",
    "title": "Confidence Intervals",
    "section": "3.1 Student t Distribution",
    "text": "3.1 Student t Distribution\nThe t distribution is also symmetric, but has thicker tails than the Normal distribution.\nIt has \\(n - 1\\) degrees of freedom where the degrees of freedom are the number of independent pieces of information that go into the computation of \\(s\\).\nFor larger samples, the t distribution is approximately the standard Normal distribution.\n\n\nCode\nx = np.linspace(-4, 4, 100)\n\npdf = t.pdf(x, df=19)\nplt.plot(x, pdf)\n\n\n\n\n\nPlot of a t distribution with d.f. 19\n\n\n\n\nThe confidence interval for \\(\\bar{x}\\) is calculated as:\n\\[\n\\bar{x} \\pm t_{\\alpha/2} \\cdot \\frac{s}{\\sqrt{n}}\n\\]\nFor large samples (\\(n \\geq 50\\)) we can calculate the confidence interval for the mean from any population.\nFor small samples (\\(n &lt; 50\\)) we need to assume the population follows a Normal distribution."
  },
  {
    "objectID": "notes/primer/hypothesis_testing/index.html",
    "href": "notes/primer/hypothesis_testing/index.html",
    "title": "Hypothesis Testing",
    "section": "",
    "text": "According to the CLT, the the mean has a sampling distribution that follows a Normal distribution as long as the sample size is large enough.\nLet’s take the average age of our customers as an example. Initially, we believe that the average age of our customers is \\(\\mu = 25\\) years old with standard deviation \\(\\sigma = 10\\).\nWe sample 100 customers and collect their age.\n\n\nCode\nfrom scipy.stats import t\nimport numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\nmean = 25\nsd = 1\nalpha = 0.05\n\nx = np.linspace(20, 35, 1000)\n\ncrit_value = norm.ppf(1 - alpha / 2, loc=mean, scale=sd)\npdf = norm.pdf(x, loc=mean, scale=sd)\nplt.axvline(31, color='r')\n\nplt.plot(x, pdf)\n\n\n\n\n\nWhat is the probability we see a sample mean \\(\\bar{x} = 31\\) under our original assumption that the mean is 25?\nIt’s very low! \\(&lt; 0.0001\\) so we have to strongly question our original hypothesis. We may no longer think it is true given the data."
  },
  {
    "objectID": "notes/primer/hypothesis_testing/index.html#type-i-error",
    "href": "notes/primer/hypothesis_testing/index.html#type-i-error",
    "title": "Hypothesis Testing",
    "section": "7.1 Type I Error",
    "text": "7.1 Type I Error\n\nReject the null hypothesis when the null hypothesis was actually true (False rejection)\nProbability of making a Type I error in a hypothesis test is called the significance level"
  },
  {
    "objectID": "notes/primer/hypothesis_testing/index.html#type-ii-error",
    "href": "notes/primer/hypothesis_testing/index.html#type-ii-error",
    "title": "Hypothesis Testing",
    "section": "7.2 Type II Error",
    "text": "7.2 Type II Error\n\nAccepting the null hypothesis when the null hypothesis was actually false (False acceptance)\nProbability of not making a Type II error in a hypothesis test is called the power\nDifficult to control Type II error\nCan only control for Type I or Type II at a time"
  },
  {
    "objectID": "notes/primer/hypothesis_testing/index.html#conditions",
    "href": "notes/primer/hypothesis_testing/index.html#conditions",
    "title": "Hypothesis Testing",
    "section": "9.1 Conditions",
    "text": "9.1 Conditions\n\nThe hypothesis test is two-sided\n\\(C = 1 - \\alpha\\) where \\(C\\) is the confidence level and \\(\\alpha\\) is the significance level"
  },
  {
    "objectID": "notes/primer/anova/index.html",
    "href": "notes/primer/anova/index.html",
    "title": "Analysis of Variance",
    "section": "",
    "text": "One sample hypothesis tests are focused on one population parameter. However, sometimes we would like to compare multiple parameters against each other. This is the foundation of an analysis called analysis of variance (ANOVA).\nRecall the one-sample case:\n\\[\nH_0: \\mu\n\\begin{cases}\n\\geq \\\\\n= \\\\\n\\leq\n\\end{cases}\n\\ \\ \\mu_0\n\\]\n\\[\nH_a: \\mu\n\\begin{cases}\n&lt; \\\\\n\\neq \\\\\n&gt;\n\\end{cases}\n\\mu_0\n\\]\nIn the two-sample case, there are two parameters we are calculating so now we have an expression:\n\\[\nH_0: \\mu_1 - \\mu_2\n\\begin{cases}\n\\geq \\\\\n= \\\\\n\\leq\n\\end{cases}\n\\ 0\n\\]\n\\[\nH_a: \\mu_1 - \\mu_2\n\\begin{cases}\n&lt; \\\\\n\\neq \\\\\n&gt;\n\\end{cases}\n\\ 0\n\\]\n\n\n\nAssume two samples are independent of each other\nWe have to take into account whether the variances are equal or not\n\nDifferent hypothesis test structures depends on whether or not variances are equal\n\n\nRecall that our general test statistic is calculated as\n\\[\n\\begin{align*}\n\\text{Test Statistic} &= \\frac{\\text{Statistic} - \\text{Null Value}}{\\text{Standard Error}} \\\\\n\\ \\\\\n&= \\frac{(\\bar{x}_1 - \\bar{x}_2) - D_0}{s_p\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\n\\end{align*}\n\\]\n\n\\(s_p\\) is the pooled standard deviation\n\nWe then calculate our p-value based on the t-distribution with \\(d.f. = n_1 - 1 + n_2 - 1 = n_1 + n_2 - 2\\)\n\n\n\nUnder assumption of equal variances we have two estimates of population variance–\\(s_1^2\\) and \\(s_2^2\\). We should combine both to get our estimate:\n\\[\n\\begin{align*}\ns_p &= \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}} \\\\\n\\ \\\\\n&= \\sqrt{\\frac{\\sum (x_{1,i} - \\bar{x}_1)^2 + \\sum (x_{2,i} - \\bar{x}_2)^2}{n_1 + n_2 - 2}}\n\\end{align*}\n\\]\n\n\n\nEach population has an approximate Normal distribution\nVariances of two groups are equal\n\n\n\n\n\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\times s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}\n\\]\n\n\n\nHypothesis Statements:\n\nSame as the prior tests\n\nOur Test Statistic:\n\\[\n\\text{Test Statistic} = \\frac{(\\bar{x}_1 - \\bar{x}_2) - D_0}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n\\]\n\nStandard error changes since we need to test estimates of our two separate population variances separately \\(\\rightarrow\\) cannot “pool” them\n\nThe degrees of freedom on our t-test are a more complicated expression:\n\\[\nd.f. = \\frac{(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2})^2}{\\frac{(\\frac{s_1^2}{n_1})^2}{n_1 - 1} + \\frac{(\\frac{s_2^2}{n_2})^2}{n_2 - 1}}\n\\]\n\n\n\nFor different variances, we don’t use the pooled variance\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2}^* \\times \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}\n\\]\n\nStandard error changes using separate population variances\n\n\n\n\n\nA human resources manager of a large business firm is trying to determine if there exists gender bias in the pay scale of employees at the company. The manager assumes the variability of salaries between genders is different, but wants to test if makes have higher average salary than females. The manager samples 62 males and 77 females. The sample of males had an average salary of $87,547 with a s.d. of $5,910. The sample of females had an average salary of $78,289 with a s.d. of $6,276. Run a hypothesis test.\n\n\n\nCode\n# H_a: mu_1 &gt; mu_2 with mu_1 representing mean of males\n\nt &lt;- ((87547 - 78289) - 0) / sqrt(5910^2 / 62 + 6276^2 / 77)\nsprintf(\"Test statistic equals %.3f\", t)\n\n\n[1] \"Test statistic equals 8.930\"\n\n\nCode\ndf &lt;- (5910^2 / 62 + 6276^2 / 77)^2 / ((5910^2 / 62)^2 / 61 + (6276^2 / 77)^2 / 76)\nsprintf(\"Df: %d\", floor(df))\n\n\n[1] \"Df: 133\"\n\n\nCode\npt(t, df, lower.tail = FALSE)\n\n\n[1] 1.468658e-15"
  },
  {
    "objectID": "notes/primer/anova/index.html#assumptions",
    "href": "notes/primer/anova/index.html#assumptions",
    "title": "Analysis of Variance",
    "section": "",
    "text": "Assume two samples are independent of each other\nWe have to take into account whether the variances are equal or not\n\nDifferent hypothesis test structures depends on whether or not variances are equal\n\n\nRecall that our general test statistic is calculated as\n\\[\n\\begin{align*}\n\\text{Test Statistic} &= \\frac{\\text{Statistic} - \\text{Null Value}}{\\text{Standard Error}} \\\\\n\\ \\\\\n&= \\frac{(\\bar{x}_1 - \\bar{x}_2) - D_0}{s_p\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\n\\end{align*}\n\\]\n\n\\(s_p\\) is the pooled standard deviation\n\nWe then calculate our p-value based on the t-distribution with \\(d.f. = n_1 - 1 + n_2 - 1 = n_1 + n_2 - 2\\)"
  },
  {
    "objectID": "notes/primer/anova/index.html#pooled-standard-deviation",
    "href": "notes/primer/anova/index.html#pooled-standard-deviation",
    "title": "Analysis of Variance",
    "section": "",
    "text": "Under assumption of equal variances we have two estimates of population variance–\\(s_1^2\\) and \\(s_2^2\\). We should combine both to get our estimate:\n\\[\n\\begin{align*}\ns_p &= \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}} \\\\\n\\ \\\\\n&= \\sqrt{\\frac{\\sum (x_{1,i} - \\bar{x}_1)^2 + \\sum (x_{2,i} - \\bar{x}_2)^2}{n_1 + n_2 - 2}}\n\\end{align*}\n\\]\n\n\n\nEach population has an approximate Normal distribution\nVariances of two groups are equal"
  },
  {
    "objectID": "notes/primer/anova/index.html#confidence-interval",
    "href": "notes/primer/anova/index.html#confidence-interval",
    "title": "Analysis of Variance",
    "section": "",
    "text": "\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\times s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}\n\\]"
  },
  {
    "objectID": "notes/primer/anova/index.html#testing-difference-in-means---unequal-variances",
    "href": "notes/primer/anova/index.html#testing-difference-in-means---unequal-variances",
    "title": "Analysis of Variance",
    "section": "",
    "text": "Hypothesis Statements:\n\nSame as the prior tests\n\nOur Test Statistic:\n\\[\n\\text{Test Statistic} = \\frac{(\\bar{x}_1 - \\bar{x}_2) - D_0}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n\\]\n\nStandard error changes since we need to test estimates of our two separate population variances separately \\(\\rightarrow\\) cannot “pool” them\n\nThe degrees of freedom on our t-test are a more complicated expression:\n\\[\nd.f. = \\frac{(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2})^2}{\\frac{(\\frac{s_1^2}{n_1})^2}{n_1 - 1} + \\frac{(\\frac{s_2^2}{n_2})^2}{n_2 - 1}}\n\\]"
  },
  {
    "objectID": "notes/primer/anova/index.html#confidence-interval-1",
    "href": "notes/primer/anova/index.html#confidence-interval-1",
    "title": "Analysis of Variance",
    "section": "",
    "text": "For different variances, we don’t use the pooled variance\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2}^* \\times \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}\n\\]\n\nStandard error changes using separate population variances"
  },
  {
    "objectID": "notes/primer/anova/index.html#example---comparing-two-means",
    "href": "notes/primer/anova/index.html#example---comparing-two-means",
    "title": "Analysis of Variance",
    "section": "",
    "text": "A human resources manager of a large business firm is trying to determine if there exists gender bias in the pay scale of employees at the company. The manager assumes the variability of salaries between genders is different, but wants to test if makes have higher average salary than females. The manager samples 62 males and 77 females. The sample of males had an average salary of $87,547 with a s.d. of $5,910. The sample of females had an average salary of $78,289 with a s.d. of $6,276. Run a hypothesis test.\n\n\n\nCode\n# H_a: mu_1 &gt; mu_2 with mu_1 representing mean of males\n\nt &lt;- ((87547 - 78289) - 0) / sqrt(5910^2 / 62 + 6276^2 / 77)\nsprintf(\"Test statistic equals %.3f\", t)\n\n\n[1] \"Test statistic equals 8.930\"\n\n\nCode\ndf &lt;- (5910^2 / 62 + 6276^2 / 77)^2 / ((5910^2 / 62)^2 / 61 + (6276^2 / 77)^2 / 76)\nsprintf(\"Df: %d\", floor(df))\n\n\n[1] \"Df: 133\"\n\n\nCode\npt(t, df, lower.tail = FALSE)\n\n\n[1] 1.468658e-15"
  },
  {
    "objectID": "notes/primer/anova/index.html#example---comparing-two-variances",
    "href": "notes/primer/anova/index.html#example---comparing-two-variances",
    "title": "Analysis of Variance",
    "section": "2.1 Example - Comparing Two Variances",
    "text": "2.1 Example - Comparing Two Variances\n\nA human resources manager of a large business firm is trying to determine if there exists gender bias in the pay scale of employees at the company. The manager has no assumption about the variability of salaries between genders, but wants to test if makes have higher average salary than females. The manager samples 62 males and 77 females. The sample of males had an average salary of $87,547 with a s.d. of $5,910. The sample of females had an average salary of $78,289 with a s.d. of $6,276. Run a hypothesis test.\nNeed to first test if variances are equal or not before running test of means\n\n\n\nCode\nf &lt;- 6276^2 / 5910^2\nsprintf(\"F Statistic: %.3f\", f)\n\n\n[1] \"F Statistic: 1.128\"\n\n\nCode\ndf1 &lt;- 76\ndf2 &lt;- 61\n\npf(f, df1, df2, lower.tail = FALSE)\n\n\n[1] 0.3147624\n\n\nAt a significance level of 0.05 we would not reject the null hypothesis that our variances are different."
  },
  {
    "objectID": "notes/primer/anova/index.html#example---sources-of-variation",
    "href": "notes/primer/anova/index.html#example---sources-of-variation",
    "title": "Analysis of Variance",
    "section": "3.1 Example - Sources of Variation",
    "text": "3.1 Example - Sources of Variation\n\nYou have SAT scores for both boys and girls from a local school\nYou believe that the boys and girls have the same avg. test score, but want to test otherwise\nOf the 39 females, 32 of them are part of the accelerated math and language arts program\nOf the 39 males, 11 of them are part of the accelerated math and language arts program\n\nMatched samples are samples selected such that each data value from one sample is related (or matched / paired) with a corresponding data value from a second sample\nIn the previous example, we would match boys and girls who were in the accelerated program and ones who were not.\nOur focus turns from individual values in the populations and to the values of the differences in the populations. All assumptions and calculations are done on the differences, not individual samples.\n\\[\nH_0: \\mu_d\n\\begin{cases}\n\\geq \\\\\n= \\\\\n\\leq\n\\end{cases}\n\\ \\ D_0\n\\]\n\\[\nH_a: \\mu_d\n\\begin{cases}\n&lt; \\\\\n\\neq \\\\\n&gt;\n\\end{cases}\n\\ \\ D_0\n\\]\n\nAssumptions for matched pairs hypothesis test are same as for regular hypothesis test for means\nLarge sample (\\(n &gt; 50\\)) of differences\nSmall samples with differences having Normal distribution\n\nHypothesis Statements:\n\\[\nH_0: \\mu_d\n\\begin{cases}\n\\geq \\\\\n= \\\\\n\\leq\n\\end{cases}\n\\ \\ D_0\n\\hspace{2cm}\nH_a: \\mu_d\n\\begin{cases}\ntest\n\\end{cases}\n\\]\nTest Statistic:\n\\[\nt = \\frac{\\bar{x}_d - D_0}{\\frac{s_d}{\\sqrt{n_d}}}\n\\]\n\\[ d.f. = n_d - 1 \\]"
  },
  {
    "objectID": "notes/primer/anova/index.html#confidence-interval-2",
    "href": "notes/primer/anova/index.html#confidence-interval-2",
    "title": "Analysis of Variance",
    "section": "3.2 Confidence Interval",
    "text": "3.2 Confidence Interval\n\\[\n\\bar{x}_d \\pm t_{\\alpha/2}^* \\times \\frac{s_d}{\\sqrt{n_d}}\n\\]"
  },
  {
    "objectID": "notes/primer/anova/index.html#example---paired-samples",
    "href": "notes/primer/anova/index.html#example---paired-samples",
    "title": "Analysis of Variance",
    "section": "3.3 Example - Paired Samples",
    "text": "3.3 Example - Paired Samples\n\nA human resources manager of a large business firm is trying to determine if there exists gender bias in the pay scale of employees at the company. The manager samples 51 pairs of male and female employees where the pair has the same job title and experience at the company. The average difference in salaries is $2,131 with a s.d. of differences of $7,898. Run a hypothesis test.\n\n\n\nCode\nt &lt;- (2131 - 0) / (7898 / sqrt(51))\nsprintf(\"Test statistic: %.3f\", t)\n\n\n[1] \"Test statistic: 1.927\"\n\n\nCode\ndf &lt;- 50\n\npt(t, df, lower.tail = FALSE)\n\n\n[1] 0.02984447\n\n\nAt a significant level of 0.05 we reject the null hypothesis that there is no gender bias in the pay scale of employees at the company."
  },
  {
    "objectID": "notes/primer/anova/index.html#confidence-interval-3",
    "href": "notes/primer/anova/index.html#confidence-interval-3",
    "title": "Analysis of Variance",
    "section": "4.1 Confidence Interval",
    "text": "4.1 Confidence Interval\n\\[\n(p_1 - p_2) \\pm z^* \\times \\sqrt{\\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 - p_2)}{n_2}}\n\\]"
  },
  {
    "objectID": "notes/primer/anova/index.html#comprehensive-example",
    "href": "notes/primer/anova/index.html#comprehensive-example",
    "title": "Analysis of Variance",
    "section": "4.2 Comprehensive Example",
    "text": "4.2 Comprehensive Example\n\nA researcher at a large university on the west coast is interested in comparing some factors between upperclassmen (juniors and seniors) and underclassmen (freshmen and sophomores) in the undergraduate school. The researcher believes that more experience in college may help students perform better in the classroom. The researcher is interested in testing if the average GPA of upperclassmen is greater than the average GPA of underclassmen. The researcher sampled 89 underclassmen with an average GPA of 2.75 with a s.d. of 0.91 and 102 upperclassmen with an average GPA of 3.07 and a s.d. of 1.02.\n\n\n\nThe researcher did not use matched sampling. Do you agree with their decision?\n\n\nNo. There are other factors that can influence GPA like major that we could match on for equal comparison\n\n\nConduct a hypothesis test on the variances to see if they are equal.\n\n\n\\[\nH_0: \\frac{\\sigma_1^2}{\\sigma_2^2} \\leq 1\n\\hspace{2cm}\nH_a: \\frac{\\sigma_1^2}{\\sigma_2^2} &gt; 1\n\\]\n\n\nCode\nf &lt;- 1.02^2 / 0.91^2\nsprintf(\"F Statistic: %0.3f\", f)\n\n\n[1] \"F Statistic: 1.256\"\n\n\nCode\ndf1 &lt;- 101\ndf2 &lt;- 88\n\npf(f, df1, df2, lower.tail = FALSE)\n\n\n[1] 0.1367661\n\n\nBased on a significance level of 0.05 we do not reject the null hypothesis. We do not have enough evidence to say that the variances between the two populations is different.\n\n\nConduct the appropriate hypothesis test on the means to see if they are equal.\n\n\n\n\nCode\ns_p &lt;- sqrt(((101 * 1.02^2) + (88 * 0.91^2)) / (102 + 89 - 2))\nsprintf(\"Pooled std. dev: %0.3f\", s_p)\n\n\n[1] \"Pooled std. dev: 0.970\"\n\n\nCode\nt &lt;- ((3.07 - 2.75) - 0) / (s_p * sqrt(1 / 102 + 1 / 89))\nsprintf(\"Test Statistic: %0.3f\", t)\n\n\n[1] \"Test Statistic: 2.274\"\n\n\nCode\npt(t, 89 + 102 - 2, lower.tail = FALSE)\n\n\n[1] 0.01205843\n\n\nAt a significance level of 0.05 we reject our null hypothesis that more experience in college does not lead to higher GPA performance."
  },
  {
    "objectID": "notes/primer/anova/index.html#example-continued",
    "href": "notes/primer/anova/index.html#example-continued",
    "title": "Analysis of Variance",
    "section": "4.3 Example Continued",
    "text": "4.3 Example Continued\n\nSame researcher as before also believes that a higher proportion of upperclassmen live off campus compared to the proportion of underclassmen. While sampling the students in the previous sample, the researcher also asked whether the student lived off campus. Of the 89 underclassmen sampled, 27 lived off campus. Of the 102 upperclassmen sampled, 65 lived off campus.\n\n\nConstruct a 95% confidence interval for the difference between the proportion of upperclassmen living off campus to the proportion of underclassmen living off campus.\n\n\\[\nH_0: p_1 - p_2 \\leq 0 \\hspace{1cm} H_a: p_1 - p_2 &gt; 0\n\\]\n\n\nCode\np1 &lt;- 65 / 102\np2 &lt;- 27 / 89\nsprintf(\"Upper p: %0.3f, Under p: %0.3f\", p1, p2)\n\n\n[1] \"Upper p: 0.637, Under p: 0.303\"\n\n\nCode\np_mean &lt;- (102 * p1 + 89 * p2) / (102 + 89)\nsprintf(\"p_mean: %0.3f\", p_mean)\n\n\n[1] \"p_mean: 0.482\"\n\n\nCode\nz &lt;- ((p1 - p2) - 0) / sqrt(p_mean * (1 - p_mean) * (1 / 102 + 1 / 89))\nsprintf(\"Z Statistic: %0.3f\", z)\n\n\n[1] \"Z Statistic: 4.607\"\n\n\nCode\nz_crit &lt;- qnorm(0.05 / 2, lower.tail = FALSE)\nz_crit\n\n\n[1] 1.959964\n\n\nCode\nmargin &lt;- z_crit * sqrt(p1 * (1 - p1) / 102 + p2 * (1 - p2) / 89)\nmargin\n\n\n[1] 0.1335203\n\n\nCode\nsprintf(\"95 perc. CI: %0.3f plus-minus %0.3f\", p1 - p2, margin)\n\n\n[1] \"95 perc. CI: 0.334 plus-minus 0.134\"\n\n\n\nConduct the appropriate hypothesis test to test the researcher’s claim.\n\n\\[\nH_0: p_1 - p_2 \\leq 0 \\hspace{1cm} H_a: p_1 - p_2 &gt; 0\n\\]\n\n\nCode\npnorm(z, lower.tail = FALSE)\n\n\n[1] 2.044913e-06\n\n\nAt a significance level of 0.0005 we reject the null hypothesis that the proportion of upperclassmen living off campus is not greater than the proportion of underclassmen living off campus.\n\nCan you compare the confidence interval and the hypothesis test?\n\nNo as the hypothesis test is one-sided while the confidence interval is two-sided."
  },
  {
    "objectID": "notes/primer/anova/index.html#one-way-anova",
    "href": "notes/primer/anova/index.html#one-way-anova",
    "title": "Analysis of Variance",
    "section": "5.1 One-Way ANOVA",
    "text": "5.1 One-Way ANOVA\nSimplest form of ANOVA is the one-way model.\n\nIndependent samples are obtained from \\(k\\) levels (categories) of a single factor (explanatory variable), then testing whether the \\(k\\) levels have equal means.\nSimilar to regression analysis in that we have one categorical variable predicting continuous response\n\n\\[\nH_0: \\mu_1 = \\mu_2 = \\cdots = \\mu_k\n\\]\n\\[\nH_a: \\text{At least one mean different than another}\n\\]\n\n5.1.1 Assumptions\n\nNormally distributed categories\nEquality of variances between categories\nIndependence\n\nTest Statistic:\n\\[\nF = \\frac{s_{max}^2}{s_{min}^2}\n\\]\nThe p-value is calculated from Hartley-s F-max distribution which isn’t covered here.\n\n\n5.1.2 Sources of Variation\n\nWithin-Sample Variability\n\nVariability in response that exists within category of a variable\n\nWhat you categories cannot explain (like SSE)\n\n\nBetween-Sample Variability\n\nVariability in response that exists between categories of a variable\n\nWhat you categories can explain (like SSR)\n\n\n\n\n\n5.1.3 Sum of Squares Within\nWithin sample is variability that you cannot explain by just knowing which category your observation falls into\n\\[\nSSW = \\sum_{i=1}^k\\sum_{j=1}^{n_i} (x_{i,j} - \\bar{x}_i)^2\n\\]\n\n\n5.1.4 Sum of Squares Between\nBetween sample is variability that you can explain by just knowing which category your observation falls into\n\\[\nSSB = \\sum_{i=1}^k n_i(\\bar{x}_i - \\bar{\\bar{x}})^2\n\\]"
  },
  {
    "objectID": "notes/primer/anova/index.html#partitioning-variability-in-anova",
    "href": "notes/primer/anova/index.html#partitioning-variability-in-anova",
    "title": "Analysis of Variance",
    "section": "5.2 Partitioning Variability in ANOVA",
    "text": "5.2 Partitioning Variability in ANOVA\n\n\n\n\nflowchart LR\nA(Total Variability) --&gt; B(SSR + SSE)\nB --&gt; C[Variability Between Groups]\nB --&gt; D[Variability Within Groups]"
  },
  {
    "objectID": "notes/primer/anova/index.html#anova-f-test",
    "href": "notes/primer/anova/index.html#anova-f-test",
    "title": "Analysis of Variance",
    "section": "5.3 ANOVA F-test",
    "text": "5.3 ANOVA F-test\n\\[\n\\begin{align*}\nH_0&: \\mu_1 = \\mu_2 = \\cdots = \\mu_k \\\\\nH_a&: \\text{At least one mean different than another}\n\\end{align*}\n\\]\nTest follows an F-distribution and is calculated as\n\\[\nF = \\frac{(\\frac{SSB}{k - 1})}{(\\frac{SSW}{N - k})}\n\\]\n\n\\(k\\) categories would be \\(k - 1\\) variables in a regression model\n\\(N\\) is the total sample size across all categories"
  },
  {
    "objectID": "notes/primer/anova/index.html#one-way-anova-table",
    "href": "notes/primer/anova/index.html#one-way-anova-table",
    "title": "Analysis of Variance",
    "section": "5.4 One-Way ANOVA Table",
    "text": "5.4 One-Way ANOVA Table\n\n\n\nOne-Way ANOVA Table"
  },
  {
    "objectID": "notes/primer/anova/index.html#one-way-anova-example",
    "href": "notes/primer/anova/index.html#one-way-anova-example",
    "title": "Analysis of Variance",
    "section": "5.5 One-Way ANOVA Example",
    "text": "5.5 One-Way ANOVA Example\n\nA marketing analyst is interested in testing the effectiveness of 4 different commercials describing their company’s new product. The marketing analyst randomly assigns a commercial to each of 32 cities across the country and measures the average increase in sales of their new product at their stores. The marketing analyst wants to test if there is a difference in sales between the commercials.\n\n\n\nFill in the blanks on the ANOVA table.\n\n\n\n\n\nSource\nDF\nSS\nMS\nF-Value\nP-Value\n\n\n\n\nBetween\n3\n2.3236\n0.775\n22.794\n\n\n\nWithin\n28\n0.9587\n0.034\n\n\n\n\nTotal\n31\n3.2823\n\n\n\n\n\n\n\n\nCode\npf(22.794, 3, 28, lower.tail = FALSE)\n\n\n[1] 1.128339e-07"
  },
  {
    "objectID": "notes/primer/anova/index.html#multiple-comparisons-problem",
    "href": "notes/primer/anova/index.html#multiple-comparisons-problem",
    "title": "Analysis of Variance",
    "section": "6.1 Multiple Comparisons Problem",
    "text": "6.1 Multiple Comparisons Problem\n\nYou have a test which makes an error 5% of the time when performed.\n\n\nWhat is the probability of making an error on your first test?\n\n5%\n\nWhat is the probability of making an error on your second test?\n\n5%\n\nWhat is the probability of making at least one error in two tests?\n\n9.75%\n\n\n\n6.1.1 Different Types of Error\nComparison-wise error rate\n\nError rate for each individual test or comparison\n\nExperiment-wise error rate\n\nError rate across all comparisons–proportion of experiments/comparisons in which at least one error occurs\n\nTests and confidence intervals usually control for comparison-wise, \\(\\alpha\\), but ideally want to control for experiment-wise."
  },
  {
    "objectID": "notes/primer/anova/index.html#multiple-comparison-methods",
    "href": "notes/primer/anova/index.html#multiple-comparison-methods",
    "title": "Analysis of Variance",
    "section": "6.2 Multiple Comparison Methods",
    "text": "6.2 Multiple Comparison Methods\n\n\n\n\n\n\n\n\nNumber of Groups Compared\nNumber of Comparisons\nExperimentwise Error Rate\n\n\n\n\n2\n1\n0.05\n\n\n3\n3\n0.14\n\n\n4\n6\n0.26\n\n\n5\n10\n0.40\n\n\n\n\n\\(EER \\leq 1 - (1 - \\alpha)^{nc}\\) where \\(nc\\) is the number of comparisons\n\n\n\n\n\nflowchart LR\nA(Control Comparisonwise Error Rate) --&gt; B(Pairwise t-tests)\nC(Control Experimentwise Error Rate) --&gt; D[Compare All Pairs Tukey]"
  },
  {
    "objectID": "notes/primer/anova/index.html#tukeys-hsd-test",
    "href": "notes/primer/anova/index.html#tukeys-hsd-test",
    "title": "Analysis of Variance",
    "section": "6.3 Tukey’s HSD Test",
    "text": "6.3 Tukey’s HSD Test\nHSD represents the Honest Significant Difference or Critical Range\nWe use Tukey’s when we consider pairwise comparisons\n\nExperimentwise error rate is equal to \\(\\alpha\\) when all pairwise comparisons are considered\nExperimentwise error rate is less than \\(\\alpha\\) when fewer than all pairwise comparisons are considered\nReplaces margin of error calculation for a typical confidence interval for a difference in means with an adjusted margin of error\n\n\\[\n\\text{Critical Range (Margin of Error)} = q_a \\times \\sqrt{\\frac{MSW}{2} \\times (\\frac{1}{n_i} + \\frac{1}{n_j})}\n\\]\n\n\\(q_a\\) is from studentized range distribution"
  },
  {
    "objectID": "notes/primer/anova/index.html#randomized-blocking",
    "href": "notes/primer/anova/index.html#randomized-blocking",
    "title": "Analysis of Variance",
    "section": "7.1 Randomized Blocking",
    "text": "7.1 Randomized Blocking\n\n7.1.1 Sources of Variation\nGenerally, comparing many population means works well in certain situations\nThere are some instances where blocking is used to control for sources of variation that might distort conclusions"
  },
  {
    "objectID": "notes/primer/anova/index.html#example",
    "href": "notes/primer/anova/index.html#example",
    "title": "Analysis of Variance",
    "section": "7.2 Example",
    "text": "7.2 Example\n\nThe same marketing analyst as before is interested in testing the effectiveness of 4 different commercials describing their company’s new product. The marketing analyst randomly assigns a commercial to each of 32 cities across the country and measures the average increase in sales of their new product at their stores. The four commercial average sales were $1.2M for commercial A, $1.8M for B, $0.76M for C, and $1.3M for D. Where are the differences in sales?\n\n\nWhat if the new product is a warm coat and a majority of the cities seeing C were warm weather cities?\nThe same marketing analyst as before is interested in testing the effectiveness of 4 different commercials describing their company’s new product. Split (block) country into 8 regions. Show each commercial to one city in each region. Sample size still 32."
  },
  {
    "objectID": "notes/primer/anova/index.html#assumptions-2",
    "href": "notes/primer/anova/index.html#assumptions-2",
    "title": "Analysis of Variance",
    "section": "7.3 Assumptions",
    "text": "7.3 Assumptions\nSame as One-Way ANOVA:\n\nNormally distributed categories\nEquality of variances between categories\nIndependence\n\nBlocking can come from collection of data as well as the analysis of the data as a variable being added to the model.\nWhen a new variable is added, we get a new source of variation–sum of squares of blocking."
  },
  {
    "objectID": "notes/primer/anova/index.html#sum-of-squares-blocks",
    "href": "notes/primer/anova/index.html#sum-of-squares-blocks",
    "title": "Analysis of Variance",
    "section": "7.4 Sum of Squares Blocks",
    "text": "7.4 Sum of Squares Blocks\n\\[\nSSBL = \\sum_{j=1}^b k(\\bar{x}_j - \\bar{\\bar{x}})^2\n\\]\nThe sum of squares comes out of the error sum of squares and gets brought into the model–the SSW shrinks even more."
  },
  {
    "objectID": "notes/primer/anova/index.html#blocking-anova-table",
    "href": "notes/primer/anova/index.html#blocking-anova-table",
    "title": "Analysis of Variance",
    "section": "7.5 Blocking ANOVA Table",
    "text": "7.5 Blocking ANOVA Table\n\n\n\nBlocking ANOVA Table\n\n\n\nThe F-Value in the Blocking row is the F-test with \\(H_a\\) at least one block mean not equal"
  },
  {
    "objectID": "notes/primer/anova/index.html#post-hoc-analysis-for-blocking",
    "href": "notes/primer/anova/index.html#post-hoc-analysis-for-blocking",
    "title": "Analysis of Variance",
    "section": "7.6 Post-hoc Analysis for blocking",
    "text": "7.6 Post-hoc Analysis for blocking\nTukey-Kramer ANOVA comparisons do not work for blocking.\nInstead, we have Fisher’s Least Significant Difference. Fisher’s LSD is a recalculation of the margin of error for the difference in means confidence interval just like Tukey’s critical range.\n\\[\nLSD = t^* \\times \\sqrt{MSW} \\times \\sqrt{\\frac{2}{b}}\n\\]"
  },
  {
    "objectID": "notes/programming/python/intro/weather.html",
    "href": "notes/programming/python/intro/weather.html",
    "title": "Yang MSA",
    "section": "",
    "text": "Code\n\"\"\" \nImported Libraries:\n    -   requests for making HTTP requests\n    -   collections for defaultdict class\n    -   operator for itemgetter methods\n    -   statistics for mean function\n\"\"\"\nimport requests\nfrom collections import defaultdict\nimport operator\nfrom statistics import mean\n\n# Constants for use in the project\n\nAPI_KEY = \"fa2f855799fef2552cb443042d5f660d\"\nLIMIT = 1\nURL = 'http://api.openweathermap.org/geo/1.0/direct'\nFORECAST_URL = 'http://api.openweathermap.org/data/2.5/forecast'\nFILENAME = \"YangC_output.csv\"\nCITIES = [\n    'Guilin, China',\n    'Dissen, Germany',\n    'Guatemala City, Guatemala',\n    'Kandukur, India',\n    'Nanaimo, British Columbia',\n    'Uijeongbu-si, South Korea',\n    'Yangon, Myanmar',\n    'Jalpa de Mendez, Mexico',\n    'Enugu, Nigeria',\n    'Peterhead, Scotland',\n    'Lima, Peru',\n    'Singapore, Singapore',\n    'Kaohsiung, Taiwan',\n    'Grimesland, North Carolina',\n    'Visalia, California',\n    'Colonia del Sacramento, Uruguay'\n]\n\n\n\n\nCode\nforecast_data = {}\n\n\"\"\" \n-   For every city name, make an HTTP request to get the lat-long coordinates\n-   Make an additional call with the coords. to get the city's 5-day forecast data and save to a dictionary\n\"\"\"\nfor city in CITIES:\n    params = {\n        \"q\": city,\n        \"limit\": LIMIT,\n        \"appid\": API_KEY\n    }\n    resp = requests.get(URL, params=params)\n    \n    if resp.ok:\n        json = resp.json() \n    else:\n        resp.raise_for_status()\n\n    if type(json) == list:\n        lat = json[0]['lat']\n        lon = json[0]['lon']\n\n    params = {\n        \"lat\": lat,\n        \"lon\": lon,\n        \"appid\": API_KEY\n    }\n    resp = requests.get(FORECAST_URL, params=params)\n\n    if resp.ok:\n        json = resp.json()\n    else:\n        resp.raise_for_status()\n\n    forecast_data[city] = json['list']\n\n\n\n\nCode\nrefined_data = {}\n\n\"\"\" \n-   For every city, save the min, max temperatures for each day starting from \"tomorrow\"\n\"\"\"\nfor city, data in forecast_data.items():\n    new_day = False\n    day = 0\n    min_max_data = defaultdict(list)\n    for d in data:\n        # \"Tomorrow\" is marked as the first day that starts at 00:00:00\n        if d[\"dt_txt\"].split()[-1] == \"00:00:00\":\n            new_day = True \n            day += 1\n\n        # Exclude the extra day 5 data\n        if day == 5:\n            break\n\n        # Min-max data from every day after starting point should be included \n        if new_day:\n            main = d[\"main\"]\n            min_max_data[day].append((main[\"temp_min\"], main[\"temp_max\"]))\n    refined_data[city] = min_max_data\n\n\n\n\nCode\nfinal_data = {city: {\"min\": [], \"max\": []} for city in refined_data.keys()}\n\n\"\"\" \n-   Calculate the min, max, min_avg, and max_avg temperatures for every day across every city\n\"\"\"\nfor city, days in refined_data.items():\n    for day, temps in days.items():\n        # Saved the data as min-max pairs so we are just retrieving the appropriate data points\n        min_temps = list(map(operator.itemgetter(0), temps))\n        max_temps = list(map(operator.itemgetter(1), temps))\n        \n        # Calculate statistics\n        min_temp = min(min_temps)\n        max_temp = max(max_temps)\n\n        # Save statistics to final data\n        final_data[city][\"min\"].append(min_temp)\n        final_data[city][\"max\"].append(max_temp)\n        \nfor city, d in final_data.items():\n    final_data[city][\"min_avg\"] = mean(d[\"min\"])\n    final_data[city][\"max_avg\"] = mean(d[\"max\"])\n\n\n\n\nCode\n\"\"\" \n-   Write the header and the collected statistics into a new CSV file\n-   Statistics are rounded to two decimal places\n\"\"\"\nwith open(FILENAME, \"w\") as f:\n    header = \"City,Min 1,Max 1,Min 2,Max 2,Min 3,Max 3,Min 4,Max 4,Min Avg,Max Avg\\n\"\n    f.write(header)\n    \n    entries = []\n    for city, d in final_data.items():\n        min_max_line = [None] * (len(d[\"min\"]) + len(d[\"max\"]))\n        min_max_line[::2] = d[\"min\"]\n        min_max_line[1::2] = d[\"max\"]\n        entry = f'\"{city}\",{\",\".join(format(x, \".2f\") for x in min_max_line)},{d[\"min_avg\"]:.2f},{d[\"max_avg\"]:.2f}\\n'\n        entries.append(entry) \n    \n    f.writelines(entries)"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro_visualization/index.html",
    "href": "notes/programming/R/r4ds/intro_visualization/index.html",
    "title": "r4ds: Visualization Introduction",
    "section": "",
    "text": "The book focuses on utilizing ggplot2 to build out data visualizations. The underlying system of the package is the grammar of graphics which builds up visuals through a layered approach of defined components.\nGrammar of graphics has a layered hierarchy of components:\nWe load the tidyverse package to have ggplot available to us in our workspace.\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nCode\n# Dataset and colorblind color palette\nlibrary(palmerpenguins)\nlibrary(ggthemes)"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro_visualization/index.html#terms",
    "href": "notes/programming/R/r4ds/intro_visualization/index.html#terms",
    "title": "r4ds: Visualization Introduction",
    "section": "1.1 Terms",
    "text": "1.1 Terms\n\nVariable is quantity, quality, property that can be measured.\nValue is the state of variable when it is measured. Value may change from measurement to measurement.\nObservations are measurements made under similar conditions. Observations contain several values for different variables. Sometimes called a data point.\nTabular data organizes values according to their variables and an observation. Considered tidy if every value is placed in its own cell, every variable in its own column, each observation on a row.\n\n\n\n\nIndex\n\\(x_1\\)\n\\(x_2\\)\n\n\n\n\n0\n1\nApple\n\n\n1\n2\nBanana\n\n\n\nTo view a dataframe / tibble:\n\n\nCode\npenguins\n\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nUse glimpse for a transposed view of the data. This function helps us view the different variables we have in our dataset.\n\n\nCode\nglimpse(penguins)\n\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro_visualization/index.html#initial-ggplot",
    "href": "notes/programming/R/r4ds/intro_visualization/index.html#initial-ggplot",
    "title": "r4ds: Visualization Introduction",
    "section": "2.1 Initial ggplot",
    "text": "2.1 Initial ggplot\nBegin a plot by calling the ggplot function along with the data you have.\n\n\nCode\nggplot(data = penguins)\n\n\n\n\n\nThe next layer in the hierarchy is aesthetics. We now add an additional layer that maps visual properties to our dataset variables. We can map x to flipper length and y to body mass.\n\n\nCode\nggplot(penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g))\n\n\n\n\n\nNext layer in the hierarchy is what actually plots the data. We define a geom to initialize a geometric object to present data. A point geom is created using geom_point.\n\n\nCode\nggplot(penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) +\n    geom_point()\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nRelationship appears to be positive between flipper length and body mass from the plot!"
  },
  {
    "objectID": "notes/programming/R/r4ds/intro_visualization/index.html#aesthetics-and-layers",
    "href": "notes/programming/R/r4ds/intro_visualization/index.html#aesthetics-and-layers",
    "title": "r4ds: Visualization Introduction",
    "section": "2.2 Aesthetics and Layers",
    "text": "2.2 Aesthetics and Layers\nWe can assign a variable to different parameters in the aes function to have ggplot automatically assign unique values of an aesthetic to a unique level of the variable.\n\n\nCode\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n    geom_point()\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "notes/programming/index.html",
    "href": "notes/programming/index.html",
    "title": "Programming",
    "section": "",
    "text": "r4ds: Introduction\n\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2023\n\n\nYang Chen\n\n\n\n\n\n\n  \n\n\n\n\nr4ds: Visualization Introduction\n\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2023\n\n\nYang Chen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notes/communication/062623/index.html",
    "href": "notes/communication/062623/index.html",
    "title": "Communications: 06/26/2023",
    "section": "",
    "text": "Make eye contact\n\nIf you’re uncomfortable making eye contact, you can look at the hairline or some other area near the face\n\nPracticing natural gestures\n\nYou can practice holding something heavy while you’re pointing in a presentation\nIf you fidget with your hands, press thumb into the joint of the middle finger\n\nAlways make sure to find something interesting to you about your presentation–when you are excited, you can get the audience excited.\n\nStrong speakers are prepared, show enthusiasm and demonstrate knowledge."
  },
  {
    "objectID": "notes/communication/062623/index.html#slide-order",
    "href": "notes/communication/062623/index.html#slide-order",
    "title": "Communications: 06/26/2023",
    "section": "2.1 Slide Order",
    "text": "2.1 Slide Order\n\n\n\n\nflowchart LR\n    A[Title Slide] --&gt; B[\"BLUF (Bottom Line Up Front)\"] --&gt; C[Agenda]\n    C --&gt; D[Section 1] --&gt; G[Appendix]\n    C --&gt; E[Section 2] --&gt; G\n    C --&gt; F[Questions] --&gt; G\n\n\n\n\n\n\nUse visual elements in the sections to highlight / call out specific details in graphs or tables\nUse a milestone bar to help the audience keep track of the overall location"
  },
  {
    "objectID": "notes/analytics/06282023/lab_2.html",
    "href": "notes/analytics/06282023/lab_2.html",
    "title": "Yang MSA",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(UsingR)\n\n\nLoading required package: MASS\n\nAttaching package: 'MASS'\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\nLoading required package: HistData\nLoading required package: Hmisc\n\nAttaching package: 'Hmisc'\n\nThe following objects are masked from 'package:dplyr':\n\n    src, summarize\n\nThe following objects are masked from 'package:base':\n\n    format.pval, units\n\n\nCode\ndata(normtemp)\nglimpse(normtemp)\n\n\nRows: 130\nColumns: 3\n$ temperature &lt;dbl&gt; 96.3, 96.7, 96.9, 97.0, 97.1, 97.1, 97.1, 97.2, 97.3, 97.4…\n$ gender      &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ hr          &lt;int&gt; 70, 71, 74, 80, 73, 75, 82, 64, 69, 70, 68, 72, 78, 70, 75…\n\n\nCode\n?normtemp\n\n\n\nRevisit the NormTemp dataset from Lab 1, where we examined the observed mean body temperature (temperature) in comparison to the well-known “average” of 98.6\n\n\n\nCode\nt.test(normtemp$temperature, mu = 98.6)\n\n\n\n    One Sample t-test\n\ndata:  normtemp$temperature\nt = -5.4548, df = 129, p-value = 2.411e-07\nalternative hypothesis: true mean is not equal to 98.6\n95 percent confidence interval:\n 98.12200 98.37646\nsample estimates:\nmean of x \n 98.24923 \n\n\n\nThe p-value is 2.411e-07\nThe p-value is the probability that we observe our data given that the mean body temperature is 98.6\nGiven our low p-value at a significance level of \\(\\alpha = 0.05\\) we reject our null hypothesis. We believe the actual mean is significantly different from 98.6\nThe 95% confidence interval for temperature is [98.12200, 98.37646]\n\n\n\nCode\nfemales &lt;- normtemp[normtemp$gender == 2, ]\nt.test(females$temperature, mu = 98.6)\n\n\n\n    One Sample t-test\n\ndata:  females$temperature\nt = -2.2355, df = 64, p-value = 0.02888\nalternative hypothesis: true mean is not equal to 98.6\n95 percent confidence interval:\n 98.20962 98.57807\nsample estimates:\nmean of x \n 98.39385 \n\n\n\nGiven our p-value \\(&lt; \\alpha\\) our conclusion does not change\n\n\n\nCode\nggplot(normtemp, aes(sample = temperature, color = gender)) +\n    stat_qq() +\n    stat_qq_line()\n\n\nWarning: The following aesthetics were dropped during statistical transformation: colour\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\nThe following aesthetics were dropped during statistical transformation: colour\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\nApproximately Normal\n\n\n\nCode\nvar.test(temperature ~ gender, data = normtemp)\n\n\n\n    F test to compare two variances\n\ndata:  temperature by gender\nF = 0.88329, num df = 64, denom df = 64, p-value = 0.6211\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.5387604 1.4481404\nsample estimates:\nratio of variances \n         0.8832897 \n\n\n\nWe believe variances are equal\n\n\n\nCode\nt.test(temperature ~ gender, data = normtemp)\n\n\n\n    Welch Two Sample t-test\n\ndata:  temperature by gender\nt = -2.2854, df = 127.51, p-value = 0.02394\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -0.53964856 -0.03881298\nsample estimates:\nmean in group 1 mean in group 2 \n       98.10462        98.39385 \n\n\n\nAt a significance level of 0.05, we reject our null hypothesis that there is no difference in means between the two genders\n\n\nThe Airline dataset contains information regarding the number of international airline travelers (variable air) across different months of the year from 1949-1960. We are interested in knowing if during this time period there was a significant difference between air travel in the Summer months of June, July, and August vs. the remainder of the year? Use a statistical hypothesis test (alpha=0.05) to support your answer.\n\n\n\nCode\ndata(AirPassengers)\nlibrary(tseries)\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nCode\nlibrary(forecast)\ncycle(AirPassengers)\n\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n1949   1   2   3   4   5   6   7   8   9  10  11  12\n1950   1   2   3   4   5   6   7   8   9  10  11  12\n1951   1   2   3   4   5   6   7   8   9  10  11  12\n1952   1   2   3   4   5   6   7   8   9  10  11  12\n1953   1   2   3   4   5   6   7   8   9  10  11  12\n1954   1   2   3   4   5   6   7   8   9  10  11  12\n1955   1   2   3   4   5   6   7   8   9  10  11  12\n1956   1   2   3   4   5   6   7   8   9  10  11  12\n1957   1   2   3   4   5   6   7   8   9  10  11  12\n1958   1   2   3   4   5   6   7   8   9  10  11  12\n1959   1   2   3   4   5   6   7   8   9  10  11  12\n1960   1   2   3   4   5   6   7   8   9  10  11  12\n\n\n\n\nCode\nair1 = data.frame(AirPassengers)\nair2 = air1 |&gt; mutate(summer = ifelse(cycle(AirPassengers) %in% 6:8, 1, 0))\n\n\n\n\nCode\nggplot(air2, aes(sample = AirPassengers, color = factor(summer))) +\n    stat_qq() +\n    stat_qq_line()\n\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\nNormality not met. We will use a nonparametric test\n\n\n\nCode\nggplot(air2, aes(x = AirPassengers, color = factor(summer))) +\n    geom_density()\n\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\nAfter plotting the distributions of both groups, we can see a similar shape but not a similar enough variation between the two groups.\nWhen we are conducting the Wilcoxon test we can’t necessarily claim anything about the mean or median but moreso about the distributional dominance\n\n\n\nCode\nwilcox.test(AirPassengers ~ summer, data = air2)\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  AirPassengers by summer\nW = 1346.5, p-value = 0.00588\nalternative hypothesis: true location shift is not equal to 0\n\n\n\nAt a significance level of 0.05, we reject our null hypothesis that the true location shift is equal to 0"
  },
  {
    "objectID": "notes/analytics/06292023/index.html",
    "href": "notes/analytics/06292023/index.html",
    "title": "Introduction to ANOVA and Regression",
    "section": "",
    "text": "The population model for our linear model is written as:\n\\[\ny = \\beta_0 + \\beta_1x_1 + \\cdots + \\beta_kx_k + \\varepsilon\n\\]\n\n\\(\\varepsilon\\) is the random error\nAll the modeled signal is the rest of the equation which is called the deterministic component\n\\(x_1, \\cdots, x_k\\) are the explanatory variables\n\\(y\\) is the response variable\n\nTypically linear models are used in an explanatory model fashion–we are trying to answer how our explanatory variables are related to our response. We are not predicting the response.\n\n\nBefore you look for any relationships, you should split into training, validation and test samples.\nDifferent rules of thumb for splits:\n\nLots of data? 50-40-10 split\nNot so much data? 70-20-10 split\nNot enough data? Use Cross-Validation\n\n\n\nModels will capture nuances of the data on which they’re built (training data)\nWhen these “patterns” do not hold up in validation or test, the model performance suffers. We call this overfitting.\n\n\n\nOverfitting Example\n\n\n\n\n\n\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(AmesHousing)\n\names &lt;- make_ordinal_ames()\nset.seed(123)\names &lt;- ames |&gt; mutate(id = row_number())\ntrain &lt;- ames |&gt; sample_frac(0.7)\ntest &lt;- anti_join(ames, train, by = \"id\")\n\ndim(train)\n\n\n[1] 2051   82\n\n\nCode\ndim(test)\n\n\n[1] 879  82"
  },
  {
    "objectID": "notes/analytics/06292023/index.html#honest-model-assessment",
    "href": "notes/analytics/06292023/index.html#honest-model-assessment",
    "title": "Introduction to ANOVA and Regression",
    "section": "",
    "text": "Before you look for any relationships, you should split into training, validation and test samples.\nDifferent rules of thumb for splits:\n\nLots of data? 50-40-10 split\nNot so much data? 70-20-10 split\nNot enough data? Use Cross-Validation\n\n\n\nModels will capture nuances of the data on which they’re built (training data)\nWhen these “patterns” do not hold up in validation or test, the model performance suffers. We call this overfitting.\n\n\n\nOverfitting Example"
  },
  {
    "objectID": "notes/analytics/06292023/index.html#train-test-split-in-r",
    "href": "notes/analytics/06292023/index.html#train-test-split-in-r",
    "title": "Introduction to ANOVA and Regression",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(AmesHousing)\n\names &lt;- make_ordinal_ames()\nset.seed(123)\names &lt;- ames |&gt; mutate(id = row_number())\ntrain &lt;- ames |&gt; sample_frac(0.7)\ntest &lt;- anti_join(ames, train, by = \"id\")\n\ndim(train)\n\n\n[1] 2051   82\n\n\nCode\ndim(test)\n\n\n[1] 879  82"
  },
  {
    "objectID": "notes/analytics/06292023/index.html#assumptions-for-anova",
    "href": "notes/analytics/06292023/index.html#assumptions-for-anova",
    "title": "Introduction to ANOVA and Regression",
    "section": "3.1 Assumptions for ANOVA",
    "text": "3.1 Assumptions for ANOVA\n\nObservations are independent\nEach group is normally distributed\n\nOr the residuals of the ANOVA model are normally distributed\n\nAll groups have equal variances (homeskedasticity)\n\nIf true, use “pooled” variance\nIf false, use Welch’s ANOVA\n\n\n\n3.1.1 Assessing ANOVA Assumptions\n\nGood data collection designs help the independence assumption\nInformal plots (QQ-Plots) or formal tests can verify the normally distributed assumption\nFormal test of equal variances or viewing residual plot to assess homoskedasticity"
  },
  {
    "objectID": "notes/analytics/06292023/index.html#anova-hypothesis-test-in-r",
    "href": "notes/analytics/06292023/index.html#anova-hypothesis-test-in-r",
    "title": "Introduction to ANOVA and Regression",
    "section": "3.2 ANOVA Hypothesis Test in R",
    "text": "3.2 ANOVA Hypothesis Test in R\n\\(H_0\\) is the means of each level of Exter-Qual are equal. \\(H_a\\) is at least one mean is different.\n\n\nCode\names_lm &lt;- lm(Sale_Price ~ Exter_Qual, data = train)\nanova(ames_lm)\n\n\nAnalysis of Variance Table\n\nResponse: Sale_Price\n             Df     Sum Sq    Mean Sq F value    Pr(&gt;F)    \nExter_Qual    3 6.6913e+12 2.2304e+12  701.83 &lt; 2.2e-16 ***\nResiduals  2047 6.5054e+12 3.1780e+09                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nThere appears to be a significant difference in mean sales price between the different levels of exterior quality.\n\n\n\nCode\ntrain$pred_anova &lt;- predict(ames_lm, data = train)\ntrain$resid_anova &lt;- resid(ames_lm, data = train)\n\nmodel_output = train |&gt; select(Sale_Price, pred_anova, resid_anova)\n\n\nAnd then to test assumptions:\n\n\nCode\npar(mfrow = c(2, 2))\nplot(ames_lm)\n\n\n\n\n\nTo formally test our variance, we have Levene’s Test which requires normality of underlying data and Fligner’s Test which does not require normality.\n\n\nCode\nlibrary(car)\n\n\nLoading required package: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\n\nCode\nleveneTest(Sale_Price ~ Exter_Qual, data = train)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n        Df F value    Pr(&gt;F)    \ngroup    3  76.879 &lt; 2.2e-16 ***\n      2047                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nfligner.test(Sale_Price ~ Exter_Qual, data = train)$p.value\n\n\n[1] 1.873388e-44"
  },
  {
    "objectID": "notes/analytics/06292023/index.html#kruskal-wallis-anova-in-r",
    "href": "notes/analytics/06292023/index.html#kruskal-wallis-anova-in-r",
    "title": "Introduction to ANOVA and Regression",
    "section": "5.1 Kruskal-Wallis ANOVA in R",
    "text": "5.1 Kruskal-Wallis ANOVA in R\n\n\nCode\nkruskal.test(Sale_Price ~ Exter_Qual, data = train)\n\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Sale_Price by Exter_Qual\nKruskal-Wallis chi-squared = 975.98, df = 3, p-value &lt; 2.2e-16"
  },
  {
    "objectID": "notes/analytics/06292023/index.html#tukeys-honest-significant-difference",
    "href": "notes/analytics/06292023/index.html#tukeys-honest-significant-difference",
    "title": "Introduction to ANOVA and Regression",
    "section": "7.1 Tukey’s Honest Significant Difference",
    "text": "7.1 Tukey’s Honest Significant Difference\nAppropriate for making all pairwise comparisons between groups.\nExperimentwise error rate is equal to \\(\\alpha\\) when all pairwise comparisons are made and less than \\(\\alpha\\) otherwise.\n\n\nCode\names_aov &lt;- aov(Sale_Price ~ Exter_Qual, data = train)\ntukey.ames &lt;- TukeyHSD(ames_aov)\nprint(tukey.ames)\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Sale_Price ~ Exter_Qual, data = train)\n\n$Exter_Qual\n                       diff       lwr       upr p adj\nTypical-Fair       57887.91  30194.31  85581.52 5e-07\nGood-Fair         144690.25 116739.87 172640.63 0e+00\nExcellent-Fair    291684.79 259752.41 323617.16 0e+00\nGood-Typical       86802.34  79910.03  93694.64 0e+00\nExcellent-Typical 233796.87 216886.62 250707.12 0e+00\nExcellent-Good    146994.54 129666.98 164322.10 0e+00\n\n\n\nConclusion is that all pairs are significantly different"
  },
  {
    "objectID": "notes/analytics/06292023/index.html#dunnetts-test-for-control-comparison",
    "href": "notes/analytics/06292023/index.html#dunnetts-test-for-control-comparison",
    "title": "Introduction to ANOVA and Regression",
    "section": "7.2 Dunnett’s Test for Control Comparison",
    "text": "7.2 Dunnett’s Test for Control Comparison\nIf you’re not making all pairwise comparisons, Tukey’s is overly conservative.\n\n\nCode\nlibrary(DescTools)\n\n\n\nAttaching package: 'DescTools'\n\n\nThe following object is masked from 'package:car':\n\n    Recode\n\n\nCode\nDunnettTest(x = train$Sale_Price, g = train$Exter_Qual, control = \"Typical\")\n\n\n\n  Dunnett's test for comparing several treatments with a control :  \n    95% family-wise confidence level\n\n$Typical\n                       diff    lwr.ci    upr.ci    pval    \nFair-Typical      -57887.91 -83628.55 -32147.28 2.6e-07 ***\nGood-Typical       86802.34  80396.08  93208.59 &lt; 2e-16 ***\nExcellent-Typical 233796.87 218079.15 249514.60 &lt; 2e-16 ***\n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "notes/analytics/06292023/breakout_3.html",
    "href": "notes/analytics/06292023/breakout_3.html",
    "title": "1 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nbike &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/bike.csv\")\nglimpse(bike)\n\n\nRows: 17,379\nColumns: 16\n$ dteday     &lt;int&gt; 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 149…\n$ season     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ yr         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ mnth       &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ hr         &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ holiday    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ weekday    &lt;int&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,…\n$ workingday &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ weathersit &lt;int&gt; 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3,…\n$ temp       &lt;dbl&gt; 0.24, 0.22, 0.22, 0.24, 0.24, 0.24, 0.22, 0.20, 0.24, 0.32,…\n$ atemp      &lt;dbl&gt; 0.2879, 0.2727, 0.2727, 0.2879, 0.2879, 0.2576, 0.2727, 0.2…\n$ hum        &lt;dbl&gt; 0.81, 0.80, 0.80, 0.75, 0.75, 0.75, 0.80, 0.86, 0.75, 0.76,…\n$ windspeed  &lt;dbl&gt; 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0896, 0.0000, 0.0…\n$ casual     &lt;int&gt; 3, 8, 5, 3, 0, 0, 2, 1, 1, 8, 12, 26, 29, 47, 35, 40, 41, 1…\n$ registered &lt;int&gt; 13, 32, 27, 10, 1, 1, 0, 2, 7, 6, 24, 30, 55, 47, 71, 70, 5…\n$ cnt        &lt;int&gt; 16, 40, 32, 13, 1, 1, 2, 3, 8, 14, 36, 56, 84, 94, 106, 110…\n\n\n\n1 1\n\n\nCode\nbike_lm &lt;- lm(cnt ~ weathersit, data = bike)\n\nggplot(bike, aes(x = cnt, fill = factor(weathersit))) +\n    geom_density(alpha = 0.2, position = \"identity\") +\n    labs(x = \"Number of riders\")\n\n\n\n\n\nCode\nggplot(bike, aes(y = cnt, x = factor(weathersit), fill = factor(weathersit))) +\n    geom_boxplot() +\n    labs(y = \"Number of riders\", x = \"Weather Category\") +\n    stat_summary(fun = mean, geom = \"point\", shape = 2, size = 3, color = \"pink\", fill = \"red\") +\n    scale_fill_brewer(palette = \"Blues\") +\n    coord_flip()"
  },
  {
    "objectID": "notes/analytics/07032023/breakout_5.html",
    "href": "notes/analytics/07032023/breakout_5.html",
    "title": "Breakout 5",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n\n\n\nCode\nbike = pd.read_csv('https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/bike.csv')\nbike.head()\n\n\n\n\n\n\n\n\n\ndteday\nseason\nyr\nmnth\nhr\nholiday\nweekday\nworkingday\nweathersit\ntemp\natemp\nhum\nwindspeed\ncasual\nregistered\ncnt\n\n\n\n\n0\n14975\n1\n0\n1\n0\n0\n6\n0\n1\n0.24\n0.2879\n0.81\n0.0\n3\n13\n16\n\n\n1\n14975\n1\n0\n1\n1\n0\n6\n0\n1\n0.22\n0.2727\n0.80\n0.0\n8\n32\n40\n\n\n2\n14975\n1\n0\n1\n2\n0\n6\n0\n1\n0.22\n0.2727\n0.80\n0.0\n5\n27\n32\n\n\n3\n14975\n1\n0\n1\n3\n0\n6\n0\n1\n0.24\n0.2879\n0.75\n0.0\n3\n10\n13\n\n\n4\n14975\n1\n0\n1\n4\n0\n6\n0\n1\n0.24\n0.2879\n0.75\n0.0\n0\n1\n1\n\n\n\n\n\n\n\n\n1 1\n\n\nCode\nbike_lm = smf.ols('cnt ~ C(workingday) * C(season)', bike).fit()\n\nsm.stats.anova_lm(bike_lm)\n\n\n\n\n\n\n\n\n\ndf\nsum_sq\nmean_sq\nF\nPR(&gt;F)\n\n\n\n\nC(workingday)\n1.0\n5.243871e+05\n5.243871e+05\n17.082764\n3.595344e-05\n\n\nC(season)\n3.0\n3.748219e+07\n1.249406e+07\n407.014449\n1.544102e-255\n\n\nC(workingday):C(season)\n3.0\n5.199753e+05\n1.733251e+05\n5.646347\n7.301192e-04\n\n\nResidual\n17371.0\n5.332350e+08\n3.069685e+04\nNaN\nNaN\n\n\n\n\n\n\n\n\nThe interaction between workingday and season seems to be significant towards predicting cnt\n\n\n\n2 2\nTalk with breakout group.\n\n\n3 3\n\n\nCode\ncasual_lm = smf.ols('casual ~ C(workingday) * C(season)', bike).fit()\n\nsm.stats.anova_lm(casual_lm)\n\n\n\n\n\n\n\n\n\ndf\nsum_sq\nmean_sq\nF\nPR(&gt;F)\n\n\n\n\nC(workingday)\n1.0\n3.826038e+06\n3.826038e+06\n1954.028610\n0.000000e+00\n\n\nC(season)\n3.0\n3.750852e+06\n1.250284e+06\n638.543326\n0.000000e+00\n\n\nC(workingday):C(season)\n3.0\n6.559238e+05\n2.186413e+05\n111.664154\n1.292550e-71\n\n\nResidual\n17371.0\n3.401286e+07\n1.958026e+03\nNaN\nNaN\n\n\n\n\n\n\n\n\nNot a significant interaction between workingday and season for casual bikers\n\n\n\nCode\nregistered_lm = smf.ols('registered ~ C(workingday) * C(season)', bike).fit()\n\nsm.stats.anova_lm(registered_lm)\n\n\n\n\n\n\n\n\n\ndf\nsum_sq\nmean_sq\nF\nPR(&gt;F)\n\n\n\n\nC(workingday)\n1.0\n7.183321e+06\n7.183321e+06\n335.449602\n3.121975e-74\n\n\nC(season)\n3.0\n1.885079e+07\n6.283597e+06\n293.433926\n7.848911e-186\n\n\nC(workingday):C(season)\n3.0\n9.621956e+04\n3.207319e+04\n1.497767\n2.129291e-01\n\n\nResidual\n17371.0\n3.719828e+08\n2.141401e+04\nNaN\nNaN\n\n\n\n\n\n\n\n\nSignificant interaction between workingday and season for registered bikers\n\n\n\nCode\nunique_season = bike['season'].unique()\n\nfor season in unique_season:\n    sliced_data = smf.ols(\"casual ~ C(workingday)\", bike[bike[\"season\"] == season]).fit()\n    print(sm.stats.anova_lm(sliced_data))\n\nfor season in unique_season:\n    sliced_data = smf.ols(\"registered ~ C(workingday)\", bike[bike[\"season\"] == season]).fit()\n    print(sm.stats.anova_lm(sliced_data))\n\n\n                   df        sum_sq        mean_sq          F        PR(&gt;F)\nC(workingday)     1.0  1.436979e+05  143697.866870  199.44088  2.751109e-44\nResidual       4240.0  3.054935e+06     720.503576        NaN           NaN\n                   df        sum_sq       mean_sq           F         PR(&gt;F)\nC(workingday)     1.0  2.044757e+06  2.044757e+06  720.507711  3.944648e-147\nResidual       4407.0  1.250680e+07  2.837939e+03         NaN            NaN\n                   df        sum_sq       mean_sq           F         PR(&gt;F)\nC(workingday)     1.0  1.623762e+06  1.623762e+06  700.640615  1.328288e-143\nResidual       4494.0  1.041502e+07  2.317539e+03         NaN            NaN\n                   df        sum_sq        mean_sq           F         PR(&gt;F)\nC(workingday)     1.0  9.299500e+05  929949.990208  489.501677  9.987658e-103\nResidual       4230.0  8.036108e+06    1899.789180         NaN            NaN\n                   df        sum_sq       mean_sq           F        PR(&gt;F)\nC(workingday)     1.0  1.278398e+06  1.278398e+06  120.723426  1.035371e-27\nResidual       4240.0  4.489940e+07  1.058948e+04         NaN           NaN\n                   df        sum_sq       mean_sq          F        PR(&gt;F)\nC(workingday)     1.0  1.351663e+06  1.351663e+06  58.687294  2.258053e-14\nResidual       4407.0  1.015003e+08  2.303161e+04        NaN           NaN\n                   df        sum_sq       mean_sq          F        PR(&gt;F)\nC(workingday)     1.0  2.328766e+06  2.328766e+06  85.657432  3.232019e-20\nResidual       4494.0  1.221782e+08  2.718697e+04        NaN           NaN\n                   df        sum_sq       mean_sq          F        PR(&gt;F)\nC(workingday)     1.0  1.629497e+06  1.629497e+06  66.658104  4.220264e-16\nResidual       4230.0  1.034048e+08  2.444559e+04        NaN           NaN\n\n\n\nFor each individual season, there is a significant difference between working days and non-working days in registered bikers"
  },
  {
    "objectID": "notes/analytics/07062023/index.html",
    "href": "notes/analytics/07062023/index.html",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "Models with more than one predictor variable are called multiple regression models.\n\\[\ny = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\beta_kx_k + \\varepsilon\n\\]\nWe are still trying to minimize the sum of squared errors:\n\\[\nSSE = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n\\]\nLinear in MLR refers to the linear combination of variables in the model–not how they’re visualized in multiple dimensions.\nA model like \\(y = \\beta_0 + \\beta_1x_1 + \\beta_1x_1^2\\) is still a linear regression!"
  },
  {
    "objectID": "notes/analytics/07062023/index.html#r-code",
    "href": "notes/analytics/07062023/index.html#r-code",
    "title": "Multiple Linear Regression",
    "section": "1.1 R Code",
    "text": "1.1 R Code\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(AmesHousing)\nlibrary(reticulate)\n\nuse_condaenv(\"blues_clues\")\n\names &lt;- make_ordinal_ames()\nset.seed(123)\names &lt;- ames |&gt; mutate(id = row_number())\ntrain &lt;- ames |&gt; sample_frac(0.7)\ntest &lt;- anti_join(ames, train, by = \"id\")\n\names_lm2 &lt;- lm(Sale_Price ~ Gr_Liv_Area + TotRms_AbvGrd, train)\nsummary(ames_lm2)\n\n\n\nCall:\nlm(formula = Sale_Price ~ Gr_Liv_Area + TotRms_AbvGrd, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-528656  -30077   -1230   21427  361465 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    42562.657   5365.721   7.932 3.51e-15 ***\nGr_Liv_Area      136.982      4.207  32.558  &lt; 2e-16 ***\nTotRms_AbvGrd -10563.324   1370.007  -7.710 1.94e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 56630 on 2048 degrees of freedom\nMultiple R-squared:  0.5024,    Adjusted R-squared:  0.5019 \nF-statistic:  1034 on 2 and 2048 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "notes/analytics/07062023/index.html#python-code",
    "href": "notes/analytics/07062023/index.html#python-code",
    "title": "Multiple Linear Regression",
    "section": "1.2 Python Code",
    "text": "1.2 Python Code\n\n\nCode\nimport pandas as pd\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\names = pd.read_csv(\"../../../data/ames.csv\")\ntrain, test = train_test_split(ames, random_state=123)\ntrain.head()\n\n\n        Id  MSSubClass MSZoning  ...  SaleType  SaleCondition SalePrice\n1446  1447          20       RL  ...        WD         Normal    157900\n1123  1124          20       RL  ...        WD         Normal    118000\n186    187          80       RL  ...        WD         Normal    173000\n1020  1021          20       RL  ...        WD         Normal    176000\n67      68          20       RL  ...        WD         Normal    226000\n\n[5 rows x 81 columns]\n\n\n\n\nCode\names_lm2 = smf.ols(\"SalePrice ~ GrLivArea + TotRmsAbvGrd\", train).fit()\n\names_lm2.f_pvalue\n\n\n9.720219891564917e-163"
  },
  {
    "objectID": "notes/analytics/07062023/index.html#assumptions",
    "href": "notes/analytics/07062023/index.html#assumptions",
    "title": "Multiple Linear Regression",
    "section": "2.1 Assumptions",
    "text": "2.1 Assumptions\n\nThe mean of \\(y\\) is accurately modeled by a linear function of the independent variables\n\\(\\varepsilon\\) is Normal with a mean of 0\n\\(\\varepsilon\\) has a constant variance\nThe errors are independent\nNo perfect collinearity"
  },
  {
    "objectID": "notes/analytics/07062023/index.html#multicollinearity",
    "href": "notes/analytics/07062023/index.html#multicollinearity",
    "title": "Multiple Linear Regression",
    "section": "2.2 Multicollinearity",
    "text": "2.2 Multicollinearity\nMulticollinearity is when predictor variables are correlated with one another.\nNo perfect collinearity means no predictor variables as a perfect linear combination of each other. In practice, we only care when collinearity has a significant impact.\n\n2.2.1 R Code\n\n\nCode\npar(mfrow = c(2, 2))\nplot(ames_lm2)\n\n\n\n\n\n\n\n2.2.2 Python Code\n\n\nCode\ntrain[\"resid\"] = ames_lm2.resid\ntrain[\"predict\"] = ames_lm2.predict()\nax = sns.relplot(train, x=\"predict\", y=\"resid\")\nplt.show()\n\n\n\n\n\n\n\nCode\nsm.qqplot(train[\"resid\"])"
  },
  {
    "objectID": "notes/analytics/07062023/index.html#predict",
    "href": "notes/analytics/07062023/index.html#predict",
    "title": "Multiple Linear Regression",
    "section": "4.1 Predict",
    "text": "4.1 Predict\nDevelop a model to predict future values of a response variable based on its relationship with other predictor variables.\nThe parameters in the model and their statistical significance are secondary importance. Focus is on producing a model that can predict future values well.\nWe should take care to be aware of and address overfitting a model in this case."
  },
  {
    "objectID": "notes/analytics/07062023/index.html#explain",
    "href": "notes/analytics/07062023/index.html#explain",
    "title": "Multiple Linear Regression",
    "section": "4.2 Explain",
    "text": "4.2 Explain\nTo develop an understanding of relationships between the response and predictor.\nThe statistical significance of coefficients as well as the magnitudes and signs of coefficients are important."
  },
  {
    "objectID": "notes/analytics/07062023/index.html#adjusted-coefficient-of-determination",
    "href": "notes/analytics/07062023/index.html#adjusted-coefficient-of-determination",
    "title": "Multiple Linear Regression",
    "section": "5.1 Adjusted Coefficient of Determination",
    "text": "5.1 Adjusted Coefficient of Determination\n\\(R_a^2\\) penalizes a model for adding variables that do not provide useful information.\n\\[\n\\begin{align*}\nR_a^2 &= 1 - [(\\frac{n - 1}{n - k - 1})(\\frac{SSE}{TSS})] \\\\\n&= 1 - [(1 - R^2)(\\frac{n - 1}{n - k - 1})]\n\\end{align*}\n\\]\n\n\\(R_a^2 \\leq R^2\\)\n\nAlthough better at determining utility of model, we lose the interpretation as the coefficient can be negative."
  },
  {
    "objectID": "notes/analytics/07062023/lab_6.html",
    "href": "notes/analytics/07062023/lab_6.html",
    "title": "Lab 6",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(AppliedPredictiveModeling)\ndata(FuelEconomy)\nglimpse(cars2010)\n\n\nRows: 1,107\nColumns: 14\n$ EngDispl            &lt;dbl&gt; 4.7, 4.7, 4.2, 4.2, 5.2, 5.2, 2.0, 6.0, 3.0, 3.0, …\n$ NumCyl              &lt;int&gt; 8, 8, 8, 8, 10, 10, 4, 12, 6, 6, 6, 6, 16, 8, 8, 8…\n$ Transmission        &lt;fct&gt; AM6, M6, M6, AM6, AM6, M6, S6, S6, S6, M6, S7, M6,…\n$ FE                  &lt;dbl&gt; 28.0198, 25.6094, 26.8000, 25.0451, 24.8000, 23.90…\n$ AirAspirationMethod &lt;fct&gt; NaturallyAspirated, NaturallyAspirated, NaturallyA…\n$ NumGears            &lt;int&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 6, 7, 6, 6, 6, 6,…\n$ TransLockup         &lt;dbl&gt; 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,…\n$ TransCreeperGear    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ DriveDesc           &lt;fct&gt; TwoWheelDriveRear, TwoWheelDriveRear, AllWheelDriv…\n$ IntakeValvePerCyl   &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1,…\n$ ExhaustValvesPerCyl &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1,…\n$ CarlineClassDesc    &lt;fct&gt; 2Seaters, 2Seaters, 2Seaters, 2Seaters, 2Seaters, …\n$ VarValveTiming      &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,…\n$ VarValveLift        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,…\n\n\n\n\n\n\nCode\ncars2010 &lt;- cars2010 %&gt;%\n    mutate(across(!c(EngDispl, FE), as.factor))\ncars_lm &lt;- lm(FE ~ ., data = cars2010)\nsummary(cars_lm)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars2010)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6399  -1.6583   0.0582   1.5708  21.6002 \n\nCoefficients: (5 not defined because of singularities)\n                                                 Estimate Std. Error t value\n(Intercept)                                      35.95655    3.34991  10.734\nEngDispl                                         -2.24571    0.26269  -8.549\nNumCyl3                                          15.88136    5.11001   3.108\nNumCyl4                                           7.76711    3.94430   1.969\nNumCyl5                                           4.89858    3.97620   1.232\nNumCyl6                                           4.19528    3.94208   1.064\nNumCyl8                                           2.51528    3.98438   0.631\nNumCyl10                                         -0.01541    4.13445  -0.004\nNumCyl12                                         -1.02329    4.11855  -0.248\nNumCyl16                                         -0.31250    5.42018  -0.058\nTransmissionA4                                   -6.93754    2.27354  -3.051\nTransmissionA5                                   -6.53146    2.27928  -2.866\nTransmissionA6                                   -4.88712    2.27829  -2.145\nTransmissionA7                                    5.70476    2.44239   2.336\nTransmissionAM6                                  -9.48575    2.46325  -3.851\nTransmissionAM7                                   0.59731    2.65233   0.225\nTransmissionAV                                   -4.40251    2.28451  -1.927\nTransmissionAVS6                                 -6.72835    2.41754  -2.783\nTransmissionM5                                   -7.00105    2.27746  -3.074\nTransmissionM6                                   -7.03693    2.26627  -3.105\nTransmissionS4                                  -10.42310    2.42863  -4.292\nTransmissionS5                                   -7.17879    2.30519  -3.114\nTransmissionS6                                   -5.09671    2.26315  -2.252\nTransmissionS7                                    4.08689    2.51141   1.627\nTransmissionS8                                   -4.61764    4.02547  -1.147\nAirAspirationMethodSupercharged                  -1.66003    0.78945  -2.103\nAirAspirationMethodTurbocharged                  -1.12911    0.32214  -3.505\nNumGears4                                              NA         NA      NA\nNumGears5                                              NA         NA      NA\nNumGears6                                              NA         NA      NA\nNumGears7                                       -10.74200    3.27897  -3.276\nNumGears8                                         1.78308    3.19710   0.558\nTransLockup1                                     -0.89442    0.35715  -2.504\nTransCreeperGear1                                -1.04006    0.49553  -2.099\nDriveDescFourWheelDrive                          -0.45145    0.43461  -1.039\nDriveDescParttimeFourWheelDrive                  -0.29399    1.06503  -0.276\nDriveDescTwoWheelDriveFront                       4.31845    0.37701  11.455\nDriveDescTwoWheelDriveRear                        1.19634    0.37255   3.211\nIntakeValvePerCyl1                                6.33644    3.32150   1.908\nIntakeValvePerCyl2                                4.88952    3.21060   1.523\nIntakeValvePerCyl3                                     NA         NA      NA\nExhaustValvesPerCyl1                              1.54229    0.75433   2.045\nExhaustValvesPerCyl2                                   NA         NA      NA\nCarlineClassDesc2Seaters                          2.85693    1.17833   2.425\nCarlineClassDescCompactCars                       3.78908    1.09963   3.446\nCarlineClassDescLargeCars                         2.56219    1.13079   2.266\nCarlineClassDescMidsizeCars                       3.39390    1.09686   3.094\nCarlineClassDescMinicompactCars                   3.63416    1.19375   3.044\nCarlineClassDescSmallPickupTrucks2WD             -1.85140    1.25181  -1.479\nCarlineClassDescSmallPickupTrucks4WD             -0.95072    1.35268  -0.703\nCarlineClassDescSmallStationWagons                2.20724    1.13608   1.943\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.07995    1.36307  -1.526\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.51997    1.10807  -1.372\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.56991    1.12243  -0.508\nCarlineClassDescStandardPickupTrucks2WD          -1.74467    1.27006  -1.374\nCarlineClassDescStandardPickupTrucks4WD          -1.94205    1.30286  -1.491\nCarlineClassDescSubcompactCars                    3.43057    1.11242   3.084\nCarlineClassDescVansCargoTypes                   -4.07446    1.51702  -2.686\nCarlineClassDescVansPassengerType                -4.27396    1.95092  -2.191\nVarValveTiming1                                   0.15943    0.29071   0.548\nVarValveLift1                                     0.82579    0.30704   2.690\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                         &lt; 2e-16 ***\nNumCyl3                                         0.001935 ** \nNumCyl4                                         0.049193 *  \nNumCyl5                                         0.218234    \nNumCyl6                                         0.287469    \nNumCyl8                                         0.527992    \nNumCyl10                                        0.997028    \nNumCyl12                                        0.803827    \nNumCyl16                                        0.954034    \nTransmissionA4                                  0.002335 ** \nTransmissionA5                                  0.004245 ** \nTransmissionA6                                  0.032175 *  \nTransmissionA7                                  0.019693 *  \nTransmissionAM6                                 0.000125 ***\nTransmissionAM7                                 0.821867    \nTransmissionAV                                  0.054234 .  \nTransmissionAVS6                                0.005480 ** \nTransmissionM5                                  0.002166 ** \nTransmissionM6                                  0.001953 ** \nTransmissionS4                                  1.94e-05 ***\nTransmissionS5                                  0.001894 ** \nTransmissionS6                                  0.024526 *  \nTransmissionS7                                  0.103967    \nTransmissionS8                                  0.251599    \nAirAspirationMethodSupercharged                 0.035723 *  \nAirAspirationMethodTurbocharged                 0.000476 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001087 ** \nNumGears8                                       0.577155    \nTransLockup1                                    0.012420 *  \nTransCreeperGear1                               0.036067 *  \nDriveDescFourWheelDrive                         0.299167    \nDriveDescParttimeFourWheelDrive                 0.782571    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.001362 ** \nIntakeValvePerCyl1                              0.056702 .  \nIntakeValvePerCyl2                              0.128077    \nIntakeValvePerCyl3                                    NA    \nExhaustValvesPerCyl1                            0.041146 *  \nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.015495 *  \nCarlineClassDescCompactCars                     0.000592 ***\nCarlineClassDescLargeCars                       0.023664 *  \nCarlineClassDescMidsizeCars                     0.002026 ** \nCarlineClassDescMinicompactCars                 0.002390 ** \nCarlineClassDescSmallPickupTrucks2WD            0.139447    \nCarlineClassDescSmallPickupTrucks4WD            0.482307    \nCarlineClassDescSmallStationWagons              0.052300 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.127330    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.170443    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.611738    \nCarlineClassDescStandardPickupTrucks2WD         0.169828    \nCarlineClassDescStandardPickupTrucks4WD         0.136365    \nCarlineClassDescSubcompactCars                  0.002097 ** \nCarlineClassDescVansCargoTypes                  0.007349 ** \nCarlineClassDescVansPassengerType               0.028690 *  \nVarValveTiming1                                 0.583517    \nVarValveLift1                                   0.007269 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.14 on 1051 degrees of freedom\nMultiple R-squared:  0.8333,    Adjusted R-squared:  0.8246 \nF-statistic: 95.55 on 55 and 1051 DF,  p-value: &lt; 2.2e-16\n\n\n\nThe F p-value is significant meaning that our overall model is significant in predicting FE\nThe 13 variables explain 83.33 percent of variation in fuel economy\n\n\n\n\n\n\nCode\ncar::Anova(cars_lm)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              720.6    1 73.0842 &lt; 2.2e-16 ***\nNumCyl                889.6    6 15.0374 &lt; 2.2e-16 ***\nTransmission          707.7   12  5.9813 3.553e-10 ***\nAirAspirationMethod   151.2    2  7.6686 0.0004939 ***\nNumGears              109.2    2  5.5361 0.0040576 ** \nTransLockup            61.8    1  6.2715 0.0124202 *  \nTransCreeperGear       43.4    1  4.4052 0.0360667 *  \nDriveDesc            1535.0    4 38.9205 &lt; 2.2e-16 ***\nIntakeValvePerCyl      56.6    2  2.8720 0.0570315 .  \nExhaustValvesPerCyl    41.2    1  4.1803 0.0411460 *  \nCarlineClassDesc     3495.4   16 22.1561 &lt; 2.2e-16 ***\nVarValveTiming          3.0    1  0.3008 0.5835171    \nVarValveLift           71.3    1  7.2336 0.0072685 ** \nResiduals           10363.0 1051                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nHighest p-value is VarValveTiming with 0.584\n\n\n\n\n\n\nCode\ncars_2010_sub &lt;- cars2010 %&gt;%\n    select(-VarValveTiming)\n\ncars_lm2 &lt;- lm(FE ~ ., cars_2010_sub)\nsummary(cars_lm2)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars_2010_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6242  -1.6504   0.0541   1.5540  21.5852 \n\nCoefficients: (5 not defined because of singularities)\n                                                 Estimate Std. Error t value\n(Intercept)                                      35.99395    3.34810  10.751\nEngDispl                                         -2.26003    0.26130  -8.649\nNumCyl3                                          16.00965    5.10296   3.137\nNumCyl4                                           7.91363    3.93394   2.012\nNumCyl5                                           5.03429    3.96717   1.269\nNumCyl6                                           4.35537    3.92996   1.108\nNumCyl8                                           2.71420    3.96652   0.684\nNumCyl10                                          0.18914    4.11622   0.046\nNumCyl12                                         -0.81976    4.10043  -0.200\nNumCyl16                                         -0.08503    5.40249  -0.016\nTransmissionA4                                   -6.98768    2.27095  -3.077\nTransmissionA5                                   -6.53850    2.27848  -2.870\nTransmissionA6                                   -4.90059    2.27740  -2.152\nTransmissionA7                                    5.71566    2.44150   2.341\nTransmissionAM6                                  -9.49295    2.46240  -3.855\nTransmissionAM7                                   0.59242    2.65143   0.223\nTransmissionAV                                   -4.40233    2.28375  -1.928\nTransmissionAVS6                                 -6.72853    2.41673  -2.784\nTransmissionM5                                   -7.01977    2.27644  -3.084\nTransmissionM6                                   -7.04911    2.26540  -3.112\nTransmissionS4                                  -10.51052    2.42259  -4.339\nTransmissionS5                                   -7.20354    2.30398  -3.127\nTransmissionS6                                   -5.10605    2.26234  -2.257\nTransmissionS7                                    4.09144    2.51056   1.630\nTransmissionS8                                   -4.62893    4.02408  -1.150\nAirAspirationMethodSupercharged                  -1.67713    0.78857  -2.127\nAirAspirationMethodTurbocharged                  -1.13613    0.32177  -3.531\nNumGears4                                              NA         NA      NA\nNumGears5                                              NA         NA      NA\nNumGears6                                              NA         NA      NA\nNumGears7                                       -10.74376    3.27788  -3.278\nNumGears8                                         1.79152    3.19600   0.561\nTransLockup1                                     -0.89373    0.35703  -2.503\nTransCreeperGear1                                -1.09666    0.48450  -2.263\nDriveDescFourWheelDrive                          -0.44026    0.43399  -1.014\nDriveDescParttimeFourWheelDrive                  -0.25475    1.06227  -0.240\nDriveDescTwoWheelDriveFront                       4.32752    0.37652  11.494\nDriveDescTwoWheelDriveRear                        1.19041    0.37227   3.198\nIntakeValvePerCyl1                                6.36976    3.31984   1.919\nIntakeValvePerCyl2                                4.90088    3.20946   1.527\nIntakeValvePerCyl3                                     NA         NA      NA\nExhaustValvesPerCyl1                              1.49669    0.74949   1.997\nExhaustValvesPerCyl2                                   NA         NA      NA\nCarlineClassDesc2Seaters                          2.85888    1.17793   2.427\nCarlineClassDescCompactCars                       3.77775    1.09907   3.437\nCarlineClassDescLargeCars                         2.55092    1.13023   2.257\nCarlineClassDescMidsizeCars                       3.38958    1.09647   3.091\nCarlineClassDescMinicompactCars                   3.62150    1.19313   3.035\nCarlineClassDescSmallPickupTrucks2WD             -1.88501    1.24990  -1.508\nCarlineClassDescSmallPickupTrucks4WD             -0.99946    1.34930  -0.741\nCarlineClassDescSmallStationWagons                2.19864    1.13559   1.936\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.14681    1.35716  -1.582\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.52376    1.10769  -1.376\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.58904    1.12151  -0.525\nCarlineClassDescStandardPickupTrucks2WD          -1.76375    1.26916  -1.390\nCarlineClassDescStandardPickupTrucks4WD          -1.97791    1.30079  -1.521\nCarlineClassDescSubcompactCars                    3.42813    1.11204   3.083\nCarlineClassDescVansCargoTypes                   -4.03720    1.51499  -2.665\nCarlineClassDescVansPassengerType                -4.21030    1.94682  -2.163\nVarValveLift1                                     0.82139    0.30683   2.677\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                         &lt; 2e-16 ***\nNumCyl3                                         0.001752 ** \nNumCyl4                                         0.044513 *  \nNumCyl5                                         0.204726    \nNumCyl6                                         0.268007    \nNumCyl8                                         0.493951    \nNumCyl10                                        0.963360    \nNumCyl12                                        0.841581    \nNumCyl16                                        0.987446    \nTransmissionA4                                  0.002145 ** \nTransmissionA5                                  0.004191 ** \nTransmissionA6                                  0.031638 *  \nTransmissionA7                                  0.019416 *  \nTransmissionAM6                                 0.000123 ***\nTransmissionAM7                                 0.823240    \nTransmissionAV                                  0.054164 .  \nTransmissionAVS6                                0.005463 ** \nTransmissionM5                                  0.002098 ** \nTransmissionM6                                  0.001911 ** \nTransmissionS4                                  1.57e-05 ***\nTransmissionS5                                  0.001817 ** \nTransmissionS6                                  0.024214 *  \nTransmissionS7                                  0.103466    \nTransmissionS8                                  0.250279    \nAirAspirationMethodSupercharged                 0.033668 *  \nAirAspirationMethodTurbocharged                 0.000432 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001081 ** \nNumGears8                                       0.575223    \nTransLockup1                                    0.012458 *  \nTransCreeperGear1                               0.023808 *  \nDriveDescFourWheelDrive                         0.310604    \nDriveDescParttimeFourWheelDrive                 0.810521    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.001427 ** \nIntakeValvePerCyl1                              0.055293 .  \nIntakeValvePerCyl2                              0.127060    \nIntakeValvePerCyl3                                    NA    \nExhaustValvesPerCyl1                            0.046088 *  \nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.015390 *  \nCarlineClassDescCompactCars                     0.000611 ***\nCarlineClassDescLargeCars                       0.024213 *  \nCarlineClassDescMidsizeCars                     0.002045 ** \nCarlineClassDescMinicompactCars                 0.002462 ** \nCarlineClassDescSmallPickupTrucks2WD            0.131822    \nCarlineClassDescSmallPickupTrucks4WD            0.459026    \nCarlineClassDescSmallStationWagons              0.053120 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.113986    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.169229    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.599543    \nCarlineClassDescStandardPickupTrucks2WD         0.164913    \nCarlineClassDescStandardPickupTrucks4WD         0.128675    \nCarlineClassDescSubcompactCars                  0.002105 ** \nCarlineClassDescVansCargoTypes                  0.007821 ** \nCarlineClassDescVansPassengerType               0.030792 *  \nVarValveLift1                                   0.007544 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.139 on 1052 degrees of freedom\nMultiple R-squared:  0.8333,    Adjusted R-squared:  0.8247 \nF-statistic: 97.38 on 54 and 1052 DF,  p-value: &lt; 2.2e-16\n\n\nCode\ncar::Anova(cars_lm2)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              737.1    1 74.8066 &lt; 2.2e-16 ***\nNumCyl                887.9    6 15.0181 &lt; 2.2e-16 ***\nTransmission          712.6   12  6.0266 2.849e-10 ***\nAirAspirationMethod   153.8    2  7.8053 0.0004316 ***\nNumGears              109.2    2  5.5431 0.0040294 ** \nTransLockup            61.7    1  6.2661 0.0124578 *  \nTransCreeperGear       50.5    1  5.1234 0.0238082 *  \nDriveDesc            1545.6    4 39.2146 &lt; 2.2e-16 ***\nIntakeValvePerCyl      57.9    2  2.9386 0.0533736 .  \nExhaustValvesPerCyl    39.3    1  3.9878 0.0460877 *  \nCarlineClassDesc     3504.2   16 22.2267 &lt; 2.2e-16 ***\nVarValveLift           70.6    1  7.1663 0.0075441 ** \nResiduals           10366.0 1052                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nThe p-value for the model did not change significantly\n\\(R^2\\) did not change significantly and \\(R_a^2\\) increased a little\n\n\n\n\n\nDropping IntakeValvePerCyl:\n\n\nCode\ncars_2010_sub &lt;- cars_2010_sub %&gt;%\n    select(-IntakeValvePerCyl)\n\ncars_lm3 &lt;- lm(FE ~ ., cars_2010_sub)\nsummary(cars_lm3)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars_2010_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.5964  -1.7032   0.0413   1.5730  21.6235 \n\nCoefficients: (4 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                      36.0050     3.3542  10.734\nEngDispl                                         -2.1120     0.2530  -8.346\nNumCyl3                                          20.9056     3.9117   5.344\nNumCyl4                                          12.6843     2.2897   5.540\nNumCyl5                                           9.6779     2.3617   4.098\nNumCyl6                                           9.0036     2.3148   3.889\nNumCyl8                                           7.0608     2.4285   2.908\nNumCyl10                                          4.4870     2.6277   1.708\nNumCyl12                                          3.0682     2.6138   1.174\nNumCyl16                                          3.8516     4.3735   0.881\nTransmissionA4                                   -7.1007     2.2745  -3.122\nTransmissionA5                                   -6.7679     2.2799  -2.968\nTransmissionA6                                   -5.2017     2.2777  -2.284\nTransmissionA7                                    5.3619     2.4409   2.197\nTransmissionAM6                                  -9.5275     2.4663  -3.863\nTransmissionAM7                                   0.5339     2.6561   0.201\nTransmissionAV                                   -4.5677     2.2867  -1.998\nTransmissionAVS6                                 -6.9582     2.4186  -2.877\nTransmissionM5                                   -7.2063     2.2788  -3.162\nTransmissionM6                                   -7.1857     2.2683  -3.168\nTransmissionS4                                  -10.7361     2.4247  -4.428\nTransmissionS5                                   -7.3945     2.3063  -3.206\nTransmissionS6                                   -5.2347     2.2655  -2.311\nTransmissionS7                                    3.8448     2.5130   1.530\nTransmissionS8                                   -4.6021     4.0315  -1.142\nAirAspirationMethodSupercharged                  -1.8711     0.7825  -2.391\nAirAspirationMethodTurbocharged                  -1.1602     0.3221  -3.602\nNumGears4                                             NA         NA      NA\nNumGears5                                             NA         NA      NA\nNumGears6                                             NA         NA      NA\nNumGears7                                       -10.6135     3.2834  -3.233\nNumGears8                                         1.7231     3.2016   0.538\nTransLockup1                                     -0.9069     0.3576  -2.536\nTransCreeperGear1                                -1.2475     0.4777  -2.612\nDriveDescFourWheelDrive                          -0.4799     0.4345  -1.105\nDriveDescParttimeFourWheelDrive                  -0.3666     1.0628  -0.345\nDriveDescTwoWheelDriveFront                       4.3236     0.3772  11.462\nDriveDescTwoWheelDriveRear                        1.1403     0.3722   3.063\nExhaustValvesPerCyl1                              2.7454     0.3965   6.925\nExhaustValvesPerCyl2                                  NA         NA      NA\nCarlineClassDesc2Seaters                          2.7680     1.1781   2.350\nCarlineClassDescCompactCars                       3.7770     1.1011   3.430\nCarlineClassDescLargeCars                         2.5646     1.1323   2.265\nCarlineClassDescMidsizeCars                       3.3732     1.0985   3.071\nCarlineClassDescMinicompactCars                   3.6283     1.1952   3.036\nCarlineClassDescSmallPickupTrucks2WD             -1.9032     1.2522  -1.520\nCarlineClassDescSmallPickupTrucks4WD             -1.0239     1.3517  -0.757\nCarlineClassDescSmallStationWagons                2.1934     1.1377   1.928\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.1150     1.3596  -1.556\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.5296     1.1097  -1.378\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.5922     1.1235  -0.527\nCarlineClassDescStandardPickupTrucks2WD          -1.7232     1.2714  -1.355\nCarlineClassDescStandardPickupTrucks4WD          -1.9711     1.3031  -1.513\nCarlineClassDescSubcompactCars                    3.4139     1.1141   3.064\nCarlineClassDescVansCargoTypes                   -3.9331     1.5169  -2.593\nCarlineClassDescVansPassengerType                -4.0805     1.9494  -2.093\nVarValveLift1                                     0.8053     0.3070   2.623\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                         &lt; 2e-16 ***\nNumCyl3                                         1.11e-07 ***\nNumCyl4                                         3.83e-08 ***\nNumCyl5                                         4.49e-05 ***\nNumCyl6                                         0.000107 ***\nNumCyl8                                         0.003719 ** \nNumCyl10                                        0.088005 .  \nNumCyl12                                        0.240713    \nNumCyl16                                        0.378695    \nTransmissionA4                                  0.001846 ** \nTransmissionA5                                  0.003061 ** \nTransmissionA6                                  0.022584 *  \nTransmissionA7                                  0.028260 *  \nTransmissionAM6                                 0.000119 ***\nTransmissionAM7                                 0.840740    \nTransmissionAV                                  0.046025 *  \nTransmissionAVS6                                0.004096 ** \nTransmissionM5                                  0.001610 ** \nTransmissionM6                                  0.001580 ** \nTransmissionS4                                  1.05e-05 ***\nTransmissionS5                                  0.001385 ** \nTransmissionS6                                  0.021044 *  \nTransmissionS7                                  0.126328    \nTransmissionS8                                  0.253901    \nAirAspirationMethodSupercharged                 0.016962 *  \nAirAspirationMethodTurbocharged                 0.000331 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001265 ** \nNumGears8                                       0.590565    \nTransLockup1                                    0.011365 *  \nTransCreeperGear1                               0.009142 ** \nDriveDescFourWheelDrive                         0.269550    \nDriveDescParttimeFourWheelDrive                 0.730220    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.002245 ** \nExhaustValvesPerCyl1                            7.58e-12 ***\nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.018981 *  \nCarlineClassDescCompactCars                     0.000626 ***\nCarlineClassDescLargeCars                       0.023715 *  \nCarlineClassDescMidsizeCars                     0.002189 ** \nCarlineClassDescMinicompactCars                 0.002458 ** \nCarlineClassDescSmallPickupTrucks2WD            0.128836    \nCarlineClassDescSmallPickupTrucks4WD            0.448949    \nCarlineClassDescSmallStationWagons              0.054126 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.120096    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.168369    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.598240    \nCarlineClassDescStandardPickupTrucks2WD         0.175593    \nCarlineClassDescStandardPickupTrucks4WD         0.130664    \nCarlineClassDescSubcompactCars                  0.002237 ** \nCarlineClassDescVansCargoTypes                  0.009648 ** \nCarlineClassDescVansPassengerType               0.036568 *  \nVarValveLift1                                   0.008839 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.145 on 1054 degrees of freedom\nMultiple R-squared:  0.8324,    Adjusted R-squared:  0.8241 \nF-statistic: 100.6 on 52 and 1054 DF,  p-value: &lt; 2.2e-16\n\n\nCode\ncar::Anova(cars_lm3)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              688.9    1 69.6604 &lt; 2.2e-16 ***\nNumCyl               1000.0    6 16.8523 &lt; 2.2e-16 ***\nTransmission          699.4   12  5.8935 5.430e-10 ***\nAirAspirationMethod   169.7    2  8.5817 0.0002009 ***\nNumGears              106.5    2  5.3833 0.0047196 ** \nTransLockup            63.6    1  6.4299 0.0113653 *  \nTransCreeperGear       67.4    1  6.8201 0.0091419 ** \nDriveDesc            1559.4    4 39.4183 &lt; 2.2e-16 ***\nExhaustValvesPerCyl   474.2    1 47.9516 7.583e-12 ***\nCarlineClassDesc     3489.4   16 22.0517 &lt; 2.2e-16 ***\nVarValveLift           68.0    1  6.8807 0.0088387 ** \nResiduals           10423.9 1054                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCode\ncars_2010_sub &lt;- cars_2010_sub %&gt;%\n    select(-TransLockup)\n\ncars_lm4 &lt;- lm(FE ~ ., cars_2010_sub)\nsummary(cars_lm4)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars_2010_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6831  -1.7755   0.0193   1.5767  22.1002 \n\nCoefficients: (4 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                      35.5540     3.3581  10.588\nEngDispl                                         -2.0676     0.2531  -8.170\nNumCyl3                                          20.3570     3.9157   5.199\nNumCyl4                                          12.6350     2.2955   5.504\nNumCyl5                                           9.6799     2.3677   4.088\nNumCyl6                                           8.8784     2.3203   3.826\nNumCyl8                                           6.8252     2.4329   2.805\nNumCyl10                                          4.2129     2.6322   1.601\nNumCyl12                                          2.7488     2.6175   1.050\nNumCyl16                                          4.1444     4.3832   0.946\nTransmissionA4                                   -7.5779     2.2725  -3.335\nTransmissionA5                                   -7.2188     2.2788  -3.168\nTransmissionA6                                   -5.5830     2.2785  -2.450\nTransmissionA7                                    4.7030     2.4333   1.933\nTransmissionAM6                                  -9.6845     2.4718  -3.918\nTransmissionAM7                                   0.5441     2.6629   0.204\nTransmissionAV                                   -4.5705     2.2925  -1.994\nTransmissionAVS6                                 -6.8711     2.4245  -2.834\nTransmissionM5                                   -6.7947     2.2788  -2.982\nTransmissionM6                                   -6.8804     2.2710  -3.030\nTransmissionS4                                  -11.2457     2.4226  -4.642\nTransmissionS5                                   -7.8915     2.3038  -3.425\nTransmissionS6                                   -5.5467     2.2680  -2.446\nTransmissionS7                                    3.1101     2.5027   1.243\nTransmissionS8                                   -5.4739     4.0271  -1.359\nAirAspirationMethodSupercharged                  -1.7876     0.7838  -2.281\nAirAspirationMethodTurbocharged                  -1.1043     0.3222  -3.427\nNumGears4                                             NA         NA      NA\nNumGears5                                             NA         NA      NA\nNumGears6                                             NA         NA      NA\nNumGears7                                       -10.2165     3.2880  -3.107\nNumGears8                                         2.2205     3.2038   0.693\nTransCreeperGear1                                -1.2791     0.4788  -2.672\nDriveDescFourWheelDrive                          -0.4976     0.4355  -1.143\nDriveDescParttimeFourWheelDrive                  -0.4061     1.0655  -0.381\nDriveDescTwoWheelDriveFront                       4.3413     0.3781  11.482\nDriveDescTwoWheelDriveRear                        1.1035     0.3729   2.959\nExhaustValvesPerCyl1                              2.7948     0.3970   7.040\nExhaustValvesPerCyl2                                  NA         NA      NA\nCarlineClassDesc2Seaters                          2.8530     1.1807   2.416\nCarlineClassDescCompactCars                       3.7853     1.1039   3.429\nCarlineClassDescLargeCars                         2.5289     1.1351   2.228\nCarlineClassDescMidsizeCars                       3.3020     1.1009   2.999\nCarlineClassDescMinicompactCars                   3.7542     1.1972   3.136\nCarlineClassDescSmallPickupTrucks2WD             -1.9188     1.2554  -1.528\nCarlineClassDescSmallPickupTrucks4WD             -1.0621     1.3551  -0.784\nCarlineClassDescSmallStationWagons                2.1620     1.1405   1.896\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.2133     1.3625  -1.624\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.5927     1.1122  -1.432\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.6482     1.1262  -0.576\nCarlineClassDescStandardPickupTrucks2WD          -1.7299     1.2746  -1.357\nCarlineClassDescStandardPickupTrucks4WD          -2.0053     1.3064  -1.535\nCarlineClassDescSubcompactCars                    3.3939     1.1169   3.039\nCarlineClassDescVansCargoTypes                   -3.9518     1.5207  -2.599\nCarlineClassDescVansPassengerType                -4.0897     1.9544  -2.093\nVarValveLift1                                     0.8016     0.3078   2.604\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                        8.79e-16 ***\nNumCyl3                                         2.41e-07 ***\nNumCyl4                                         4.66e-08 ***\nNumCyl5                                         4.68e-05 ***\nNumCyl6                                         0.000138 ***\nNumCyl8                                         0.005119 ** \nNumCyl10                                        0.109781    \nNumCyl12                                        0.293871    \nNumCyl16                                        0.344606    \nTransmissionA4                                  0.000884 ***\nTransmissionA5                                  0.001580 ** \nTransmissionA6                                  0.014438 *  \nTransmissionA7                                  0.053532 .  \nTransmissionAM6                                 9.50e-05 ***\nTransmissionAM7                                 0.838126    \nTransmissionAV                                  0.046450 *  \nTransmissionAVS6                                0.004685 ** \nTransmissionM5                                  0.002933 ** \nTransmissionM6                                  0.002507 ** \nTransmissionS4                                  3.88e-06 ***\nTransmissionS5                                  0.000638 ***\nTransmissionS6                                  0.014620 *  \nTransmissionS7                                  0.214253    \nTransmissionS8                                  0.174354    \nAirAspirationMethodSupercharged                 0.022764 *  \nAirAspirationMethodTurbocharged                 0.000633 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001939 ** \nNumGears8                                       0.488417    \nTransCreeperGear1                               0.007665 ** \nDriveDescFourWheelDrive                         0.253447    \nDriveDescParttimeFourWheelDrive                 0.703142    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.003153 ** \nExhaustValvesPerCyl1                            3.46e-12 ***\nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.015841 *  \nCarlineClassDescCompactCars                     0.000629 ***\nCarlineClassDescLargeCars                       0.026094 *  \nCarlineClassDescMidsizeCars                     0.002770 ** \nCarlineClassDescMinicompactCars                 0.001761 ** \nCarlineClassDescSmallPickupTrucks2WD            0.126696    \nCarlineClassDescSmallPickupTrucks4WD            0.433337    \nCarlineClassDescSmallStationWagons              0.058280 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.104587    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.152446    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.565022    \nCarlineClassDescStandardPickupTrucks2WD         0.175017    \nCarlineClassDescStandardPickupTrucks4WD         0.125076    \nCarlineClassDescSubcompactCars                  0.002435 ** \nCarlineClassDescVansCargoTypes                  0.009490 ** \nCarlineClassDescVansPassengerType               0.036625 *  \nVarValveLift1                                   0.009338 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.153 on 1055 degrees of freedom\nMultiple R-squared:  0.8313,    Adjusted R-squared:  0.8232 \nF-statistic:   102 on 51 and 1055 DF,  p-value: &lt; 2.2e-16\n\n\nCode\ncar::Anova(cars_lm4)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              663.5    1 66.7421 8.786e-16 ***\nNumCyl               1037.6    6 17.3966 &lt; 2.2e-16 ***\nTransmission          638.4   12  5.3520 7.426e-09 ***\nAirAspirationMethod   155.0    2  7.7971  0.000435 ***\nNumGears              101.0    2  5.0780  0.006385 ** \nTransCreeperGear       71.0    1  7.1376  0.007665 ** \nDriveDesc            1586.1    4 39.8882 &lt; 2.2e-16 ***\nExhaustValvesPerCyl   492.7    1 49.5606 3.460e-12 ***\nCarlineClassDesc     3548.8   16 22.3123 &lt; 2.2e-16 ***\nVarValveLift           67.4    1  6.7819  0.009338 ** \nResiduals           10487.5 1055                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCode\ncars_2010_sub &lt;- cars_2010_sub %&gt;%\n    select(-VarValveLift)\n\ncars_lm5 &lt;- lm(FE ~ ., cars_2010_sub)\nsummary(cars_lm5)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars_2010_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.7951  -1.7259   0.0248   1.6395  22.0010 \n\nCoefficients: (4 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                      35.6506     3.3670  10.588\nEngDispl                                         -2.0915     0.2536  -8.247\nNumCyl3                                          20.1462     3.9256   5.132\nNumCyl4                                          12.9901     2.2977   5.653\nNumCyl5                                           9.9691     2.3716   4.204\nNumCyl6                                           9.2880     2.3213   4.001\nNumCyl8                                           7.1931     2.4355   2.953\nNumCyl10                                          4.2902     2.6392   1.626\nNumCyl12                                          2.9960     2.6229   1.142\nNumCyl16                                          4.2509     4.3950   0.967\nTransmissionA4                                   -7.9263     2.2748  -3.484\nTransmissionA5                                   -7.4632     2.2831  -3.269\nTransmissionA6                                   -5.9012     2.2815  -2.587\nTransmissionA7                                    4.9316     2.4383   2.023\nTransmissionAM6                                 -10.0571     2.4744  -4.064\nTransmissionAM7                                   0.4535     2.6700   0.170\nTransmissionAV                                   -4.8272     2.2967  -2.102\nTransmissionAVS6                                 -7.2674     2.4264  -2.995\nTransmissionM5                                   -7.0899     2.2822  -3.107\nTransmissionM6                                   -7.0372     2.2764  -3.091\nTransmissionS4                                  -11.2013     2.4291  -4.611\nTransmissionS5                                   -8.0730     2.3091  -3.496\nTransmissionS6                                   -5.7943     2.2722  -2.550\nTransmissionS7                                    3.4280     2.5065   1.368\nTransmissionS8                                   -5.5848     4.0379  -1.383\nAirAspirationMethodSupercharged                  -1.9893     0.7821  -2.544\nAirAspirationMethodTurbocharged                  -1.2457     0.3184  -3.912\nNumGears4                                             NA         NA      NA\nNumGears5                                             NA         NA      NA\nNumGears6                                             NA         NA      NA\nNumGears7                                       -10.6500     3.2928  -3.234\nNumGears8                                         2.0751     3.2121   0.646\nTransCreeperGear1                                -1.3661     0.4789  -2.852\nDriveDescFourWheelDrive                          -0.6841     0.4308  -1.588\nDriveDescParttimeFourWheelDrive                  -0.7039     1.0622  -0.663\nDriveDescTwoWheelDriveFront                       4.1905     0.3747  11.185\nDriveDescTwoWheelDriveRear                        0.9965     0.3717   2.681\nExhaustValvesPerCyl1                              2.7810     0.3980   6.986\nExhaustValvesPerCyl2                                  NA         NA      NA\nCarlineClassDesc2Seaters                          3.0982     1.1801   2.625\nCarlineClassDescCompactCars                       3.8878     1.1062   3.515\nCarlineClassDescLargeCars                         2.6874     1.1366   2.364\nCarlineClassDescMidsizeCars                       3.4001     1.1033   3.082\nCarlineClassDescMinicompactCars                   4.3247     1.1802   3.664\nCarlineClassDescSmallPickupTrucks2WD             -1.8684     1.2587  -1.484\nCarlineClassDescSmallPickupTrucks4WD             -0.9067     1.3575  -0.668\nCarlineClassDescSmallStationWagons                2.2224     1.1434   1.944\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.1858     1.3662  -1.600\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.5070     1.1148  -1.352\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.4822     1.1274  -0.428\nCarlineClassDescStandardPickupTrucks2WD          -1.6614     1.2778  -1.300\nCarlineClassDescStandardPickupTrucks4WD          -1.8270     1.3081  -1.397\nCarlineClassDescSubcompactCars                    3.6375     1.1160   3.259\nCarlineClassDescVansCargoTypes                   -3.8763     1.5246  -2.542\nCarlineClassDescVansPassengerType                -4.0117     1.9595  -2.047\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                        4.79e-16 ***\nNumCyl3                                         3.41e-07 ***\nNumCyl4                                         2.02e-08 ***\nNumCyl5                                         2.85e-05 ***\nNumCyl6                                         6.74e-05 ***\nNumCyl8                                         0.003212 ** \nNumCyl10                                        0.104342    \nNumCyl12                                        0.253614    \nNumCyl16                                        0.333656    \nTransmissionA4                                  0.000513 ***\nTransmissionA5                                  0.001115 ** \nTransmissionA6                                  0.009827 ** \nTransmissionA7                                  0.043374 *  \nTransmissionAM6                                 5.17e-05 ***\nTransmissionAM7                                 0.865169    \nTransmissionAV                                  0.035807 *  \nTransmissionAVS6                                0.002807 ** \nTransmissionM5                                  0.001944 ** \nTransmissionM6                                  0.002044 ** \nTransmissionS4                                  4.49e-06 ***\nTransmissionS5                                  0.000492 ***\nTransmissionS6                                  0.010908 *  \nTransmissionS7                                  0.171715    \nTransmissionS8                                  0.166927    \nAirAspirationMethodSupercharged                 0.011113 *  \nAirAspirationMethodTurbocharged                 9.74e-05 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001257 ** \nNumGears8                                       0.518403    \nTransCreeperGear1                               0.004423 ** \nDriveDescFourWheelDrive                         0.112532    \nDriveDescParttimeFourWheelDrive                 0.507654    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.007448 ** \nExhaustValvesPerCyl1                            4.98e-12 ***\nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.008782 ** \nCarlineClassDescCompactCars                     0.000459 ***\nCarlineClassDescLargeCars                       0.018235 *  \nCarlineClassDescMidsizeCars                     0.002111 ** \nCarlineClassDescMinicompactCars                 0.000260 ***\nCarlineClassDescSmallPickupTrucks2WD            0.137996    \nCarlineClassDescSmallPickupTrucks4WD            0.504354    \nCarlineClassDescSmallStationWagons              0.052206 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.109914    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.176714    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.668970    \nCarlineClassDescStandardPickupTrucks2WD         0.193828    \nCarlineClassDescStandardPickupTrucks4WD         0.162813    \nCarlineClassDescSubcompactCars                  0.001152 ** \nCarlineClassDescVansCargoTypes                  0.011149 *  \nCarlineClassDescVansPassengerType               0.040873 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.162 on 1056 degrees of freedom\nMultiple R-squared:  0.8303,    Adjusted R-squared:  0.8222 \nF-statistic: 103.3 on 50 and 1056 DF,  p-value: &lt; 2.2e-16\n\n\nCode\ncar::Anova(cars_lm5)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              679.8    1 68.0122 4.791e-16 ***\nNumCyl               1043.7    6 17.4026 &lt; 2.2e-16 ***\nTransmission          613.6   12  5.1154 2.307e-08 ***\nAirAspirationMethod   202.9    2 10.1494 4.305e-05 ***\nNumGears              108.9    2  5.4475  0.004429 ** \nTransCreeperGear       81.3    1  8.1365  0.004423 ** \nDriveDesc            1537.5    4 38.4558 &lt; 2.2e-16 ***\nExhaustValvesPerCyl   487.9    1 48.8110 4.982e-12 ***\nCarlineClassDesc     3715.0   16 23.2300 &lt; 2.2e-16 ***\nResiduals           10554.9 1056                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nBoth \\(R^2\\) and \\(R_a^2\\) decreased\n9 variables significant at the 0.008 level"
  },
  {
    "objectID": "notes/analytics/07062023/lab_6.html#a",
    "href": "notes/analytics/07062023/lab_6.html#a",
    "title": "Lab 6",
    "section": "",
    "text": "Code\ncars2010 &lt;- cars2010 %&gt;%\n    mutate(across(!c(EngDispl, FE), as.factor))\ncars_lm &lt;- lm(FE ~ ., data = cars2010)\nsummary(cars_lm)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars2010)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6399  -1.6583   0.0582   1.5708  21.6002 \n\nCoefficients: (5 not defined because of singularities)\n                                                 Estimate Std. Error t value\n(Intercept)                                      35.95655    3.34991  10.734\nEngDispl                                         -2.24571    0.26269  -8.549\nNumCyl3                                          15.88136    5.11001   3.108\nNumCyl4                                           7.76711    3.94430   1.969\nNumCyl5                                           4.89858    3.97620   1.232\nNumCyl6                                           4.19528    3.94208   1.064\nNumCyl8                                           2.51528    3.98438   0.631\nNumCyl10                                         -0.01541    4.13445  -0.004\nNumCyl12                                         -1.02329    4.11855  -0.248\nNumCyl16                                         -0.31250    5.42018  -0.058\nTransmissionA4                                   -6.93754    2.27354  -3.051\nTransmissionA5                                   -6.53146    2.27928  -2.866\nTransmissionA6                                   -4.88712    2.27829  -2.145\nTransmissionA7                                    5.70476    2.44239   2.336\nTransmissionAM6                                  -9.48575    2.46325  -3.851\nTransmissionAM7                                   0.59731    2.65233   0.225\nTransmissionAV                                   -4.40251    2.28451  -1.927\nTransmissionAVS6                                 -6.72835    2.41754  -2.783\nTransmissionM5                                   -7.00105    2.27746  -3.074\nTransmissionM6                                   -7.03693    2.26627  -3.105\nTransmissionS4                                  -10.42310    2.42863  -4.292\nTransmissionS5                                   -7.17879    2.30519  -3.114\nTransmissionS6                                   -5.09671    2.26315  -2.252\nTransmissionS7                                    4.08689    2.51141   1.627\nTransmissionS8                                   -4.61764    4.02547  -1.147\nAirAspirationMethodSupercharged                  -1.66003    0.78945  -2.103\nAirAspirationMethodTurbocharged                  -1.12911    0.32214  -3.505\nNumGears4                                              NA         NA      NA\nNumGears5                                              NA         NA      NA\nNumGears6                                              NA         NA      NA\nNumGears7                                       -10.74200    3.27897  -3.276\nNumGears8                                         1.78308    3.19710   0.558\nTransLockup1                                     -0.89442    0.35715  -2.504\nTransCreeperGear1                                -1.04006    0.49553  -2.099\nDriveDescFourWheelDrive                          -0.45145    0.43461  -1.039\nDriveDescParttimeFourWheelDrive                  -0.29399    1.06503  -0.276\nDriveDescTwoWheelDriveFront                       4.31845    0.37701  11.455\nDriveDescTwoWheelDriveRear                        1.19634    0.37255   3.211\nIntakeValvePerCyl1                                6.33644    3.32150   1.908\nIntakeValvePerCyl2                                4.88952    3.21060   1.523\nIntakeValvePerCyl3                                     NA         NA      NA\nExhaustValvesPerCyl1                              1.54229    0.75433   2.045\nExhaustValvesPerCyl2                                   NA         NA      NA\nCarlineClassDesc2Seaters                          2.85693    1.17833   2.425\nCarlineClassDescCompactCars                       3.78908    1.09963   3.446\nCarlineClassDescLargeCars                         2.56219    1.13079   2.266\nCarlineClassDescMidsizeCars                       3.39390    1.09686   3.094\nCarlineClassDescMinicompactCars                   3.63416    1.19375   3.044\nCarlineClassDescSmallPickupTrucks2WD             -1.85140    1.25181  -1.479\nCarlineClassDescSmallPickupTrucks4WD             -0.95072    1.35268  -0.703\nCarlineClassDescSmallStationWagons                2.20724    1.13608   1.943\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.07995    1.36307  -1.526\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.51997    1.10807  -1.372\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.56991    1.12243  -0.508\nCarlineClassDescStandardPickupTrucks2WD          -1.74467    1.27006  -1.374\nCarlineClassDescStandardPickupTrucks4WD          -1.94205    1.30286  -1.491\nCarlineClassDescSubcompactCars                    3.43057    1.11242   3.084\nCarlineClassDescVansCargoTypes                   -4.07446    1.51702  -2.686\nCarlineClassDescVansPassengerType                -4.27396    1.95092  -2.191\nVarValveTiming1                                   0.15943    0.29071   0.548\nVarValveLift1                                     0.82579    0.30704   2.690\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                         &lt; 2e-16 ***\nNumCyl3                                         0.001935 ** \nNumCyl4                                         0.049193 *  \nNumCyl5                                         0.218234    \nNumCyl6                                         0.287469    \nNumCyl8                                         0.527992    \nNumCyl10                                        0.997028    \nNumCyl12                                        0.803827    \nNumCyl16                                        0.954034    \nTransmissionA4                                  0.002335 ** \nTransmissionA5                                  0.004245 ** \nTransmissionA6                                  0.032175 *  \nTransmissionA7                                  0.019693 *  \nTransmissionAM6                                 0.000125 ***\nTransmissionAM7                                 0.821867    \nTransmissionAV                                  0.054234 .  \nTransmissionAVS6                                0.005480 ** \nTransmissionM5                                  0.002166 ** \nTransmissionM6                                  0.001953 ** \nTransmissionS4                                  1.94e-05 ***\nTransmissionS5                                  0.001894 ** \nTransmissionS6                                  0.024526 *  \nTransmissionS7                                  0.103967    \nTransmissionS8                                  0.251599    \nAirAspirationMethodSupercharged                 0.035723 *  \nAirAspirationMethodTurbocharged                 0.000476 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001087 ** \nNumGears8                                       0.577155    \nTransLockup1                                    0.012420 *  \nTransCreeperGear1                               0.036067 *  \nDriveDescFourWheelDrive                         0.299167    \nDriveDescParttimeFourWheelDrive                 0.782571    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.001362 ** \nIntakeValvePerCyl1                              0.056702 .  \nIntakeValvePerCyl2                              0.128077    \nIntakeValvePerCyl3                                    NA    \nExhaustValvesPerCyl1                            0.041146 *  \nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.015495 *  \nCarlineClassDescCompactCars                     0.000592 ***\nCarlineClassDescLargeCars                       0.023664 *  \nCarlineClassDescMidsizeCars                     0.002026 ** \nCarlineClassDescMinicompactCars                 0.002390 ** \nCarlineClassDescSmallPickupTrucks2WD            0.139447    \nCarlineClassDescSmallPickupTrucks4WD            0.482307    \nCarlineClassDescSmallStationWagons              0.052300 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.127330    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.170443    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.611738    \nCarlineClassDescStandardPickupTrucks2WD         0.169828    \nCarlineClassDescStandardPickupTrucks4WD         0.136365    \nCarlineClassDescSubcompactCars                  0.002097 ** \nCarlineClassDescVansCargoTypes                  0.007349 ** \nCarlineClassDescVansPassengerType               0.028690 *  \nVarValveTiming1                                 0.583517    \nVarValveLift1                                   0.007269 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.14 on 1051 degrees of freedom\nMultiple R-squared:  0.8333,    Adjusted R-squared:  0.8246 \nF-statistic: 95.55 on 55 and 1051 DF,  p-value: &lt; 2.2e-16\n\n\n\nThe F p-value is significant meaning that our overall model is significant in predicting FE\nThe 13 variables explain 83.33 percent of variation in fuel economy"
  },
  {
    "objectID": "notes/analytics/07062023/lab_6.html#b",
    "href": "notes/analytics/07062023/lab_6.html#b",
    "title": "Lab 6",
    "section": "",
    "text": "Code\ncar::Anova(cars_lm)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              720.6    1 73.0842 &lt; 2.2e-16 ***\nNumCyl                889.6    6 15.0374 &lt; 2.2e-16 ***\nTransmission          707.7   12  5.9813 3.553e-10 ***\nAirAspirationMethod   151.2    2  7.6686 0.0004939 ***\nNumGears              109.2    2  5.5361 0.0040576 ** \nTransLockup            61.8    1  6.2715 0.0124202 *  \nTransCreeperGear       43.4    1  4.4052 0.0360667 *  \nDriveDesc            1535.0    4 38.9205 &lt; 2.2e-16 ***\nIntakeValvePerCyl      56.6    2  2.8720 0.0570315 .  \nExhaustValvesPerCyl    41.2    1  4.1803 0.0411460 *  \nCarlineClassDesc     3495.4   16 22.1561 &lt; 2.2e-16 ***\nVarValveTiming          3.0    1  0.3008 0.5835171    \nVarValveLift           71.3    1  7.2336 0.0072685 ** \nResiduals           10363.0 1051                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nHighest p-value is VarValveTiming with 0.584"
  },
  {
    "objectID": "notes/analytics/07062023/lab_6.html#c",
    "href": "notes/analytics/07062023/lab_6.html#c",
    "title": "Lab 6",
    "section": "",
    "text": "Code\ncars_2010_sub &lt;- cars2010 %&gt;%\n    select(-VarValveTiming)\n\ncars_lm2 &lt;- lm(FE ~ ., cars_2010_sub)\nsummary(cars_lm2)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars_2010_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6242  -1.6504   0.0541   1.5540  21.5852 \n\nCoefficients: (5 not defined because of singularities)\n                                                 Estimate Std. Error t value\n(Intercept)                                      35.99395    3.34810  10.751\nEngDispl                                         -2.26003    0.26130  -8.649\nNumCyl3                                          16.00965    5.10296   3.137\nNumCyl4                                           7.91363    3.93394   2.012\nNumCyl5                                           5.03429    3.96717   1.269\nNumCyl6                                           4.35537    3.92996   1.108\nNumCyl8                                           2.71420    3.96652   0.684\nNumCyl10                                          0.18914    4.11622   0.046\nNumCyl12                                         -0.81976    4.10043  -0.200\nNumCyl16                                         -0.08503    5.40249  -0.016\nTransmissionA4                                   -6.98768    2.27095  -3.077\nTransmissionA5                                   -6.53850    2.27848  -2.870\nTransmissionA6                                   -4.90059    2.27740  -2.152\nTransmissionA7                                    5.71566    2.44150   2.341\nTransmissionAM6                                  -9.49295    2.46240  -3.855\nTransmissionAM7                                   0.59242    2.65143   0.223\nTransmissionAV                                   -4.40233    2.28375  -1.928\nTransmissionAVS6                                 -6.72853    2.41673  -2.784\nTransmissionM5                                   -7.01977    2.27644  -3.084\nTransmissionM6                                   -7.04911    2.26540  -3.112\nTransmissionS4                                  -10.51052    2.42259  -4.339\nTransmissionS5                                   -7.20354    2.30398  -3.127\nTransmissionS6                                   -5.10605    2.26234  -2.257\nTransmissionS7                                    4.09144    2.51056   1.630\nTransmissionS8                                   -4.62893    4.02408  -1.150\nAirAspirationMethodSupercharged                  -1.67713    0.78857  -2.127\nAirAspirationMethodTurbocharged                  -1.13613    0.32177  -3.531\nNumGears4                                              NA         NA      NA\nNumGears5                                              NA         NA      NA\nNumGears6                                              NA         NA      NA\nNumGears7                                       -10.74376    3.27788  -3.278\nNumGears8                                         1.79152    3.19600   0.561\nTransLockup1                                     -0.89373    0.35703  -2.503\nTransCreeperGear1                                -1.09666    0.48450  -2.263\nDriveDescFourWheelDrive                          -0.44026    0.43399  -1.014\nDriveDescParttimeFourWheelDrive                  -0.25475    1.06227  -0.240\nDriveDescTwoWheelDriveFront                       4.32752    0.37652  11.494\nDriveDescTwoWheelDriveRear                        1.19041    0.37227   3.198\nIntakeValvePerCyl1                                6.36976    3.31984   1.919\nIntakeValvePerCyl2                                4.90088    3.20946   1.527\nIntakeValvePerCyl3                                     NA         NA      NA\nExhaustValvesPerCyl1                              1.49669    0.74949   1.997\nExhaustValvesPerCyl2                                   NA         NA      NA\nCarlineClassDesc2Seaters                          2.85888    1.17793   2.427\nCarlineClassDescCompactCars                       3.77775    1.09907   3.437\nCarlineClassDescLargeCars                         2.55092    1.13023   2.257\nCarlineClassDescMidsizeCars                       3.38958    1.09647   3.091\nCarlineClassDescMinicompactCars                   3.62150    1.19313   3.035\nCarlineClassDescSmallPickupTrucks2WD             -1.88501    1.24990  -1.508\nCarlineClassDescSmallPickupTrucks4WD             -0.99946    1.34930  -0.741\nCarlineClassDescSmallStationWagons                2.19864    1.13559   1.936\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.14681    1.35716  -1.582\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.52376    1.10769  -1.376\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.58904    1.12151  -0.525\nCarlineClassDescStandardPickupTrucks2WD          -1.76375    1.26916  -1.390\nCarlineClassDescStandardPickupTrucks4WD          -1.97791    1.30079  -1.521\nCarlineClassDescSubcompactCars                    3.42813    1.11204   3.083\nCarlineClassDescVansCargoTypes                   -4.03720    1.51499  -2.665\nCarlineClassDescVansPassengerType                -4.21030    1.94682  -2.163\nVarValveLift1                                     0.82139    0.30683   2.677\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                         &lt; 2e-16 ***\nNumCyl3                                         0.001752 ** \nNumCyl4                                         0.044513 *  \nNumCyl5                                         0.204726    \nNumCyl6                                         0.268007    \nNumCyl8                                         0.493951    \nNumCyl10                                        0.963360    \nNumCyl12                                        0.841581    \nNumCyl16                                        0.987446    \nTransmissionA4                                  0.002145 ** \nTransmissionA5                                  0.004191 ** \nTransmissionA6                                  0.031638 *  \nTransmissionA7                                  0.019416 *  \nTransmissionAM6                                 0.000123 ***\nTransmissionAM7                                 0.823240    \nTransmissionAV                                  0.054164 .  \nTransmissionAVS6                                0.005463 ** \nTransmissionM5                                  0.002098 ** \nTransmissionM6                                  0.001911 ** \nTransmissionS4                                  1.57e-05 ***\nTransmissionS5                                  0.001817 ** \nTransmissionS6                                  0.024214 *  \nTransmissionS7                                  0.103466    \nTransmissionS8                                  0.250279    \nAirAspirationMethodSupercharged                 0.033668 *  \nAirAspirationMethodTurbocharged                 0.000432 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001081 ** \nNumGears8                                       0.575223    \nTransLockup1                                    0.012458 *  \nTransCreeperGear1                               0.023808 *  \nDriveDescFourWheelDrive                         0.310604    \nDriveDescParttimeFourWheelDrive                 0.810521    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.001427 ** \nIntakeValvePerCyl1                              0.055293 .  \nIntakeValvePerCyl2                              0.127060    \nIntakeValvePerCyl3                                    NA    \nExhaustValvesPerCyl1                            0.046088 *  \nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.015390 *  \nCarlineClassDescCompactCars                     0.000611 ***\nCarlineClassDescLargeCars                       0.024213 *  \nCarlineClassDescMidsizeCars                     0.002045 ** \nCarlineClassDescMinicompactCars                 0.002462 ** \nCarlineClassDescSmallPickupTrucks2WD            0.131822    \nCarlineClassDescSmallPickupTrucks4WD            0.459026    \nCarlineClassDescSmallStationWagons              0.053120 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.113986    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.169229    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.599543    \nCarlineClassDescStandardPickupTrucks2WD         0.164913    \nCarlineClassDescStandardPickupTrucks4WD         0.128675    \nCarlineClassDescSubcompactCars                  0.002105 ** \nCarlineClassDescVansCargoTypes                  0.007821 ** \nCarlineClassDescVansPassengerType               0.030792 *  \nVarValveLift1                                   0.007544 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.139 on 1052 degrees of freedom\nMultiple R-squared:  0.8333,    Adjusted R-squared:  0.8247 \nF-statistic: 97.38 on 54 and 1052 DF,  p-value: &lt; 2.2e-16\n\n\nCode\ncar::Anova(cars_lm2)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              737.1    1 74.8066 &lt; 2.2e-16 ***\nNumCyl                887.9    6 15.0181 &lt; 2.2e-16 ***\nTransmission          712.6   12  6.0266 2.849e-10 ***\nAirAspirationMethod   153.8    2  7.8053 0.0004316 ***\nNumGears              109.2    2  5.5431 0.0040294 ** \nTransLockup            61.7    1  6.2661 0.0124578 *  \nTransCreeperGear       50.5    1  5.1234 0.0238082 *  \nDriveDesc            1545.6    4 39.2146 &lt; 2.2e-16 ***\nIntakeValvePerCyl      57.9    2  2.9386 0.0533736 .  \nExhaustValvesPerCyl    39.3    1  3.9878 0.0460877 *  \nCarlineClassDesc     3504.2   16 22.2267 &lt; 2.2e-16 ***\nVarValveLift           70.6    1  7.1663 0.0075441 ** \nResiduals           10366.0 1052                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nThe p-value for the model did not change significantly\n\\(R^2\\) did not change significantly and \\(R_a^2\\) increased a little"
  },
  {
    "objectID": "notes/analytics/07062023/lab_6.html#d",
    "href": "notes/analytics/07062023/lab_6.html#d",
    "title": "Lab 6",
    "section": "",
    "text": "Dropping IntakeValvePerCyl:\n\n\nCode\ncars_2010_sub &lt;- cars_2010_sub %&gt;%\n    select(-IntakeValvePerCyl)\n\ncars_lm3 &lt;- lm(FE ~ ., cars_2010_sub)\nsummary(cars_lm3)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars_2010_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.5964  -1.7032   0.0413   1.5730  21.6235 \n\nCoefficients: (4 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                      36.0050     3.3542  10.734\nEngDispl                                         -2.1120     0.2530  -8.346\nNumCyl3                                          20.9056     3.9117   5.344\nNumCyl4                                          12.6843     2.2897   5.540\nNumCyl5                                           9.6779     2.3617   4.098\nNumCyl6                                           9.0036     2.3148   3.889\nNumCyl8                                           7.0608     2.4285   2.908\nNumCyl10                                          4.4870     2.6277   1.708\nNumCyl12                                          3.0682     2.6138   1.174\nNumCyl16                                          3.8516     4.3735   0.881\nTransmissionA4                                   -7.1007     2.2745  -3.122\nTransmissionA5                                   -6.7679     2.2799  -2.968\nTransmissionA6                                   -5.2017     2.2777  -2.284\nTransmissionA7                                    5.3619     2.4409   2.197\nTransmissionAM6                                  -9.5275     2.4663  -3.863\nTransmissionAM7                                   0.5339     2.6561   0.201\nTransmissionAV                                   -4.5677     2.2867  -1.998\nTransmissionAVS6                                 -6.9582     2.4186  -2.877\nTransmissionM5                                   -7.2063     2.2788  -3.162\nTransmissionM6                                   -7.1857     2.2683  -3.168\nTransmissionS4                                  -10.7361     2.4247  -4.428\nTransmissionS5                                   -7.3945     2.3063  -3.206\nTransmissionS6                                   -5.2347     2.2655  -2.311\nTransmissionS7                                    3.8448     2.5130   1.530\nTransmissionS8                                   -4.6021     4.0315  -1.142\nAirAspirationMethodSupercharged                  -1.8711     0.7825  -2.391\nAirAspirationMethodTurbocharged                  -1.1602     0.3221  -3.602\nNumGears4                                             NA         NA      NA\nNumGears5                                             NA         NA      NA\nNumGears6                                             NA         NA      NA\nNumGears7                                       -10.6135     3.2834  -3.233\nNumGears8                                         1.7231     3.2016   0.538\nTransLockup1                                     -0.9069     0.3576  -2.536\nTransCreeperGear1                                -1.2475     0.4777  -2.612\nDriveDescFourWheelDrive                          -0.4799     0.4345  -1.105\nDriveDescParttimeFourWheelDrive                  -0.3666     1.0628  -0.345\nDriveDescTwoWheelDriveFront                       4.3236     0.3772  11.462\nDriveDescTwoWheelDriveRear                        1.1403     0.3722   3.063\nExhaustValvesPerCyl1                              2.7454     0.3965   6.925\nExhaustValvesPerCyl2                                  NA         NA      NA\nCarlineClassDesc2Seaters                          2.7680     1.1781   2.350\nCarlineClassDescCompactCars                       3.7770     1.1011   3.430\nCarlineClassDescLargeCars                         2.5646     1.1323   2.265\nCarlineClassDescMidsizeCars                       3.3732     1.0985   3.071\nCarlineClassDescMinicompactCars                   3.6283     1.1952   3.036\nCarlineClassDescSmallPickupTrucks2WD             -1.9032     1.2522  -1.520\nCarlineClassDescSmallPickupTrucks4WD             -1.0239     1.3517  -0.757\nCarlineClassDescSmallStationWagons                2.1934     1.1377   1.928\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.1150     1.3596  -1.556\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.5296     1.1097  -1.378\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.5922     1.1235  -0.527\nCarlineClassDescStandardPickupTrucks2WD          -1.7232     1.2714  -1.355\nCarlineClassDescStandardPickupTrucks4WD          -1.9711     1.3031  -1.513\nCarlineClassDescSubcompactCars                    3.4139     1.1141   3.064\nCarlineClassDescVansCargoTypes                   -3.9331     1.5169  -2.593\nCarlineClassDescVansPassengerType                -4.0805     1.9494  -2.093\nVarValveLift1                                     0.8053     0.3070   2.623\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                         &lt; 2e-16 ***\nNumCyl3                                         1.11e-07 ***\nNumCyl4                                         3.83e-08 ***\nNumCyl5                                         4.49e-05 ***\nNumCyl6                                         0.000107 ***\nNumCyl8                                         0.003719 ** \nNumCyl10                                        0.088005 .  \nNumCyl12                                        0.240713    \nNumCyl16                                        0.378695    \nTransmissionA4                                  0.001846 ** \nTransmissionA5                                  0.003061 ** \nTransmissionA6                                  0.022584 *  \nTransmissionA7                                  0.028260 *  \nTransmissionAM6                                 0.000119 ***\nTransmissionAM7                                 0.840740    \nTransmissionAV                                  0.046025 *  \nTransmissionAVS6                                0.004096 ** \nTransmissionM5                                  0.001610 ** \nTransmissionM6                                  0.001580 ** \nTransmissionS4                                  1.05e-05 ***\nTransmissionS5                                  0.001385 ** \nTransmissionS6                                  0.021044 *  \nTransmissionS7                                  0.126328    \nTransmissionS8                                  0.253901    \nAirAspirationMethodSupercharged                 0.016962 *  \nAirAspirationMethodTurbocharged                 0.000331 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001265 ** \nNumGears8                                       0.590565    \nTransLockup1                                    0.011365 *  \nTransCreeperGear1                               0.009142 ** \nDriveDescFourWheelDrive                         0.269550    \nDriveDescParttimeFourWheelDrive                 0.730220    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.002245 ** \nExhaustValvesPerCyl1                            7.58e-12 ***\nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.018981 *  \nCarlineClassDescCompactCars                     0.000626 ***\nCarlineClassDescLargeCars                       0.023715 *  \nCarlineClassDescMidsizeCars                     0.002189 ** \nCarlineClassDescMinicompactCars                 0.002458 ** \nCarlineClassDescSmallPickupTrucks2WD            0.128836    \nCarlineClassDescSmallPickupTrucks4WD            0.448949    \nCarlineClassDescSmallStationWagons              0.054126 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.120096    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.168369    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.598240    \nCarlineClassDescStandardPickupTrucks2WD         0.175593    \nCarlineClassDescStandardPickupTrucks4WD         0.130664    \nCarlineClassDescSubcompactCars                  0.002237 ** \nCarlineClassDescVansCargoTypes                  0.009648 ** \nCarlineClassDescVansPassengerType               0.036568 *  \nVarValveLift1                                   0.008839 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.145 on 1054 degrees of freedom\nMultiple R-squared:  0.8324,    Adjusted R-squared:  0.8241 \nF-statistic: 100.6 on 52 and 1054 DF,  p-value: &lt; 2.2e-16\n\n\nCode\ncar::Anova(cars_lm3)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              688.9    1 69.6604 &lt; 2.2e-16 ***\nNumCyl               1000.0    6 16.8523 &lt; 2.2e-16 ***\nTransmission          699.4   12  5.8935 5.430e-10 ***\nAirAspirationMethod   169.7    2  8.5817 0.0002009 ***\nNumGears              106.5    2  5.3833 0.0047196 ** \nTransLockup            63.6    1  6.4299 0.0113653 *  \nTransCreeperGear       67.4    1  6.8201 0.0091419 ** \nDriveDesc            1559.4    4 39.4183 &lt; 2.2e-16 ***\nExhaustValvesPerCyl   474.2    1 47.9516 7.583e-12 ***\nCarlineClassDesc     3489.4   16 22.0517 &lt; 2.2e-16 ***\nVarValveLift           68.0    1  6.8807 0.0088387 ** \nResiduals           10423.9 1054                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCode\ncars_2010_sub &lt;- cars_2010_sub %&gt;%\n    select(-TransLockup)\n\ncars_lm4 &lt;- lm(FE ~ ., cars_2010_sub)\nsummary(cars_lm4)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars_2010_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6831  -1.7755   0.0193   1.5767  22.1002 \n\nCoefficients: (4 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                      35.5540     3.3581  10.588\nEngDispl                                         -2.0676     0.2531  -8.170\nNumCyl3                                          20.3570     3.9157   5.199\nNumCyl4                                          12.6350     2.2955   5.504\nNumCyl5                                           9.6799     2.3677   4.088\nNumCyl6                                           8.8784     2.3203   3.826\nNumCyl8                                           6.8252     2.4329   2.805\nNumCyl10                                          4.2129     2.6322   1.601\nNumCyl12                                          2.7488     2.6175   1.050\nNumCyl16                                          4.1444     4.3832   0.946\nTransmissionA4                                   -7.5779     2.2725  -3.335\nTransmissionA5                                   -7.2188     2.2788  -3.168\nTransmissionA6                                   -5.5830     2.2785  -2.450\nTransmissionA7                                    4.7030     2.4333   1.933\nTransmissionAM6                                  -9.6845     2.4718  -3.918\nTransmissionAM7                                   0.5441     2.6629   0.204\nTransmissionAV                                   -4.5705     2.2925  -1.994\nTransmissionAVS6                                 -6.8711     2.4245  -2.834\nTransmissionM5                                   -6.7947     2.2788  -2.982\nTransmissionM6                                   -6.8804     2.2710  -3.030\nTransmissionS4                                  -11.2457     2.4226  -4.642\nTransmissionS5                                   -7.8915     2.3038  -3.425\nTransmissionS6                                   -5.5467     2.2680  -2.446\nTransmissionS7                                    3.1101     2.5027   1.243\nTransmissionS8                                   -5.4739     4.0271  -1.359\nAirAspirationMethodSupercharged                  -1.7876     0.7838  -2.281\nAirAspirationMethodTurbocharged                  -1.1043     0.3222  -3.427\nNumGears4                                             NA         NA      NA\nNumGears5                                             NA         NA      NA\nNumGears6                                             NA         NA      NA\nNumGears7                                       -10.2165     3.2880  -3.107\nNumGears8                                         2.2205     3.2038   0.693\nTransCreeperGear1                                -1.2791     0.4788  -2.672\nDriveDescFourWheelDrive                          -0.4976     0.4355  -1.143\nDriveDescParttimeFourWheelDrive                  -0.4061     1.0655  -0.381\nDriveDescTwoWheelDriveFront                       4.3413     0.3781  11.482\nDriveDescTwoWheelDriveRear                        1.1035     0.3729   2.959\nExhaustValvesPerCyl1                              2.7948     0.3970   7.040\nExhaustValvesPerCyl2                                  NA         NA      NA\nCarlineClassDesc2Seaters                          2.8530     1.1807   2.416\nCarlineClassDescCompactCars                       3.7853     1.1039   3.429\nCarlineClassDescLargeCars                         2.5289     1.1351   2.228\nCarlineClassDescMidsizeCars                       3.3020     1.1009   2.999\nCarlineClassDescMinicompactCars                   3.7542     1.1972   3.136\nCarlineClassDescSmallPickupTrucks2WD             -1.9188     1.2554  -1.528\nCarlineClassDescSmallPickupTrucks4WD             -1.0621     1.3551  -0.784\nCarlineClassDescSmallStationWagons                2.1620     1.1405   1.896\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.2133     1.3625  -1.624\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.5927     1.1122  -1.432\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.6482     1.1262  -0.576\nCarlineClassDescStandardPickupTrucks2WD          -1.7299     1.2746  -1.357\nCarlineClassDescStandardPickupTrucks4WD          -2.0053     1.3064  -1.535\nCarlineClassDescSubcompactCars                    3.3939     1.1169   3.039\nCarlineClassDescVansCargoTypes                   -3.9518     1.5207  -2.599\nCarlineClassDescVansPassengerType                -4.0897     1.9544  -2.093\nVarValveLift1                                     0.8016     0.3078   2.604\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                        8.79e-16 ***\nNumCyl3                                         2.41e-07 ***\nNumCyl4                                         4.66e-08 ***\nNumCyl5                                         4.68e-05 ***\nNumCyl6                                         0.000138 ***\nNumCyl8                                         0.005119 ** \nNumCyl10                                        0.109781    \nNumCyl12                                        0.293871    \nNumCyl16                                        0.344606    \nTransmissionA4                                  0.000884 ***\nTransmissionA5                                  0.001580 ** \nTransmissionA6                                  0.014438 *  \nTransmissionA7                                  0.053532 .  \nTransmissionAM6                                 9.50e-05 ***\nTransmissionAM7                                 0.838126    \nTransmissionAV                                  0.046450 *  \nTransmissionAVS6                                0.004685 ** \nTransmissionM5                                  0.002933 ** \nTransmissionM6                                  0.002507 ** \nTransmissionS4                                  3.88e-06 ***\nTransmissionS5                                  0.000638 ***\nTransmissionS6                                  0.014620 *  \nTransmissionS7                                  0.214253    \nTransmissionS8                                  0.174354    \nAirAspirationMethodSupercharged                 0.022764 *  \nAirAspirationMethodTurbocharged                 0.000633 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001939 ** \nNumGears8                                       0.488417    \nTransCreeperGear1                               0.007665 ** \nDriveDescFourWheelDrive                         0.253447    \nDriveDescParttimeFourWheelDrive                 0.703142    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.003153 ** \nExhaustValvesPerCyl1                            3.46e-12 ***\nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.015841 *  \nCarlineClassDescCompactCars                     0.000629 ***\nCarlineClassDescLargeCars                       0.026094 *  \nCarlineClassDescMidsizeCars                     0.002770 ** \nCarlineClassDescMinicompactCars                 0.001761 ** \nCarlineClassDescSmallPickupTrucks2WD            0.126696    \nCarlineClassDescSmallPickupTrucks4WD            0.433337    \nCarlineClassDescSmallStationWagons              0.058280 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.104587    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.152446    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.565022    \nCarlineClassDescStandardPickupTrucks2WD         0.175017    \nCarlineClassDescStandardPickupTrucks4WD         0.125076    \nCarlineClassDescSubcompactCars                  0.002435 ** \nCarlineClassDescVansCargoTypes                  0.009490 ** \nCarlineClassDescVansPassengerType               0.036625 *  \nVarValveLift1                                   0.009338 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.153 on 1055 degrees of freedom\nMultiple R-squared:  0.8313,    Adjusted R-squared:  0.8232 \nF-statistic:   102 on 51 and 1055 DF,  p-value: &lt; 2.2e-16\n\n\nCode\ncar::Anova(cars_lm4)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              663.5    1 66.7421 8.786e-16 ***\nNumCyl               1037.6    6 17.3966 &lt; 2.2e-16 ***\nTransmission          638.4   12  5.3520 7.426e-09 ***\nAirAspirationMethod   155.0    2  7.7971  0.000435 ***\nNumGears              101.0    2  5.0780  0.006385 ** \nTransCreeperGear       71.0    1  7.1376  0.007665 ** \nDriveDesc            1586.1    4 39.8882 &lt; 2.2e-16 ***\nExhaustValvesPerCyl   492.7    1 49.5606 3.460e-12 ***\nCarlineClassDesc     3548.8   16 22.3123 &lt; 2.2e-16 ***\nVarValveLift           67.4    1  6.7819  0.009338 ** \nResiduals           10487.5 1055                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCode\ncars_2010_sub &lt;- cars_2010_sub %&gt;%\n    select(-VarValveLift)\n\ncars_lm5 &lt;- lm(FE ~ ., cars_2010_sub)\nsummary(cars_lm5)\n\n\n\nCall:\nlm(formula = FE ~ ., data = cars_2010_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.7951  -1.7259   0.0248   1.6395  22.0010 \n\nCoefficients: (4 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                      35.6506     3.3670  10.588\nEngDispl                                         -2.0915     0.2536  -8.247\nNumCyl3                                          20.1462     3.9256   5.132\nNumCyl4                                          12.9901     2.2977   5.653\nNumCyl5                                           9.9691     2.3716   4.204\nNumCyl6                                           9.2880     2.3213   4.001\nNumCyl8                                           7.1931     2.4355   2.953\nNumCyl10                                          4.2902     2.6392   1.626\nNumCyl12                                          2.9960     2.6229   1.142\nNumCyl16                                          4.2509     4.3950   0.967\nTransmissionA4                                   -7.9263     2.2748  -3.484\nTransmissionA5                                   -7.4632     2.2831  -3.269\nTransmissionA6                                   -5.9012     2.2815  -2.587\nTransmissionA7                                    4.9316     2.4383   2.023\nTransmissionAM6                                 -10.0571     2.4744  -4.064\nTransmissionAM7                                   0.4535     2.6700   0.170\nTransmissionAV                                   -4.8272     2.2967  -2.102\nTransmissionAVS6                                 -7.2674     2.4264  -2.995\nTransmissionM5                                   -7.0899     2.2822  -3.107\nTransmissionM6                                   -7.0372     2.2764  -3.091\nTransmissionS4                                  -11.2013     2.4291  -4.611\nTransmissionS5                                   -8.0730     2.3091  -3.496\nTransmissionS6                                   -5.7943     2.2722  -2.550\nTransmissionS7                                    3.4280     2.5065   1.368\nTransmissionS8                                   -5.5848     4.0379  -1.383\nAirAspirationMethodSupercharged                  -1.9893     0.7821  -2.544\nAirAspirationMethodTurbocharged                  -1.2457     0.3184  -3.912\nNumGears4                                             NA         NA      NA\nNumGears5                                             NA         NA      NA\nNumGears6                                             NA         NA      NA\nNumGears7                                       -10.6500     3.2928  -3.234\nNumGears8                                         2.0751     3.2121   0.646\nTransCreeperGear1                                -1.3661     0.4789  -2.852\nDriveDescFourWheelDrive                          -0.6841     0.4308  -1.588\nDriveDescParttimeFourWheelDrive                  -0.7039     1.0622  -0.663\nDriveDescTwoWheelDriveFront                       4.1905     0.3747  11.185\nDriveDescTwoWheelDriveRear                        0.9965     0.3717   2.681\nExhaustValvesPerCyl1                              2.7810     0.3980   6.986\nExhaustValvesPerCyl2                                  NA         NA      NA\nCarlineClassDesc2Seaters                          3.0982     1.1801   2.625\nCarlineClassDescCompactCars                       3.8878     1.1062   3.515\nCarlineClassDescLargeCars                         2.6874     1.1366   2.364\nCarlineClassDescMidsizeCars                       3.4001     1.1033   3.082\nCarlineClassDescMinicompactCars                   4.3247     1.1802   3.664\nCarlineClassDescSmallPickupTrucks2WD             -1.8684     1.2587  -1.484\nCarlineClassDescSmallPickupTrucks4WD             -0.9067     1.3575  -0.668\nCarlineClassDescSmallStationWagons                2.2224     1.1434   1.944\nCarlineClassDescSpecialPurposeVehicleminivan2WD  -2.1858     1.3662  -1.600\nCarlineClassDescSpecialPurposeVehicleSUV2WD      -1.5070     1.1148  -1.352\nCarlineClassDescSpecialPurposeVehicleSUV4WD      -0.4822     1.1274  -0.428\nCarlineClassDescStandardPickupTrucks2WD          -1.6614     1.2778  -1.300\nCarlineClassDescStandardPickupTrucks4WD          -1.8270     1.3081  -1.397\nCarlineClassDescSubcompactCars                    3.6375     1.1160   3.259\nCarlineClassDescVansCargoTypes                   -3.8763     1.5246  -2.542\nCarlineClassDescVansPassengerType                -4.0117     1.9595  -2.047\n                                                Pr(&gt;|t|)    \n(Intercept)                                      &lt; 2e-16 ***\nEngDispl                                        4.79e-16 ***\nNumCyl3                                         3.41e-07 ***\nNumCyl4                                         2.02e-08 ***\nNumCyl5                                         2.85e-05 ***\nNumCyl6                                         6.74e-05 ***\nNumCyl8                                         0.003212 ** \nNumCyl10                                        0.104342    \nNumCyl12                                        0.253614    \nNumCyl16                                        0.333656    \nTransmissionA4                                  0.000513 ***\nTransmissionA5                                  0.001115 ** \nTransmissionA6                                  0.009827 ** \nTransmissionA7                                  0.043374 *  \nTransmissionAM6                                 5.17e-05 ***\nTransmissionAM7                                 0.865169    \nTransmissionAV                                  0.035807 *  \nTransmissionAVS6                                0.002807 ** \nTransmissionM5                                  0.001944 ** \nTransmissionM6                                  0.002044 ** \nTransmissionS4                                  4.49e-06 ***\nTransmissionS5                                  0.000492 ***\nTransmissionS6                                  0.010908 *  \nTransmissionS7                                  0.171715    \nTransmissionS8                                  0.166927    \nAirAspirationMethodSupercharged                 0.011113 *  \nAirAspirationMethodTurbocharged                 9.74e-05 ***\nNumGears4                                             NA    \nNumGears5                                             NA    \nNumGears6                                             NA    \nNumGears7                                       0.001257 ** \nNumGears8                                       0.518403    \nTransCreeperGear1                               0.004423 ** \nDriveDescFourWheelDrive                         0.112532    \nDriveDescParttimeFourWheelDrive                 0.507654    \nDriveDescTwoWheelDriveFront                      &lt; 2e-16 ***\nDriveDescTwoWheelDriveRear                      0.007448 ** \nExhaustValvesPerCyl1                            4.98e-12 ***\nExhaustValvesPerCyl2                                  NA    \nCarlineClassDesc2Seaters                        0.008782 ** \nCarlineClassDescCompactCars                     0.000459 ***\nCarlineClassDescLargeCars                       0.018235 *  \nCarlineClassDescMidsizeCars                     0.002111 ** \nCarlineClassDescMinicompactCars                 0.000260 ***\nCarlineClassDescSmallPickupTrucks2WD            0.137996    \nCarlineClassDescSmallPickupTrucks4WD            0.504354    \nCarlineClassDescSmallStationWagons              0.052206 .  \nCarlineClassDescSpecialPurposeVehicleminivan2WD 0.109914    \nCarlineClassDescSpecialPurposeVehicleSUV2WD     0.176714    \nCarlineClassDescSpecialPurposeVehicleSUV4WD     0.668970    \nCarlineClassDescStandardPickupTrucks2WD         0.193828    \nCarlineClassDescStandardPickupTrucks4WD         0.162813    \nCarlineClassDescSubcompactCars                  0.001152 ** \nCarlineClassDescVansCargoTypes                  0.011149 *  \nCarlineClassDescVansPassengerType               0.040873 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.162 on 1056 degrees of freedom\nMultiple R-squared:  0.8303,    Adjusted R-squared:  0.8222 \nF-statistic: 103.3 on 50 and 1056 DF,  p-value: &lt; 2.2e-16\n\n\nCode\ncar::Anova(cars_lm5)\n\n\nNote: model has aliased coefficients\n      sums of squares computed by model comparison\n\n\nAnova Table (Type II tests)\n\nResponse: FE\n                     Sum Sq   Df F value    Pr(&gt;F)    \nEngDispl              679.8    1 68.0122 4.791e-16 ***\nNumCyl               1043.7    6 17.4026 &lt; 2.2e-16 ***\nTransmission          613.6   12  5.1154 2.307e-08 ***\nAirAspirationMethod   202.9    2 10.1494 4.305e-05 ***\nNumGears              108.9    2  5.4475  0.004429 ** \nTransCreeperGear       81.3    1  8.1365  0.004423 ** \nDriveDesc            1537.5    4 38.4558 &lt; 2.2e-16 ***\nExhaustValvesPerCyl   487.9    1 48.8110 4.982e-12 ***\nCarlineClassDesc     3715.0   16 23.2300 &lt; 2.2e-16 ***\nResiduals           10554.9 1056                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nBoth \\(R^2\\) and \\(R_a^2\\) decreased\n9 variables significant at the 0.008 level"
  },
  {
    "objectID": "notes/analytics/06272023/index.html",
    "href": "notes/analytics/06272023/index.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Our variables are quantities or qualities of interest. These are also called:\n\nAttributes\nFeatures\nPredictors/Targets\nFactors\nInputs/Outputs\nCovariates\n\n\n\nQuantitative variables have a quantity value associated with them. These are intervals, numerics or ratios.\n\nTime\nTemperature\nPrice\n\n\n\n\nCategorical variables are inherently described by categories instead of quantities.\nThere are two types of categorical variables:\n\nNominal\n\nSoda, Milk, Tea\n\nOrdinal\n\nHave logical orderings associated with them\nSmall, Medium, Large\n\n\nWith ordinal variables, you can treat them as either nominal or quantitative. You have to make the decision.\nCategorical Dummy Variables:\n\n\n\nSmall\nMedium\nLarge\n\n\n\n\n1\n0\n0\n\n\n0\n1\n0\n\n\n0\n0\n1\n\n\n\nThe table shows an example of one-hot encoding. We can achieve this in R using the onehot package:\n\n\nCode\nlibrary(onehot)\n\nset.seed(41)\ndat &lt;- data.frame(\n    y = c(rnorm(10, 2), rnorm(10, 1), rnorm(10, 0)),\n    x1 = factor(rep(c(\"A\", \"B\", \"C\"), each = 10)),\n    x2 = factor(rep(c(\"Z\", \"X\", \"Y\", \"W\", \"V\", \"U\"), each = 5))\n)\n\nencoder &lt;- onehot(dat)\ndummies &lt;- predict(encoder, dat)\nhead(dummies)\n\n\n            y x1=A x1=B x1=C x2=U x2=V x2=W x2=X x2=Y x2=Z\n[1,] 1.205632    1    0    0    0    0    0    0    0    1\n[2,] 2.197258    1    0    0    0    0    0    0    0    1\n[3,] 3.001704    1    0    0    0    0    0    0    0    1\n[4,] 3.288825    1    0    0    0    0    0    0    0    1\n[5,] 2.905753    1    0    0    0    0    0    0    0    1\n[6,] 2.493667    1    0    0    0    0    0    1    0    0\n\n\nAnd in Python:\n\n\nCode\nimport numpy as np\nfrom numpy import random\nimport pandas as pd\n\nx1 = np.repeat([\"A\", \"B\", \"C\"], 10)\nx2 = np.repeat([\"Z\", \"X\", \"Y\", \"W\", \"V\", \"U\"], 5)\n\nrandom.seed(41)\ny = np.concatenate([random.normal(2.0, 1.0, 10), random.normal(1.0, 1.0, 10), random.normal(0.0, 1.0, 10)])\narray = np.array([x1, x2, y])\narray2 = np.transpose(array)\n\ndf = pd.DataFrame(data = array2, columns = [\"x1\", \"x2\", \"y\"])\ndf.head()\n\n\n  x1 x2                   y\n0  A  Z  1.7292876769326795\n1  A  Z    2.10484805260974\n2  A  Z   2.250527815723572\n3  A  Z  1.0748000347219233\n4  A  Z   2.567143660285906\n\n\n\n\nCode\none_hot_encoded_data = pd.get_dummies(df, columns = ['x1', 'x2'])\none_hot_encoded_data.head()\n\n\n                    y  x1_A   x1_B   x1_C  ...   x2_W   x2_X   x2_Y  x2_Z\n0  1.7292876769326795  True  False  False  ...  False  False  False  True\n1    2.10484805260974  True  False  False  ...  False  False  False  True\n2   2.250527815723572  True  False  False  ...  False  False  False  True\n3  1.0748000347219233  True  False  False  ...  False  False  False  True\n4   2.567143660285906  True  False  False  ...  False  False  False  True\n\n[5 rows x 10 columns]\n\n\nThe levels are given values if treated quantitatively:\n\n\n\nSize\nSize\n\n\n\n\nS\n1\n\n\nM\n2\n\n\nL\n3\n\n\n\nIn addition, we also could do optimal scaling to represent the scale of the ordinal variables. This requires a careful definition of a “1-unit” change in the variable.\n\n\n\nEducation\nEducation\n\n\n\n\nNo HS degree\n1\n\n\nGED\n2\n\n\nHS Diploma\n3\n\n\nBachelors\n10\n\n\nMasters\n16\n\n\nPhD\n20"
  },
  {
    "objectID": "notes/analytics/06272023/index.html#quantiative-variables",
    "href": "notes/analytics/06272023/index.html#quantiative-variables",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Quantitative variables have a quantity value associated with them. These are intervals, numerics or ratios.\n\nTime\nTemperature\nPrice"
  },
  {
    "objectID": "notes/analytics/06272023/index.html#categorical-variables",
    "href": "notes/analytics/06272023/index.html#categorical-variables",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Categorical variables are inherently described by categories instead of quantities.\nThere are two types of categorical variables:\n\nNominal\n\nSoda, Milk, Tea\n\nOrdinal\n\nHave logical orderings associated with them\nSmall, Medium, Large\n\n\nWith ordinal variables, you can treat them as either nominal or quantitative. You have to make the decision.\nCategorical Dummy Variables:\n\n\n\nSmall\nMedium\nLarge\n\n\n\n\n1\n0\n0\n\n\n0\n1\n0\n\n\n0\n0\n1\n\n\n\nThe table shows an example of one-hot encoding. We can achieve this in R using the onehot package:\n\n\nCode\nlibrary(onehot)\n\nset.seed(41)\ndat &lt;- data.frame(\n    y = c(rnorm(10, 2), rnorm(10, 1), rnorm(10, 0)),\n    x1 = factor(rep(c(\"A\", \"B\", \"C\"), each = 10)),\n    x2 = factor(rep(c(\"Z\", \"X\", \"Y\", \"W\", \"V\", \"U\"), each = 5))\n)\n\nencoder &lt;- onehot(dat)\ndummies &lt;- predict(encoder, dat)\nhead(dummies)\n\n\n            y x1=A x1=B x1=C x2=U x2=V x2=W x2=X x2=Y x2=Z\n[1,] 1.205632    1    0    0    0    0    0    0    0    1\n[2,] 2.197258    1    0    0    0    0    0    0    0    1\n[3,] 3.001704    1    0    0    0    0    0    0    0    1\n[4,] 3.288825    1    0    0    0    0    0    0    0    1\n[5,] 2.905753    1    0    0    0    0    0    0    0    1\n[6,] 2.493667    1    0    0    0    0    0    1    0    0\n\n\nAnd in Python:\n\n\nCode\nimport numpy as np\nfrom numpy import random\nimport pandas as pd\n\nx1 = np.repeat([\"A\", \"B\", \"C\"], 10)\nx2 = np.repeat([\"Z\", \"X\", \"Y\", \"W\", \"V\", \"U\"], 5)\n\nrandom.seed(41)\ny = np.concatenate([random.normal(2.0, 1.0, 10), random.normal(1.0, 1.0, 10), random.normal(0.0, 1.0, 10)])\narray = np.array([x1, x2, y])\narray2 = np.transpose(array)\n\ndf = pd.DataFrame(data = array2, columns = [\"x1\", \"x2\", \"y\"])\ndf.head()\n\n\n  x1 x2                   y\n0  A  Z  1.7292876769326795\n1  A  Z    2.10484805260974\n2  A  Z   2.250527815723572\n3  A  Z  1.0748000347219233\n4  A  Z   2.567143660285906\n\n\n\n\nCode\none_hot_encoded_data = pd.get_dummies(df, columns = ['x1', 'x2'])\none_hot_encoded_data.head()\n\n\n                    y  x1_A   x1_B   x1_C  ...   x2_W   x2_X   x2_Y  x2_Z\n0  1.7292876769326795  True  False  False  ...  False  False  False  True\n1    2.10484805260974  True  False  False  ...  False  False  False  True\n2   2.250527815723572  True  False  False  ...  False  False  False  True\n3  1.0748000347219233  True  False  False  ...  False  False  False  True\n4   2.567143660285906  True  False  False  ...  False  False  False  True\n\n[5 rows x 10 columns]\n\n\nThe levels are given values if treated quantitatively:\n\n\n\nSize\nSize\n\n\n\n\nS\n1\n\n\nM\n2\n\n\nL\n3\n\n\n\nIn addition, we also could do optimal scaling to represent the scale of the ordinal variables. This requires a careful definition of a “1-unit” change in the variable.\n\n\n\nEducation\nEducation\n\n\n\n\nNo HS degree\n1\n\n\nGED\n2\n\n\nHS Diploma\n3\n\n\nBachelors\n10\n\n\nMasters\n16\n\n\nPhD\n20"
  },
  {
    "objectID": "notes/analytics/06272023/index.html#measures-of-central-tendency",
    "href": "notes/analytics/06272023/index.html#measures-of-central-tendency",
    "title": "Exploratory Data Analysis",
    "section": "2.1 Measures of Central Tendency",
    "text": "2.1 Measures of Central Tendency\n\n2.1.1 Mean\n\\[\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i\n\\]\n\n\n2.1.2 Median\nMiddle value. 50th percentile. Unaffected by outliers. In a right-skew, median is lower than the mean. In a left-skew, median is higher than the mean.\n\n\n2.1.3 Mode\nMost frequent value. Typical for categorical data"
  },
  {
    "objectID": "notes/analytics/06272023/index.html#measures-of-location",
    "href": "notes/analytics/06272023/index.html#measures-of-location",
    "title": "Exploratory Data Analysis",
    "section": "2.2 Measures of Location",
    "text": "2.2 Measures of Location\nPercentiles are a point, \\(x_p\\), in your data for which \\(p\\%\\) of the data is \\(\\leq x_p\\).\nQuantiles are the same thing as percentiles. The 10th percentile is the 0.10 quantile."
  },
  {
    "objectID": "notes/analytics/06272023/index.html#measures-of-spreaddispersion",
    "href": "notes/analytics/06272023/index.html#measures-of-spreaddispersion",
    "title": "Exploratory Data Analysis",
    "section": "2.3 Measures of Spread/Dispersion",
    "text": "2.3 Measures of Spread/Dispersion\nRange is \\(\\text{max}(data) - \\text{min}(data)\\)\n\n2.3.1 Interquartile Range\nIQR is the difference between third and first quartile. What is the range of the middle 50% of data.\n\n\n2.3.2 Variance \\(\\sigma^2\\) and Standard Deviation \nDispersion of the data around the mean. Average squared deviation from the mean.\n\\[\ns^2 = \\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\n\\]\n\nThe \\(n - 1\\) comes from the degrees of freedom. In theory this will make this an unbiased estimator of the variance."
  },
  {
    "objectID": "notes/analytics/06272023/index.html#measure-of-shape",
    "href": "notes/analytics/06272023/index.html#measure-of-shape",
    "title": "Exploratory Data Analysis",
    "section": "2.4 Measure of Shape",
    "text": "2.4 Measure of Shape\n\n2.4.1 Modality\nModality is the number of humps a distribution has. A Normal distribution is unimodal.\n\n\n2.4.2 Skew\nIs the distribution symmetric? Or does it have a longer tail on one side?\n\n\n\nLeft-skew and Right-skew\n\n\n\n\n2.4.3 Kurtosis\nDoes the distribution have thicker/thinner tails than a Normal distribution with same mean and variance?\nA leptokurtic distribution has more data in the tails than a Normal distribution.\nA platykurtic distribution has less data in the tails than a Normal distribution.\nThis only makes sense if you have a symmetric distribution."
  },
  {
    "objectID": "notes/analytics/06272023/index.html#the-normal-distribution",
    "href": "notes/analytics/06272023/index.html#the-normal-distribution",
    "title": "Exploratory Data Analysis",
    "section": "2.5 The Normal Distribution",
    "text": "2.5 The Normal Distribution\nA Normal distribution is a distribution that is\n\nSymmetric\nFully defined by the mean and standard deviation\nBell-shaped / Unimodal\nMean = Median = Mode\nAsymptotic to the x-axis (bounds are \\(-\\infty\\) and \\(\\infty\\))\nKurtosis = 3 (kurtosis often reported as excess kurtosis = kurtosis - 3)\nSkew = 0 (there is no skew)\n\n\n\nCode\nfrom scipy.stats import norm\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(-4, 4, 100)\n\nmean = 0\nsd = 1\n\ny = norm.pdf(x, mean, sd)\n\nplt.plot(x, y)"
  },
  {
    "objectID": "notes/analytics/06272023/index.html#graphical-displays-of-distributions",
    "href": "notes/analytics/06272023/index.html#graphical-displays-of-distributions",
    "title": "Exploratory Data Analysis",
    "section": "3.1 Graphical Displays of Distributions",
    "text": "3.1 Graphical Displays of Distributions\n\n3.1.1 Histograms\nEach bar in the histogram represents a group of values (bin).\nThe height of the bar represents the frequency of percent of values in the bin. You can specify the number of width of the bins as desired.\n\n3.1.1.1 R Code\n\n\nCode\nlibrary(ggplot2)\n\nggplot(ames, aes(x = Sale_Price / 1000)) +\n    geom_histogram(mapping = aes(y = after_stat(density)), alpha = 0.5) +\n    geom_density(alpha = 0.2) +\n    labs(x = \"Sales Price (Thousands $)\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n3.1.1.2 Python Code\nNote this is a different Ames Housing dataset.\n\n\nCode\nimport seaborn as sns\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n\names_py = pd.read_csv(\"../../../data/ames.csv\")\nax = sns.histplot(x = ames_py['SalePrice'] / 1000, kde = True, data = ames_py, color = \"blue\")\nax.set(\n    xlabel = 'Sales Price (Thousands $)',\n    ylabel = 'Frequency',\n    title = 'Histogram of Sales Price in Thousands of Dollars'\n)\nplt.show()\n\n\n\n\n\n\n\nCode\nax = sns.displot(ames_py, x = ames_py['SalePrice'] / 1000, kde=True)\nax.set(\n    xlabel = 'Sales Price (Thousands $)',\n    ylabel = 'Frequency')\n\n\n\n\n\nThe distribution is right-skewed so the mean is greater than the median housing price.\n\n\n\n3.1.2 Normal Probability Plots (QQ-Plots)\nUsed to compare two distributions, typically to verify that a variable is approx. Normal.\nCompare observed quantiles to theoretical quantiles of a Normal distribution with the same mean and variance.\nIf the points follow the line diagonal line, the distribution is Normal.\n\n\n\nQQ-Plot Problem Indicators\n\n\n\nQuadratic patterns indicate problems with skew\nCubic patterns indicate problems with kurtosis\n\n\n3.1.2.1 R Code\n\n\nCode\nggplot(ames, aes(sample = Sale_Price / 1000)) +\n    stat_qq() +\n    stat_qq_line() +\n    labs(x = \"theoretical\", y = \"observed\")\n\n\n\n\n\n\n\n3.1.2.2 Python Code\n\n\nCode\nimport statsmodels.api as sma\n\nsma.qqplot(ames_py['SalePrice'] / 1000, line='45', fit = True)\n\n\n\n\n\n\n\n\n3.1.3 Box Plots\n\n\n\nBox Plot\n\n\n\n3.1.3.1 R Code\n\n\nCode\nggplot(ames, aes(y = Sale_Price / 1000, x = Central_Air, fill = Central_Air)) +\n    geom_boxplot() +\n    labs(y = \"Sales Price (Thousands $)\", x = \"Central Air\") +\n    scale_fill_brewer(palette = \"Accent\") +\n    theme_classic() +\n    coord_flip()\n\n\n\n\n\n\n\n3.1.3.2 Python Code\n\n\nCode\nax = sns.boxplot(ames_py, x = ames_py['SalePrice'] / 1000)\nax.set(\n    xlabel='Sales Price (Thousands $)',\n    title='Boxplot of Sales Price in Thousands of Dollars')\nplt.show()\n\n\n\n\n\n\n\nCode\nax = sns.catplot(ames_py, x='CentralAir', y='SalePrice', kind='box')\nplt.show()"
  },
  {
    "objectID": "notes/analytics/06272023/index.html#defining-anomalous-observations",
    "href": "notes/analytics/06272023/index.html#defining-anomalous-observations",
    "title": "Exploratory Data Analysis",
    "section": "3.2 Defining Anomalous Observations",
    "text": "3.2 Defining Anomalous Observations\n\n3.2.1 Standard Deviations from the Mean\nFor symmetric distributions and particularly for the Normal distribution, it’s common to consider observations more than 3 standard deviations from the mean as anomalous.\n\n\n3.2.2 Box-Plot Definition\nBox plots define outliers as poitns that are \\(1.5 \\times IQR\\) above the third quartile or less than \\(1.5 \\times IQR\\) below the first quartile.\nThere are more definitions but these are the first couple we are considering now."
  },
  {
    "objectID": "notes/analytics/06272023/breakout_1.html",
    "href": "notes/analytics/06272023/breakout_1.html",
    "title": "Breakout 1",
    "section": "",
    "text": "1 Loading the Data\n\n\nCode\nbike &lt;- read.csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/bike.csv\")\nstr(bike)\n\n\n'data.frame':   17379 obs. of  16 variables:\n $ dteday    : int  14975 14975 14975 14975 14975 14975 14975 14975 14975 14975 ...\n $ season    : int  1 1 1 1 1 1 1 1 1 1 ...\n $ yr        : int  0 0 0 0 0 0 0 0 0 0 ...\n $ mnth      : int  1 1 1 1 1 1 1 1 1 1 ...\n $ hr        : int  0 1 2 3 4 5 6 7 8 9 ...\n $ holiday   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ weekday   : int  6 6 6 6 6 6 6 6 6 6 ...\n $ workingday: int  0 0 0 0 0 0 0 0 0 0 ...\n $ weathersit: int  1 1 1 1 1 2 1 1 1 1 ...\n $ temp      : num  0.24 0.22 0.22 0.24 0.24 0.24 0.22 0.2 0.24 0.32 ...\n $ atemp     : num  0.288 0.273 0.273 0.288 0.288 ...\n $ hum       : num  0.81 0.8 0.8 0.75 0.75 0.75 0.8 0.86 0.75 0.76 ...\n $ windspeed : num  0 0 0 0 0 0.0896 0 0 0 0 ...\n $ casual    : int  3 8 5 3 0 0 2 1 1 8 ...\n $ registered: int  13 32 27 10 1 1 0 2 7 6 ...\n $ cnt       : int  16 40 32 13 1 1 2 3 8 14 ...\n\n\nCode\ntable(bike$season)\n\n\n\n   1    2    3    4 \n4242 4409 4496 4232 \n\n\n\n\n2 Plotting the Distribution\n\n\nCode\nlibrary(ggplot2)\nggplot(bike, aes(x = cnt)) +\n    geom_histogram(fill = \"blue\") +\n    labs(x = \"Bike Rentals\", title = \"Histogram of Bike Rentals\", y = \"Frequency\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n3 Getting Summary Statistics\n\n\nCode\nsummary(bike$cnt)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    1.0    40.0   142.0   189.5   281.0   977.0 \n\n\nCode\nsd(bike$cnt)\n\n\n[1] 181.3876\n\n\nCode\nquantile(bike$cnt, probs = c(0.10, 0.40, 0.80))\n\n\n10% 40% 80% \n  9  98 321 \n\n\n\n\nCode\nggplot(bike, aes(x = cnt)) +\n    geom_histogram(fill = \"red\", binwidth = 50) +\n    labs(x = \"Bike Rentals\", title = \"Histogram of Bike Rentals\", y = \"Frequency\")\n\n\n\n\n\nCode\nggplot(bike, aes(x = cnt)) +\n    geom_histogram(fill = \"purple\", binwidth = 100) +\n    labs(x = \"Bike Rentals\", title = \"Histogram of Bike Rentals\", y = \"Frequency\")\n\n\n\n\n\nCode\nggplot(bike, aes(x = cnt)) +\n    geom_histogram(fill = \"pink\", binwidth = 250) +\n    labs(x = \"Bike Rentals\", title = \"Histogram of Bike Rentals\", y = \"Frequency\")\n\n\n\n\n\nWe can overlay a density estimator on our histogram:\n\n\nCode\nggplot(bike, aes(x = cnt)) +\n    geom_histogram(aes(y = after_stat(!!str2lang(\"density\"))), alpha = 0.2) +\n    geom_density() +\n    labs(x = \"Bike Rentals\", title = \"Histogram of Bike Rentals\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nUsing a QQ-Plot we can also see that the distribution is right-skewed:\n\n\nCode\nggplot(bike, aes(sample = cnt)) +\n    stat_qq(shape = 2) +\n    stat_qq_line()\n\n\n\n\n\n\n\n4 Associations\n\n\nCode\nggplot(bike, aes(x = factor(season), y = cnt, fill = factor(season))) +\n    geom_boxplot() +\n    scale_x_discrete(labels = c(\"Spring\", \"Summer\", \"Fall\", \"Winter\")) +\n    labs(x = \"Season\", y = \"Bike Rentals\", fill = \"Season\")\n\n\n\n\n\nSpring seems to have the fewest number of bike rentals. There are anomalous observations for count within each season."
  },
  {
    "objectID": "notes/analytics/06302023/breakout_4.html",
    "href": "notes/analytics/06302023/breakout_4.html",
    "title": "1",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/IAA-Faculty/statistical_foundations/master/bike.csv\")\n\ndf.head()\n\n\n\n\n\n\n\n\n\ndteday\nseason\nyr\nmnth\nhr\nholiday\nweekday\nworkingday\nweathersit\ntemp\natemp\nhum\nwindspeed\ncasual\nregistered\ncnt\n\n\n\n\n0\n14975\n1\n0\n1\n0\n0\n6\n0\n1\n0.24\n0.2879\n0.81\n0.0\n3\n13\n16\n\n\n1\n14975\n1\n0\n1\n1\n0\n6\n0\n1\n0.22\n0.2727\n0.80\n0.0\n8\n32\n40\n\n\n2\n14975\n1\n0\n1\n2\n0\n6\n0\n1\n0.22\n0.2727\n0.80\n0.0\n5\n27\n32\n\n\n3\n14975\n1\n0\n1\n3\n0\n6\n0\n1\n0.24\n0.2879\n0.75\n0.0\n3\n10\n13\n\n\n4\n14975\n1\n0\n1\n4\n0\n6\n0\n1\n0.24\n0.2879\n0.75\n0.0\n0\n1\n1\n\n\n\n\n\n\n\n\n\nCode\nnp.corrcoef(df[['temp', 'atemp', 'hum', 'windspeed', 'cnt']])\n\n\narray([[1.        , 0.9996723 , 0.99977045, ..., 0.99927588, 0.99933747,\n        0.99944454],\n       [0.9996723 , 1.        , 0.99999127, ..., 0.99992236, 0.99994156,\n        0.99997001],\n       [0.99977045, 0.99999127, 1.        , ..., 0.99986162, 0.99988766,\n        0.99992905],\n       ...,\n       [0.99927588, 0.99992236, 0.99986162, ..., 1.        , 0.99999853,\n        0.99998878],\n       [0.99933747, 0.99994156, 0.99988766, ..., 0.99999853, 1.        ,\n        0.99999501],\n       [0.99944454, 0.99997001, 0.99992905, ..., 0.99998878, 0.99999501,\n        1.        ]])\n\n\n\n\nCode\nax = sns.pairplot(df[['temp', 'atemp', 'hum', 'windspeed', 'cnt']])\n\nplt.show()\n\n\n\n\n\n\nStrong linear relationship between temp and atemp\n\n\n1 2\nPicking atemp\n\n\nCode\nslr = smf.ols('cnt ~ atemp', df).fit()\nslr.summary()\nslr.rsquared\n\n\n0.16074430690746544\n\n\n\natemp explains about 16% of the variability in cnt\natemp has a coefficient of 423.1802. For every unit increase in atemp the cnt increases by 423.1802 all other variables held constant"
  }
]